<!DOCTYPE html><html lang="en">
  <head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-59JLR64');</script>
<!-- End Google Tag Manager --><title>Annotators</title><meta property="og:title" content=""/>

<meta name="description" content="High Performance NLP with Apache Spark
">
<link rel="canonical" href="/docs/en/annotators"><link rel="alternate" type="application/rss+xml" title="Spark NLP" href="/feed.xml"><!-- start favicons snippet, use https://realfavicongenerator.net/ -->
<!---->
<!-- <link rel="apple-touch-icon" sizes="180x180" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="32x32" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="16x16" href="/fav.ico"> -->

<!---->
<!-- <link rel="manifest" href="/fav.ico"> --><link rel="mask-icon" href="/fav.ico" color="#fc4d50"><link rel="shortcut icon" href="/fav.ico">

<meta name="msapplication-TileColor" content="#ffc40d"><meta name="msapplication-config" content="/assets/browserconfig.xml">

<meta name="theme-color" content="#ffffff">
<!-- end favicons snippet --><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" >
<link rel="stylesheet" href="/static/models.css" /><!-- start custom head snippets -->
 <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800&display=swap" rel="stylesheet"> 
 <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
<!-- end custom head snippets -->
<script>(function() {
  window.isArray = function(val) {
    return Object.prototype.toString.call(val) === '[object Array]';
  };
  window.isString = function(val) {
    return typeof val === 'string';
  };

  window.decodeUrl = function(str) {
    return str ? decodeURIComponent(str.replace(/\+/g, '%20')) : '';
  };

  window.hasEvent = function(event) {
    return 'on'.concat(event) in window.document;
  };

  window.isOverallScroller = function(node) {
    return node === document.documentElement || node === document.body || node === window;
  };

  window.isFormElement = function(node) {
    var tagName = node.tagName;
    return tagName === 'INPUT' || tagName === 'SELECT' || tagName === 'TEXTAREA';
  };

  window.pageLoad = (function () {
    var loaded = false, cbs = [];
    window.addEventListener('load', function () {
      var i;
      loaded = true;
      if (cbs.length > 0) {
        for (i = 0; i < cbs.length; i++) {
          cbs[i]();
        }
      }
    });
    return {
      then: function(cb) {
        cb && (loaded ? cb() : (cbs.push(cb)));
      }
    };
  })();
})();
(function() {
  window.throttle = function(func, wait) {
    var args, result, thisArg, timeoutId, lastCalled = 0;

    function trailingCall() {
      lastCalled = new Date;
      timeoutId = null;
      result = func.apply(thisArg, args);
    }
    return function() {
      var now = new Date,
        remaining = wait - (now - lastCalled);

      args = arguments;
      thisArg = this;

      if (remaining <= 0) {
        clearTimeout(timeoutId);
        timeoutId = null;
        lastCalled = now;
        result = func.apply(thisArg, args);
      } else if (!timeoutId) {
        timeoutId = setTimeout(trailingCall, remaining);
      }
      return result;
    };
  };
})();
(function() {
  var Set = (function() {
    var add = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (data[i] === item) {
          return;
        }
      }
      this.size ++;
      data.push(item);
      return data;
    };

    var Set = function(data) {
      this.size = 0;
      this._data = [];
      var i;
      if (data.length > 0) {
        for (i = 0; i < data.length; i++) {
          add.call(this, data[i]);
        }
      }
    };
    Set.prototype.add = add;
    Set.prototype.get = function(index) { return this._data[index]; };
    Set.prototype.has = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (this.get(i) === item) {
          return true;
        }
      }
      return false;
    };
    Set.prototype.is = function(map) {
      if (map._data.length !== this._data.length) { return false; }
      var i, j, flag, tData = this._data, mData = map._data;
      for (i = 0; i < tData.length; i++) {
        for (flag = false, j = 0; j < mData.length; j++) {
          if (tData[i] === mData[j]) {
            flag = true;
            break;
          }
        }
        if (!flag) { return false; }
      }
      return true;
    };
    Set.prototype.values = function() {
      return this._data;
    };
    return Set;
  })();

  window.Lazyload = (function(doc) {
    var queue = {js: [], css: []}, sources = {js: {}, css: {}}, context = this;
    var createNode = function(name, attrs) {
      var node = doc.createElement(name), attr;
      for (attr in attrs) {
        if (attrs.hasOwnProperty(attr)) {
          node.setAttribute(attr, attrs[attr]);
        }
      }
      return node;
    };
    var end = function(type, url) {
      var s, q, qi, cbs, i, j, cur, val, flag;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        s[url] = true;
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (cur.urls.has(url)) {
            qi = cur, val = qi.urls.values();
            qi && (cbs = qi.callbacks);
            for (flag = true, j = 0; j < val.length; j++) {
              cur = val[j];
              if (!s[cur]) {
                flag = false;
              }
            }
            if (flag && cbs && cbs.length > 0) {
              for (j = 0; j < cbs.length; j++) {
                cbs[j].call(context);
              }
              qi.load = true;
            }
          }
        }
      }
    };
    var load = function(type, urls, callback) {
      var s, q, qi, node, i, cur,
        _urls = typeof urls === 'string' ? new Set([urls]) : new Set(urls), val, url;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (_urls.is(cur.urls)) {
            qi = cur;
            break;
          }
        }
        val = _urls.values();
        if (qi) {
          callback && (qi.load || qi.callbacks.push(callback));
          callback && (qi.load && callback());
        } else {
          q.push({
            urls: _urls,
            callbacks: callback ? [callback] : [],
            load: false
          });
          for (i = 0; i < val.length; i++) {
            node = null, url = val[i];
            if (s[url] === undefined) {
              (type === 'js' ) && (node = createNode('script', { src: url }));
              (type === 'css') && (node = createNode('link', { rel: 'stylesheet', href: url }));
              if (node) {
                node.onload = (function(type, url) {
                  return function() {
                    end(type, url);
                  };
                })(type, url);
                (doc.head || doc.body).appendChild(node);
                s[url] = false;
              }
            }
          }
        }
      }
    };
    return {
      js: function(url, callback) {
        load('js', url, callback);
      },
      css: function(url, callback) {
        load('css', url, callback);
      }
    };
  })(this.document);
})();
</script><script>
  (function() {
    var TEXT_VARIABLES = {
      version: '2.2.4',
      sources: {
        font_awesome: 'https://use.fontawesome.com/releases/v5.0.13/css/all.css',
        jquery: 'https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js',
        leancloud_js_sdk: '//cdn1.lncld.net/static/js/3.4.1/av-min.js',
        chart: 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js',
        gitalk: {
          js: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.js',
          css: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.css'
        },
        valine: 'https://unpkg.com/valine/dist/Valine.min.js',
        mathjax: 'https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML',
        mermaid: 'https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js'
      },
      site: {
        toc: {
          selectors: 'h1,h2,h3'
        }
      },
      paths: {
        search_js: '/assets/search.js'
      }
    };
    window.TEXT_VARIABLES = TEXT_VARIABLES;
  })();
</script></head>
  <body>
    <div class="root" data-is-touch="false">
      <div class="layout--page layout--page--sidebar clearfix js-page-root&nbsp; layout--page--aside">
  <div class="page__mask d-print-none js-page-mask js-sidebar-hide"></div>
  <div class="page__viewport">
    <div class="page__actions d-print-none">
      <div class="js-sidebar-show">
        <i class="fas fa-bars icon--show"></i>
      </div>
    </div>

    <div class="grid page__grid">

      <div class="page__sidebar d-print-none"><a title="High Performance NLP with Apache Spark
" href="/">
    <!--<svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
-->
</a><div class="sidebar-toc"><ul class="toc toc--navigator"><li class="toc-h1">Spark NLP</li><li class="toc-h2"><a href="/docs/en/quickstart">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/install">Install Spark NLP</a></li><li class="toc-h2"><a href="/docs/en/concepts">General Concepts</a></li><li class="toc-h2 active"><a href="/docs/en/annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/transformers">Transformers</a></li><li class="toc-h2"><a href="/docs/en/training">Training</a></li><li class="toc-h2"><a href="/docs/en/display">Spark NLP Display</a></li><li class="toc-h2"><a href="/docs/en/mlflow">Experiment Tracking</a></li><li class="toc-h2"><a href="/docs/en/serving_spark_nlp_via_api_databricks_mlflow">Serving Spark NLP&#58 MLFlow on Databricks</a></li><li class="toc-h2"><a href="/docs/en/hardware_acceleration">Hardware Acceleration</a></li><li class="toc-h2"><a href="/docs/en/CPUvsGPUbenchmark">GPU vs CPU Training</a></li><li class="toc-h2"><a href="/docs/en/auxiliary">Helpers</a></li><li class="toc-h2"><a href="/api/">Scala API (Scaladoc)</a></li><li class="toc-h2"><a href="/api/python/">Python API (Sphinx)</a></li><li class="toc-h2"><a href="/docs/en/developers">Developers</a></li><li class="toc-h2"><a href="/docs/en/third-party-projects">Third Party Projects</a></li><li class="toc-h2"><a href="/docs/en/release_notes">Release Notes</a></li></ul></div></div><div class="page__main js-page-main has-aside cell cell--auto">

      <div class="page__main-inner"><div class="page__header d-print-none"><!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-59JLR64"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) --><header class="header"><div class="main">
      <div class="header__title">
        <a class="responsive_btn" href="#" id="responsive_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
        <div class="header__brand">
          <a title="High Performance NLP with Apache Spark
" href="https://www.johnsnowlabs.com" target="_blank"><svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
</a><!---->
            <!-- <a title="High Performance NLP with Apache Spark
" href="/">Spark NLP</a> -->
          <!---->
        </div></div><nav class="navigation top_navigation">
        <ul class="top-menu"><li class="navigation__item "><a href="/">Home</a></li><li class="navigation__item navigation__item--active"><a href="/docs">Docs</a></li><li class="navigation__item "><a href="/learn">Learn</a></li><li class="navigation__item "><a href="/models">Models</a></li><li class="navigation__item "><a href="/demos">Demo</a></li><li class="navigation__item "><a href="https://github.com/JohnSnowLabs/spark-nlp"><span style="color: #FF8A00;"><i class = "fab fa-github fa-2x"></i></span></a></li><li class="navigation__item "><a href="https://www.johnsnowlabs.com/slack-redirect/"><span style="color: #FF8A00;"><i class="fab fa-slack-hash fa-2x"></i></span></a></li></ul>
      </nav><a class="responsive_btn" href="#" id="aside_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
    </div>
  </header>
</div><div class="page__content "><div class ="main"><div class="grid grid--reverse">

              <div class="col-aside d-print-none js-col-aside"><aside class="page__aside js-page-aside"><div class="toc-aside js-toc-root"></div></aside></div>

              <div class="col-main cell cell--auto"><!-- start custom main top snippet -->

<!-- end custom main top snippet --><article itemscope itemtype="http://schema.org/Article"><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script><div class="article__header"><div class="header-nav"><div class="main-docs">
  <ul class="breadcrambs">
    <li><a href="/docs">Documentation</a></li>
    <li>Annotators</li>
  </ul>
</div></div><header class="main-docs have_subtitle">
          <h1>Annotators</h1><div class="top-subtitle mont"></div></header><span class="split-space">&nbsp;</span>
          <a class="edit-on-github"
            title="Edit on Github"
            href="https://github.com/johnsnowlabs/spark-nlp/tree/master/docs/en/annotators.md">
            <i class="far fa-edit"></i></a></div><meta itemprop="headline" content="Annotators"><meta itemprop="author" content=""/><div class="js-article-content"><div class="docs-wrapper">
<div class="layout--article"><!-- start custom article top snippet -->

<!-- end custom article top snippet --><div class="article__content" itemprop="articleBody"><div class="h3-box">

  <h2 id="how-to-read-this-section">How to read this section</h2>

  <p>All annotators in Spark NLP share a common interface, this is:</p>

  <ul>
    <li><strong>Annotation</strong>: <code class="language-plaintext highlighter-rouge">Annotation(annotatorType, begin, end, result, meta-data,
embeddings)</code></li>
    <li><strong>AnnotatorType</strong>: some annotators share a type. This is not only
figurative, but also tells about the structure of the <code class="language-plaintext highlighter-rouge">metadata</code> map in
the Annotation. This is the one referred in the input and output of
annotators.</li>
    <li><strong>Inputs</strong>: Represents how many and which annotator types are expected
in <code class="language-plaintext highlighter-rouge">setInputCols()</code>. These are column names of output of other annotators
in the DataFrames.</li>
    <li><strong>Output</strong> Represents the type of the output in the column
<code class="language-plaintext highlighter-rouge">setOutputCol()</code>.</li>
  </ul>

  <p>There are two types of Annotators:</p>

  <ul>
    <li><strong>Approach</strong>: AnnotatorApproach extend Estimators, which are meant to be trained through <code class="language-plaintext highlighter-rouge">fit()</code></li>
    <li><strong>Model</strong>: AnnotatorModel extend from Transformers, which are meant to transform DataFrames through <code class="language-plaintext highlighter-rouge">transform()</code></li>
  </ul>

  <blockquote>
    <p><strong><code class="language-plaintext highlighter-rouge">Model</code></strong> suffix is explicitly stated when the annotator is the result of a training process. Some annotators, such as <strong><em>Tokenizer</em></strong> are transformers, but do not contain the word Model since they are not trained annotators.</p>
  </blockquote>

  <p><code class="language-plaintext highlighter-rouge">Model</code> annotators have a <code class="language-plaintext highlighter-rouge">pretrained()</code> on it’s static object, to retrieve the public pre-trained version of a model.</p>

  <ul>
    <li><code class="language-plaintext highlighter-rouge">pretrained(name, language, extra_location)</code> -&gt; by default, pre-trained will bring a default model, sometimes we offer more than one model, in this case, you may have to use name, language or extra location to download them.</li>
  </ul>

  <h2 id="available-annotators">Available Annotators</h2>

  <table class="table-model-big">
    <thead>
      <tr>
        <th>Annotator</th>
        <th>Description</th>
        <th>Version</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a href="#bigtextmatcher">BigTextMatcher</a></td>
        <td>Annotator to match exact phrases (by token) provided in a file against a Document.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#chunk2doc">Chunk2Doc</a></td>
        <td>Converts a <code class="language-plaintext highlighter-rouge">CHUNK</code> type column back into <code class="language-plaintext highlighter-rouge">DOCUMENT</code>. Useful when trying to re-tokenize or do further analysis on a <code class="language-plaintext highlighter-rouge">CHUNK</code> result.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#chunkembeddings">ChunkEmbeddings</a></td>
        <td>This annotator utilizes WordEmbeddings, BertEmbeddings etc. to generate chunk embeddings from either Chunker, NGramGenerator, or NerConverter outputs.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#chunktokenizer">ChunkTokenizer</a></td>
        <td>Tokenizes and flattens extracted NER chunks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#chunker">Chunker</a></td>
        <td>This annotator matches a pattern of part-of-speech tags in order to return meaningful phrases from document.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#classifierdl">ClassifierDL</a></td>
        <td>ClassifierDL for generic Multi-class Text Classification.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#contextspellchecker">ContextSpellChecker</a></td>
        <td>Implements a deep-learning based Noisy Channel Model Spell Algorithm.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#datematcher">DateMatcher</a></td>
        <td>Matches standard date formats into a provided format.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#dependencyparser">DependencyParser</a></td>
        <td>Unlabeled parser that finds a grammatical relation between two words in a sentence.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#doc2chunk">Doc2Chunk</a></td>
        <td>Converts <code class="language-plaintext highlighter-rouge">DOCUMENT</code> type annotations into <code class="language-plaintext highlighter-rouge">CHUNK</code> type with the contents of a <code class="language-plaintext highlighter-rouge">chunkCol</code>.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#doc2vec">Doc2Vec</a></td>
        <td>Word2Vec model that creates vector representations of words in a text corpus.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#documentassembler">DocumentAssembler</a></td>
        <td>Prepares data into a format that is processable by Spark NLP. This is the entry point for every Spark NLP pipeline.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#documentnormalizer">DocumentNormalizer</a></td>
        <td>Annotator which normalizes raw text from tagged text, e.g. scraped web pages or xml documents, from document type columns into Sentence.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#entityruler">EntityRuler</a></td>
        <td>Fits an Annotator to match exact strings or regex patterns provided in a file against a Document and assigns them an named entity.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#embeddingsfinisher">EmbeddingsFinisher</a></td>
        <td>Extracts embeddings from Annotations into a more easily usable form.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#finisher">Finisher</a></td>
        <td>Converts annotation results into a format that easier to use. It is useful to extract the results from Spark NLP Pipelines.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#graphextraction">GraphExtraction</a></td>
        <td>Extracts a dependency graph between entities.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#graphfinisher">GraphFinisher</a></td>
        <td>Helper class to convert the knowledge graph from GraphExtraction into a generic format, such as RDF.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#imageassembler">ImageAssembler</a></td>
        <td>Prepares images read by Spark into a format that is processable by Spark NLP.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#languagedetectordl">LanguageDetectorDL</a></td>
        <td>Language Identification and Detection by using CNN and RNN architectures in TensorFlow.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#lemmatizer">Lemmatizer</a></td>
        <td>Finds lemmas out of words with the objective of returning a base dictionary word.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#multiclassifierdl">MultiClassifierDL</a></td>
        <td>Multi-label Text Classification.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#multidatematcher">MultiDateMatcher</a></td>
        <td>Matches standard date formats into a provided format.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#multidocumentassembler">MultiDocumentAssembler</a></td>
        <td>Prepares data into a format that is processable by Spark NLP.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#ngramgenerator">NGramGenerator</a></td>
        <td>A feature transformer that converts the input array of strings (annotatorType TOKEN) into an array of n-grams (annotatorType CHUNK).</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#nerconverter">NerConverter</a></td>
        <td>Converts a IOB or IOB2 representation of NER to a user-friendly one, by associating the tokens of recognized entities and their label.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#nercrf">NerCrf</a></td>
        <td>Extracts Named Entities based on a CRF Model.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#nerdl">NerDL</a></td>
        <td>This Named Entity recognition annotator is a generic NER model based on Neural Networks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#neroverwriter">NerOverwriter</a></td>
        <td>Overwrites entities of specified strings.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#normalizer">Normalizer</a></td>
        <td>Removes all dirty characters from text following a regex pattern and transforms words based on a provided dictionary.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#norvigsweeting-spellchecker">NorvigSweeting Spellchecker</a></td>
        <td>Retrieves tokens and makes corrections automatically if not found in an English dictionary.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#postagger-part-of-speech-tagger">POSTagger (Part of speech tagger)</a></td>
        <td>Averaged Perceptron model to tag words part-of-speech.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#recursivetokenizer">RecursiveTokenizer</a></td>
        <td>Tokenizes raw text recursively based on a handful of definable rules.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#regexmatcher">RegexMatcher</a></td>
        <td>Uses rules to match a set of regular expressions and associate them with a provided identifier.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#regextokenizer">RegexTokenizer</a></td>
        <td>A tokenizer that splits text by a regex pattern.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#sentencedetector">SentenceDetector</a></td>
        <td>Annotator that detects sentence boundaries using regular expressions.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#sentencedetectordl">SentenceDetectorDL</a></td>
        <td>Detects sentence boundaries using a deep learning approach.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#sentenceembeddings">SentenceEmbeddings</a></td>
        <td>Converts the results from WordEmbeddings, BertEmbeddings, or ElmoEmbeddings into sentence or document embeddings by either summing up or averaging all the word embeddings in a sentence or a document (depending on the inputCols).</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#sentimentdl">SentimentDL</a></td>
        <td>Annotator for multi-class sentiment analysis.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#sentimentdetector">SentimentDetector</a></td>
        <td>Rule based sentiment detector, which calculates a score based on predefined keywords.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#stemmer">Stemmer</a></td>
        <td>Returns hard-stems out of words with the objective of retrieving the meaningful part of the word.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#stopwordscleaner">StopWordsCleaner</a></td>
        <td>This annotator takes a sequence of strings (e.g. the output of a Tokenizer, Normalizer, Lemmatizer, and Stemmer) and drops all the stop words from the input sequences.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#symmetricdelete-spellchecker">SymmetricDelete Spellchecker</a></td>
        <td>Symmetric Delete spelling correction algorithm.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#textmatcher">TextMatcher</a></td>
        <td>Matches exact phrases (by token) provided in a file against a Document.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#token2chunk">Token2Chunk</a></td>
        <td>Converts <code class="language-plaintext highlighter-rouge">TOKEN</code> type Annotations to <code class="language-plaintext highlighter-rouge">CHUNK</code> type.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#tokenassembler">TokenAssembler</a></td>
        <td>This transformer reconstructs a DOCUMENT type annotation from tokens, usually after these have been normalized, lemmatized, normalized, spell checked, etc, in order to use this document annotation in further annotators.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#tokenizer">Tokenizer</a></td>
        <td>Tokenizes raw text into word pieces, tokens. Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#typeddependencyparser">TypedDependencyParser</a></td>
        <td>Labeled parser that finds a grammatical relation between two words in a sentence.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#viveknsentiment">ViveknSentiment</a></td>
        <td>Sentiment analyser inspired by the algorithm by Vivek Narayanan.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#wordembeddings">WordEmbeddings</a></td>
        <td>Word Embeddings lookup annotator that maps tokens to vectors.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#word2vec">Word2Vec</a></td>
        <td>Word2Vec model that creates vector representations of words in a text corpus.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#wordsegmenter">WordSegmenter</a></td>
        <td>Tokenizes non-english or non-whitespace separated texts.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="#yakekeywordextraction">YakeKeywordExtraction</a></td>
        <td>Unsupervised, Corpus-Independent, Domain and Language-Independent and Single-Document keyword extraction.</td>
        <td>Opensource</td>
      </tr>
    </tbody>
  </table>

  <h2 id="available-transformers">Available Transformers</h2>
  <p>Additionally, these transformers are available to generate embeddings.</p>

  <table class="table-model-big">
    <thead>
      <tr>
        <th>Transformer</th>
        <th>Description</th>
        <th>Version</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a href="./transformers#albertembeddings">AlbertEmbeddings</a></td>
        <td>ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#albertforquestionanswering">AlbertForQuestionAnswering</a></td>
        <td>AlbertForQuestionAnswering can load ALBERT Models with a span classification head on top for extractive question-answering tasks like SQuAD.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#albertfortokenclassification">AlbertForTokenClassification</a></td>
        <td>AlbertForTokenClassification can load ALBERT Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#albertforsequenceclassification">AlbertForSequenceClassification</a></td>
        <td>AlbertForSequenceClassification can load ALBERT Models with sequence classification/regression head on top e.g. for multi-class document classification tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#bertembeddings">BertEmbeddings</a></td>
        <td>Token-level embeddings using BERT. BERT (Bidirectional Encoder Representations from Transformers) provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#bertforquestionanswering">BertForQuestionAnswering</a></td>
        <td>BertForQuestionAnswering can load Bert Models with a span classification head on top for extractive question-answering tasks like SQuAD.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#bertforsequenceclassification">BertForSequenceClassification</a></td>
        <td>Bert Models with sequence classification/regression head on top.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#bertfortokenclassification">BertForTokenClassification</a></td>
        <td>BertForTokenClassification can load Bert Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#bertsentenceembeddings">BertSentenceEmbeddings</a></td>
        <td>Sentence-level embeddings using BERT. BERT (Bidirectional Encoder Representations from Transformers) provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#camembertembeddings">CamemBertEmbeddings</a></td>
        <td>CamemBert is based on Facebook’s RoBERTa model released in 2019.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#camembertforsequenceclassification">CamemBertForSequenceClassification</a></td>
        <td>amemBertForSequenceClassification can load CamemBERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#camembertfortokenclassification">CamemBertForTokenClassification</a></td>
        <td>CamemBertForTokenClassification can load CamemBERT Models with a token classification head on top</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#debertaembeddings">DeBertaEmbeddings</a></td>
        <td>DeBERTa builds on RoBERTa with disentangled attention and enhanced mask decoder training with half of the data used in RoBERTa.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#debertaforquestionanswering">DeBertaForQuestionAnswering</a></td>
        <td>DeBertaForQuestionAnswering can load DeBERTa Models with a span classification head on top for extractive question-answering tasks like SQuAD.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#distilbertembeddings">DistilBertEmbeddings</a></td>
        <td>DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#distilbertforquestionanswering">DistilBertForQuestionAnswering</a></td>
        <td>DistilBertForQuestionAnswering can load DistilBert Models with a span classification head on top for extractive question-answering tasks like SQuAD.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#distilbertforsequenceclassification">DistilBertForSequenceClassification</a></td>
        <td>DistilBertForSequenceClassification can load DistilBERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#distilbertfortokenclassification">DistilBertForTokenClassification</a></td>
        <td>DistilBertForTokenClassification can load DistilBERT Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#elmoembeddings">ElmoEmbeddings</a></td>
        <td>Word embeddings from ELMo (Embeddings from Language Models), a language model trained on the 1 Billion Word Benchmark.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#gpt2transformer">GPT2Transformer</a></td>
        <td>GPT-2 is a large transformer-based language model with 1.5 billion parameters, trained on a dataset of 8 million web pages.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#longformerembeddings">LongformerEmbeddings</a></td>
        <td>Longformer is a BERT-like model started from the RoBERTa checkpoint and pretrained for MLM on long documents.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#longformerforquestionanswering">LongformerForQuestionAnswering</a></td>
        <td>LongformerForQuestionAnswering can load Longformer Models with a span classification head on top for extractive question-answering tasks like SQuAD.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#longformerforsequenceclassification">LongformerForSequenceClassification</a></td>
        <td>LongformerForSequenceClassification can load Longformer Models with sequence classification/regression head on top e.g. for multi-class document classification tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#longformerfortokenclassification">LongformerForTokenClassification</a></td>
        <td>LongformerForTokenClassification can load Longformer Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#mariantransformer">MarianTransformer</a></td>
        <td>Marian is an efficient, free Neural Machine Translation framework written in pure C++ with minimal dependencies.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#robertaembeddings">RoBertaEmbeddings</a></td>
        <td>RoBERTa: A Robustly Optimized BERT Pretraining Approach</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#robertaforquestionanswering">RoBertaForQuestionAnswering</a></td>
        <td>RoBertaForQuestionAnswering can load RoBERTa Models with a span classification head on top for extractive question-answering tasks like SQuAD.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#robertaforsequenceclassification">RoBertaForSequenceClassification</a></td>
        <td>RoBertaForSequenceClassification can load RoBERTa Models with sequence classification/regression head on top e.g. for multi-class document classification tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#robertafortokenclassification">RoBertaForTokenClassification</a></td>
        <td>RoBertaForTokenClassification can load RoBERTa Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#robertasentenceembeddings">RoBertaSentenceEmbeddings</a></td>
        <td>Sentence-level embeddings using RoBERTa.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#spanbertcoref">SpanBertCoref</a></td>
        <td>A coreference resolution model based on SpanBert.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#t5transformer">T5Transformer</a></td>
        <td>T5 reconsiders all NLP tasks into a unified text-to-text-format where the input and output are always text strings, in contrast to BERT-style models that can only output either a class label or a span of the input.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#tapasforquestionanswering">TapasForQuestionAnswering</a></td>
        <td>TapasForQuestionAnswering is an implementation of TaPas - a BERT-based model specifically designed for answering questions about tabular data.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#universalsentenceencoder">UniversalSentenceEncoder</a></td>
        <td>The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#vitforimageclassification">ViTForImageClassification</a></td>
        <td>Vision Transformer (ViT) for image classification.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#wav2vec2forctc">Wav2Vec2ForCTC</a></td>
        <td>Wav2Vec2 Model with a language modeling head on top for Connectionist Temporal Classification (CTC).</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#xlmrobertaembeddings">XlmRoBertaEmbeddings</a></td>
        <td>XlmRoBerta is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#xlmrobertaforquestionanswering">XlmRoBertaForQuestionAnswering</a></td>
        <td>XlmRoBertaForQuestionAnswering can load XLM-RoBERTa Models with a span classification head on top for extractive question-answering tasks like SQuAD.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#xlmrobertaforsequenceclassification">XlmRoBertaForSequenceClassification</a></td>
        <td>XlmRoBertaForSequenceClassification can load XLM-RoBERTa Models with sequence classification/regression head on top e.g. for multi-class document classification tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#xlmrobertafortokenclassification">XlmRoBertaForTokenClassification</a></td>
        <td>XlmRoBertaForTokenClassification can load XLM-RoBERTa Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#xlmrobertasentenceembeddings">XlmRoBertaSentenceEmbeddings</a></td>
        <td>Sentence-level embeddings using XLM-RoBERTa.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#xlnetembeddings">XlnetEmbeddings</a></td>
        <td>XLNet is a new unsupervised language representation learning method based on a novel generalized permutation language modeling objective.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#xlnetfortokenclassification">XlnetForTokenClassification</a></td>
        <td>XlnetForTokenClassification can load XLNet Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.</td>
        <td>Opensource</td>
      </tr>
      <tr>
        <td><a href="./transformers#xlnetforsequenceclassification">XlnetForSequenceClassification</a></td>
        <td>XlnetForSequenceClassification can load XLNet Models with sequence classification/regression head on top e.g. for multi-class document classification tasks.</td>
        <td>Opensource</td>
      </tr>
    </tbody>
  </table>

</div>

<script> jQuery(document).ready(function () {
    $(".model-button").click(function () {
        $(this).closest(".tabs-box").find(".model-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        //remove  active class from all other buttons
        $(this).closest(".tabs-box").find(".approach-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".h3-box.approach-content").hide()
        $(this.parentNode).siblings(".h3-box.model-content").show()
    });

    $(".approach-button").click(function () {
        //set current button to active class and remove unactive class
        $(this).closest(".tabs-box").find(".approach-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        //remove  active class from all other buttons
        $(this).closest(".tabs-box").find(".model-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".h3-box.model-content").hide()
        $(this.parentNode).siblings(".h3-box.approach-content").show()
    });
});
 </script>

<div class="tabs-box tabs-new">

  <h2 id="bigtextmatcher">BigTextMatcher</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Annotator to match exact phrases (by token) provided in a file against a Document.</p>

    <p>A text file of predefined phrases must be provided with <code class="language-plaintext highlighter-rouge">setStoragePath</code>.</p>

    <p>In contrast to the normal <code class="language-plaintext highlighter-rouge">TextMatcher</code>, the <code class="language-plaintext highlighter-rouge">BigTextMatcher</code> is designed for large corpora.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherTestSpec.scala">BigTextMatcherTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index.html#sparknlp.annotator.matcher.big_text_matcher.BigTextMatcher">BigTextMatcher</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcher">BigTextMatcher</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcher.scala">BigTextMatcher</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># In this example, the entities file is of the form
#
# ...
# dolore magna aliqua
# lorem ipsum dolor. sit
# laborum
# ...
#
# where each line represents an entity phrase to be extracted.
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Hello dolore magna aliqua. Lorem ipsum dolor. sit in laborum"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">entityExtractor</span> <span class="o">=</span> <span class="n">BigTextMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStoragePath</span><span class="p">(</span><span class="s">"src/test/resources/entity-extractor/test-phrases.txt"</span><span class="p">,</span> <span class="n">ReadAs</span><span class="p">.</span><span class="n">TEXT</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">entityExtractor</span><span class="p">])</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(entity)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                 <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="n">dolore</span> <span class="n">magna</span> <span class="n">aliqua</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span> <span class="mi">59</span><span class="p">,</span> <span class="n">laborum</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[]]</span>           <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the entities file is of the form</span>
<span class="c1">//</span>
<span class="c1">// ...</span>
<span class="c1">// dolore magna aliqua</span>
<span class="c1">// lorem ipsum dolor. sit</span>
<span class="c1">// laborum</span>
<span class="c1">// ...</span>
<span class="c1">//</span>
<span class="c1">// where each line represents an entity phrase to be extracted.</span>
<span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.BigTextMatcher</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.util.io.ReadAs</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Hello dolore magna aliqua. Lorem ipsum dolor. sit in laborum"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">entityExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">BigTextMatcher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStoragePath</span><span class="o">(</span><span class="s">"src/test/resources/entity-extractor/test-phrases.txt"</span><span class="o">,</span> <span class="nv">ReadAs</span><span class="o">.</span><span class="py">TEXT</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">tokenizer</span><span class="o">,</span> <span class="n">entityExtractor</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="nv">results</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(entity)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                 <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">6</span>, <span class="err">24</span>, <span class="kt">dolore</span> <span class="kt">magna</span> <span class="kt">aliqua</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">53</span>, <span class="err">59</span>, <span class="kt">laborum</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">1</span><span class="o">]</span>, <span class="o">[]]</span>           <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Instantiated model of the BigTextMatcher.
For usage and examples see the documentation of the main class.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/matcher/big_text_matcher/index.html#sparknlp.annotator.matcher.big_text_matcher.BigTextMatcherModel">BigTextMatcherModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherModel">BigTextMatcherModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/btm/BigTextMatcherModel.scala">BigTextMatcherModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="chunk2doc">Chunk2Doc</h2>

  <p>Converts a <code class="language-plaintext highlighter-rouge">CHUNK</code> type column back into <code class="language-plaintext highlighter-rouge">DOCUMENT</code>. Useful when trying to re-tokenize or do further analysis on a
<code class="language-plaintext highlighter-rouge">CHUNK</code> result.</p>

  <p>For more extended examples on document pre-processing see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/base/chunk2_doc/index.html#sparknlp.base.chunk2_doc.Chunk2Doc">Chunk2Doc</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/Chunk2Doc">Chunk2Doc</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/Chunk2Doc.scala">Chunk2Doc</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">PretrainedPipeline</span>
<span class="c1"># Location entities are extracted and converted back into `DOCUMENT` type for further processing
</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="s">"New York and New Jersey aren't that far apart actually."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"id"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">)</span>

<span class="c1"># Extracts Named Entities amongst other things
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">PretrainedPipeline</span><span class="p">(</span><span class="s">"explain_document_dl"</span><span class="p">)</span>

<span class="n">chunkToDoc</span> <span class="o">=</span> <span class="n">Chunk2Doc</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"entities"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunkConverted"</span><span class="p">)</span>
<span class="n">explainResult</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">chunkToDoc</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">explainResult</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(chunkConverted)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                           <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">New</span> <span class="n">York</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">LOC</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span>    <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="n">New</span> <span class="n">Jersey</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">LOC</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Location entities are extracted and converted back into `DOCUMENT` type for further processing</span>
<span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.pretrained.PretrainedPipeline</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.Chunk2Doc</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="s">"New York and New Jersey aren't that far apart actually."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"id"</span><span class="o">,</span> <span class="s">"text"</span><span class="o">)</span>

<span class="c1">// Extracts Named Entities amongst other things</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="nc">PretrainedPipeline</span><span class="o">(</span><span class="s">"explain_document_dl"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkToDoc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunk2Doc</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"entities"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunkConverted"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">explainResult</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">chunkToDoc</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">explainResult</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(chunkConverted)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                           <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">7</span>, <span class="kt">New</span> <span class="kt">York</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">LOC</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]</span>    <span class="o">|</span>
<span class="o">|[</span><span class="kt">document</span>, <span class="err">13</span>, <span class="err">22</span>, <span class="kt">New</span> <span class="kt">Jersey</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">LOC</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">1</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">+------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="chunkembeddings">ChunkEmbeddings</h2>

  <p>This annotator utilizes WordEmbeddings, BertEmbeddings etc. to generate chunk embeddings from either
<a href="/docs/en/annotators#chunker">Chunker</a>, <a href="/docs/en/annotators#ngramgenerator">NGramGenerator</a>,
or <a href="/docs/en/annotators#nerconverter">NerConverter</a> outputs.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddingsTestSpec.scala">ChunkEmbeddingsTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, WORD_EMBEDDINGS</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/chunk_embeddings/index.html#sparknlp.annotator.embeddings.chunk_embeddings.ChunkEmbeddings">ChunkEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddings">ChunkEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/ChunkEmbeddings.scala">ChunkEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># Extract the Embeddings from the NGrams
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">nGrams</span> <span class="o">=</span> <span class="n">NGramGenerator</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setN</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Convert the NGram chunks into Word Embeddings
</span><span class="n">chunkEmbeddings</span> <span class="o">=</span> <span class="n">ChunkEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentence</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">nGrams</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">chunkEmbeddings</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(chunk_embeddings) as result"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"result.annotatorType"</span><span class="p">,</span> <span class="s">"result.result"</span><span class="p">,</span> <span class="s">"result.embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+---------------+----------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>  <span class="n">annotatorType</span><span class="o">|</span>    <span class="n">result</span><span class="o">|</span>                                                                      <span class="n">embeddings</span><span class="o">|</span>
<span class="o">+---------------+----------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">word_embeddings</span><span class="o">|</span>   <span class="n">This</span> <span class="ow">is</span><span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.55661</span><span class="p">,</span> <span class="mf">0.42829502</span><span class="p">,</span> <span class="mf">0.86661</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.409785</span><span class="p">,</span> <span class="mf">0.06316501</span><span class="p">,</span> <span class="mf">0.120775</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0732005</span><span class="p">,</span> <span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="n">word_embeddings</span><span class="o">|</span>      <span class="ow">is</span> <span class="n">a</span><span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.40674996</span><span class="p">,</span> <span class="mf">0.22938299</span><span class="p">,</span> <span class="mf">0.50597</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.288195</span><span class="p">,</span> <span class="mf">0.555655</span><span class="p">,</span> <span class="mf">0.465145</span><span class="p">,</span> <span class="mf">0.140118</span><span class="p">,</span> <span class="mf">0.</span><span class="p">..</span><span class="o">|</span>
<span class="o">|</span><span class="n">word_embeddings</span><span class="o">|</span><span class="n">a</span> <span class="n">sentence</span><span class="o">|</span><span class="p">[</span><span class="mf">0.17417</span><span class="p">,</span> <span class="mf">0.095253006</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0530925</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.218465</span><span class="p">,</span> <span class="mf">0.714395</span><span class="p">,</span> <span class="mf">0.79860497</span><span class="p">,</span> <span class="mf">0.0129999</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="n">word_embeddings</span><span class="o">|</span><span class="n">sentence</span> <span class="p">.</span><span class="o">|</span><span class="p">[</span><span class="mf">0.139705</span><span class="p">,</span> <span class="mf">0.177955</span><span class="p">,</span> <span class="mf">0.1887775</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.45545</span><span class="p">,</span> <span class="mf">0.20030999</span><span class="p">,</span> <span class="mf">0.461557</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07891501</span><span class="p">,</span> <span class="p">...</span><span class="o">|</span>
<span class="o">+---------------+----------+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.</span><span class="o">{</span><span class="nc">NGramGenerator</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.ChunkEmbeddings</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// Extract the Embeddings from the NGrams</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nGrams</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NGramGenerator</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// Convert the NGram chunks into Word Embeddings</span>
<span class="k">val</span> <span class="nv">chunkEmbeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"AVERAGE"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentence</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">nGrams</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">chunkEmbeddings</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(chunk_embeddings) as result"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"result.annotatorType"</span><span class="o">,</span> <span class="s">"result.result"</span><span class="o">,</span> <span class="s">"result.embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+---------------+----------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>  <span class="n">annotatorType</span><span class="o">|</span>    <span class="n">result</span><span class="o">|</span>                                                                      <span class="n">embeddings</span><span class="o">|</span>
<span class="o">+---------------+----------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">word_embeddings</span><span class="o">|</span>   <span class="nc">This</span> <span class="n">is</span><span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">55661</span>, <span class="err">0</span><span class="kt">.</span><span class="err">42829502</span>, <span class="err">0</span><span class="kt">.</span><span class="err">86661</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">409785</span>, <span class="err">0</span><span class="kt">.</span><span class="err">06316501</span>, <span class="err">0</span><span class="kt">.</span><span class="err">120775</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0732005</span>, <span class="kt">...|</span>
<span class="kt">|word_embeddings|</span>      <span class="kt">is</span> <span class="kt">a|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">40674996</span>, <span class="err">0</span><span class="kt">.</span><span class="err">22938299</span>, <span class="err">0</span><span class="kt">.</span><span class="err">50597</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">288195</span>, <span class="err">0</span><span class="kt">.</span><span class="err">555655</span>, <span class="err">0</span><span class="kt">.</span><span class="err">465145</span>, <span class="err">0</span><span class="kt">.</span><span class="err">140118</span>, <span class="err">0</span><span class="kt">...|</span>
<span class="kt">|word_embeddings|a</span> <span class="kt">sentence|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">17417</span>, <span class="err">0</span><span class="kt">.</span><span class="err">095253006</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0530925</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">218465</span>, <span class="err">0</span><span class="kt">.</span><span class="err">714395</span>, <span class="err">0</span><span class="kt">.</span><span class="err">79860497</span>, <span class="err">0</span><span class="kt">.</span><span class="err">0129999</span><span class="kt">...|</span>
<span class="kt">|word_embeddings|sentence</span> <span class="kt">.|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">139705</span>, <span class="err">0</span><span class="kt">.</span><span class="err">177955</span>, <span class="err">0</span><span class="kt">.</span><span class="err">1887775</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">45545</span>, <span class="err">0</span><span class="kt">.</span><span class="err">20030999</span>, <span class="err">0</span><span class="kt">.</span><span class="err">461557</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07891501</span>, <span class="kt">...|</span>
<span class="kt">+---------------+----------+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box tabs-new">

  <h2 id="chunktokenizer">ChunkTokenizer</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Tokenizes and flattens extracted NER chunks.</p>

    <p>The ChunkTokenizer will split the extracted NER <code class="language-plaintext highlighter-rouge">CHUNK</code> type Annotations and will create <code class="language-plaintext highlighter-rouge">TOKEN</code> type Annotations.
The result is then flattened, resulting in a single array.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/ChunkTokenizerTestSpec.scala">ChunkTokenizerTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index.html#sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizer">ChunkTokenizer</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizer">ChunkTokenizer</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ChunkTokenizer.scala">ChunkTokenizer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">entityExtractor</span> <span class="o">=</span> <span class="n">TextMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setEntities</span><span class="p">(</span><span class="s">"src/test/resources/entity-extractor/test-chunks.txt"</span><span class="p">,</span> <span class="n">ReadAs</span><span class="p">.</span><span class="n">TEXT</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span>

<span class="n">chunkTokenizer</span> <span class="o">=</span> <span class="n">ChunkTokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"entity"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk_token"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">entityExtractor</span><span class="p">,</span>
      <span class="n">chunkTokenizer</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span>
    <span class="s">"Hello world, my name is Michael, I am an artist and I work at Benezar"</span><span class="p">,</span>
    <span class="s">"Robert, an engineer from Farendell, graduated last year. The other one, Lucas, graduated last week."</span>
<span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"entity.result as entity"</span> <span class="p">,</span> <span class="s">"chunk_token.result as chunk_token"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------+---------------------------------------------------+</span>
<span class="o">|</span><span class="n">entity</span>                                         <span class="o">|</span><span class="n">chunk_token</span>                                        <span class="o">|</span>
<span class="o">+-----------------------------------------------+---------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">world</span><span class="p">,</span> <span class="n">Michael</span><span class="p">,</span> <span class="n">work</span> <span class="n">at</span> <span class="n">Benezar</span><span class="p">]</span>              <span class="o">|</span><span class="p">[</span><span class="n">world</span><span class="p">,</span> <span class="n">Michael</span><span class="p">,</span> <span class="n">work</span><span class="p">,</span> <span class="n">at</span><span class="p">,</span> <span class="n">Benezar</span><span class="p">]</span>                <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">engineer</span> <span class="k">from</span> <span class="n">Farendell</span><span class="p">,</span> <span class="n">last</span> <span class="n">year</span><span class="p">,</span> <span class="n">last</span> <span class="n">week</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">engineer</span><span class="p">,</span> <span class="k">from</span><span class="p">,</span> <span class="n">Farendell</span><span class="p">,</span> <span class="n">last</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">last</span><span class="p">,</span> <span class="n">week</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------+---------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.</span><span class="o">{</span><span class="nc">ChunkTokenizer</span><span class="o">,</span> <span class="nc">TextMatcher</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.util.io.ReadAs</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">entityExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextMatcher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEntities</span><span class="o">(</span><span class="s">"src/test/resources/entity-extractor/test-chunks.txt"</span><span class="o">,</span> <span class="nv">ReadAs</span><span class="o">.</span><span class="py">TEXT</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkTokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkTokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk_token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">entityExtractor</span><span class="o">,</span>
    <span class="n">chunkTokenizer</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Hello world, my name is Michael, I am an artist and I work at Benezar"</span><span class="o">,</span>
  <span class="s">"Robert, an engineer from Farendell, graduated last year. The other one, Lucas, graduated last week."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"entity.result as entity"</span> <span class="o">,</span> <span class="s">"chunk_token.result as chunk_token"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-----------------------------------------------+---------------------------------------------------+</span>
<span class="o">|</span><span class="n">entity</span>                                         <span class="o">|</span><span class="n">chunk_token</span>                                        <span class="o">|</span>
<span class="o">+-----------------------------------------------+---------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">world</span>, <span class="kt">Michael</span>, <span class="kt">work</span> <span class="kt">at</span> <span class="kt">Benezar</span><span class="o">]</span>              <span class="o">|[</span><span class="kt">world</span>, <span class="kt">Michael</span>, <span class="kt">work</span>, <span class="kt">at</span>, <span class="kt">Benezar</span><span class="o">]</span>                <span class="o">|</span>
<span class="o">|[</span><span class="kt">engineer</span> <span class="kt">from</span> <span class="kt">Farendell</span>, <span class="kt">last</span> <span class="kt">year</span>, <span class="kt">last</span> <span class="kt">week</span><span class="o">]|[</span><span class="kt">engineer</span>, <span class="kt">from</span>, <span class="kt">Farendell</span>, <span class="kt">last</span>, <span class="kt">year</span>, <span class="kt">last</span>, <span class="kt">week</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------+---------------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Instantiated model of the ChunkTokenizer.
For usage and examples see the documentation of the main class.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/token/chunk_tokenizer/index.html#sparknlp.annotator.token.chunk_tokenizer.ChunkTokenizerModel">ChunkTokenizerModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ChunkTokenizerModel">ChunkTokenizerModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ChunkTokenizerModel.scala">ChunkTokenizerModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="chunker">Chunker</h2>

  <p>This annotator matches a pattern of part-of-speech tags in order to return meaningful phrases from document.
Extracted part-of-speech tags are mapped onto the sentence, which can then be parsed by regular expressions.
The part-of-speech tags are wrapped by angle brackets <code class="language-plaintext highlighter-rouge">&lt;&gt;</code> to be easily distinguishable in the text itself.
This example sentence will result in the form:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"Peter Pipers employees are picking pecks of pickled peppers."
"&lt;NNP&gt;&lt;NNP&gt;&lt;NNS&gt;&lt;VBP&gt;&lt;VBG&gt;&lt;NNS&gt;&lt;IN&gt;&lt;JJ&gt;&lt;NNS&gt;&lt;.&gt;"
</code></pre></div>  </div>
  <p>To then extract these tags, <code class="language-plaintext highlighter-rouge">regexParsers</code> need to be set with e.g.:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val chunker = new Chunker()
  .setInputCols("sentence", "pos")
  .setOutputCol("chunk")
  .setRegexParsers(Array("&lt;NNP&gt;+", "&lt;NNS&gt;+"))
</code></pre></div>  </div>
  <p>When defining the regular expressions, tags enclosed in angle brackets are treated as groups, so here specifically
<code class="language-plaintext highlighter-rouge">"&lt;NNP&gt;+"</code> means 1 or more nouns in succession. Additional patterns can also be set with <code class="language-plaintext highlighter-rouge">addRegexParsers</code>.</p>

  <p>For more extended examples see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb">Spark NLP Workshop</a>)
and the  <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/ChunkerTestSpec.scala">ChunkerTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, POS</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/chunker/index.html#sparknlp.annotator.chunker.Chunker">Chunker</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/Chunker">Chunker</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Chunker.scala">Chunker</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">POSTag</span> <span class="o">=</span> <span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">chunker</span> <span class="o">=</span> <span class="n">Chunker</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"&lt;NNP&gt;+"</span><span class="p">,</span> <span class="s">"&lt;NNS&gt;+"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentence</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">POSTag</span><span class="p">,</span>
      <span class="n">chunker</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Peter Pipers employees are picking pecks of pickled peppers."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(chunk) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                       <span class="o">|</span>
<span class="o">+-------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">Peter</span> <span class="n">Pipers</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">employees</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[]]</span>  <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="n">pecks</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[]]</span>      <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">52</span><span class="p">,</span> <span class="mi">58</span><span class="p">,</span> <span class="n">peppers</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[]]</span>    <span class="o">|</span>
<span class="o">+-------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.</span><span class="o">{</span><span class="nc">Chunker</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">POSTag</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"&lt;NNP&gt;+"</span><span class="o">,</span> <span class="s">"&lt;NNS&gt;+"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentence</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="nc">POSTag</span><span class="o">,</span>
    <span class="n">chunker</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Peter Pipers employees are picking pecks of pickled peppers."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(chunk) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                       <span class="o">|</span>
<span class="o">+-------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">0</span>, <span class="err">11</span>, <span class="kt">Peter</span> <span class="kt">Pipers</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">13</span>, <span class="err">21</span>, <span class="kt">employees</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">1</span><span class="o">]</span>, <span class="o">[]]</span>  <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">35</span>, <span class="err">39</span>, <span class="kt">pecks</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">2</span><span class="o">]</span>, <span class="o">[]]</span>      <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">52</span>, <span class="err">58</span>, <span class="kt">peppers</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">3</span><span class="o">]</span>, <span class="o">[]]</span>    <span class="o">|</span>
<span class="o">+-------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box tabs-new">

  <h2 id="classifierdl">ClassifierDL</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a ClassifierDL for generic Multi-class Text Classification.</p>

    <p>ClassifierDL uses the state-of-the-art Universal Sentence Encoder as an input for text classifications.
The ClassifierDL annotator uses a deep learning model (DNNs) we have built inside TensorFlow and supports up to
100 classes.</p>

    <p>For instantiated/pretrained models, see ClassifierDLModel.</p>

    <p>Setting a test dataset to monitor model metrics can be done with <code class="language-plaintext highlighter-rouge">.setTestDataset</code>. The
method expects a path to a parquet file containing a dataframe that has the same
required columns as the training dataframe. The pre-processing steps for the training
dataframe should also be applied to the test dataframe. The following example will show
how to create the test dataset:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val documentAssembler = new DocumentAssembler()
  .setInputCol("text")
  .setOutputCol("document")

val embeddings = UniversalSentenceEncoder.pretrained()
  .setInputCols("document")
  .setOutputCol("sentence_embeddings")

val preProcessingPipeline = new Pipeline().setStages(Array(documentAssembler, embeddings))

val Array(train, test) = data.randomSplit(Array(0.8, 0.2))
preProcessingPipeline
  .fit(test)
  .transform(test)
  .write
  .mode("overwrite")
  .parquet("test_data")

val classifier = new ClassifierDLApproach()
  .setInputCols("sentence_embeddings")
  .setOutputCol("category")
  .setLabelColumn("label")
  .setTestDataset("test_data")
</code></pre></div>    </div>

    <p>For extended examples of usage, see the Spark NLP Workshop
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/scala/training/Train%20Multi-Class%20Text%20Classification%20on%20News%20Articles.scala">[1] </a>
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb">[2] </a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLTestSpec.scala">ClassifierDLTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <blockquote>
      <p><strong>Note:</strong> This annotator accepts a label column of a single item in either type of String, Int, Float, or Double. UniversalSentenceEncoder, BertSentenceEmbeddings, or SentenceEmbeddings can be used for the inputCol</p>
    </blockquote>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index.html#sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach">ClassifierDLApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach">ClassifierDLApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach.scala">ClassifierDLApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># In this example, the training data `"sentiment.csv"` has the form of
#
# text,label
# This movie is the best movie I have wached ever! In my opinion this movie can win an award.,0
# This was a terrible movie! The acting was bad really bad!,1
# ...
#
# Then traning can be done like so:
</span>
<span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">smallCorpus</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"header"</span><span class="p">,</span><span class="s">"True"</span><span class="p">).</span><span class="n">csv</span><span class="p">(</span><span class="s">"src/test/resources/classifier/sentiment.csv"</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">useEmbeddings</span> <span class="o">=</span> <span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">docClassifier</span> <span class="o">=</span> <span class="n">ClassifierDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLr</span><span class="p">(</span><span class="mf">5e-3</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">(</span>
      <span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">useEmbeddings</span><span class="p">,</span>
        <span class="n">docClassifier</span>
      <span class="p">]</span>
    <span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">smallCorpus</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the training data `"sentiment.csv"` has the form of</span>
<span class="c1">//</span>
<span class="c1">// text,label</span>
<span class="c1">// This movie is the best movie I have wached ever! In my opinion this movie can win an award.,0</span>
<span class="c1">// This was a terrible movie! The acting was bad really bad!,1</span>
<span class="c1">// ...</span>
<span class="c1">//</span>
<span class="c1">// Then traning can be done like so:</span>

<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLApproach</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">smallCorpus</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span><span class="s">"true"</span><span class="o">).</span><span class="py">csv</span><span class="o">(</span><span class="s">"src/test/resources/classifier/sentiment.csv"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">useEmbeddings</span> <span class="k">=</span> <span class="nv">UniversalSentenceEncoder</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">docClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ClassifierDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">64</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mf">3f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span>
    <span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span>
      <span class="n">useEmbeddings</span><span class="o">,</span>
      <span class="n">docClassifier</span>
    <span class="o">)</span>
  <span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">smallCorpus</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>ClassifierDL for generic Multi-class Text Classification.</p>

    <p>ClassifierDL uses the state-of-the-art Universal Sentence Encoder as an input for text classifications.
The ClassifierDL annotator uses a deep learning model (DNNs) we have built inside TensorFlow and supports up to
100 classes.</p>

    <p>This is the instantiated model of the ClassifierDLApproach.
For training your own model, please see the documentation of that class.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val classifierDL = ClassifierDLModel.pretrained()
  .setInputCols("sentence_embeddings")
  .setOutputCol("classification")
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"classifierdl_use_trec6"</code>, if no name is provided. It uses embeddings from the
<a href="/docs/en/transformers#universalsentenceencoder">UniversalSentenceEncoder</a> and is trained on the
<a href="https://deepai.org/dataset/trec-6#:~:text=The%20TREC%20dataset%20is%20dataset,50%20has%20finer%2Dgrained%20labels">TREC-6</a> dataset.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Text+Classification">Models Hub</a>.</p>

    <p>For extended examples of usage, see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLTestSpec.scala">ClassifierDLTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index.html#sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLModel">ClassifierDLModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel">ClassifierDLModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLModel.scala">ClassifierDLModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">useEmbeddings</span> <span class="o">=</span> <span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">sarcasmDL</span> <span class="o">=</span> <span class="n">ClassifierDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"classifierdl_use_sarcasm"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sarcasm"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentence</span><span class="p">,</span>
      <span class="n">useEmbeddings</span><span class="p">,</span>
      <span class="n">sarcasmDL</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"I'm ready!"</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"If I could put into words how much I love waking up at 6 am on Mondays I would."</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(arrays_zip(sentence, sarcasm)) as out"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"out.sentence.result as sentence"</span><span class="p">,</span> <span class="s">"out.sarcasm.result as sarcasm"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span><span class="n">sentence</span>                                                                       <span class="o">|</span><span class="n">sarcasm</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span><span class="n">I</span><span class="s">'m ready!                                                                     |normal |
|If I could put into words how much I love waking up at 6 am on Mondays I would.|sarcasm|
+-------------------------------------------------------------------------------+-------+
</span></code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.classifier.dl.ClassifierDLModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">useEmbeddings</span> <span class="k">=</span> <span class="nv">UniversalSentenceEncoder</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sarcasmDL</span> <span class="k">=</span> <span class="nv">ClassifierDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"classifierdl_use_sarcasm"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sarcasm"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentence</span><span class="o">,</span>
    <span class="n">useEmbeddings</span><span class="o">,</span>
    <span class="n">sarcasmDL</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"I'm ready!"</span><span class="o">,</span>
  <span class="s">"If I could put into words how much I love waking up at 6 am on Mondays I would."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(arrays_zip(sentence, sarcasm)) as out"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"out.sentence.result as sentence"</span><span class="o">,</span> <span class="s">"out.sarcasm.result as sarcasm"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span><span class="n">sentence</span>                                                                       <span class="o">|</span><span class="n">sarcasm</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span><span class="n">I</span><span class="ss">'m</span> <span class="n">ready</span><span class="o">!</span>                                                                     <span class="o">|</span><span class="n">normal</span> <span class="o">|</span>
<span class="o">|</span><span class="nc">If</span> <span class="n">I</span> <span class="n">could</span> <span class="n">put</span> <span class="n">into</span> <span class="n">words</span> <span class="n">how</span> <span class="n">much</span> <span class="n">I</span> <span class="n">love</span> <span class="n">waking</span> <span class="n">up</span> <span class="n">at</span> <span class="mi">6</span> <span class="n">am</span> <span class="n">on</span> <span class="nc">Mondays</span> <span class="n">I</span> <span class="n">would</span><span class="o">.|</span><span class="n">sarcasm</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------+-------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box tabs-new">

  <h2 id="contextspellchecker">ContextSpellChecker</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a deep-learning based Noisy Channel Model Spell Algorithm.
Correction candidates are extracted combining context information and word information.</p>

    <p>For instantiated/pretrained models, see ContextSpellCheckerModel.</p>

    <p>Spell Checking is a sequence to sequence mapping problem. Given an input sequence, potentially containing a
certain number of errors, <code class="language-plaintext highlighter-rouge">ContextSpellChecker</code> will rank correction sequences according to three things:</p>
    <ol>
      <li>Different correction candidates for each word — <strong>word level</strong>.</li>
      <li>The surrounding text of each word, i.e. it’s context — <strong>sentence level</strong>.</li>
      <li>The relative cost of different correction candidates according to the edit operations at the character level it requires — <strong>subword level</strong>.</li>
    </ol>

    <p>For an in-depth explanation of the module see the article <a href="https://medium.com/spark-nlp/applying-context-aware-spell-checking-in-spark-nlp-3c29c46963bc">Applying Context Aware Spell Checking in Spark NLP</a>.</p>

    <p>For extended examples of usage, see the article <a href="https://towardsdatascience.com/training-a-contextual-spell-checker-for-italian-language-66dda528e4bf">Training a Contextual Spell Checker for Italian Language</a>,
the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/blogposts/5.TrainingContextSpellChecker.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerTestSpec.scala">ContextSpellCheckerTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html#sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach">ContextSpellCheckerApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach">ContextSpellCheckerApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach.scala">ContextSpellCheckerApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># For this example, we use the first Sherlock Holmes book as the training dataset.
</span>
<span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>


<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">spellChecker</span> <span class="o">=</span> <span class="n">ContextSpellCheckerApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"corrected"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setWordMaxDistance</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochs</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLanguageModelClasses</span><span class="p">(</span><span class="mi">1650</span><span class="p">)</span>  <span class="c1"># dependant on vocabulary size
</span>    <span class="c1"># .addVocabClass("_NAME_", names) # Extra classes for correction could be added like this
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">spellChecker</span>
<span class="p">])</span>

<span class="n">path</span> <span class="o">=</span> <span class="s">"sherlockholmes.txt"</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// For this example, we use the first Sherlock Holmes book as the training dataset.</span>

<span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.spell.context.ContextSpellCheckerApproach</span>

<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">spellChecker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ContextSpellCheckerApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"corrected"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWordMaxDistance</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">24</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochs</span><span class="o">(</span><span class="mi">8</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLanguageModelClasses</span><span class="o">(</span><span class="mi">1650</span><span class="o">)</span>  <span class="c1">// dependant on vocabulary size</span>
  <span class="c1">// .addVocabClass("_NAME_", names) // Extra classes for correction could be added like this</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">spellChecker</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">path</span> <span class="k">=</span> <span class="s">"src/test/resources/spell/sherlockholmes.txt"</span>
<span class="k">val</span> <span class="nv">dataset</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="n">path</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Implements a deep-learning based Noisy Channel Model Spell Algorithm.
Correction candidates are extracted combining context information and word information.</p>

    <p>Spell Checking is a sequence to sequence mapping problem. Given an input sequence, potentially containing a
certain number of errors, <code class="language-plaintext highlighter-rouge">ContextSpellChecker</code> will rank correction sequences according to three things:</p>
    <ol>
      <li>Different correction candidates for each word — <strong>word level</strong>.</li>
      <li>The surrounding text of each word, i.e. it’s context — <strong>sentence level</strong>.</li>
      <li>The relative cost of different correction candidates according to the edit operations at the character level it requires — <strong>subword level</strong>.</li>
    </ol>

    <p>For an in-depth explanation of the module see the article <a href="https://medium.com/spark-nlp/applying-context-aware-spell-checking-in-spark-nlp-3c29c46963bc">Applying Context Aware Spell Checking in Spark NLP</a>.</p>

    <p>This is the instantiated model of the ContextSpellCheckerApproach.
For training your own model, please see the documentation of that class.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val spellChecker = ContextSpellCheckerModel.pretrained()
  .setInputCols("token")
  .setOutputCol("checked")
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"spellcheck_dl"</code>, if no name is provided.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Spell+Check">Models Hub</a>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SPELL_CHECKER_EN.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerTestSpec.scala">ContextSpellCheckerTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html#sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel">ContextSpellCheckerModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel">ContextSpellCheckerModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerModel.scala">ContextSpellCheckerModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="datematcher">DateMatcher</h2>

  <p>Matches standard date formats into a provided format.</p>

  <p>Reads from different forms of date and time expressions and converts them to a provided date format.</p>

  <p>Extracts only <strong>one</strong> date per document. Use with sentence detector to find matches in each sentence.
To extract multiple dates from a document, please use the MultiDateMatcher.</p>

  <p>Reads the following kind of dates:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"1978-01-28", "1984/04/02,1/02/1980", "2/28/79", "The 31st of April in the year 2008",
"Fri, 21 Nov 1997", "Jan 21, ‘97", "Sun", "Nov 21", "jan 1st", "next thursday",
"last wednesday", "today", "tomorrow", "yesterday", "next week", "next month",
"next year", "day after", "the day before", "0600h", "06:00 hours", "6pm", "5:30 a.m.",
"at 5", "12:59", "23:59", "1988/11/23 6pm", "next week at 7.30", "5 am tomorrow"
</code></pre></div>  </div>

  <p>For example <code class="language-plaintext highlighter-rouge">"The 31st of April in the year 2008"</code> will be converted into <code class="language-plaintext highlighter-rouge">2008/04/31</code>.</p>

  <p>Pretrained pipelines are available for this module, see <a href="https://nlp.johnsnowlabs.com/docs/en/pipelines">Pipelines</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/DateMatcherTestSpec.scala">DateMatcherTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DATE</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/matcher/date_matcher/index.html#sparknlp.annotator.matcher.date_matcher.DateMatcher">DateMatcher</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/DateMatcher">DateMatcher</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/DateMatcher.scala">DateMatcher</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">date</span> <span class="o">=</span> <span class="n">DateMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAnchorDateYear</span><span class="p">(</span><span class="mi">2020</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAnchorDateMonth</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAnchorDateDay</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormat</span><span class="p">(</span><span class="s">"yyyy/MM/dd"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">date</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Fri, 21 Nov 1997"</span><span class="p">],</span> <span class="p">[</span><span class="s">"next week at 7.30"</span><span class="p">],</span> <span class="p">[</span><span class="s">"see you a day after"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"date"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------+</span>
<span class="o">|</span><span class="n">date</span>                                             <span class="o">|</span>
<span class="o">+-------------------------------------------------+</span>
<span class="o">|</span><span class="p">[[</span><span class="n">date</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">1997</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="mi">21</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[[</span><span class="n">date</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2020</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">18</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]]</span>  <span class="o">|</span>
<span class="o">|</span><span class="p">[[</span><span class="n">date</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">2020</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">12</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]]</span><span class="o">|</span>
<span class="o">+-------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.DateMatcher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">date</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DateMatcher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAnchorDateYear</span><span class="o">(</span><span class="mi">2020</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAnchorDateMonth</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAnchorDateDay</span><span class="o">(</span><span class="mi">11</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDateFormat</span><span class="o">(</span><span class="s">"yyyy/MM/dd"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">date</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Fri, 21 Nov 1997"</span><span class="o">,</span> <span class="s">"next week at 7.30"</span><span class="o">,</span> <span class="s">"see you a day after"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"date"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-------------------------------------------------+</span>
<span class="o">|</span><span class="n">date</span>                                             <span class="o">|</span>
<span class="o">+-------------------------------------------------+</span>
<span class="o">|[[</span><span class="kt">date</span>, <span class="err">5</span>, <span class="err">15</span>, <span class="err">1997</span><span class="kt">/</span><span class="err">11</span><span class="kt">/</span><span class="err">21</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]]</span> <span class="o">|</span>
<span class="o">|[[</span><span class="kt">date</span>, <span class="err">0</span>, <span class="err">8</span>, <span class="err">2020</span><span class="kt">/</span><span class="err">01</span><span class="kt">/</span><span class="err">18</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]]</span>  <span class="o">|</span>
<span class="o">|[[</span><span class="kt">date</span>, <span class="err">10</span>, <span class="err">18</span>, <span class="err">2020</span><span class="kt">/</span><span class="err">01</span><span class="kt">/</span><span class="err">12</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]]|</span>
<span class="o">+-------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box tabs-new">

  <h2 id="dependencyparser">DependencyParser</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains an unlabeled parser that finds a grammatical relations between two words in a sentence.</p>

    <p>For instantiated/pretrained models, see DependencyParserModel.</p>

    <p>Dependency parser provides information about word relationship. For example, dependency parsing can tell you what
the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help
you find precise answers to specific questions.</p>

    <p>The required training data can be set in two different ways (only one can be chosen for a particular model):</p>
    <ul>
      <li>Dependency treebank in the <a href="http://www.nltk.org/nltk_data/">Penn Treebank format</a> set with <code class="language-plaintext highlighter-rouge">setDependencyTreeBank</code></li>
      <li>Dataset in the <a href="https://universaldependencies.org/format.html">CoNLL-U format</a> set with <code class="language-plaintext highlighter-rouge">setConllU</code></li>
    </ul>

    <p>Apart from that, no additional training data is needed.</p>

    <p>See <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproachTestSpec.scala">DependencyParserApproachTestSpec</a> for further reference on how to use this API.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, POS, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DEPENDENCY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html#sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach">DependencyParserApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach">DependencyParserApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach.scala">DependencyParserApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">dependencyParserApproach</span> <span class="o">=</span> <span class="n">DependencyParserApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependency"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDependencyTreeBank</span><span class="p">(</span><span class="s">"src/test/resources/parser/unlabeled/dependency_treebank"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">posTagger</span><span class="p">,</span>
    <span class="n">dependencyParserApproach</span>
<span class="p">])</span>

<span class="c1"># Additional training data is not needed, the dependency parser relies on the dependency tree bank / CoNLL-U only.
</span><span class="n">emptyDataSet</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">emptyDataSet</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserApproach</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependencyParserApproach</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DependencyParserApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependency"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDependencyTreeBank</span><span class="o">(</span><span class="s">"src/test/resources/parser/unlabeled/dependency_treebank"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">posTagger</span><span class="o">,</span>
  <span class="n">dependencyParserApproach</span>
<span class="o">))</span>

<span class="c1">// Additional training data is not needed, the dependency parser relies on the dependency tree bank / CoNLL-U only.</span>
<span class="k">val</span> <span class="nv">emptyDataSet</span> <span class="k">=</span> <span class="nv">Seq</span><span class="o">.</span><span class="py">empty</span><span class="o">[</span><span class="kt">String</span><span class="o">].</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">emptyDataSet</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Unlabeled parser that finds a grammatical relation between two words in a sentence.</p>

    <p>Dependency parser provides information about word relationship. For example, dependency parsing can tell you what
the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help
you find precise answers to specific questions.</p>

    <p>This is the instantiated model of the DependencyParserApproach.
For training your own model, please see the documentation of that class.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val dependencyParserApproach = DependencyParserModel.pretrained()
  .setInputCols("sentence", "pos", "token")
  .setOutputCol("dependency")
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"dependency_conllu"</code>, if no name is provided.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models">Models Hub</a>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproachTestSpec.scala">DependencyParserApproachTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">[String]DOCUMENT, POS, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DEPENDENCY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html#sparknlp.annotator.dependency.dependency_parser.DependencyParserModel">DependencyParserModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel">DependencyParserModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserModel.scala">DependencyParserModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="doc2chunk">Doc2Chunk</h2>

  <p>Converts <code class="language-plaintext highlighter-rouge">DOCUMENT</code> type annotations into <code class="language-plaintext highlighter-rouge">CHUNK</code> type with the contents of a <code class="language-plaintext highlighter-rouge">chunkCol</code>.
Chunk text must be contained within input <code class="language-plaintext highlighter-rouge">DOCUMENT</code>. May be either <code class="language-plaintext highlighter-rouge">StringType</code> or <code class="language-plaintext highlighter-rouge">ArrayType[StringType]</code>
(using setIsArray). Useful for annotators that require a CHUNK type input.</p>

  <p>For more extended examples on document pre-processing see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/base/doc2_chunk/index.html#sparknlp.base.doc2_chunk.Doc2Chunk">Doc2Chunk</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/Doc2Chunk">Doc2Chunk</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/Doc2Chunk.scala">Doc2Chunk</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setIsArray</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span>
    <span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="p">,</span>
      <span class="p">[</span><span class="s">"Spark NLP"</span><span class="p">,</span> <span class="s">"text processing library"</span><span class="p">,</span> <span class="s">"natural language processing"</span><span class="p">]</span>
<span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"target"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">chunkAssembler</span><span class="p">]).</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"chunk.result"</span><span class="p">,</span> <span class="s">"chunk.annotatorType"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                           <span class="o">|</span><span class="n">annotatorType</span>        <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Spark</span> <span class="n">NLP</span><span class="p">,</span> <span class="n">text</span> <span class="n">processing</span> <span class="n">library</span><span class="p">,</span> <span class="n">natural</span> <span class="n">language</span> <span class="n">processing</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.</span><span class="o">{</span><span class="nc">Doc2Chunk</span><span class="o">,</span> <span class="nc">DocumentAssembler</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setIsArray</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="o">,</span>
    <span class="nc">Seq</span><span class="o">(</span><span class="s">"Spark NLP"</span><span class="o">,</span> <span class="s">"text processing library"</span><span class="o">,</span> <span class="s">"natural language processing"</span><span class="o">))</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"target"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">chunkAssembler</span><span class="o">)).</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"chunk.result"</span><span class="o">,</span> <span class="s">"chunk.annotatorType"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                           <span class="o">|</span><span class="n">annotatorType</span>        <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|[</span><span class="kt">Spark</span> <span class="kt">NLP</span>, <span class="kt">text</span> <span class="kt">processing</span> <span class="kt">library</span>, <span class="kt">natural</span> <span class="kt">language</span> <span class="kt">processing</span><span class="o">]|[</span><span class="kt">chunk</span>, <span class="kt">chunk</span>, <span class="kt">chunk</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box tabs-new">

  <h2 id="doc2vec-1">Doc2Vec 1</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a Word2Vec model that creates vector representations of words in a text corpus.</p>

    <p>The algorithm first constructs a vocabulary from the corpus
and then learns vector representation of words in the vocabulary.
The vector representation can be used as features in
natural language processing and machine learning algorithms.</p>

    <p>We use Word2Vec implemented in Spark ML. It uses skip-gram model in our implementation and a hierarchical softmax
method to train the model. The variable names in the implementation match the original C implementation.</p>

    <p>For instantiated/pretrained models, see Doc2VecModel.</p>

    <p><strong>Sources</strong> :</p>

    <p>For the original C implementation, see <a href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a></p>

    <p>For the research paper, see
<a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a>
and <a href="https://arxiv.org/pdf/1310.4546v1.pdf">Distributed Representations of Words and Phrases and their Compositionality</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html#sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach">Doc2VecApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/Doc2VecApproach">Doc2VecApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/Doc2VecApproach.scala">Doc2VecApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">Doc2VecApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span>
    <span class="p">])</span>

<span class="n">path</span> <span class="o">=</span> <span class="s">"sherlockholmes.txt"</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">path</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.</span><span class="o">{</span><span class="nc">Tokenizer</span><span class="o">,</span> <span class="nc">Doc2VecApproach</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2VecApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">path</span> <span class="k">=</span> <span class="s">"src/test/resources/spell/sherlockholmes.txt"</span>
<span class="k">val</span> <span class="nv">dataset</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="n">path</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Word2Vec model that creates vector representations of words in a text corpus.</p>

    <p>The algorithm first constructs a vocabulary from the corpus
and then learns vector representation of words in the vocabulary.
The vector representation can be used as features in
natural language processing and machine learning algorithms.</p>

    <p>We use Word2Vec implemented in Spark ML. It uses skip-gram model in our implementation and a hierarchical softmax
method to train the model. The variable names in the implementation match the original C implementation.</p>

    <p>This is the instantiated model of the Doc2VecApproach.
For training your own model, please see the documentation of that class.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = Doc2VecModel.pretrained()
  .setInputCols("token")
  .setOutputCol("embeddings")
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"doc2vec_gigaword_300"</code>, if no name is provided.</p>

    <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models">Models Hub</a>.</p>

    <p><strong>Sources</strong> :</p>

    <p>For the original C implementation, see <a href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a></p>

    <p>For the research paper, see
<a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a>
and <a href="https://arxiv.org/pdf/1310.4546v1.pdf">Distributed Representations of Words and Phrases and their Compositionality</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html#sparknlp.annotator.embeddings.doc2vec.Doc2VecModel">Doc2VecModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/Doc2VecModel">Doc2VecModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/Doc2VecModel.scala">Doc2VecModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">Doc2VecModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.06222493574023247</span><span class="p">,</span><span class="mf">0.011579325422644615</span><span class="p">,</span><span class="mf">0.009919632226228714</span><span class="p">,</span><span class="mf">0.109361454844</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.</span><span class="o">{</span><span class="nc">Tokenizer</span><span class="o">,</span> <span class="nc">Doc2VecModel</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>

<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">Doc2VecModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">06222493574023247</span>,<span class="err">0</span><span class="kt">.</span><span class="err">011579325422644615</span>,<span class="err">0</span><span class="kt">.</span><span class="err">009919632226228714</span>,<span class="err">0</span><span class="kt">.</span><span class="err">109361454844</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="documentassembler">DocumentAssembler</h2>

  <p>Prepares data into a format that is processable by Spark NLP. This is the entry point for every Spark NLP pipeline.
The <code class="language-plaintext highlighter-rouge">DocumentAssembler</code> can read either a <code class="language-plaintext highlighter-rouge">String</code> column or an <code class="language-plaintext highlighter-rouge">Array[String]</code>. Additionally, setCleanupMode
can be used to pre-process the text (Default: <code class="language-plaintext highlighter-rouge">disabled</code>). For possible options please refer the parameters section.</p>

  <p>For more extended examples on document pre-processing see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/base/document_assembler/index.html#sparknlp.base.document_assembler.DocumentAssembler">DocumentAssembler</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/DocumentAssembler">DocumentAssembler</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/DocumentAssembler.scala">DocumentAssembler</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Spark NLP is an open-source text processing library."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">documentAssembler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"document"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">document</span>                                                                                      <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[[</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="n">Spark</span> <span class="n">NLP</span> <span class="ow">is</span> <span class="n">an</span> <span class="nb">open</span><span class="o">-</span><span class="n">source</span> <span class="n">text</span> <span class="n">processing</span> <span class="n">library</span><span class="p">.,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]]</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"document"</span><span class="p">).</span><span class="n">printSchema</span>
<span class="n">root</span>
 <span class="o">|--</span> <span class="n">document</span><span class="p">:</span> <span class="n">array</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
 <span class="o">|</span>    <span class="o">|--</span> <span class="n">element</span><span class="p">:</span> <span class="n">struct</span> <span class="p">(</span><span class="n">containsNull</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">annotatorType</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">begin</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">end</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">result</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">metadata</span><span class="p">:</span> <span class="nb">map</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">key</span><span class="p">:</span> <span class="n">string</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">value</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">valueContainsNull</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">embeddings</span><span class="p">:</span> <span class="n">array</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">element</span><span class="p">:</span> <span class="nb">float</span> <span class="p">(</span><span class="n">containsNull</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Spark NLP is an open-source text processing library."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">documentAssembler</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">document</span>                                                                                      <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|[[</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">51</span>, <span class="kt">Spark</span> <span class="kt">NLP</span> <span class="kt">is</span> <span class="kt">an</span> <span class="kt">open-source</span> <span class="kt">text</span> <span class="kt">processing</span> <span class="kt">library.</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]]|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">printSchema</span>
<span class="n">root</span>
 <span class="o">|--</span> <span class="n">document</span><span class="k">:</span> <span class="kt">array</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|--</span> <span class="n">element</span><span class="k">:</span> <span class="kt">struct</span> <span class="o">(</span><span class="kt">containsNull</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">annotatorType</span><span class="k">:</span> <span class="kt">string</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">begin</span><span class="k">:</span> <span class="kt">integer</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">false</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">end</span><span class="k">:</span> <span class="kt">integer</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">false</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">result</span><span class="k">:</span> <span class="kt">string</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">metadata</span><span class="k">:</span> <span class="kt">map</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">key</span><span class="k">:</span> <span class="kt">string</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">value</span><span class="k">:</span> <span class="kt">string</span> <span class="o">(</span><span class="kt">valueContainsNull</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">embeddings</span><span class="k">:</span> <span class="kt">array</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">element</span><span class="k">:</span> <span class="kt">float</span> <span class="o">(</span><span class="kt">containsNull</span> <span class="o">=</span> <span class="kt">false</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="documentnormalizer">DocumentNormalizer</h2>

  <p>Annotator which normalizes raw text from tagged text, e.g. scraped web pages or xml documents, from document type columns into Sentence.
Removes all dirty characters from text following one or more input regex patterns.
Can apply not wanted character removal with a specific policy.
Can apply lower case normalization.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/document_normalizer/index.html#sparknlp.annotator.document_normalizer.DocumentNormalizer">DocumentNormalizer</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/DocumentNormalizer">DocumentNormalizer</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/DocumentNormalizer.scala">DocumentNormalizer</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">cleanUpPatterns</span> <span class="o">=</span> <span class="p">[</span><span class="s">"&lt;[^&gt;]&gt;"</span><span class="p">]</span>

<span class="n">documentNormalizer</span> <span class="o">=</span> <span class="n">DocumentNormalizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalizedDocument"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAction</span><span class="p">(</span><span class="s">"clean"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPatterns</span><span class="p">(</span><span class="n">cleanUpPatterns</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setReplacement</span><span class="p">(</span><span class="s">" "</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPolicy</span><span class="p">(</span><span class="s">"pretty_all"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLowercase</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">documentNormalizer</span>
<span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""
&lt;div id="theworldsgreatest" class='my-right my-hide-small my-wide toptext' style="font-family:'Segoe UI',Arial,sans-serif"&gt;
    THE WORLD'S LARGEST WEB DEVELOPER SITE
    &lt;h1 style="font-size:300%;"&gt;THE WORLD'S LARGEST WEB DEVELOPER SITE&lt;/h1&gt;
    &lt;p style="font-size:160%;"&gt;Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum..&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;"""</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipelineModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"normalizedDocument.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span> <span class="n">the</span> <span class="n">world</span><span class="s">'s largest web developer site the world'</span><span class="n">s</span> <span class="n">largest</span> <span class="n">web</span> <span class="n">developer</span> <span class="n">site</span> <span class="n">lorem</span> <span class="n">ipsum</span> <span class="ow">is</span> <span class="n">simply</span> <span class="n">dummy</span> <span class="n">text</span> <span class="n">of</span> <span class="n">the</span> <span class="n">printing</span> <span class="ow">and</span> <span class="n">typesetting</span> <span class="n">industry</span><span class="p">.</span> <span class="n">lorem</span> <span class="n">ipsum</span> <span class="n">has</span> <span class="n">been</span> <span class="n">the</span> <span class="n">industry</span><span class="s">'s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..]|
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
</span></code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.DocumentNormalizer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">cleanUpPatterns</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"&lt;[^&gt;]&gt;"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentNormalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentNormalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalizedDocument"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAction</span><span class="o">(</span><span class="s">"clean"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPatterns</span><span class="o">(</span><span class="n">cleanUpPatterns</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReplacement</span><span class="o">(</span><span class="s">" "</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPolicy</span><span class="o">(</span><span class="s">"pretty_all"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLowercase</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">documentNormalizer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span>
  <span class="s">"""
&lt;div id="theworldsgreatest" class='my-right my-hide-small my-wide toptext' style="font-family:'Segoe UI',Arial,sans-serif"&gt;
  THE WORLD'S LARGEST WEB DEVELOPER SITE
  &lt;h1 style="font-size:300%;"&gt;THE WORLD'S LARGEST WEB DEVELOPER SITE&lt;/h1&gt;
  &lt;p style="font-size:160%;"&gt;Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum..&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;"""</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipelineModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"normalizedDocument.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span> <span class="kt">the</span> <span class="kt">world's</span> <span class="kt">largest</span> <span class="kt">web</span> <span class="kt">developer</span> <span class="kt">site</span> <span class="kt">the</span> <span class="kt">world's</span> <span class="kt">largest</span> <span class="kt">web</span> <span class="kt">developer</span> <span class="kt">site</span> <span class="kt">lorem</span> <span class="kt">ipsum</span> <span class="kt">is</span> <span class="kt">simply</span> <span class="kt">dummy</span> <span class="kt">text</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">printing</span> <span class="kt">and</span> <span class="k">type</span><span class="kt">setting</span> <span class="kt">industry.</span> <span class="kt">lorem</span> <span class="kt">ipsum</span> <span class="kt">has</span> <span class="kt">been</span> <span class="kt">the</span> <span class="kt">industry's</span> <span class="kt">standard</span> <span class="kt">dummy</span> <span class="kt">text</span> <span class="kt">ever</span> <span class="kt">since</span> <span class="kt">the</span> <span class="err">1500</span><span class="kt">s</span>, <span class="kt">when</span> <span class="kt">an</span> <span class="kt">unknown</span> <span class="kt">printer</span> <span class="kt">took</span> <span class="kt">a</span> <span class="kt">galley</span> <span class="kt">of</span> <span class="k">type</span> <span class="kt">and</span> <span class="kt">scrambled</span> <span class="kt">it</span> <span class="kt">to</span> <span class="kt">make</span> <span class="kt">a</span> <span class="k">type</span> <span class="kt">specimen</span> <span class="kt">book.</span> <span class="kt">it</span> <span class="kt">has</span> <span class="kt">survived</span> <span class="kt">not</span> <span class="kt">only</span> <span class="kt">five</span> <span class="kt">centuries</span>, <span class="kt">but</span> <span class="kt">also</span> <span class="kt">the</span> <span class="kt">leap</span> <span class="kt">into</span> <span class="kt">electronic</span> <span class="k">type</span><span class="kt">setting</span>, <span class="kt">remaining</span> <span class="kt">essentially</span> <span class="kt">unchanged.</span> <span class="kt">it</span> <span class="kt">was</span> <span class="kt">popularised</span> <span class="kt">in</span> <span class="kt">the</span> <span class="err">1960</span><span class="kt">s</span> <span class="kt">with</span> <span class="kt">the</span> <span class="kt">release</span> <span class="kt">of</span> <span class="kt">letraset</span> <span class="kt">sheets</span> <span class="kt">containing</span> <span class="kt">lorem</span> <span class="kt">ipsum</span> <span class="kt">passages</span>, <span class="kt">and</span> <span class="kt">more</span> <span class="kt">recently</span> <span class="kt">with</span> <span class="kt">desktop</span> <span class="kt">publishing</span> <span class="kt">software</span> <span class="kt">like</span> <span class="kt">aldus</span> <span class="kt">pagemaker</span> <span class="kt">including</span> <span class="kt">versions</span> <span class="kt">of</span> <span class="kt">lorem</span> <span class="kt">ipsum..</span><span class="o">]|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="embeddingsfinisher">EmbeddingsFinisher</h2>

  <p>Extracts embeddings from Annotations into a more easily usable form.</p>

  <p>This is useful for example:
<a href="/docs/en/annotators#wordembeddings">WordEmbeddings</a>,
<a href="/docs/en/transformers#bertembeddings">BertEmbeddings</a>,
<a href="/docs/en/annotators#sentenceembeddings">SentenceEmbeddings</a> and
<a href="/docs/en/annotators#chunkembeddings">ChunkEmbeddings</a>.</p>

  <p>By using <code class="language-plaintext highlighter-rouge">EmbeddingsFinisher</code> you can easily transform your embeddings into array of floats or vectors which are
compatible with Spark ML functions such as LDA, K-mean, Random Forest classifier or any other functions that require
<code class="language-plaintext highlighter-rouge">featureCol</code>.</p>

  <p>For more extended examples see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.1_Text_classification_examples_in_SparkML_SparkNLP.ipynb">Spark NLP Workshop</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">EMBEDDINGS</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/base/embeddings_finisher/index.html#sparknlp.base.embeddings_finisher.EmbeddingsFinisher">EmbeddingsFinisher</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/EmbeddingsFinisher">EmbeddingsFinisher</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/EmbeddingsFinisher.scala">EmbeddingsFinisher</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span>

<span class="n">stopwordsCleaner</span> <span class="o">=</span> <span class="n">StopWordsCleaner</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">gloveEmbeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"cleanTokens"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Spark NLP is an open-source text processing library."</span><span class="p">]])</span> \
    <span class="p">.</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">normalizer</span><span class="p">,</span>
    <span class="n">stopwordsCleaner</span><span class="p">,</span>
    <span class="n">gloveEmbeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">]).</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">resultWithSize</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_sentence_embeddings) as embeddings"</span><span class="p">)</span>

<span class="n">resultWithSize</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                      <span class="n">embeddings</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.1619900017976761</span><span class="p">,</span><span class="mf">0.045552998781204224</span><span class="p">,</span><span class="o">-</span><span class="mf">0.03229299932718277</span><span class="p">,</span><span class="o">-</span><span class="mf">0.685609996318</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.42416998744010925</span><span class="p">,</span><span class="mf">1.1378999948501587</span><span class="p">,</span><span class="o">-</span><span class="mf">0.5717899799346924</span><span class="p">,</span><span class="o">-</span><span class="mf">0.5078899860382</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.08621499687433243</span><span class="p">,</span><span class="o">-</span><span class="mf">0.15772999823093414</span><span class="p">,</span><span class="o">-</span><span class="mf">0.06067200005054474</span><span class="p">,</span><span class="mf">0.395359992980</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.4970499873161316</span><span class="p">,</span><span class="mf">0.7164199948310852</span><span class="p">,</span><span class="mf">0.40119001269340515</span><span class="p">,</span><span class="o">-</span><span class="mf">0.05761000141501</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.08170200139284134</span><span class="p">,</span><span class="mf">0.7159299850463867</span><span class="p">,</span><span class="o">-</span><span class="mf">0.20677000284194946</span><span class="p">,</span><span class="mf">0.0295659992843</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.</span><span class="o">{</span><span class="nc">DocumentAssembler</span><span class="o">,</span> <span class="nc">EmbeddingsFinisher</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.</span><span class="o">{</span><span class="nc">Normalizer</span><span class="o">,</span> <span class="nc">StopWordsCleaner</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">,</span> <span class="nc">WordEmbeddingsModel</span><span class="o">}</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopwordsCleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsCleaner</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gloveEmbeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Spark NLP is an open-source text processing library."</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">normalizer</span><span class="o">,</span>
  <span class="n">stopwordsCleaner</span><span class="o">,</span>
  <span class="n">gloveEmbeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">)).</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">resultWithSize</span> <span class="k">=</span> <span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_sentence_embeddings)"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">map</span> <span class="o">{</span> <span class="n">row</span> <span class="k">=&gt;</span>
    <span class="k">val</span> <span class="nv">vector</span> <span class="k">=</span> <span class="nv">row</span><span class="o">.</span><span class="py">getAs</span><span class="o">[</span><span class="kt">org.apache.spark.ml.linalg.DenseVector</span><span class="o">](</span><span class="mi">0</span><span class="o">)</span>
    <span class="o">(</span><span class="nv">vector</span><span class="o">.</span><span class="py">size</span><span class="o">,</span> <span class="n">vector</span><span class="o">)</span>
  <span class="o">}.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"size"</span><span class="o">,</span> <span class="s">"vector"</span><span class="o">)</span>

<span class="nv">resultWithSize</span><span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+----+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">size</span><span class="o">|</span>                                                                          <span class="n">vector</span><span class="o">|</span>
<span class="o">+----+--------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="mi">100</span><span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">1619900017976761</span>,<span class="err">0</span><span class="kt">.</span><span class="err">045552998781204224</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03229299932718277</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">685609996318</span><span class="kt">...|</span>
<span class="kt">|</span> <span class="err">100</span><span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">42416998744010925</span>,<span class="err">1</span><span class="kt">.</span><span class="err">1378999948501587</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">5717899799346924</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">5078899860382</span><span class="kt">...|</span>
<span class="kt">|</span> <span class="err">100</span><span class="kt">|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">08621499687433243</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">15772999823093414</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">06067200005054474</span>,<span class="err">0</span><span class="kt">.</span><span class="err">395359992980</span><span class="kt">...|</span>
<span class="kt">|</span> <span class="err">100</span><span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">4970499873161316</span>,<span class="err">0</span><span class="kt">.</span><span class="err">7164199948310852</span>,<span class="err">0</span><span class="kt">.</span><span class="err">40119001269340515</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">05761000141501</span><span class="kt">...|</span>
<span class="kt">|</span> <span class="err">100</span><span class="kt">|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">08170200139284134</span>,<span class="err">0</span><span class="kt">.</span><span class="err">7159299850463867</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">20677000284194946</span>,<span class="err">0</span><span class="kt">.</span><span class="err">0295659992843</span><span class="kt">...|</span>
<span class="kt">+----+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box tabs-new">

  <h2 id="entityruler">EntityRuler</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Fits an Annotator to match exact strings or regex patterns provided in a file against a Document and assigns them an
named entity. The definitions can contain any number of named entities.</p>

    <p>There are multiple ways and formats to set the extraction resource. It is possible to set it either as a “JSON”,
“JSONL” or “CSV” file. A path to the file needs to be provided to <code class="language-plaintext highlighter-rouge">setPatternsResource</code>. The file format needs to be
set as the “format” field in the <code class="language-plaintext highlighter-rouge">option</code> parameter map and depending on the file type, additional parameters might
need to be set.</p>

    <p>To enable regex extraction, <code class="language-plaintext highlighter-rouge">setEnablePatternRegex(true)</code> needs to be called.</p>

    <p>If the file is in a JSON format, then the rule definitions need to be given in a list with the fields “id”, “label”
and “patterns”:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> [
  {
    "id": "person-regex",
    "label": "PERSON",
    "patterns": ["\\w+\\s\\w+", "\\w+-\\w+"]
  },
  {
    "id": "locations-words",
    "label": "LOCATION",
    "patterns": ["Winterfell"]
  }
]
</code></pre></div>    </div>

    <p>The same fields also apply to a file in the JSONL format:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{"id": "names-with-j", "label": "PERSON", "patterns": ["Jon", "John", "John Snow"]}
{"id": "names-with-s", "label": "PERSON", "patterns": ["Stark", "Snow"]}
{"id": "names-with-e", "label": "PERSON", "patterns": ["Eddard", "Eddard Stark"]}
</code></pre></div>    </div>

    <p>In order to use a CSV file, an additional parameter “delimiter” needs to be set. In this case, the delimiter might be
set by using <code class="language-plaintext highlighter-rouge">.setPatternsResource("patterns.csv", ReadAs.TEXT, Map("format"-&gt;"csv", "delimiter" -&gt; "\\|"))</code></p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PERSON|Jon
PERSON|John
PERSON|John Snow
LOCATION|Winterfell
</code></pre></div>    </div>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/er/entity_ruler/index.html#sparknlp.annotator.er.entity_ruler.EntityRulerApproach">EntityRulerApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerApproach">EntityRulerApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/er/EntityRulerApproach.scala">EntityRulerApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># In this example, the entities file as the form of
#
# PERSON|Jon
# PERSON|John
# PERSON|John Snow
# LOCATION|Winterfell
#
# where each line represents an entity and the associated string delimited by "|".
</span>
<span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">entityRuler</span> <span class="o">=</span> <span class="n">EntityRulerApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entities"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPatternsResource</span><span class="p">(</span>
      <span class="s">"patterns.csv"</span><span class="p">,</span>
      <span class="n">ReadAs</span><span class="p">.</span><span class="n">TEXT</span><span class="p">,</span>
      <span class="p">{</span><span class="s">"format"</span><span class="p">:</span> <span class="s">"csv"</span><span class="p">,</span> <span class="s">"delimiter"</span><span class="p">:</span> <span class="s">"</span><span class="se">\\</span><span class="s">|"</span><span class="p">}</span>
    <span class="p">)</span> \
    <span class="p">.</span><span class="n">setEnablePatternRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">entityRuler</span>
<span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Jon Snow wants to be lord of Winterfell."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(entities)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                 <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">Jon</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">PERSON</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span>           <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="mi">38</span><span class="p">,</span> <span class="n">Winterfell</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">LOCATION</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the entities file as the form of</span>
<span class="c1">//</span>
<span class="c1">// PERSON|Jon</span>
<span class="c1">// PERSON|John</span>
<span class="c1">// PERSON|John Snow</span>
<span class="c1">// LOCATION|Winterfell</span>
<span class="c1">//</span>
<span class="c1">// where each line represents an entity and the associated string delimited by "|".</span>

<span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.er.EntityRulerApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.util.io.ReadAs</span>

<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">entityRuler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EntityRulerApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entities"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPatternsResource</span><span class="o">(</span>
    <span class="s">"src/test/resources/entity-ruler/patterns.csv"</span><span class="o">,</span>
    <span class="nv">ReadAs</span><span class="o">.</span><span class="py">TEXT</span><span class="o">,</span>
    <span class="o">{</span><span class="s">"format"</span><span class="k">:</span> <span class="err">"</span><span class="kt">csv</span><span class="err">"</span><span class="o">,</span> <span class="s">"delimiter"</span><span class="k">:</span> <span class="err">"</span><span class="kt">|</span><span class="err">"</span><span class="o">)}</span>
  <span class="o">)</span>
  <span class="o">.</span><span class="py">setEnablePatternRegex</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">entityRuler</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Jon Snow wants to be lord of Winterfell."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(entities)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                 <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">0</span>, <span class="err">2</span>, <span class="kt">Jon</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">PERSON</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]</span>           <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">29</span>, <span class="err">38</span>, <span class="kt">Winterfell</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">LOCATION</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">+--------------------------------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Instantiated model of the EntityRulerApproach.
For usage and examples see the documentation of the main class.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/er/entity_ruler/index.html#sparknlp.annotator.er.entity_ruler.EntityRulerModel">EntityRulerModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerModel">EntityRulerModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/er/EntityRulerModel.scala">EntityRulerModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="finisher">Finisher</h2>

  <p>Converts annotation results into a format that easier to use. It is useful to extract the results from Spark NLP
Pipelines. The Finisher outputs annotation(s) values into <code class="language-plaintext highlighter-rouge">String</code>.</p>

  <p>For more extended examples on document pre-processing see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">ANY</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/base/finisher/index.html#sparknlp.base.finisher.Finisher">Finisher</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/Finisher">Finisher</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/Finisher.scala">Finisher</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sparknlp.pretrained</span> <span class="kn">import</span> <span class="n">PretrainedPipeline</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="s">"New York and New Jersey aren't that far apart actually."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"id"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">)</span>

<span class="c1"># Extracts Named Entities amongst other things
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">PretrainedPipeline</span><span class="p">(</span><span class="s">"explain_document_dl"</span><span class="p">)</span>

<span class="n">finisher</span> <span class="o">=</span> <span class="n">Finisher</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"entities"</span><span class="p">).</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"output"</span><span class="p">)</span>
<span class="n">explainResult</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">explainResult</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(entities)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">entities</span>                                                                                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">New</span> <span class="n">York</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">LOC</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]],</span> <span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="n">New</span> <span class="n">Jersey</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">LOC</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[]]]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">finisher</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">explainResult</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"output"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------+</span>
<span class="o">|</span><span class="n">output</span>                <span class="o">|</span>
<span class="o">+----------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">New</span> <span class="n">York</span><span class="p">,</span> <span class="n">New</span> <span class="n">Jersey</span><span class="p">]</span><span class="o">|</span>
<span class="o">+----------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.pretrained.PretrainedPipeline</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.Finisher</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="mi">1</span><span class="o">,</span> <span class="s">"New York and New Jersey aren't that far apart actually."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"id"</span><span class="o">,</span> <span class="s">"text"</span><span class="o">)</span>

<span class="c1">// Extracts Named Entities amongst other things</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="nc">PretrainedPipeline</span><span class="o">(</span><span class="s">"explain_document_dl"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">finisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Finisher</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"entities"</span><span class="o">).</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"output"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">explainResult</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">explainResult</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(entities)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">entities</span>                                                                                                                                              <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[[</span><span class="kt">chunk</span>, <span class="err">0</span>, <span class="err">7</span>, <span class="kt">New</span> <span class="kt">York</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">LOC</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]</span>, <span class="o">[</span><span class="kt">chunk</span>, <span class="err">13</span>, <span class="err">22</span>, <span class="kt">New</span> <span class="kt">Jersey</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">LOC</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">1</span><span class="o">]</span>, <span class="o">[]]]|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">finisher</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">explainResult</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"output"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------+</span>
<span class="o">|</span><span class="n">output</span>                <span class="o">|</span>
<span class="o">+----------------------+</span>
<span class="o">|[</span><span class="kt">New</span> <span class="kt">York</span>, <span class="kt">New</span> <span class="kt">Jersey</span><span class="o">]|</span>
<span class="o">+----------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="graphextraction">GraphExtraction</h2>

  <p>Extracts a dependency graph between entities.</p>

  <p>The GraphExtraction class takes e.g. extracted entities from a
<a href="/docs/en/annotators#nerdl">NerDLModel</a> and creates a dependency tree which describes how
the entities relate to each other. For that a triple store format is used. Nodes represent the entities and the
edges represent the relations between those entities. The graph can then be used to find relevant relationships
between words.</p>

  <p>Both the <a href="/docs/en/annotators#dependencyparser">DependencyParserModel</a> and
<a href="/docs/en/annotators#typeddependencyparser">TypedDependencyParserModel</a> need to be
present in the pipeline. There are two ways to set them:</p>

  <ol>
    <li>Both Annotators are present in the pipeline already. The dependencies are taken implicitly from these two
Annotators.</li>
    <li>Setting <code class="language-plaintext highlighter-rouge">setMergeEntities</code> to <code class="language-plaintext highlighter-rouge">true</code> will download the default pretrained models for those two Annotators
automatically. The specific models can also be set with <code class="language-plaintext highlighter-rouge">setDependencyParserModel</code> and
<code class="language-plaintext highlighter-rouge">setTypedDependencyParserModel</code>:
      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      val graph_extraction = new GraphExtraction()
        .setInputCols("document", "token", "ner")
        .setOutputCol("graph")
        .setRelationshipTypes(Array("prefer-LOC"))
        .setMergeEntities(true)
      //.setDependencyParserModel(Array("dependency_conllu", "en",  "public/models"))
      //.setTypedDependencyParserModel(Array("dependency_typed_conllu", "en",  "public/models"))
</code></pre></div>      </div>
    </li>
  </ol>

  <p>To transform the resulting graph into a more generic form such as RDF, see the
<a href="/docs/en/annotators#graphfinisher">GraphFinisher</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, NAMED_ENTITY</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NODE</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/graph_extraction/index.html#sparknlp.annotator.graph_extraction.GraphExtraction">GraphExtraction</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/GraphExtraction">GraphExtraction</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/GraphExtraction.scala">GraphExtraction</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">dependencyParser</span> <span class="o">=</span> <span class="n">DependencyParserModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependency"</span><span class="p">)</span>

<span class="n">typedDependencyParser</span> <span class="o">=</span> <span class="n">TypedDependencyParserModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"dependency"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependency_type"</span><span class="p">)</span>

<span class="n">graph_extraction</span> <span class="o">=</span> <span class="n">GraphExtraction</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"graph"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRelationshipTypes</span><span class="p">([</span><span class="s">"prefer-LOC"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span><span class="p">,</span>
    <span class="n">posTagger</span><span class="p">,</span>
    <span class="n">dependencyParser</span><span class="p">,</span>
    <span class="n">typedDependencyParser</span><span class="p">,</span>
    <span class="n">graph_extraction</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"You and John prefer the morning flight through Denver"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"graph"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">graph</span>                                                                                                            <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="mi">13</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="n">prefer</span><span class="p">,</span> <span class="p">[</span><span class="n">relationship</span> <span class="o">-&gt;</span> <span class="n">prefer</span><span class="p">,</span><span class="n">LOC</span><span class="p">,</span> <span class="n">path1</span> <span class="o">-&gt;</span> <span class="n">prefer</span><span class="p">,</span><span class="n">nsubj</span><span class="p">,</span><span class="n">morning</span><span class="p">,</span><span class="n">flat</span><span class="p">,</span><span class="n">flight</span><span class="p">,</span><span class="n">flat</span><span class="p">,</span><span class="n">Denver</span><span class="p">],</span> <span class="p">[]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.parser.typdep.TypedDependencyParserModel</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.GraphExtraction</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependencyParser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependency"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">typedDependencyParser</span> <span class="k">=</span> <span class="nv">TypedDependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"dependency"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependency_type"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">graph_extraction</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GraphExtraction</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"graph"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationshipTypes</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"prefer-LOC"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span><span class="o">,</span>
  <span class="n">posTagger</span><span class="o">,</span>
  <span class="n">dependencyParser</span><span class="o">,</span>
  <span class="n">typedDependencyParser</span><span class="o">,</span>
  <span class="n">graph_extraction</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"You and John prefer the morning flight through Denver"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"graph"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">graph</span>                                                                                                            <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[[</span><span class="kt">node</span>, <span class="err">13</span>, <span class="err">18</span>, <span class="kt">prefer</span>, <span class="o">[</span><span class="kt">relationship</span> <span class="kt">-&gt;</span> <span class="kt">prefer</span>,<span class="kt">LOC</span>, <span class="kt">path1</span> <span class="kt">-&gt;</span> <span class="kt">prefer</span>,<span class="kt">nsubj</span>,<span class="kt">morning</span>,<span class="kt">flat</span>,<span class="kt">flight</span>,<span class="kt">flat</span>,<span class="kt">Denver</span><span class="o">]</span>, <span class="o">[]]]|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="graphfinisher">GraphFinisher</h2>

  <p>Helper class to convert the knowledge graph from GraphExtraction into a generic format, such as RDF.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/base/graph_finisher/index.html#sparknlp.base.graph_finisher.GraphFinisher">GraphFinisher</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/GraphFinisher">GraphFinisher</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/GraphFinisher.scala">GraphFinisher</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># This is a continuation of the example of
# GraphExtraction. To see how the graph is extracted, see the
# documentation of that class.
</span>
<span class="n">graphFinisher</span> <span class="o">=</span> <span class="n">GraphFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"graph"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"graph_finished"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputAs</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span>

<span class="n">finishedResult</span> <span class="o">=</span> <span class="n">graphFinisher</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="n">finishedResult</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"graph_finished"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------------+-----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">text</span>                                                 <span class="o">|</span><span class="n">graph_finished</span>                                                         <span class="o">|</span>
<span class="o">+-----------------------------------------------------+-----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">You</span> <span class="ow">and</span> <span class="n">John</span> <span class="n">prefer</span> <span class="n">the</span> <span class="n">morning</span> <span class="n">flight</span> <span class="n">through</span> <span class="n">Denver</span><span class="o">|</span><span class="p">(</span><span class="n">morning</span><span class="p">,</span><span class="n">flat</span><span class="p">,</span><span class="n">flight</span><span class="p">),</span> <span class="p">(</span><span class="n">flight</span><span class="p">,</span><span class="n">flat</span><span class="p">,</span><span class="n">Denver</span><span class="p">)</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------+-----------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This is a continuation of the example of</span>
<span class="c1">// [[com.johnsnowlabs.nlp.annotators.GraphExtraction GraphExtraction]]. To see how the graph is extracted, see the</span>
<span class="c1">// documentation of that class.</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.GraphFinisher</span>

<span class="k">val</span> <span class="nv">graphFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GraphFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"graph"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"graph_finished"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsArray</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">finishedResult</span> <span class="k">=</span> <span class="nv">graphFinisher</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">result</span><span class="o">)</span>
<span class="nv">finishedResult</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"graph_finished"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-----------------------------------------------------+-----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">text</span>                                                 <span class="o">|</span><span class="n">graph_finished</span>                                                         <span class="o">|</span>
<span class="o">+-----------------------------------------------------+-----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">You</span> <span class="n">and</span> <span class="nc">John</span> <span class="n">prefer</span> <span class="n">the</span> <span class="n">morning</span> <span class="n">flight</span> <span class="n">through</span> <span class="nc">Denver</span><span class="o">|[[(</span><span class="kt">prefer</span>,<span class="kt">nsubj</span>,<span class="kt">morning</span><span class="o">)</span>, <span class="o">(</span><span class="kt">morning</span>,<span class="kt">flat</span>,<span class="kt">flight</span><span class="o">)</span>, <span class="o">(</span><span class="kt">flight</span>,<span class="kt">flat</span>,<span class="kt">Denver</span><span class="o">)]]|</span>
<span class="o">+-----------------------------------------------------+-----------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="imageassembler">ImageAssembler</h2>

  <p>Prepares images read by Spark into a format that is processable by Spark NLP. This component
is needed to process images.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">IMAGE</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/base/image_assembler/index.html#sparknlp.base.image_assembler.ImageAssembler">ImageAssembler</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/ImageAssembler">ImageAssembler</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/ImageAssembler.scala">ImageAssembler</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"image"</span><span class="p">).</span><span class="n">load</span><span class="p">(</span><span class="s">"./tmp/images/"</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"image"</span><span class="p">)</span>
<span class="n">imageAssembler</span> <span class="o">=</span> <span class="n">ImageAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"image"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"image_assembler"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">imageAssembler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"image_assembler"</span><span class="p">).</span><span class="n">show</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"image_assembler"</span><span class="p">).</span><span class="n">printSchema</span><span class="p">()</span>
<span class="n">root</span>
  <span class="o">|--</span> <span class="n">image_assembler</span><span class="p">:</span> <span class="n">array</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
  <span class="o">|</span>    <span class="o">|--</span> <span class="n">element</span><span class="p">:</span> <span class="n">struct</span> <span class="p">(</span><span class="n">containsNull</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
  <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">annotatorType</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
  <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">origin</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
  <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">height</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
  <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">width</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
  <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">nChannels</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
  <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">mode</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
  <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">result</span><span class="p">:</span> <span class="n">binary</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
  <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">metadata</span><span class="p">:</span> <span class="nb">map</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
  <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">key</span><span class="p">:</span> <span class="n">string</span>
  <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">value</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">valueContainsNull</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.ImageAssembler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">imageDF</span><span class="k">:</span> <span class="kt">DataFrame</span> <span class="o">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span>
  <span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"image"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"dropInvalid"</span><span class="o">,</span> <span class="n">value</span> <span class="k">=</span> <span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">load</span><span class="o">(</span><span class="s">"src/test/resources/image/"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">imageAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ImageAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"image"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"image_assembler"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">imageAssembler</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">pipelineDF</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">imageDF</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">imageDF</span><span class="o">)</span>
<span class="nv">pipelineDF</span><span class="o">.</span><span class="py">printSchema</span><span class="o">()</span>
<span class="n">root</span>
 <span class="o">|--</span> <span class="n">image_assembler</span><span class="k">:</span> <span class="kt">array</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|--</span> <span class="n">element</span><span class="k">:</span> <span class="kt">struct</span> <span class="o">(</span><span class="kt">containsNull</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">annotatorType</span><span class="k">:</span> <span class="kt">string</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">origin</span><span class="k">:</span> <span class="kt">string</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">height</span><span class="k">:</span> <span class="kt">integer</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">false</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">width</span><span class="k">:</span> <span class="kt">integer</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">false</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">nChannels</span><span class="k">:</span> <span class="kt">integer</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">false</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">mode</span><span class="k">:</span> <span class="kt">integer</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">false</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">result</span><span class="k">:</span> <span class="kt">binary</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">metadata</span><span class="k">:</span> <span class="kt">map</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">key</span><span class="k">:</span> <span class="kt">string</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">value</span><span class="k">:</span> <span class="kt">string</span> <span class="o">(</span><span class="kt">valueContainsNull</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="languagedetectordl">LanguageDetectorDL</h2>

  <p>Language Identification and Detection by using CNN and RNN architectures in TensorFlow.</p>

  <p><code class="language-plaintext highlighter-rouge">LanguageDetectorDL</code> is an annotator that detects the language of documents or sentences depending on the inputCols.
The models are trained on large datasets such as Wikipedia and Tatoeba.
Depending on the language (how similar the characters are), the LanguageDetectorDL works
best with text longer than 140 characters.
The output is a language code in <a href="https://en.wikipedia.org/wiki/List_of_Wikipedias">Wiki Code style</a>.</p>

  <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Val languageDetector = LanguageDetectorDL.pretrained()
  .setInputCols("sentence")
  .setOutputCol("language")
</code></pre></div>  </div>
  <p>The default model is <code class="language-plaintext highlighter-rouge">"ld_wiki_tatoeba_cnn_21"</code>, default language is <code class="language-plaintext highlighter-rouge">"xx"</code> (meaning multi-lingual),
if no values are provided.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Language+Detection">Models Hub</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/language-detection/Language_Detection_and_Indentification.ipynb">Spark NLP Workshop</a>
And the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDLTestSpec.scala">LanguageDetectorDLTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">LANGUAGE</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index.html#sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL">LanguageDetectorDL</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL">LanguageDetectorDL</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ld/dl/LanguageDetectorDL.scala">LanguageDetectorDL</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">languageDetector</span> <span class="o">=</span> <span class="n">LanguageDetectorDL</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"language"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">languageDetector</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing for the Python, Java and Scala programming languages."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Spark NLP est une bibliothèque de traitement de texte open source pour le traitement avancé du langage naturel pour les langages de programmation Python, Java et Scala."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Spark NLP ist eine Open-Source-Textverarbeitungsbibliothek für fortgeschrittene natürliche Sprachverarbeitung für die Programmiersprachen Python, Java und Scala."</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"language.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">en</span><span class="p">]</span>  <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">fr</span><span class="p">]</span>  <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">de</span><span class="p">]</span>  <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ld.dl.LanguageDetectorDL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">languageDetector</span> <span class="k">=</span> <span class="nv">LanguageDetectorDL</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"language"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">languageDetector</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing for the Python, Java and Scala programming languages."</span><span class="o">,</span>
  <span class="s">"Spark NLP est une bibliothèque de traitement de texte open source pour le traitement avancé du langage naturel pour les langages de programmation Python, Java et Scala."</span><span class="o">,</span>
  <span class="s">"Spark NLP ist eine Open-Source-Textverarbeitungsbibliothek für fortgeschrittene natürliche Sprachverarbeitung für die Programmiersprachen Python, Java und Scala."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"language.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+</span>
<span class="o">|[</span><span class="kt">en</span><span class="o">]</span>  <span class="o">|</span>
<span class="o">|[</span><span class="kt">fr</span><span class="o">]</span>  <span class="o">|</span>
<span class="o">|[</span><span class="kt">de</span><span class="o">]</span>  <span class="o">|</span>
<span class="o">+------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box tabs-new">

  <h2 id="lemmatizer">Lemmatizer</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Class to find lemmas out of words with the objective of returning a base dictionary word.
Retrieves the significant part of a word. A dictionary of predefined lemmas must be provided with <code class="language-plaintext highlighter-rouge">setDictionary</code>.
The dictionary can be set as a delimited text file.
Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">LemmatizerModel.pretrained</code>.</p>

    <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Lemmatization">Models Hub</a>.
For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html#sparknlp.annotator.lemmatizer.Lemmatizer">Lemmatizer</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/Lemmatizer">Lemmatizer</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Lemmatizer.scala">Lemmatizer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># In this example, the lemma dictionary `lemmas_small.txt` has the form of
#
# ...
# pick	-&gt;	pick	picks	picking	picked
# peck	-&gt;	peck	pecking	pecked	pecks
# pickle	-&gt;	pickle	pickles	pickled	pickling
# pepper	-&gt;	pepper	peppers	peppered	peppering
# ...
#
# where each key is delimited by `-&gt;` and values are delimited by `\t`
</span>
<span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">lemmatizer</span> <span class="o">=</span> <span class="n">Lemmatizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"lemma"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"src/test/resources/lemma-corpus-small/lemmas_small.txt"</span><span class="p">,</span> <span class="s">"-&gt;"</span><span class="p">,</span> <span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">lemmatizer</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Peter Pipers employees are picking pecks of pickled peppers."</span><span class="p">]])</span> \
    <span class="p">.</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"lemma.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                            <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Peter</span><span class="p">,</span> <span class="n">Pipers</span><span class="p">,</span> <span class="n">employees</span><span class="p">,</span> <span class="n">are</span><span class="p">,</span> <span class="n">pick</span><span class="p">,</span> <span class="n">peck</span><span class="p">,</span> <span class="n">of</span><span class="p">,</span> <span class="n">pickle</span><span class="p">,</span> <span class="n">pepper</span><span class="p">,</span> <span class="p">.]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the lemma dictionary `lemmas_small.txt` has the form of</span>
<span class="c1">//</span>
<span class="c1">// ...</span>
<span class="c1">// pick	-&gt;	pick	picks	picking	picked</span>
<span class="c1">// peck	-&gt;	peck	pecking	pecked	pecks</span>
<span class="c1">// pickle	-&gt;	pickle	pickles	pickled	pickling</span>
<span class="c1">// pepper	-&gt;	pepper	peppers	peppered	peppering</span>
<span class="c1">// ...</span>
<span class="c1">//</span>
<span class="c1">// where each key is delimited by `-&gt;` and values are delimited by `\t`</span>
<span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Lemmatizer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">lemmatizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Lemmatizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"lemma"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"src/test/resources/lemma-corpus-small/lemmas_small.txt"</span><span class="o">,</span> <span class="s">"-&gt;"</span><span class="o">,</span> <span class="s">"\t"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">lemmatizer</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Peter Pipers employees are picking pecks of pickled peppers."</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"lemma.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                            <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Peter</span>, <span class="kt">Pipers</span>, <span class="kt">employees</span>, <span class="kt">are</span>, <span class="kt">pick</span>, <span class="kt">peck</span>, <span class="kt">of</span>, <span class="kt">pickle</span>, <span class="kt">pepper</span>, <span class="kt">.</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Instantiated Model of the Lemmatizer. For usage and examples, please see the documentation of that class.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Lemmatization">Models Hub</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html#sparknlp.annotator.lemmatizer.LemmatizerModel">LemmatizerModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel">LemmatizerModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/LemmatizerModel.scala">LemmatizerModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box tabs-new">

  <h2 id="multiclassifierdl">MultiClassifierDL</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a MultiClassifierDL for Multi-label Text Classification.</p>

    <p>MultiClassifierDL uses a Bidirectional GRU with a convolutional model that we have built inside TensorFlow and supports
up to 100 classes.</p>

    <p>For instantiated/pretrained models, see MultiClassifierDLModel.</p>

    <p>The input to <code class="language-plaintext highlighter-rouge">MultiClassifierDL</code> are Sentence Embeddings such as the state-of-the-art
<a href="/docs/en/transformers#universalsentenceencoder">UniversalSentenceEncoder</a>,
<a href="/docs/en/transformers#bertsentenceembeddings">BertSentenceEmbeddings</a> or
<a href="/docs/en/annotators#sentenceembeddings">SentenceEmbeddings</a>.</p>

    <p>In machine learning, multi-label classification and the strongly related problem of multi-output classification are
variants of the classification problem where multiple labels may be assigned to each instance. Multi-label
classification is a generalization of multiclass classification, which is the single-label problem of categorizing
instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many
of the classes the instance can be assigned to.
Formally, multi-label classification is the problem of finding a model that maps inputs x to binary vectors y
(assigning a value of 0 or 1 for each element (label) in y).</p>

    <p>Setting a test dataset to monitor model metrics can be done with <code class="language-plaintext highlighter-rouge">.setTestDataset</code>. The method
expects a path to a parquet file containing a dataframe that has the same required columns as
the training dataframe. The pre-processing steps for the training dataframe should also be
applied to the test dataframe. The following example will show how to create the test dataset:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val documentAssembler = new DocumentAssembler()
  .setInputCol("text")
  .setOutputCol("document")

val embeddings = UniversalSentenceEncoder.pretrained()
  .setInputCols("document")
  .setOutputCol("sentence_embeddings")

val preProcessingPipeline = new Pipeline().setStages(Array(documentAssembler, embeddings))

val Array(train, test) = data.randomSplit(Array(0.8, 0.2))
preProcessingPipeline
  .fit(test)
  .transform(test)
  .write
  .mode("overwrite")
  .parquet("test_data")

val multiClassifier = new MultiClassifierDLApproach()
  .setInputCols("sentence_embeddings")
  .setOutputCol("category")
  .setLabelColumn("label")
  .setTestDataset("test_data")
</code></pre></div>    </div>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/classification/MultiClassifierDL_train_multi_label_E2E_challenge_classifier.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLTestSpec.scala">MultiClassifierDLTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <blockquote>
      <p><strong>Note:</strong> This annotator accepts a label column of a single item in either type of String, Int, Float, or Double. UniversalSentenceEncoder, BertSentenceEmbeddings, SentenceEmbeddings or other sentence based embeddings can be used for the inputCol</p>
    </blockquote>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.html#sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach">MultiClassifierDLApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLApproach">MultiClassifierDLApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLApproach.scala">MultiClassifierDLApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># In this example, the training data has the form
#
# +----------------+--------------------+--------------------+
# |              id|                text|              labels|
# +----------------+--------------------+--------------------+
# |ed58abb40640f983|PN NewsYou mean ... |             [toxic]|
# |a1237f726b5f5d89|Dude.  Place the ...|   [obscene, insult]|
# |24b0d6c8733c2abe|Thanks  - thanks ...|            [insult]|
# |8c4478fb239bcfc0|" Gee, 5 minutes ...|[toxic, obscene, ...|
# +----------------+--------------------+--------------------+
</span>
<span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># Process training data to create text with associated array of labels
</span>
<span class="n">trainDataset</span><span class="p">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="c1"># root
#  |-- id: string (nullable = true)
#  |-- text: string (nullable = true)
#  |-- labels: array (nullable = true)
#  |    |-- element: string (containsNull = true)
</span>

<span class="c1"># Then create pipeline for training
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanupMode</span><span class="p">(</span><span class="s">"shrink"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">docClassifier</span> <span class="o">=</span> <span class="n">MultiClassifierDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"labels"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLr</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">(</span>
      <span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">docClassifier</span>
      <span class="p">]</span>
    <span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainDataset</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the training data has the form (Note: labels can be arbitrary)</span>
<span class="c1">//</span>
<span class="c1">// mr,ref</span>
<span class="c1">// "name[Alimentum], area[city centre], familyFriendly[no], near[Burger King]",Alimentum is an adult establish found in the city centre area near Burger King.</span>
<span class="c1">// "name[Alimentum], area[city centre], familyFriendly[yes]",Alimentum is a family-friendly place in the city centre.</span>
<span class="c1">// ...</span>
<span class="c1">//</span>
<span class="c1">// It needs some pre-processing first, so the labels are of type `Array[String]`. This can be done like so:</span>

<span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.</span><span class="o">{</span><span class="n">col</span><span class="o">,</span> <span class="n">udf</span><span class="o">}</span>

<span class="c1">// Process training data to create text with associated array of labels</span>
<span class="k">def</span> <span class="nf">splitAndTrim</span> <span class="k">=</span> <span class="n">udf</span> <span class="o">{</span> <span class="n">labels</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=&gt;</span>
  <span class="nv">labels</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">", "</span><span class="o">).</span><span class="py">map</span><span class="o">(</span><span class="n">x</span><span class="k">=&gt;</span><span class="nv">x</span><span class="o">.</span><span class="py">trim</span><span class="o">)</span>
<span class="o">}</span>

<span class="k">val</span> <span class="nv">smallCorpus</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span>
  <span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"inferSchema"</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"mode"</span><span class="o">,</span> <span class="s">"DROPMALFORMED"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">csv</span><span class="o">(</span><span class="s">"src/test/resources/classifier/e2e.csv"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">withColumn</span><span class="o">(</span><span class="s">"labels"</span><span class="o">,</span> <span class="nf">splitAndTrim</span><span class="o">(</span><span class="nf">col</span><span class="o">(</span><span class="s">"mr"</span><span class="o">)))</span>
  <span class="o">.</span><span class="py">withColumn</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="nf">col</span><span class="o">(</span><span class="s">"ref"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">drop</span><span class="o">(</span><span class="s">"mr"</span><span class="o">)</span>

<span class="nv">smallCorpus</span><span class="o">.</span><span class="py">printSchema</span><span class="o">()</span>
<span class="c1">// root</span>
<span class="c1">// |-- ref: string (nullable = true)</span>
<span class="c1">// |-- labels: array (nullable = true)</span>
<span class="c1">// |    |-- element: string (containsNull = true)</span>

<span class="c1">// Then create pipeline for training</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanupMode</span><span class="o">(</span><span class="s">"shrink"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">UniversalSentenceEncoder</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">docClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiClassifierDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"labels"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">128</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mf">3f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.1f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span>
    <span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span>
      <span class="n">embeddings</span><span class="o">,</span>
      <span class="n">docClassifier</span>
    <span class="o">)</span>
  <span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">smallCorpus</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>MultiClassifierDL for Multi-label Text Classification.</p>

    <p>MultiClassifierDL Bidirectional GRU with Convolution model we have built inside TensorFlow and supports up to 100 classes.
The input to MultiClassifierDL are Sentence Embeddings such as state-of-the-art
<a href="/docs/en/transformers#universalsentenceencoder">UniversalSentenceEncoder</a>,
<a href="/docs/en/transformers#bertsentenceembeddings">BertSentenceEmbeddings</a> or
<a href="/docs/en/annotators#sentenceembeddings">SentenceEmbeddings</a>.</p>

    <p>This is the instantiated model of the MultiClassifierDLApproach.
For training your own model, please see the documentation of that class.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val multiClassifier = MultiClassifierDLModel.pretrained()
  .setInputCols("sentence_embeddings")
  .setOutputCol("categories")
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"multiclassifierdl_use_toxic"</code>, if no name is provided. It uses embeddings from the
<a href="/docs/en/transformers#universalsentenceencoder">UniversalSentenceEncoder</a> and classifies toxic comments.
The data is based on the
<a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview">Jigsaw Toxic Comment Classification Challenge</a>.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Text+Classification">Models Hub</a>.</p>

    <p>In machine learning, multi-label classification and the strongly related problem of multi-output classification are
variants of the classification problem where multiple labels may be assigned to each instance. Multi-label
classification is a generalization of multiclass classification, which is the single-label problem of categorizing
instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many
of the classes the instance can be assigned to.
Formally, multi-label classification is the problem of finding a model that maps inputs x to binary vectors y
(assigning a value of 0 or 1 for each element (label) in y).</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/classification/MultiClassifierDL_train_multi_label_E2E_challenge_classifier.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLTestSpec.scala">MultiClassifierDLTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.html#sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLModel">MultiClassifierDLModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel">MultiClassifierDLModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLModel.scala">MultiClassifierDLModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">useEmbeddings</span> <span class="o">=</span> <span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">multiClassifierDl</span> <span class="o">=</span> <span class="n">MultiClassifierDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"classifications"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">useEmbeddings</span><span class="p">,</span>
      <span class="n">multiClassifierDl</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"This is pretty good stuff!"</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Wtf kind of crap is this"</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"classifications.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------+----------------+</span>
<span class="o">|</span><span class="n">text</span>                      <span class="o">|</span><span class="n">result</span>          <span class="o">|</span>
<span class="o">+--------------------------+----------------+</span>
<span class="o">|</span><span class="n">This</span> <span class="ow">is</span> <span class="n">pretty</span> <span class="n">good</span> <span class="n">stuff</span><span class="err">!</span><span class="o">|</span><span class="p">[]</span>              <span class="o">|</span>
<span class="o">|</span><span class="n">Wtf</span> <span class="n">kind</span> <span class="n">of</span> <span class="n">crap</span> <span class="ow">is</span> <span class="n">this</span>  <span class="o">|</span><span class="p">[</span><span class="n">toxic</span><span class="p">,</span> <span class="n">obscene</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------+----------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.classifier.dl.MultiClassifierDLModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.UniversalSentenceEncoder</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">useEmbeddings</span> <span class="k">=</span> <span class="nv">UniversalSentenceEncoder</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">multiClassifierDl</span> <span class="k">=</span> <span class="nv">MultiClassifierDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"classifications"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">useEmbeddings</span><span class="o">,</span>
    <span class="n">multiClassifierDl</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"This is pretty good stuff!"</span><span class="o">,</span>
  <span class="s">"Wtf kind of crap is this"</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"classifications.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------+----------------+</span>
<span class="o">|</span><span class="n">text</span>                      <span class="o">|</span><span class="n">result</span>          <span class="o">|</span>
<span class="o">+--------------------------+----------------+</span>
<span class="o">|</span><span class="nc">This</span> <span class="n">is</span> <span class="n">pretty</span> <span class="n">good</span> <span class="n">stuff</span><span class="o">!|[]</span>              <span class="o">|</span>
<span class="o">|</span><span class="nc">Wtf</span> <span class="n">kind</span> <span class="n">of</span> <span class="n">crap</span> <span class="n">is</span> <span class="k">this</span>  <span class="o">|[</span><span class="kt">toxic</span>, <span class="kt">obscene</span><span class="o">]|</span>
<span class="o">+--------------------------+----------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="multidatematcher">MultiDateMatcher</h2>

  <p>Matches standard date formats into a provided format.</p>

  <p>Reads the following kind of dates:</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"1978-01-28", "1984/04/02,1/02/1980", "2/28/79", "The 31st of April in the year 2008",
"Fri, 21 Nov 1997", "Jan 21, ‘97", "Sun", "Nov 21", "jan 1st", "next thursday",
"last wednesday", "today", "tomorrow", "yesterday", "next week", "next month",
"next year", "day after", "the day before", "0600h", "06:00 hours", "6pm", "5:30 a.m.",
"at 5", "12:59", "23:59", "1988/11/23 6pm", "next week at 7.30", "5 am tomorrow"
</code></pre></div>  </div>

  <p>For example <code class="language-plaintext highlighter-rouge">"The 31st of April in the year 2008"</code> will be converted into <code class="language-plaintext highlighter-rouge">2008/04/31</code>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/MultiDateMatcherTestSpec.scala">MultiDateMatcherTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DATE</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index.html#sparknlp.annotator.matcher.multi_date_matcher.MultiDateMatcher">MultiDateMatcher</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/MultiDateMatcher">MultiDateMatcher</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/MultiDateMatcher.scala">MultiDateMatcher</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">date</span> <span class="o">=</span> <span class="n">MultiDateMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAnchorDateYear</span><span class="p">(</span><span class="mi">2020</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAnchorDateMonth</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAnchorDateDay</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormat</span><span class="p">(</span><span class="s">"yyyy/MM/dd"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">date</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I saw him yesterday and he told me that he will visit us next week"</span><span class="p">]])</span> \
    <span class="p">.</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(date) as dates"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------+</span>
<span class="o">|</span><span class="n">dates</span>                                          <span class="o">|</span>
<span class="o">+-----------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">date</span><span class="p">,</span> <span class="mi">57</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="mi">2020</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">18</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">date</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">2020</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">10</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.MultiDateMatcher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">date</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDateMatcher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAnchorDateYear</span><span class="o">(</span><span class="mi">2020</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAnchorDateMonth</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAnchorDateDay</span><span class="o">(</span><span class="mi">11</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDateFormat</span><span class="o">(</span><span class="s">"yyyy/MM/dd"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">date</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I saw him yesterday and he told me that he will visit us next week"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(date) as dates"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-----------------------------------------------+</span>
<span class="o">|</span><span class="n">dates</span>                                          <span class="o">|</span>
<span class="o">+-----------------------------------------------+</span>
<span class="o">|[</span><span class="kt">date</span>, <span class="err">57</span>, <span class="err">65</span>, <span class="err">2020</span><span class="kt">/</span><span class="err">01</span><span class="kt">/</span><span class="err">18</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">|[</span><span class="kt">date</span>, <span class="err">10</span>, <span class="err">18</span>, <span class="err">2020</span><span class="kt">/</span><span class="err">01</span><span class="kt">/</span><span class="err">10</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">+-----------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="multidocumentassembler">MultiDocumentAssembler</h2>

  <p>Prepares data into a format that is processable by Spark NLP. This is the entry point for
every Spark NLP pipeline. The <code class="language-plaintext highlighter-rouge">MultiDocumentAssembler</code> can read either a <code class="language-plaintext highlighter-rouge">String</code> column or an
<code class="language-plaintext highlighter-rouge">Array[String]</code>. Additionally, MultiDocumentAssembler.setCleanupMode can be used to
pre-process the text (Default: <code class="language-plaintext highlighter-rouge">disabled</code>). For possible options please refer the parameters
section.</p>

  <p>For more extended examples on document pre-processing see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/base/multi_document_assembler/index.html#sparknlp.base.multi_document_assembler.MultiDocumentAssembler">MultiDocumentAssembler</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/MultiDocumentAssembler">MultiDocumentAssembler</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/MultiDocumentAssembler.scala">MultiDocumentAssembler</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>

<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Spark NLP is an open-source text processing library."</span><span class="p">],</span> <span class="p">[</span><span class="s">"Spark NLP is a state-of-the-art Natural Language Processing library built on top of Apache Spark"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"text2"</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">MultiDocumentAssembler</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"text2"</span><span class="p">]).</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"document1"</span><span class="p">,</span> <span class="s">"document2"</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">documentAssembler</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"document1"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">document1</span>                                                                                      <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[[</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="n">Spark</span> <span class="n">NLP</span> <span class="ow">is</span> <span class="n">an</span> <span class="nb">open</span><span class="o">-</span><span class="n">source</span> <span class="n">text</span> <span class="n">processing</span> <span class="n">library</span><span class="p">.,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]]</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"document1"</span><span class="p">).</span><span class="n">printSchema</span><span class="p">()</span>
<span class="n">root</span>
<span class="o">|--</span> <span class="n">document</span><span class="p">:</span> <span class="n">array</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="o">|</span>    <span class="o">|--</span> <span class="n">element</span><span class="p">:</span> <span class="n">struct</span> <span class="p">(</span><span class="n">containsNull</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">annotatorType</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">begin</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">end</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">result</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">metadata</span><span class="p">:</span> <span class="nb">map</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">key</span><span class="p">:</span> <span class="n">string</span>
<span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">value</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">valueContainsNull</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">embeddings</span><span class="p">:</span> <span class="n">array</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">element</span><span class="p">:</span> <span class="nb">float</span> <span class="p">(</span><span class="n">containsNull</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.MultiDocumentAssembler</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Spark NLP is an open-source text processing library."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">multiDocumentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDocumentAssembler</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">multiDocumentAssembler</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">document</span>                                                                                      <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>
<span class="o">|[[</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">51</span>, <span class="kt">Spark</span> <span class="kt">NLP</span> <span class="kt">is</span> <span class="kt">an</span> <span class="kt">open-source</span> <span class="kt">text</span> <span class="kt">processing</span> <span class="kt">library.</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]]|</span>
<span class="o">+----------------------------------------------------------------------------------------------+</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">printSchema</span>
<span class="n">root</span>
 <span class="o">|--</span> <span class="n">document</span><span class="k">:</span> <span class="kt">array</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|--</span> <span class="n">element</span><span class="k">:</span> <span class="kt">struct</span> <span class="o">(</span><span class="kt">containsNull</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">annotatorType</span><span class="k">:</span> <span class="kt">string</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">begin</span><span class="k">:</span> <span class="kt">integer</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">false</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">end</span><span class="k">:</span> <span class="kt">integer</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">false</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">result</span><span class="k">:</span> <span class="kt">string</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">metadata</span><span class="k">:</span> <span class="kt">map</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">key</span><span class="k">:</span> <span class="kt">string</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">value</span><span class="k">:</span> <span class="kt">string</span> <span class="o">(</span><span class="kt">valueContainsNull</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">embeddings</span><span class="k">:</span> <span class="kt">array</span> <span class="o">(</span><span class="kt">nullable</span> <span class="o">=</span> <span class="kt">true</span><span class="o">)</span>
 <span class="o">|</span>    <span class="o">|</span>    <span class="o">|</span>    <span class="o">|--</span> <span class="n">element</span><span class="k">:</span> <span class="kt">float</span> <span class="o">(</span><span class="kt">containsNull</span> <span class="o">=</span> <span class="kt">false</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="ngramgenerator">NGramGenerator</h2>

  <p>A feature transformer that converts the input array of strings (annotatorType TOKEN) into an
array of n-grams (annotatorType CHUNK).
Null values in the input array are ignored.
It returns an array of n-grams where each n-gram is represented by a space-separated string of
words.</p>

  <p>When the input is empty, an empty array is returned.
When the input array length is less than n (number of elements per n-gram), no n-grams are
returned.</p>

  <p>For more extended examples see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/chunking/NgramGenerator.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/NGramGeneratorTestSpec.scala">NGramGeneratorTestSpec</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/n_gram_generator/index.html#sparknlp.annotator.n_gram_generator.NGramGenerator">NGramGenerator</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/NGramGenerator">NGramGenerator</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/NGramGenerator.scala">NGramGenerator</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">nGrams</span> <span class="o">=</span> <span class="n">NGramGenerator</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngrams"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setN</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentence</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">nGrams</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is my sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ngrams) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                      <span class="o">|</span>
<span class="o">+------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">This</span> <span class="ow">is</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span>     <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="ow">is</span> <span class="n">my</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[]]</span>       <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="n">my</span> <span class="n">sentence</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="n">sentence</span> <span class="p">.,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.NGramGenerator</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nGrams</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NGramGenerator</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentence</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">nGrams</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is my sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">results</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(ngrams) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                      <span class="o">|</span>
<span class="o">+------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">0</span>, <span class="err">6</span>, <span class="kt">This</span> <span class="kt">is</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]</span>     <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">5</span>, <span class="err">9</span>, <span class="kt">is</span> <span class="kt">my</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">1</span><span class="o">]</span>, <span class="o">[]]</span>       <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">8</span>, <span class="err">18</span>, <span class="kt">my</span> <span class="kt">sentence</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">2</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">11</span>, <span class="err">19</span>, <span class="kt">sentence</span> <span class="kt">.</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">3</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">+------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="nerconverter">NerConverter</h2>

  <p>Converts a IOB or IOB2 representation of NER to a user-friendly one,
by associating the tokens of recognized entities and their label. Results in <code class="language-plaintext highlighter-rouge">CHUNK</code> Annotation type.</p>

  <p>NER chunks can then be filtered by setting a whitelist with <code class="language-plaintext highlighter-rouge">setWhiteList</code>.
Chunks with no associated entity (tagged “O”) are filtered.</p>

  <p>See also <a href="https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)">Inside–outside–beginning (tagging)</a> for more information.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, NAMED_ENTITY</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/ner/ner_converter/index.html#sparknlp.annotator.ner.ner_converter.NerConverter">NerConverter</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter">NerConverter</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/NerConverter.scala">NerConverter</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># This is a continuation of the example of the NerDLModel. See that class
# on how to extract the entities.
# The output of the NerDLModel follows the Annotator schema and can be converted like so:
#
# result.selectExpr("explode(ner)").show(truncate=False)
# +----------------------------------------------------+
# |col                                                 |
# +----------------------------------------------------+
# |[named_entity, 0, 2, B-ORG, [word -&gt; U.N], []]      |
# |[named_entity, 3, 3, O, [word -&gt; .], []]            |
# |[named_entity, 5, 12, O, [word -&gt; official], []]    |
# |[named_entity, 14, 18, B-PER, [word -&gt; Ekeus], []]  |
# |[named_entity, 20, 24, O, [word -&gt; heads], []]      |
# |[named_entity, 26, 28, O, [word -&gt; for], []]        |
# |[named_entity, 30, 36, B-LOC, [word -&gt; Baghdad], []]|
# |[named_entity, 37, 37, O, [word -&gt; .], []]          |
# +----------------------------------------------------+
#
# After the converter is used:
</span><span class="n">converter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entities"</span><span class="p">)</span>

<span class="n">converter</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">).</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(entities)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                     <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">U</span><span class="p">.</span><span class="n">N</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">ORG</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span>      <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="n">Ekeus</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">PER</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[]]</span>  <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="n">Baghdad</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">LOC</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This is a continuation of the example of the [[com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel NerDLModel]]. See that class</span>
<span class="c1">// on how to extract the entities.</span>
<span class="c1">// The output of the NerDLModel follows the Annotator schema and can be converted like so:</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(ner)").show(false)</span>
<span class="c1">// +----------------------------------------------------+</span>
<span class="c1">// |col                                                 |</span>
<span class="c1">// +----------------------------------------------------+</span>
<span class="c1">// |[named_entity, 0, 2, B-ORG, [word -&gt; U.N], []]      |</span>
<span class="c1">// |[named_entity, 3, 3, O, [word -&gt; .], []]            |</span>
<span class="c1">// |[named_entity, 5, 12, O, [word -&gt; official], []]    |</span>
<span class="c1">// |[named_entity, 14, 18, B-PER, [word -&gt; Ekeus], []]  |</span>
<span class="c1">// |[named_entity, 20, 24, O, [word -&gt; heads], []]      |</span>
<span class="c1">// |[named_entity, 26, 28, O, [word -&gt; for], []]        |</span>
<span class="c1">// |[named_entity, 30, 36, B-LOC, [word -&gt; Baghdad], []]|</span>
<span class="c1">// |[named_entity, 37, 37, O, [word -&gt; .], []]          |</span>
<span class="c1">// +----------------------------------------------------+</span>
<span class="c1">//</span>
<span class="c1">// After the converter is used:</span>
<span class="k">val</span> <span class="nv">converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entities"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPreservePosition</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="nv">converter</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">result</span><span class="o">).</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(entities)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                     <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">0</span>, <span class="err">2</span>, <span class="kt">U.N</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">ORG</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]</span>      <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">14</span>, <span class="err">18</span>, <span class="kt">Ekeus</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">PER</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">1</span><span class="o">]</span>, <span class="o">[]]</span>  <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">30</span>, <span class="err">36</span>, <span class="kt">Baghdad</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">LOC</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">2</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">+------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box tabs-new">

  <h2 id="nercrf">NerCrf</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Algorithm for training a Named Entity Recognition Model</p>

    <p>For instantiated/pretrained models, see NerCrfModel.</p>

    <p>This Named Entity recognition annotator allows for a generic model to be trained by utilizing a CRF machine learning
algorithm. The training data should be a labeled Spark Dataset, e.g. <a href="/docs/en/training#conll-dataset">CoNLL</a> 2003 IOB with
<code class="language-plaintext highlighter-rouge">Annotation</code> type columns. The data should have columns of type <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS</code> and an
additional label column of annotator type <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code>.
Excluding the label, this can be done with for example</p>
    <ul>
      <li>a <a href="/docs/en/annotators#sentencedetector">SentenceDetector</a>,</li>
      <li>a <a href="/docs/en/annotators#tokenizer">Tokenizer</a> and</li>
      <li>a <a href="/docs/en/annotators#postagger-part-of-speech-tagger">PerceptronModel</a> and</li>
      <li>a <a href="/docs/en/annotators#wordembeddings">WordEmbeddingsModel</a>
  (any word embeddings can be chosen, e.g. <a href="/docs/en/transformers#bertembeddings">BertEmbeddings</a> for BERT based embeddings).</li>
    </ul>

    <p>Optionally the user can provide an entity dictionary file with setExternalFeatures for better accuracy.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/crf-ner/ner_dl_crf.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproachTestSpec.scala">NerCrfApproachTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html#sparknlp.annotator.ner.ner_crf.NerCrfApproach">NerCrfApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach">NerCrfApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach.scala">NerCrfApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This CoNLL dataset already includes the sentence, token, pos and label column with their respective annotator types.
# If a custom dataset is used, these need to be defined.
</span>
<span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerCrfApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMinEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setC0</span><span class="p">(</span><span class="mi">34</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setL2</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>


<span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// This CoNLL dataset already includes the sentence, token, pos and label column with their respective annotator types.</span>
<span class="c1">// If a custom dataset is used, these need to be defined.</span>

<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.NerCrfApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerCrfApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMinEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setC0</span><span class="o">(</span><span class="mi">34</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setL2</span><span class="o">(</span><span class="mf">3.0</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>


<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Extracts Named Entities based on a CRF Model.</p>

    <p>This Named Entity recognition annotator allows for a generic model to be trained by utilizing a CRF machine learning
algorithm. The data should have columns of type <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS</code>.
These can be extracted with for example</p>
    <ul>
      <li>a <a href="/docs/en/annotators#sentencedetector">SentenceDetector</a>,</li>
      <li>a <a href="/docs/en/annotators#tokenizer">Tokenizer</a> and</li>
      <li>a <a href="/docs/en/annotators#postagger-part-of-speech-tagger">PerceptronModel</a></li>
    </ul>

    <p>This is the instantiated model of the NerCrfApproach.
For training your own model, please see the documentation of that class.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val nerTagger = NerCrfModel.pretrained()
  .setInputCols("sentence", "token", "word_embeddings", "pos")
  .setOutputCol("ner"
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"ner_crf"</code>, if no name is provided.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition">Models Hub</a>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/model-downloader/Running_Pretrained_pipelines.ipynb">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, POS, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html#sparknlp.annotator.ner.ner_crf.NerCrfModel">NerCrfModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel">NerCrfModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfModel.scala">NerCrfModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box tabs-new">

  <h2 id="nerdl">NerDL</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>This Named Entity recognition annotator allows to train generic NER model based on Neural Networks.</p>

    <p>The architecture of the neural network is a Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets.</p>

    <p>For instantiated/pretrained models, see NerDLModel.</p>

    <p>The training data should be a labeled Spark Dataset, in the format of <a href="/docs/en/training#conll-dataset">CoNLL</a>
2003 IOB with <code class="language-plaintext highlighter-rouge">Annotation</code> type columns. The data should have columns of type <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, WORD_EMBEDDINGS</code> and an
additional label column of annotator type <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code>.
Excluding the label, this can be done with for example</p>
    <ul>
      <li>a <a href="/docs/en/annotators#sentencedetector">SentenceDetector</a>,</li>
      <li>a <a href="/docs/en/annotators#tokenizer">Tokenizer</a> and</li>
      <li>a <a href="/docs/en/annotators#postagger-part-of-speech-tagger">PerceptronModel</a> and</li>
      <li>a <a href="/docs/en/annotators#wordembeddings">WordEmbeddingsModel</a>
  (any word embeddings can be chosen, e.g. <a href="/docs/en/transformers#bertembeddings">BertEmbeddings</a> for BERT based embeddings).</li>
    </ul>

    <p>Setting a test dataset to monitor model metrics can be done with <code class="language-plaintext highlighter-rouge">.setTestDataset</code>. The method
expects a path to a parquet file containing a dataframe that has the same required columns as
the training dataframe. The pre-processing steps for the training dataframe should also be
applied to the test dataframe. The following example will show how to create the test dataset
with a CoNLL dataset:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val documentAssembler = new DocumentAssembler()
  .setInputCol("text")
  .setOutputCol("document")

val embeddings = WordEmbeddingsModel
  .pretrained()
  .setInputCols("document", "token")
  .setOutputCol("embeddings")

val preProcessingPipeline = new Pipeline().setStages(Array(documentAssembler, embeddings))

val conll = CoNLL()
val Array(train, test) = conll
  .readDataset(spark, "src/test/resources/conll2003/eng.train")
  .randomSplit(Array(0.8, 0.2))

preProcessingPipeline
  .fit(test)
  .transform(test)
  .write
  .mode("overwrite")
  .parquet("test_data")

val nerTagger = new NerDLApproach()
  .setInputCols("document", "token", "embeddings")
  .setLabelColumn("label")
  .setOutputCol("ner")
  .setTestDataset("test_data")
</code></pre></div>    </div>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/jupyter/training/english/dl-ner">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLSpec.scala">NerDLSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/index.html#sparknlp.annotator.ner.ner_dl.NerDLApproach">NerDLApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach">NerDLApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach.scala">NerDLApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.BertEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.CoNLL</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDLApproach</span><span class="o">()</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>This Named Entity recognition annotator is a generic NER model based on Neural Networks.</p>

    <p>Neural Network architecture is Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets.</p>

    <p>This is the instantiated model of the NerDLApproach.
For training your own model, please see the documentation of that class.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val nerModel = NerDLModel.pretrained()
  .setInputCols("sentence", "token", "embeddings")
  .setOutputCol("ner")
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"ner_dl"</code>, if no name is provided.</p>

    <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition">Models Hub</a>.
Additionally, pretrained pipelines are available for this module, see <a href="https://nlp.johnsnowlabs.com/docs/en/pipelines">Pipelines</a>.</p>

    <p>Note that some pretrained models require specific types of embeddings, depending on which they were trained on.
For example, the default model <code class="language-plaintext highlighter-rouge">"ner_dl"</code> requires the
<a href="/docs/en/annotators#wordembeddings">WordEmbeddings</a> <code class="language-plaintext highlighter-rouge">"glove_100d"</code>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLSpec.scala">NerDLSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/index.html#sparknlp.annotator.ner.ner_dl.NerDLModel">NerDLModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel">NerDLModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLModel.scala">NerDLModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="neroverwriter">NerOverwriter</h2>

  <p>Overwrites entities of specified strings.</p>

  <p>The input for this Annotator have to be entities that are already extracted, Annotator type <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code>.
The strings specified with <code class="language-plaintext highlighter-rouge">setStopWords</code> will have new entities assigned to, specified with <code class="language-plaintext highlighter-rouge">setNewResult</code>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index.html#sparknlp.annotator.ner.ner_overwriter.NerOverwriter">NerOverwriter</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ner/NerOverwriter">NerOverwriter</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ner/NerOverwriter.scala">NerOverwriter</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First extract the prerequisite Entities
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert"</span><span class="p">)</span>

<span class="n">nerTagger</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"bert"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerTagger</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Spark NLP Crosses Five Million Downloads, John Snow Labs Announces."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1"># +------------------------------------------------------+
# |col                                                   |
# +------------------------------------------------------+
# |[named_entity, 0, 4, B-ORG, [word -&gt; Spark], []]      |
# |[named_entity, 6, 8, I-ORG, [word -&gt; NLP], []]        |
# |[named_entity, 10, 16, O, [word -&gt; Crosses], []]      |
# |[named_entity, 18, 21, O, [word -&gt; Five], []]         |
# |[named_entity, 23, 29, O, [word -&gt; Million], []]      |
# |[named_entity, 31, 39, O, [word -&gt; Downloads], []]    |
# |[named_entity, 40, 40, O, [word -&gt; ,], []]            |
# |[named_entity, 42, 45, B-ORG, [word -&gt; John], []]     |
# |[named_entity, 47, 50, I-ORG, [word -&gt; Snow], []]     |
# |[named_entity, 52, 55, I-ORG, [word -&gt; Labs], []]     |
# |[named_entity, 57, 65, I-ORG, [word -&gt; Announces], []]|
# |[named_entity, 66, 66, O, [word -&gt; .], []]            |
# +------------------------------------------------------+
</span>
<span class="c1"># The recognized entities can then be overwritten
</span><span class="n">nerOverwriter</span> <span class="o">=</span> <span class="n">NerOverwriter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_overwritten"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStopWords</span><span class="p">([</span><span class="s">"Million"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setNewResult</span><span class="p">(</span><span class="s">"B-CARDINAL"</span><span class="p">)</span>

<span class="n">nerOverwriter</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">).</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_overwritten)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                      <span class="o">|</span>
<span class="o">+---------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">ORG</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">Spark</span><span class="p">],</span> <span class="p">[]]</span>         <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">ORG</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">NLP</span><span class="p">],</span> <span class="p">[]]</span>           <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">Crosses</span><span class="p">],</span> <span class="p">[]]</span>         <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">Five</span><span class="p">],</span> <span class="p">[]]</span>            <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">CARDINAL</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">Million</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">Downloads</span><span class="p">],</span> <span class="p">[]]</span>       <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="p">,],</span> <span class="p">[]]</span>               <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">42</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">ORG</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">John</span><span class="p">],</span> <span class="p">[]]</span>        <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">47</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">ORG</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">Snow</span><span class="p">],</span> <span class="p">[]]</span>        <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">52</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">ORG</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">Labs</span><span class="p">],</span> <span class="p">[]]</span>        <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">57</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">ORG</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">Announces</span><span class="p">],</span> <span class="p">[]]</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">66</span><span class="p">,</span> <span class="mi">66</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="p">.],</span> <span class="p">[]]</span>               <span class="o">|</span>
<span class="o">+---------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.dl.NerDLModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ner.NerOverwriter</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First extract the prerequisite Entities</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"bert"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Spark NLP Crosses Five Million Downloads, John Snow Labs Announces."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(ner)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">/</span>
<span class="o">+------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                   <span class="o">|</span>
<span class="o">+------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">0</span>, <span class="err">4</span>, <span class="kt">B-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Spark</span><span class="o">]</span>, <span class="o">[]]</span>      <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">6</span>, <span class="err">8</span>, <span class="kt">I-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">NLP</span><span class="o">]</span>, <span class="o">[]]</span>        <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">10</span>, <span class="err">16</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Crosses</span><span class="o">]</span>, <span class="o">[]]</span>      <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">18</span>, <span class="err">21</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Five</span><span class="o">]</span>, <span class="o">[]]</span>         <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">23</span>, <span class="err">29</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Million</span><span class="o">]</span>, <span class="o">[]]</span>      <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">31</span>, <span class="err">39</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Downloads</span><span class="o">]</span>, <span class="o">[]]</span>    <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">40</span>, <span class="err">40</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> ,<span class="o">]</span>, <span class="o">[]]</span>            <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">42</span>, <span class="err">45</span>, <span class="kt">B-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">John</span><span class="o">]</span>, <span class="o">[]]</span>     <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">47</span>, <span class="err">50</span>, <span class="kt">I-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Snow</span><span class="o">]</span>, <span class="o">[]]</span>     <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">52</span>, <span class="err">55</span>, <span class="kt">I-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Labs</span><span class="o">]</span>, <span class="o">[]]</span>     <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">57</span>, <span class="err">65</span>, <span class="kt">I-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Announces</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">66</span>, <span class="err">66</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">.</span><span class="o">]</span>, <span class="o">[]]</span>            <span class="o">|</span>
<span class="o">+------------------------------------------------------+</span>
<span class="o">/</span>
<span class="c1">// The recognized entities can then be overwritten</span>
<span class="k">val</span> <span class="nv">nerOverwriter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerOverwriter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_overwritten"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStopWords</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"Million"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setNewResult</span><span class="o">(</span><span class="s">"B-CARDINAL"</span><span class="o">)</span>

<span class="nv">nerOverwriter</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">result</span><span class="o">).</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(ner_overwritten)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                      <span class="o">|</span>
<span class="o">+---------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">0</span>, <span class="err">4</span>, <span class="kt">B-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Spark</span><span class="o">]</span>, <span class="o">[]]</span>         <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">6</span>, <span class="err">8</span>, <span class="kt">I-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">NLP</span><span class="o">]</span>, <span class="o">[]]</span>           <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">10</span>, <span class="err">16</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Crosses</span><span class="o">]</span>, <span class="o">[]]</span>         <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">18</span>, <span class="err">21</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Five</span><span class="o">]</span>, <span class="o">[]]</span>            <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">23</span>, <span class="err">29</span>, <span class="kt">B-CARDINAL</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Million</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">31</span>, <span class="err">39</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Downloads</span><span class="o">]</span>, <span class="o">[]]</span>       <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">40</span>, <span class="err">40</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> ,<span class="o">]</span>, <span class="o">[]]</span>               <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">42</span>, <span class="err">45</span>, <span class="kt">B-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">John</span><span class="o">]</span>, <span class="o">[]]</span>        <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">47</span>, <span class="err">50</span>, <span class="kt">I-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Snow</span><span class="o">]</span>, <span class="o">[]]</span>        <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">52</span>, <span class="err">55</span>, <span class="kt">I-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Labs</span><span class="o">]</span>, <span class="o">[]]</span>        <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">57</span>, <span class="err">65</span>, <span class="kt">I-ORG</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">Announces</span><span class="o">]</span>, <span class="o">[]]</span>   <span class="o">|</span>
<span class="o">|[</span><span class="kt">named_entity</span>, <span class="err">66</span>, <span class="err">66</span>, <span class="kt">O</span>, <span class="o">[</span><span class="kt">word</span> <span class="kt">-&gt;</span> <span class="kt">.</span><span class="o">]</span>, <span class="o">[]]</span>               <span class="o">|</span>
<span class="o">+---------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box tabs-new">

  <h2 id="normalizer">Normalizer</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Annotator that cleans out tokens. Requires stems, hence tokens.
Removes all dirty characters from text following a regex pattern and transforms words based on a provided dictionary</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/normalizer/index.html#sparknlp.annotator.normalizer.Normalizer">Normalizer</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/Normalizer">Normalizer</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Normalizer.scala">Normalizer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLowercase</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanupPatterns</span><span class="p">([</span><span class="s">"""[^\w\d\s]"""</span><span class="p">])</span> <span class="c1"># remove punctuations (keep alphanumeric chars)
# if we don't set CleanupPatterns, it will only keep alphabet letters ([^A-Za-z])
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">normalizer</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"John and Peter are brothers. However they don't support each other that much."</span><span class="p">]])</span> \
    <span class="p">.</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"normalized.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                  <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">john</span><span class="p">,</span> <span class="ow">and</span><span class="p">,</span> <span class="n">peter</span><span class="p">,</span> <span class="n">are</span><span class="p">,</span> <span class="n">brothers</span><span class="p">,</span> <span class="n">however</span><span class="p">,</span> <span class="n">they</span><span class="p">,</span> <span class="n">dont</span><span class="p">,</span> <span class="n">support</span><span class="p">,</span> <span class="n">each</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">that</span><span class="p">,</span> <span class="n">much</span><span class="p">]</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.</span><span class="o">{</span><span class="nc">Normalizer</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLowercase</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanupPatterns</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"""[^\w\d\s]"""</span><span class="o">))</span> <span class="c1">// remove punctuations (keep alphanumeric chars)</span>
<span class="c1">// if we don't set CleanupPatterns, it will only keep alphabet letters ([^A-Za-z])</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">normalizer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"John and Peter are brothers. However they don't support each other that much."</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"normalized.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                  <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">john</span>, <span class="kt">and</span>, <span class="kt">peter</span>, <span class="kt">are</span>, <span class="kt">brothers</span>, <span class="kt">however</span>, <span class="kt">they</span>, <span class="kt">dont</span>, <span class="kt">support</span>, <span class="kt">each</span>, <span class="kt">other</span>, <span class="kt">that</span>, <span class="kt">much</span><span class="o">]|</span>
<span class="o">+----------------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Instantiated Model of the Normalizer. For usage and examples, please see the documentation of that class.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/normalizer/index.html#sparknlp.annotator.normalizer.NormalizerModel">NormalizerModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/NormalizerModel">NormalizerModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/NormalizerModel.scala">NormalizerModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box tabs-new">

  <h2 id="norvigsweeting-spellchecker">NorvigSweeting Spellchecker</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains annotator, that retrieves tokens and makes corrections automatically if not found in an English dictionary.</p>

    <p>The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and
dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster
(than the standard approach with deletes + transposes + replaces + inserts) and language independent.
A dictionary of correct spellings must be provided with <code class="language-plaintext highlighter-rouge">setDictionary</code> as a text file, where each word is parsed by a regex pattern.</p>

    <p>Inspired by Norvig model and <a href="https://github.com/wolfgarbe/SymSpell">SymSpell</a>.</p>

    <p>For instantiated/pretrained models, see NorvigSweetingModel.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/vivekn-sentiment/VivekNarayanSentimentApproach.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingTestSpec.scala">NorvigSweetingTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach">NorvigSweetingApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach">NorvigSweetingApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach.scala">NorvigSweetingApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># In this example, the dictionary `"words.txt"` has the form of
#
# ...
# gummy
# gummic
# gummier
# gummiest
# gummiferous
# ...
#
# This dictionary is then set to be the basis of the spell checker.
</span>
<span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">spellChecker</span> <span class="o">=</span> <span class="n">NorvigSweetingApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"spell"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"src/test/resources/spell/words.txt"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">spellChecker</span>
<span class="p">])</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the dictionary `"words.txt"` has the form of</span>
<span class="c1">//</span>
<span class="c1">// ...</span>
<span class="c1">// gummy</span>
<span class="c1">// gummic</span>
<span class="c1">// gummier</span>
<span class="c1">// gummiest</span>
<span class="c1">// gummiferous</span>
<span class="c1">// ...</span>
<span class="c1">//</span>
<span class="c1">// This dictionary is then set to be the basis of the spell checker.</span>

<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.spell.norvig.NorvigSweetingApproach</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">spellChecker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NorvigSweetingApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"spell"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"src/test/resources/spell/words.txt"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">spellChecker</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>This annotator retrieves tokens and makes corrections automatically if not found in an English dictionary.
Inspired by Norvig model and <a href="https://github.com/wolfgarbe/SymSpell">SymSpell</a>.</p>

    <p>The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and
dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster
(than the standard approach with deletes + transposes + replaces + inserts) and language independent.</p>

    <p>This is the instantiated model of the NorvigSweetingApproach.
For training your own model, please see the documentation of that class.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val spellChecker = NorvigSweetingModel.pretrained()
  .setInputCols("token")
  .setOutputCol("spell")
  .setDoubleVariants(true)
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"spellcheck_norvig"</code>, if no name is provided.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Spell+Check">Models Hub</a>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/vivekn-sentiment/VivekNarayanSentimentApproach.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingTestSpec.scala">NorvigSweetingTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel">NorvigSweetingModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel">NorvigSweetingModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel.scala">NorvigSweetingModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box tabs-new">

  <h2 id="postagger-part-of-speech-tagger">POSTagger (Part of speech tagger)</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains an averaged Perceptron model to tag words part-of-speech.
Sets a POS tag to each word within a sentence.</p>

    <p>For pretrained models please see the PerceptronModel.</p>

    <p>The training data needs to be in a Spark DataFrame, where the column needs to consist of
<a href="/api/com/johnsnowlabs/nlp/Annotation">Annotations</a> of type <code class="language-plaintext highlighter-rouge">POS</code>. The <code class="language-plaintext highlighter-rouge">Annotation</code> needs to have member <code class="language-plaintext highlighter-rouge">result</code>
set to the POS tag and have a <code class="language-plaintext highlighter-rouge">"word"</code> mapping to its word inside of member <code class="language-plaintext highlighter-rouge">metadata</code>.
This DataFrame for training can easily created by the helper class <a href="/docs/en/training#pos-dataset">POS</a>.</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>POS().readDataset(spark, datasetPath).selectExpr("explode(tags) as tags").show(false)
+---------------------------------------------+
|tags                                         |
+---------------------------------------------+
|[pos, 0, 5, NNP, [word -&gt; Pierre], []]       |
|[pos, 7, 12, NNP, [word -&gt; Vinken], []]      |
|[pos, 14, 14, ,, [word -&gt; ,], []]            |
|[pos, 31, 34, MD, [word -&gt; will], []]        |
|[pos, 36, 39, VB, [word -&gt; join], []]        |
|[pos, 41, 43, DT, [word -&gt; the], []]         |
|[pos, 45, 49, NN, [word -&gt; board], []]       |
                      ...
</code></pre></div>    </div>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/french/Train-Perceptron-French.ipynb">Spark NLP Workshop</a>
and <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron">PerceptronApproach tests</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">POS</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/index.html#sparknlp.annotator.pos.perceptron.PerceptronApproach">PerceptronApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach">PerceptronApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach.scala">PerceptronApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">datasetPath</span> <span class="o">=</span> <span class="s">"src/test/resources/anc-pos-corpus-small/test-training.txt"</span>
<span class="n">trainingPerceptronDF</span> <span class="o">=</span> <span class="n">POS</span><span class="p">().</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="n">datasetPath</span><span class="p">)</span>

<span class="n">trainedPos</span> <span class="o">=</span> <span class="n">PerceptronApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPosColumn</span><span class="p">(</span><span class="s">"tags"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingPerceptronDF</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">trainedPos</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"To be or not to be, is this the question?"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"pos.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                            <span class="o">|</span>
<span class="o">+--------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">NNP</span><span class="p">,</span> <span class="n">NNP</span><span class="p">,</span> <span class="n">CD</span><span class="p">,</span> <span class="n">JJ</span><span class="p">,</span> <span class="n">NNP</span><span class="p">,</span> <span class="n">NNP</span><span class="p">,</span> <span class="p">,,</span> <span class="n">MD</span><span class="p">,</span> <span class="n">VB</span><span class="p">,</span> <span class="n">DT</span><span class="p">,</span> <span class="n">CD</span><span class="p">,</span> <span class="p">.]</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.POS</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronApproach</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">datasetPath</span> <span class="k">=</span> <span class="s">"src/test/resources/anc-pos-corpus-small/test-training.txt"</span>
<span class="k">val</span> <span class="nv">trainingPerceptronDF</span> <span class="k">=</span> <span class="nc">POS</span><span class="o">().</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="n">datasetPath</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainedPos</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PerceptronApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPosColumn</span><span class="o">(</span><span class="s">"tags"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingPerceptronDF</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">trainedPos</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"To be or not to be, is this the question?"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"pos.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                            <span class="o">|</span>
<span class="o">+--------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">NNP</span>, <span class="kt">NNP</span>, <span class="kt">CD</span>, <span class="kt">JJ</span>, <span class="kt">NNP</span>, <span class="kt">NNP</span>, ,, <span class="kt">MD</span>, <span class="kt">VB</span>, <span class="kt">DT</span>, <span class="kt">CD</span>, <span class="kt">.</span><span class="o">]|</span>
<span class="o">+--------------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Averaged Perceptron model to tag words part-of-speech.
Sets a POS tag to each word within a sentence.</p>

    <p>This is the instantiated model of the PerceptronApproach.
For training your own model, please see the documentation of that class.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val posTagger = PerceptronModel.pretrained()
  .setInputCols("document", "token")
  .setOutputCol("pos")
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"pos_anc"</code>, if no name is provided.</p>

    <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Part+of+Speech+Tagging">Models Hub</a>.
Additionally, pretrained pipelines are available for this module, see <a href="https://nlp.johnsnowlabs.com/docs/en/pipelines">Pipelines</a>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">POS</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/index.html#sparknlp.annotator.pos.perceptron.PerceptronModel">PerceptronModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel">PerceptronModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel.scala">PerceptronModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box tabs-new">

  <h2 id="recursivetokenizer">RecursiveTokenizer</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Tokenizes raw text recursively based on a handful of definable rules.</p>

    <p>Unlike the Tokenizer, the RecursiveTokenizer operates based on these array string parameters only:</p>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">prefixes</code>: Strings that will be split when found at the beginning of token.</li>
      <li><code class="language-plaintext highlighter-rouge">suffixes</code>: Strings that will be split when found at the end of token.</li>
      <li><code class="language-plaintext highlighter-rouge">infixes</code>: Strings that will be split when found at the middle of token.</li>
      <li><code class="language-plaintext highlighter-rouge">whitelist</code>: Whitelist of strings not to split</li>
    </ul>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/7.Context_Spell_Checker.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/TokenizerTestSpec.scala">TokenizerTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index.html#sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizer">RecursiveTokenizer</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizer">RecursiveTokenizer</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/RecursiveTokenizer.scala">RecursiveTokenizer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RecursiveTokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"One, after the Other, (and) again. PO, QAM,"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"token.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                            <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">One</span><span class="p">,</span> <span class="p">,,</span> <span class="n">after</span><span class="p">,</span> <span class="n">the</span><span class="p">,</span> <span class="n">Other</span><span class="p">,</span> <span class="p">,,</span> <span class="p">(,</span> <span class="ow">and</span><span class="p">,</span> <span class="p">),</span> <span class="n">again</span><span class="p">,</span> <span class="p">.,</span> <span class="n">PO</span><span class="p">,</span> <span class="p">,,</span> <span class="n">QAM</span><span class="p">,</span> <span class="p">,]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.RecursiveTokenizer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RecursiveTokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"One, after the Other, (and) again. PO, QAM,"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"token.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                            <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">One</span>, ,, <span class="kt">after</span>, <span class="kt">the</span>, <span class="kt">Other</span>, ,, <span class="o">(</span>, <span class="kt">and</span>, <span class="o">)</span>, <span class="kt">again</span>, <span class="kt">.</span>, <span class="kt">PO</span>, ,, <span class="kt">QAM</span>, ,<span class="o">]|</span>
<span class="o">+------------------------------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Instantiated model of the RecursiveTokenizer.
For usage and examples see the documentation of the main class.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/token/recursive_tokenizer/index.html#sparknlp.annotator.token.recursive_tokenizer.RecursiveTokenizerModel">RecursiveTokenizerModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/RecursiveTokenizerModel">RecursiveTokenizerModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/RecursiveTokenizerModel.scala">RecursiveTokenizerModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box tabs-new">

  <h2 id="regexmatcher">RegexMatcher</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Uses rules to match a set of regular expressions and associate them with a provided
identifier.</p>

    <p>A rule consists of a regex pattern and an identifier, delimited by a character of choice. An
example could be <code class="language-plaintext highlighter-rouge">"\d{4}\/\d\d\/\d\d,date"</code> which will match strings like <code class="language-plaintext highlighter-rouge">"1970/01/01"</code> to the
identifier <code class="language-plaintext highlighter-rouge">"date"</code>.</p>

    <p>Rules must be provided by either <code class="language-plaintext highlighter-rouge">setRules</code> (followed by <code class="language-plaintext highlighter-rouge">setDelimiter</code>) or an external file.</p>

    <p>To use an external file, a dictionary of predefined regular expressions must be provided with
<code class="language-plaintext highlighter-rouge">setExternalRules</code>. The dictionary can be set as a delimited text file.</p>

    <p>Pretrained pipelines are available for this module, see <a href="https://nlp.johnsnowlabs.com/docs/en/pipelines">Pipelines</a>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/RegexMatcherTestSpec.scala">RegexMatcherTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index.html#sparknlp.annotator.matcher.regex_matcher.RegexMatcher">RegexMatcher</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/RegexMatcher">RegexMatcher</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/RegexMatcher.scala">RegexMatcher</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># In this example, the `rules.txt` has the form of
#
# the\s\w+, followed by 'the'
# ceremonies, ceremony
#
# where each regex is separated by the identifier by `","`
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">regexMatcher</span> <span class="o">=</span> <span class="n">RegexMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setExternalRules</span><span class="p">(</span><span class="s">"src/test/resources/regex-matcher/rules.txt"</span><span class="p">,</span>  <span class="s">","</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStrategy</span><span class="p">(</span><span class="s">"MATCH_ALL"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">regexMatcher</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span>
    <span class="s">"My first sentence with the first rule. This is my second sentence with ceremonies rule."</span>
<span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(regex) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                      <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="n">the</span> <span class="n">first</span><span class="p">,</span> <span class="p">[</span><span class="n">identifier</span> <span class="o">-&gt;</span> <span class="n">followed</span> <span class="n">by</span> <span class="s">'the'</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">71</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="n">ceremonies</span><span class="p">,</span> <span class="p">[</span><span class="n">identifier</span> <span class="o">-&gt;</span> <span class="n">ceremony</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span>        <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the `rules.txt` has the form of</span>
<span class="c1">//</span>
<span class="c1">// the\s\w+, followed by 'the'</span>
<span class="c1">// ceremonies, ceremony</span>
<span class="c1">//</span>
<span class="c1">// where each regex is separated by the identifier by `","`</span>
<span class="k">import</span> <span class="nn">ResourceHelper.spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.RegexMatcher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">regexMatcher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexMatcher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setExternalRules</span><span class="o">(</span><span class="s">"src/test/resources/regex-matcher/rules.txt"</span><span class="o">,</span>  <span class="s">","</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regex"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStrategy</span><span class="o">(</span><span class="s">"MATCH_ALL"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">sentence</span><span class="o">,</span> <span class="n">regexMatcher</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"My first sentence with the first rule. This is my second sentence with ceremonies rule."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">results</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(regex) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                      <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">23</span>, <span class="err">31</span>, <span class="kt">the</span> <span class="kt">first</span>, <span class="o">[</span><span class="kt">identifier</span> <span class="kt">-&gt;</span> <span class="kt">followed</span> <span class="kt">by</span> <span class="kt">'the'</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">71</span>, <span class="err">80</span>, <span class="kt">ceremonies</span>, <span class="o">[</span><span class="kt">identifier</span> <span class="kt">-&gt;</span> <span class="kt">ceremony</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">1</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]</span>        <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Instantiated model of the RegexMatcher.
For usage and examples see the documentation of the main class.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index.html#sparknlp.annotator.matcher.regex_matcher.RegexMatcherModel">RegexMatcherModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/RegexMatcherModel">RegexMatcherModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/RegexMatcherModel.scala">RegexMatcherModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="regextokenizer">RegexTokenizer</h2>

  <p>A tokenizer that splits text by a regex pattern.</p>

  <p>The pattern needs to be set with <code class="language-plaintext highlighter-rouge">setPattern</code> and this sets the delimiting pattern or how the tokens should be split.
By default this pattern is <code class="language-plaintext highlighter-rouge">\s+</code> which means that tokens should be split by 1 or more whitespace characters.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index.html#sparknlp.annotator.token.regex_tokenizer.RegexTokenizer">RegexTokenizer</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/RegexTokenizer">RegexTokenizer</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/RegexTokenizer.scala">RegexTokenizer</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">regexTokenizer</span> <span class="o">=</span> <span class="n">RegexTokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regexToken"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setToLowercase</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPattern</span><span class="p">(</span><span class="s">"</span><span class="se">\\</span><span class="s">s+"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">regexTokenizer</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is my first sentence.</span><span class="se">\n</span><span class="s">This is my second."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"regexToken.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                 <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">this</span><span class="p">,</span> <span class="ow">is</span><span class="p">,</span> <span class="n">my</span><span class="p">,</span> <span class="n">first</span><span class="p">,</span> <span class="n">sentence</span><span class="p">.,</span> <span class="n">this</span><span class="p">,</span> <span class="ow">is</span><span class="p">,</span> <span class="n">my</span><span class="p">,</span> <span class="n">second</span><span class="p">.]</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.RegexTokenizer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">regexTokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexTokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regexToken"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setToLowercase</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPattern</span><span class="o">(</span><span class="s">"\\s+"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">regexTokenizer</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is my first sentence.\nThis is my second."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"regexToken.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                 <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">this</span>, <span class="kt">is</span>, <span class="kt">my</span>, <span class="kt">first</span>, <span class="kt">sentence.</span>, <span class="kt">this</span>, <span class="kt">is</span>, <span class="kt">my</span>, <span class="kt">second.</span><span class="o">]|</span>
<span class="o">+-------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="sentencedetector">SentenceDetector</h2>

  <p>Annotator that detects sentence boundaries using regular expressions.</p>

  <p>The following characters are checked as sentence boundaries:</p>

  <ol>
    <li>Lists (“(i), (ii)”, “(a), (b)”, “1., 2.”)</li>
    <li>Numbers</li>
    <li>Abbreviations</li>
    <li>Punctuations</li>
    <li>Multiple Periods</li>
    <li>Geo-Locations/Coordinates (“N°. 1026.253.553.”)</li>
    <li>Ellipsis (“…”)</li>
    <li>In-between punctuations</li>
    <li>Quotation marks</li>
    <li>Exclamation Points</li>
    <li>Basic Breakers (“.”, “;”)</li>
  </ol>

  <p>For the explicit regular expressions used for detection, refer to source of
<a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/PragmaticContentFormatter.scala">PragmaticContentFormatter</a>.</p>

  <p>To add additional custom bounds, the parameter <code class="language-plaintext highlighter-rouge">customBounds</code> can be set with an array:</p>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sentence = new SentenceDetector()
  .setInputCols("document")
  .setOutputCol("sentence")
  .setCustomBounds(Array("\n\n"))
</code></pre></div>  </div>

  <p>If only the custom bounds should be used, then the parameter <code class="language-plaintext highlighter-rouge">useCustomBoundsOnly</code> should be set to <code class="language-plaintext highlighter-rouge">true</code>.</p>

  <p>Each extracted sentence can be returned in an Array or exploded to separate rows,
if <code class="language-plaintext highlighter-rouge">explodeSentences</code> is set to <code class="language-plaintext highlighter-rouge">true</code>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index.html#sparknlp.annotator.sentence.sentence_detector.SentenceDetector">SentenceDetector</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector">SentenceDetector</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sbd/pragmatic/SentenceDetector.scala">SentenceDetector</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCustomBounds</span><span class="p">([</span><span class="s">"</span><span class="se">\n\n</span><span class="s">"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is my first sentence. This my second. How about a third?"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(sentence) as sentences"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">sentences</span>                                                         <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">This</span> <span class="ow">is</span> <span class="n">my</span> <span class="n">first</span> <span class="n">sentence</span><span class="p">.,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="mi">41</span><span class="p">,</span> <span class="n">This</span> <span class="n">my</span> <span class="n">second</span><span class="p">.,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[]]</span>          <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="n">How</span> <span class="n">about</span> <span class="n">a</span> <span class="n">third</span><span class="err">?</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[]]</span>       <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetector</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCustomBounds</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"\n\n"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is my first sentence. This my second. How about a third?"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(sentence) as sentences"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">sentences</span>                                                         <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">25</span>, <span class="kt">This</span> <span class="kt">is</span> <span class="kt">my</span> <span class="kt">first</span> <span class="kt">sentence.</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">|[</span><span class="kt">document</span>, <span class="err">27</span>, <span class="err">41</span>, <span class="kt">This</span> <span class="kt">my</span> <span class="kt">second.</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">1</span><span class="o">]</span>, <span class="o">[]]</span>          <span class="o">|</span>
<span class="o">|[</span><span class="kt">document</span>, <span class="err">43</span>, <span class="err">60</span>, <span class="kt">How</span> <span class="kt">about</span> <span class="kt">a</span> <span class="kt">third?</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">2</span><span class="o">]</span>, <span class="o">[]]</span>       <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box tabs-new">

  <h2 id="sentencedetectordl">SentenceDetectorDL</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains an annotator that detects sentence boundaries using a deep learning approach.</p>

    <p>For pretrained models see SentenceDetectorDLModel.</p>

    <p>Currently, only the CNN model is supported for training, but in the future the architecture of the model can
be set with <code class="language-plaintext highlighter-rouge">setModelArchitecture</code>.</p>

    <p>The default model <code class="language-plaintext highlighter-rouge">"cnn"</code> is based on the paper
<a href="https://konvens.org/proceedings/2019/papers/KONVENS2019_paper_41.pdf">Deep-EOS: General-Purpose Neural Networks for Sentence Boundary Detection (2020, Stefan Schweter, Sajawel Ahmed)</a>
using a CNN architecture. We also modified the original implementation a little bit to cover broken sentences and some impossible end of line chars.</p>

    <p>Each extracted sentence can be returned in an Array or exploded to separate rows,
if <code class="language-plaintext highlighter-rouge">explodeSentences</code> is set to <code class="language-plaintext highlighter-rouge">true</code>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/9.SentenceDetectorDL.ipynb">Spark NLP Workshop</a> and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLSpec.scala">SentenceDetectorDLSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.html#sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach">SentenceDetectorDLApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLApproach">SentenceDetectorDLApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLApproach.scala">SentenceDetectorDLApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The training process needs data, where each data point is a sentence.
# In this example the `train.txt` file has the form of
#
# ...
# Slightly more moderate language would make our present situation – namely the lack of progress – a little easier.
# His political successors now have great responsibilities to history and to the heritage of values bequeathed to them by Nelson Mandela.
# ...
#
# where each line is one sentence.
# Training can then be started like so:
</span>
<span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">trainingData</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="s">"train.txt"</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetectorDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">sentenceDetector</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// The training process needs data, where each data point is a sentence.</span>
<span class="c1">// In this example the `train.txt` file has the form of</span>
<span class="c1">//</span>
<span class="c1">// ...</span>
<span class="c1">// Slightly more moderate language would make our present situation – namely the lack of progress – a little easier.</span>
<span class="c1">// His political successors now have great responsibilities to history and to the heritage of values bequeathed to them by Nelson Mandela.</span>
<span class="c1">// ...</span>
<span class="c1">//</span>
<span class="c1">// where each line is one sentence.</span>
<span class="c1">// Training can then be started like so:</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sentence_detector_dl.SentenceDetectorDLApproach</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">text</span><span class="o">(</span><span class="s">"train.txt"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetectorDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">sentenceDetector</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Annotator that detects sentence boundaries using a deep learning approach.</p>

    <p>Instantiated Model of the SentenceDetectorDLApproach.
Detects sentence boundaries using a deep learning approach.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sentenceDL = SentenceDetectorDLModel.pretrained()
  .setInputCols("document")
  .setOutputCol("sentencesDL")
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"sentence_detector_dl"</code>, if no name is provided.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Sentence+Detection">Models Hub</a>.</p>

    <p>Each extracted sentence can be returned in an Array or exploded to separate rows,
if <code class="language-plaintext highlighter-rouge">explodeSentences</code> is set to <code class="language-plaintext highlighter-rouge">true</code>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLSpec.scala">SentenceDetectorDLSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.html#sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLModel">SentenceDetectorDLModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLModel">SentenceDetectorDLModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLModel.scala">SentenceDetectorDLModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="sentenceembeddings">SentenceEmbeddings</h2>

  <p>Converts the results from WordEmbeddings, BertEmbeddings, or ElmoEmbeddings into sentence
or document embeddings by either summing up or averaging all the word embeddings in a sentence or a document
(depending on the inputCols).</p>

  <p>This can be configured with <code class="language-plaintext highlighter-rouge">setPoolingStrategy</code>, which either be <code class="language-plaintext highlighter-rouge">"AVERAGE"</code> or <code class="language-plaintext highlighter-rouge">"SUM"</code>.</p>

  <p>For more extended examples see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.1_Text_classification_examples_in_SparkML_SparkNLP.ipynb">Spark NLP Workshop</a>.
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddingsTestSpec.scala">SentenceEmbeddingsTestSpec</a>.</p>

  <p><strong>TIP:</strong> Here is how you can explode and convert these embeddings into <code class="language-plaintext highlighter-rouge">Vectors</code> or what’s known as <code class="language-plaintext highlighter-rouge">Feature</code> column so it can be used in Spark ML regression or clustering functions:</p>

  <div class="tabs-box tabs-new">

    <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">org.apache.spark.ml.linal</span> <span class="kn">import</span> <span class="n">Vector</span><span class="p">,</span> <span class="n">Vectors</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">udf</span>
<span class="c1"># Let's create a UDF to take array of embeddings and output Vectors
</span><span class="o">@</span><span class="n">udf</span><span class="p">(</span><span class="n">Vector</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">convertToVectorUDF</span><span class="p">(</span><span class="n">matrix</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Vectors</span><span class="p">.</span><span class="n">dense</span><span class="p">(</span><span class="n">matrix</span><span class="p">.</span><span class="n">toArray</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">_</span><span class="p">.</span><span class="n">toDouble</span><span class="p">))</span>


<span class="c1"># Now let's explode the sentence_embeddings column and have a new feature column for Spark ML
</span><span class="n">pipelineDF</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">explode</span><span class="p">(</span><span class="s">"sentence_embeddings.embeddings"</span><span class="p">).</span><span class="k">as</span><span class="p">(</span><span class="s">"sentence_embedding"</span><span class="p">))</span>
<span class="p">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">"features"</span><span class="p">,</span> <span class="n">convertToVectorUDF</span><span class="p">(</span><span class="s">"sentence_embedding"</span><span class="p">))</span>
</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">org.apache.spark.ml.linalg.</span><span class="o">{</span><span class="nc">Vector</span><span class="o">,</span> <span class="nc">Vectors</span><span class="o">}</span>

<span class="c1">// Let's create a UDF to take array of embeddings and output Vectors</span>
<span class="k">val</span> <span class="nv">convertToVectorUDF</span> <span class="k">=</span> <span class="nf">udf</span><span class="o">((</span><span class="n">matrix</span> <span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">Float</span><span class="o">])</span> <span class="k">=&gt;</span> <span class="o">{</span>
    <span class="nv">Vectors</span><span class="o">.</span><span class="py">dense</span><span class="o">(</span><span class="nv">matrix</span><span class="o">.</span><span class="py">toArray</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="nv">_</span><span class="o">.</span><span class="py">toDouble</span><span class="o">))</span>
<span class="o">})</span>

<span class="c1">// Now let's explode the sentence_embeddings column and have a new feature column for Spark ML</span>
<span class="nv">pipelineDF</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="nf">explode</span><span class="o">(</span><span class="n">$</span><span class="s">"sentence_embeddings.embeddings"</span><span class="o">).</span><span class="py">as</span><span class="o">(</span><span class="s">"sentence_embedding"</span><span class="o">))</span>
<span class="o">.</span><span class="py">withColumn</span><span class="o">(</span><span class="s">"features"</span><span class="o">,</span> <span class="nf">convertToVectorUDF</span><span class="o">(</span><span class="n">$</span><span class="s">"sentence_embedding"</span><span class="o">))</span>
</code></pre></div>    </div>
  </div>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, WORD_EMBEDDINGS</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

  <blockquote>
    <p><strong>Note:</strong> If you choose <code class="language-plaintext highlighter-rouge">document</code> as your input for <code class="language-plaintext highlighter-rouge">Tokenizer</code>, <code class="language-plaintext highlighter-rouge">WordEmbeddings</code>/<code class="language-plaintext highlighter-rouge">BertEmbeddings</code>, and <code class="language-plaintext highlighter-rouge">SentenceEmbeddings</code> then it averages/sums all the embeddings into one array of embeddings. However, if you choose <code class="language-plaintext highlighter-rouge">sentence</code> as <code class="language-plaintext highlighter-rouge">inputCols</code> then for each sentence <code class="language-plaintext highlighter-rouge">SentenceEmbeddings</code> generates one array of embeddings.</p>
  </blockquote>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index.html#sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings">SentenceEmbeddings</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings">SentenceEmbeddings</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings.scala">SentenceEmbeddings</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">embeddingsSentence</span> <span class="o">=</span> <span class="n">SentenceEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">embeddingsSentence</span><span class="p">,</span>
      <span class="n">embeddingsFinisher</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.22093398869037628</span><span class="p">,</span><span class="mf">0.25130119919776917</span><span class="p">,</span><span class="mf">0.41810303926467896</span><span class="p">,</span><span class="o">-</span><span class="mf">0.380883991718</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.WordEmbeddingsModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.SentenceEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsSentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"AVERAGE"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">embeddingsSentence</span><span class="o">,</span>
    <span class="n">embeddingsFinisher</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">22093398869037628</span>,<span class="err">0</span><span class="kt">.</span><span class="err">25130119919776917</span>,<span class="err">0</span><span class="kt">.</span><span class="err">41810303926467896</span>,<span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">380883991718</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box tabs-new">

  <h2 id="sentimentdl">SentimentDL</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a SentimentDL, an annotator for multi-class sentiment analysis.</p>

    <p>In natural language processing, sentiment analysis is the task of classifying the affective state or subjective view
of a text. A common example is if either a product review or tweet can be interpreted positively or negatively.</p>

    <p>For the instantiated/pretrained models, see SentimentDLModel.</p>

    <p><strong>Notes</strong>:</p>
    <ul>
      <li>This annotator accepts a label column of a single item in either type of
String, Int, Float, or Double. So positive sentiment can be expressed as
either <code class="language-plaintext highlighter-rouge">"positive"</code> or <code class="language-plaintext highlighter-rouge">0</code>, negative sentiment as <code class="language-plaintext highlighter-rouge">"negative"</code> or <code class="language-plaintext highlighter-rouge">1</code>.</li>
      <li><a href="/docs/en/transformers#universalsentenceencoder">UniversalSentenceEncoder</a>,
<a href="/docs/en/transformers#bertsentenceembeddings">BertSentenceEmbeddings</a>,
<a href="/docs/en/annotators#sentenceembeddings">SentenceEmbeddings</a> or other
sentence based embeddings can be used</li>
    </ul>

    <p>Setting a test dataset to monitor model metrics can be done with <code class="language-plaintext highlighter-rouge">.setTestDataset</code>. The method
expects a path to a parquet file containing a dataframe that has the same required columns as
the training dataframe. The pre-processing steps for the training dataframe should also be
applied to the test dataframe. The following example will show how to create the test dataset:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val documentAssembler = new DocumentAssembler()
  .setInputCol("text")
  .setOutputCol("document")

val embeddings = UniversalSentenceEncoder.pretrained()
  .setInputCols("document")
  .setOutputCol("sentence_embeddings")

val preProcessingPipeline = new Pipeline().setStages(Array(documentAssembler, embeddings))

val Array(train, test) = data.randomSplit(Array(0.8, 0.2))
preProcessingPipeline
  .fit(test)
  .transform(test)
  .write
  .mode("overwrite")
  .parquet("test_data")

val classifier = new SentimentDLApproach()
  .setInputCols("sentence_embeddings")
  .setOutputCol("sentiment")
  .setLabelColumn("label")
  .setTestDataset("test_data")
</code></pre></div>    </div>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/classification/SentimentDL_train_multiclass_sentiment_classifier.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLTestSpec.scala">SentimentDLTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index.html#sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach">SentimentDLApproach</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLApproach">SentimentDLApproach</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLApproach.scala">SentimentDLApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># In this example, `sentiment.csv` is in the form
#
# text,label
# This movie is the best movie I have watched ever! In my opinion this movie can win an award.,0
# This was a terrible movie! The acting was bad really bad!,1
#
# The model can then be trained with
</span>
<span class="n">smallCorpus</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"header"</span><span class="p">,</span> <span class="s">"True"</span><span class="p">).</span><span class="n">csv</span><span class="p">(</span><span class="s">"src/test/resources/classifier/sentiment.csv"</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">useEmbeddings</span> <span class="o">=</span> <span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">docClassifier</span> <span class="o">=</span> <span class="n">SentimentDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentiment"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLr</span><span class="p">(</span><span class="mf">5e-3</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">(</span>
      <span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">useEmbeddings</span><span class="p">,</span>
        <span class="n">docClassifier</span>
      <span class="p">]</span>
    <span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">smallCorpus</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, `sentiment.csv` is in the form</span>
<span class="c1">//</span>
<span class="c1">// text,label</span>
<span class="c1">// This movie is the best movie I have watched ever! In my opinion this movie can win an award.,0</span>
<span class="c1">// This was a terrible movie! The acting was bad really bad!,1</span>
<span class="c1">//</span>
<span class="c1">// The model can then be trained with</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.UniversalSentenceEncoder</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.classifier.dl.</span><span class="o">{</span><span class="nc">SentimentDLApproach</span><span class="o">,</span> <span class="nc">SentimentDLModel</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">smallCorpus</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">read</span><span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"header"</span><span class="o">,</span> <span class="s">"true"</span><span class="o">).</span><span class="py">csv</span><span class="o">(</span><span class="s">"src/test/resources/classifier/sentiment.csv"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">useEmbeddings</span> <span class="k">=</span> <span class="nv">UniversalSentenceEncoder</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">docClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentimentDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentiment"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">32</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mi">5</span><span class="n">e</span><span class="o">-</span><span class="mf">3f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span>
    <span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span>
      <span class="n">useEmbeddings</span><span class="o">,</span>
      <span class="n">docClassifier</span>
    <span class="o">)</span>
  <span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">smallCorpus</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>SentimentDL, an annotator for multi-class sentiment analysis.</p>

    <p>In natural language processing, sentiment analysis is the task of classifying the affective state or subjective view
of a text. A common example is if either a product review or tweet can be interpreted positively or negatively.</p>

    <p>This is the instantiated model of the SentimentDLApproach.
For training your own model, please see the documentation of that class.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val sentiment = SentimentDLModel.pretrained()
  .setInputCols("sentence_embeddings")
  .setOutputCol("sentiment")
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"sentimentdl_use_imdb"</code>, if no name is provided. It is english sentiment analysis trained on
the IMDB dataset.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Sentiment+Analysis">Models Hub</a>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLTestSpec.scala">SentimentDLTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index.html#sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLModel">SentimentDLModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel">SentimentDLModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/classifier/dl/SentimentDLModel.scala">SentimentDLModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box tabs-new">

  <h2 id="sentimentdetector">SentimentDetector</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a rule based sentiment detector, which calculates a score based on predefined keywords.</p>

    <p>A dictionary of predefined sentiment keywords must be provided with <code class="language-plaintext highlighter-rouge">setDictionary</code>, where each line is a word
delimited to its class (either <code class="language-plaintext highlighter-rouge">positive</code> or <code class="language-plaintext highlighter-rouge">negative</code>).
The dictionary can be set as a delimited text file.</p>

    <p>By default, the sentiment score will be assigned labels <code class="language-plaintext highlighter-rouge">"positive"</code> if the score is <code class="language-plaintext highlighter-rouge">&gt;= 0</code>, else <code class="language-plaintext highlighter-rouge">"negative"</code>.
To retrieve the raw sentiment scores, <code class="language-plaintext highlighter-rouge">enableScore</code> needs to be set to <code class="language-plaintext highlighter-rouge">true</code>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dictionary-sentiment/sentiment.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/sda/pragmatic/PragmaticSentimentTestSpec.scala">SentimentTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTIMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index.html#sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector">SentimentDetector</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector">SentimentDetector</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetector.scala">SentimentDetector</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># In this example, the dictionary `default-sentiment-dict.txt` has the form of
#
# ...
# cool,positive
# superb,positive
# bad,negative
# uninspired,negative
# ...
#
# where each sentiment keyword is delimited by `","`.
</span>
<span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">lemmatizer</span> <span class="o">=</span> <span class="n">Lemmatizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"lemma"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"lemmas_small.txt"</span><span class="p">,</span> <span class="s">"-&gt;"</span><span class="p">,</span> <span class="s">"</span><span class="se">\t</span><span class="s">"</span><span class="p">)</span>

<span class="n">sentimentDetector</span> <span class="o">=</span> <span class="n">SentimentDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"lemma"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentimentScore"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"default-sentiment-dict.txt"</span><span class="p">,</span> <span class="s">","</span><span class="p">,</span> <span class="n">ReadAs</span><span class="p">.</span><span class="n">TEXT</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">lemmatizer</span><span class="p">,</span>
    <span class="n">sentimentDetector</span><span class="p">,</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"The staff of the restaurant is nice"</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"I recommend others to avoid because it is too expensive"</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"sentimentScore.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------+</span>  <span class="c1">#  +------+ for enableScore set to True
</span><span class="o">|</span><span class="n">result</span>    <span class="o">|</span>  <span class="c1">#  |result|
</span><span class="o">+----------+</span>  <span class="c1">#  +------+
</span><span class="o">|</span><span class="p">[</span><span class="n">positive</span><span class="p">]</span><span class="o">|</span>  <span class="c1">#  |[1.0] |
</span><span class="o">|</span><span class="p">[</span><span class="n">negative</span><span class="p">]</span><span class="o">|</span>  <span class="c1">#  |[-2.0]|
</span><span class="o">+----------+</span>  <span class="c1">#  +------+
</span></code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the dictionary `default-sentiment-dict.txt` has the form of</span>
<span class="c1">//</span>
<span class="c1">// ...</span>
<span class="c1">// cool,positive</span>
<span class="c1">// superb,positive</span>
<span class="c1">// bad,negative</span>
<span class="c1">// uninspired,negative</span>
<span class="c1">// ...</span>
<span class="c1">//</span>
<span class="c1">// where each sentiment keyword is delimited by `","`.</span>

<span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Lemmatizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sda.pragmatic.SentimentDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.util.io.ReadAs</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">lemmatizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Lemmatizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"lemma"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"src/test/resources/lemma-corpus-small/lemmas_small.txt"</span><span class="o">,</span> <span class="s">"-&gt;"</span><span class="o">,</span> <span class="s">"\t"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentimentDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentimentDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"lemma"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentimentScore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"src/test/resources/sentiment-corpus/default-sentiment-dict.txt"</span><span class="o">,</span> <span class="s">","</span><span class="o">,</span> <span class="nv">ReadAs</span><span class="o">.</span><span class="py">TEXT</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">lemmatizer</span><span class="o">,</span>
  <span class="n">sentimentDetector</span><span class="o">,</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"The staff of the restaurant is nice"</span><span class="o">,</span>
  <span class="s">"I recommend others to avoid because it is too expensive"</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"sentimentScore.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+----------+</span>  <span class="c1">//  +------+ for enableScore set to true</span>
<span class="o">|</span><span class="n">result</span>    <span class="o">|</span>  <span class="c1">//  |result|</span>
<span class="o">+----------+</span>  <span class="c1">//  +------+</span>
<span class="o">|[</span><span class="kt">positive</span><span class="o">]|</span>  <span class="c1">//  |[1.0] |</span>
<span class="o">|[</span><span class="kt">negative</span><span class="o">]|</span>  <span class="c1">//  |[-2.0]|</span>
<span class="o">+----------+</span>  <span class="c1">//  +------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Rule based sentiment detector, which calculates a score based on predefined keywords.</p>

    <p>This is the instantiated model of the SentimentDetector.
For training your own model, please see the documentation of that class.</p>

    <p>A dictionary of predefined sentiment keywords must be provided with <code class="language-plaintext highlighter-rouge">setDictionary</code>, where each line is a word
delimited to its class (either <code class="language-plaintext highlighter-rouge">positive</code> or <code class="language-plaintext highlighter-rouge">negative</code>).
The dictionary can be set as a delimited text file.</p>

    <p>By default, the sentiment score will be assigned labels <code class="language-plaintext highlighter-rouge">"positive"</code> if the score is <code class="language-plaintext highlighter-rouge">&gt;= 0</code>, else <code class="language-plaintext highlighter-rouge">"negative"</code>.
To retrieve the raw sentiment scores, <code class="language-plaintext highlighter-rouge">enableScore</code> needs to be set to <code class="language-plaintext highlighter-rouge">true</code>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dictionary-sentiment/sentiment.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/sda/pragmatic/PragmaticSentimentTestSpec.scala">SentimentTestSpec</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTIMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index.html#sparknlp.annotator.sentiment.sentiment_detector.SentimentDetectorModel">SentimentDetectorModel</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel">SentimentDetectorModel</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/pragmatic/SentimentDetectorModel.scala">SentimentDetectorModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="stemmer">Stemmer</h2>

  <p>Returns hard-stems out of words with the objective of retrieving the meaningful part of the word.
For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/stemmer/index.html#sparknlp.annotator.stemmer.Stemmer">Stemmer</a></td>
        <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/Stemmer">Stemmer</a></td>
        <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Stemmer.scala">Stemmer</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

      <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">Stemmer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"stem"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">stemmer</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Peter Pipers employees are picking pecks of pickled peppers."</span><span class="p">]])</span> \
    <span class="p">.</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"stem.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                       <span class="o">|</span>
<span class="o">+-------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">peter</span><span class="p">,</span> <span class="n">piper</span><span class="p">,</span> <span class="n">employe</span><span class="p">,</span> <span class="n">ar</span><span class="p">,</span> <span class="n">pick</span><span class="p">,</span> <span class="n">peck</span><span class="p">,</span> <span class="n">of</span><span class="p">,</span> <span class="n">pickl</span><span class="p">,</span> <span class="n">pepper</span><span class="p">,</span> <span class="p">.]</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.</span><span class="o">{</span><span class="nc">Stemmer</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stemmer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Stemmer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">stemmer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Peter Pipers employees are picking pecks of pickled peppers."</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"stem.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+-------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                       <span class="o">|</span>
<span class="o">+-------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">peter</span>, <span class="kt">piper</span>, <span class="kt">employe</span>, <span class="kt">ar</span>, <span class="kt">pick</span>, <span class="kt">peck</span>, <span class="kt">of</span>, <span class="kt">pickl</span>, <span class="kt">pepper</span>, <span class="kt">.</span><span class="o">]|</span>
<span class="o">+-------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="stopwordscleaner">StopWordsCleaner</h2>

  <p>This annotator takes a sequence of strings (e.g. the output of a Tokenizer, Normalizer, Lemmatizer, and Stemmer)
and drops all the stop words from the input sequences.</p>

  <p>By default, it uses stop words from MLlibs
<a href="https://spark.apache.org/docs/latest/ml-features#stopwordsremover">StopWordsRemover</a>.
Stop words can also be defined by explicitly setting them with <code class="language-plaintext highlighter-rouge">setStopWords(value: Array[String])</code> or loaded from
pretrained models using <code class="language-plaintext highlighter-rouge">pretrained</code> of its companion object.</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val stopWords = StopWordsCleaner.pretrained()
  .setInputCols("token")
  .setOutputCol("cleanTokens")
  .setCaseSensitive(false)
// will load the default pretrained model `"stopwords_en"`.
</code></pre></div>  </div>
  <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Stop+Words+Removal">Models Hub</a>.</p>

  <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>
and <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleanerTestSpec.scala">StopWordsCleanerTestSpec</a>.</p>

  <blockquote>
    <p><strong>NOTE:</strong>
If you need to <code class="language-plaintext highlighter-rouge">setStopWords</code> from a text file, you can first read and convert it into an array of string as follows.</p>
  </blockquote>

  <div class="tabs-box tabs-new">

    <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># your stop words text file, each line is one stop word
</span><span class="n">stopwords</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">"/tmp/stopwords/english.txt"</span><span class="p">).</span><span class="n">collect</span><span class="p">()</span>

<span class="c1"># simply use it in StopWordsCleaner
</span><span class="n">stopWordsCleaner</span> <span class="o">=</span> <span class="n">StopWordsCleaner</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setStopWords</span><span class="p">(</span><span class="n">stopwords</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># or you can use pretrained models for StopWordsCleaner
</span><span class="n">stopWordsCleaner</span> <span class="o">=</span> <span class="n">StopWordsCleaner</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

</code></pre></div>    </div>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// your stop words text file, each line is one stop word</span>
<span class="k">val</span> <span class="nv">stopwords</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"/tmp/stopwords/english.txt"</span><span class="o">).</span><span class="py">collect</span><span class="o">()</span>

<span class="c1">// simply use it in StopWordsCleaner</span>
<span class="k">val</span> <span class="nv">stopWordsCleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsCleaner</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setStopWords</span><span class="o">(</span><span class="n">stopwords</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// or you can use pretrained models for StopWordsCleaner</span>
<span class="k">val</span> <span class="nv">stopWordsCleaner</span> <span class="k">=</span> <span class="nv">StopWordsCleaner</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>      
</code></pre></div>    </div>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/stop_words_cleaner/index.html#sparknlp.annotator.stop_words_cleaner.StopWordsCleaner">StopWordsCleaner</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/StopWordsCleaner">StopWordsCleaner</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/StopWordsCleaner.scala">StopWordsCleaner</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">stopWords</span> <span class="o">=</span> <span class="n">StopWordsCleaner</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">stopWords</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"This is my first sentence. This is my second."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"This is my third sentence. This is my forth."</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"cleanTokens.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                         <span class="o">|</span>
<span class="o">+-------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">first</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="p">.,</span> <span class="n">second</span><span class="p">,</span> <span class="p">.]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">third</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="p">.,</span> <span class="n">forth</span><span class="p">,</span> <span class="p">.]</span> <span class="o">|</span>
<span class="o">+-------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.StopWordsCleaner</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopWords</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsCleaner</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">stopWords</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"This is my first sentence. This is my second."</span><span class="o">,</span>
  <span class="s">"This is my third sentence. This is my forth."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"cleanTokens.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                         <span class="o">|</span>
<span class="o">+-------------------------------+</span>
<span class="o">|[</span><span class="kt">first</span>, <span class="kt">sentence</span>, <span class="kt">.</span>, <span class="kt">second</span>, <span class="kt">.</span><span class="o">]|</span>
<span class="o">|[</span><span class="kt">third</span>, <span class="kt">sentence</span>, <span class="kt">.</span>, <span class="kt">forth</span>, <span class="kt">.</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+-------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="tabs-box tabs-new">

    <h2 id="symmetricdelete-spellchecker">SymmetricDelete Spellchecker</h2>

    <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

    <div class="h3-box approach-content">

      <p>Trains a Symmetric Delete spelling correction algorithm.
Retrieves tokens and utilizes distance metrics to compute possible derived words.</p>

      <p>Inspired by <a href="https://github.com/wolfgarbe/SymSpell">SymSpell</a>.</p>

      <p>For instantiated/pretrained models, see SymmetricDeleteModel.</p>

      <p>See <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModelTestSpec.scala">SymmetricDeleteModelTestSpec</a> for further reference.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach">SymmetricDeleteApproach</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach">SymmetricDeleteApproach</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach.scala">SymmetricDeleteApproach</a></td>
          </tr>
        </tbody>
      </table>

      <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

          <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># In this example, the dictionary `"words.txt"` has the form of
#
# ...
# gummy
# gummic
# gummier
# gummiest
# gummiferous
# ...
#
# This dictionary is then set to be the basis of the spell checker.
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">spellChecker</span> <span class="o">=</span> <span class="n">SymmetricDeleteApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"spell"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"src/test/resources/spell/words.txt"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">spellChecker</span>
<span class="p">])</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the dictionary `"words.txt"` has the form of</span>
<span class="c1">//</span>
<span class="c1">// ...</span>
<span class="c1">// gummy</span>
<span class="c1">// gummic</span>
<span class="c1">// gummier</span>
<span class="c1">// gummiest</span>
<span class="c1">// gummiferous</span>
<span class="c1">// ...</span>
<span class="c1">//</span>
<span class="c1">// This dictionary is then set to be the basis of the spell checker.</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.spell.symmetric.SymmetricDeleteApproach</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">spellChecker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SymmetricDeleteApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"spell"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"src/test/resources/spell/words.txt"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">spellChecker</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

</details>

    </div>

    <div class="h3-box model-content" style="display: none;">

      <p>Symmetric Delete spelling correction algorithm.</p>

      <p>The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and
dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster
(than the standard approach with deletes + transposes + replaces + inserts) and language independent.</p>

      <p>Inspired by <a href="https://github.com/wolfgarbe/SymSpell">SymSpell</a>.</p>

      <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val spell = SymmetricDeleteModel.pretrained()
  .setInputCols("token")
  .setOutputCol("spell")
</code></pre></div>      </div>
      <p>The default model is <code class="language-plaintext highlighter-rouge">"spellcheck_sd"</code>, if no name is provided.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Spell+Check">Models Hub</a>.</p>

      <p>See <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModelTestSpec.scala">SymmetricDeleteModelTestSpec</a> for further reference.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel">SymmetricDeleteModel</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel">SymmetricDeleteModel</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteModel.scala">SymmetricDeleteModel</a></td>
          </tr>
        </tbody>
      </table>

    </div>

  </div>

  <div class="tabs-box tabs-new">

    <h2 id="textmatcher">TextMatcher</h2>

    <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

    <div class="h3-box approach-content">

      <p>Annotator to match exact phrases (by token) provided in a file against a Document.</p>

      <p>A text file of predefined phrases must be provided with <code class="language-plaintext highlighter-rouge">setEntities</code>.</p>

      <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/TextMatcherTestSpec.scala">TextMatcherTestSpec</a>.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/matcher/text_matcher/index.html#sparknlp.annotator.matcher.text_matcher.TextMatcher">TextMatcher</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/TextMatcher">TextMatcher</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/TextMatcher.scala">TextMatcher</a></td>
          </tr>
        </tbody>
      </table>

      <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

          <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># In this example, the entities file is of the form
#
# ...
# dolore magna aliqua
# lorem ipsum dolor. sit
# laborum
# ...
#
# where each line represents an entity phrase to be extracted.
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Hello dolore magna aliqua. Lorem ipsum dolor. sit in laborum"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">entityExtractor</span> <span class="o">=</span> <span class="n">TextMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setEntities</span><span class="p">(</span><span class="s">"src/test/resources/entity-extractor/test-phrases.txt"</span><span class="p">,</span> <span class="n">ReadAs</span><span class="p">.</span><span class="n">TEXT</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">entityExtractor</span><span class="p">])</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(entity) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                    <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="n">dolore</span> <span class="n">magna</span> <span class="n">aliqua</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">entity</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span>    <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="n">Lorem</span> <span class="n">ipsum</span> <span class="n">dolor</span><span class="p">.</span> <span class="n">sit</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">entity</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span> <span class="mi">59</span><span class="p">,</span> <span class="n">laborum</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">entity</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[]]</span>               <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the entities file is of the form</span>
<span class="c1">//</span>
<span class="c1">// ...</span>
<span class="c1">// dolore magna aliqua</span>
<span class="c1">// lorem ipsum dolor. sit</span>
<span class="c1">// laborum</span>
<span class="c1">// ...</span>
<span class="c1">//</span>
<span class="c1">// where each line represents an entity phrase to be extracted.</span>
<span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.TextMatcher</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.util.io.ReadAs</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Hello dolore magna aliqua. Lorem ipsum dolor. sit in laborum"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">entityExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextMatcher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEntities</span><span class="o">(</span><span class="s">"src/test/resources/entity-extractor/test-phrases.txt"</span><span class="o">,</span> <span class="nv">ReadAs</span><span class="o">.</span><span class="py">TEXT</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setTokenizer</span><span class="o">(</span><span class="nv">tokenizer</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">tokenizer</span><span class="o">,</span> <span class="n">entityExtractor</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">results</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(entity) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                    <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">6</span>, <span class="err">24</span>, <span class="kt">dolore</span> <span class="kt">magna</span> <span class="kt">aliqua</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">entity</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]</span>    <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">27</span>, <span class="err">48</span>, <span class="kt">Lorem</span> <span class="kt">ipsum</span> <span class="kt">dolor.</span> <span class="kt">sit</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">entity</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">1</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">53</span>, <span class="err">59</span>, <span class="kt">laborum</span>, <span class="o">[</span><span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">entity</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">2</span><span class="o">]</span>, <span class="o">[]]</span>               <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

</details>

    </div>

    <div class="h3-box model-content" style="display: none;">

      <p>Instantiated model of the TextMatcher.
For usage and examples see the documentation of the main class.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/matcher/text_matcher/index.html#sparknlp.annotator.matcher.text_matcher.TextMatcherModel">TextMatcherModel</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/TextMatcherModel">TextMatcherModel</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/TextMatcherModel.scala">TextMatcherModel</a></td>
          </tr>
        </tbody>
      </table>

    </div>

  </div>

  <div class="h3-box model-content">

    <h2 id="token2chunk">Token2Chunk</h2>

    <p>Converts <code class="language-plaintext highlighter-rouge">TOKEN</code> type Annotations to <code class="language-plaintext highlighter-rouge">CHUNK</code> type.</p>

    <p>This can be useful if a entities have been already extracted as <code class="language-plaintext highlighter-rouge">TOKEN</code> and following annotators require <code class="language-plaintext highlighter-rouge">CHUNK</code> types.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/token/token2_chunk/index.html#sparknlp.annotator.token.token2_chunk.Token2Chunk">Token2Chunk</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/Token2Chunk">Token2Chunk</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Token2Chunk.scala">Token2Chunk</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>


<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">token2chunk</span> <span class="o">=</span> <span class="n">Token2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">token2chunk</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"One Two Three Four"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(chunk) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                    <span class="o">|</span>
<span class="o">+------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">One</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">Two</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">Three</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="n">Four</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]]</span><span class="o">|</span>
<span class="o">+------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.</span><span class="o">{</span><span class="nc">Token2Chunk</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>

<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token2chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Token2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">token2chunk</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"One Two Three Four"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(chunk) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                    <span class="o">|</span>
<span class="o">+------------------------------------------+</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">0</span>, <span class="err">2</span>, <span class="kt">One</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]</span>   <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">4</span>, <span class="err">6</span>, <span class="kt">Two</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]</span>   <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">8</span>, <span class="err">12</span>, <span class="kt">Three</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">14</span>, <span class="err">17</span>, <span class="kt">Four</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">+------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content">

    <h2 id="tokenassembler">TokenAssembler</h2>

    <p>This transformer reconstructs a <code class="language-plaintext highlighter-rouge">DOCUMENT</code> type annotation from tokens, usually after these have been normalized,
lemmatized, normalized, spell checked, etc, in order to use this document annotation in further annotators.
Requires <code class="language-plaintext highlighter-rouge">DOCUMENT</code> and <code class="language-plaintext highlighter-rouge">TOKEN</code> type annotations as input.</p>

    <p>For more extended examples on document pre-processing see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/base/token_assembler/index.html#sparknlp.base.token_assembler.TokenAssembler">TokenAssembler</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/TokenAssembler">TokenAssembler</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/TokenAssembler.scala">TokenAssembler</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># First, the text is tokenized and cleaned
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLowercase</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">stopwordsCleaner</span> <span class="o">=</span> <span class="n">StopWordsCleaner</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"normalized"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Then the TokenAssembler turns the cleaned tokens into a `DOCUMENT` type structure.
</span><span class="n">tokenAssembler</span> <span class="o">=</span> <span class="n">TokenAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"cleanTokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanText"</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="p">]])</span> \
    <span class="p">.</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">normalizer</span><span class="p">,</span>
    <span class="n">stopwordsCleaner</span><span class="p">,</span>
    <span class="n">tokenAssembler</span>
<span class="p">]).</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"cleanText"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">cleanText</span>                                                                                                                  <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="n">Spark</span> <span class="n">NLP</span> <span class="n">opensource</span> <span class="n">text</span> <span class="n">processing</span> <span class="n">library</span> <span class="n">advanced</span> <span class="n">natural</span> <span class="n">language</span> <span class="n">processing</span><span class="p">,</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[]</span><span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.</span><span class="o">{</span><span class="nc">Normalizer</span><span class="o">,</span> <span class="nc">StopWordsCleaner</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.TokenAssembler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="c1">// First, the text is tokenized and cleaned</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLowercase</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopwordsCleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsCleaner</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// Then the TokenAssembler turns the cleaned tokens into a `DOCUMENT` type structure.</span>
<span class="k">val</span> <span class="nv">tokenAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TokenAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanText"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">normalizer</span><span class="o">,</span>
  <span class="n">stopwordsCleaner</span><span class="o">,</span>
  <span class="n">tokenAssembler</span>
<span class="o">)).</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"cleanText"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">cleanText</span>                                                                                                                  <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[[</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">80</span>, <span class="kt">Spark</span> <span class="kt">NLP</span> <span class="kt">opensource</span> <span class="kt">text</span> <span class="kt">processing</span> <span class="kt">library</span> <span class="kt">advanced</span> <span class="kt">natural</span> <span class="kt">language</span> <span class="kt">processing</span>, <span class="o">[</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">]</span>, <span class="o">[]]]|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="tabs-box tabs-new">

    <h2 id="tokenizer">Tokenizer</h2>

    <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

    <div class="h3-box approach-content">

      <p>Tokenizes raw text in document type columns into TokenizedSentence .</p>

      <p>This class represents a non fitted tokenizer. Fitting it will cause the internal RuleFactory to construct the rules for tokenizing from the input configuration.</p>

      <p>Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs.</p>

      <p>For extended examples of usage see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>
and <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/TokenizerTestSpec.scala">Tokenizer test class</a></p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

      <blockquote>
        <p><strong>Note:</strong> All these APIs receive regular expressions so please make sure that you escape special characters according to Java conventions.</p>
      </blockquote>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/token/tokenizer/index.html#sparknlp.annotator.token.tokenizer.Tokenizer">Tokenizer</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/Tokenizer">Tokenizer</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Tokenizer.scala">Tokenizer</a></td>
          </tr>
        </tbody>
      </table>

      <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

          <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I'd like to say we didn't expect that. Jane's boyfriend."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">]).</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"token.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">output</span>                                                                 <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">I</span><span class="s">'d, like, to, say, we, didn'</span><span class="n">t</span><span class="p">,</span> <span class="n">expect</span><span class="p">,</span> <span class="n">that</span><span class="p">,</span> <span class="p">.,</span> <span class="n">Jane</span><span class="s">'s, boyfriend, .]|
+-----------------------------------------------------------------------+
</span></code></pre></div>          </div>

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"I'd like to say we didn't expect that. Jane's boyfriend."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">).</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">tokenizer</span><span class="o">)).</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"token.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">output</span>                                                                 <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">I'd</span>, <span class="kt">like</span>, <span class="kt">to</span>, <span class="kt">say</span>, <span class="kt">we</span>, <span class="kt">didn't</span>, <span class="kt">expect</span>, <span class="kt">that</span>, <span class="kt">.</span>, <span class="kt">Jane's</span>, <span class="kt">boyfriend</span>, <span class="kt">.</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

</details>

    </div>

    <div class="h3-box model-content" style="display: none;">

      <p>Tokenizes raw text into word pieces, tokens. Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs.</p>

      <p>This class represents an already fitted Tokenizer model.</p>

      <p>See the main class Tokenizer for more examples of usage.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT //A Tokenizer could require only for now a SentenceDetector annotator</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/token/tokenizer/index.html#sparknlp.annotator.token.tokenizer.TokenizerModel">TokenizerModel</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/TokenizerModel">TokenizerModel</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/TokenizerModel.scala">TokenizerModel</a></td>
          </tr>
        </tbody>
      </table>

    </div>

  </div>

  <div class="tabs-box tabs-new">

    <h2 id="typeddependencyparser">TypedDependencyParser</h2>

    <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

    <div class="h3-box approach-content">

      <p>Labeled parser that finds a grammatical relation between two words in a sentence.
Its input is either a CoNLL2009 or ConllU dataset.</p>

      <p>For instantiated/pretrained models, see TypedDependencyParserModel.</p>

      <p>Dependency parsers provide information about word relationship. For example, dependency parsing can tell you what
the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help
you find precise answers to specific questions.</p>

      <p>The parser requires the dependant tokens beforehand with e.g. <a href="/docs/en/annotators#dependencyparser">DependencyParser</a>.
The required training data can be set in two different ways (only one can be chosen for a particular model):</p>
      <ul>
        <li>Dataset in the <a href="https://ufal.mff.cuni.cz/conll2009-st/trial-data.html">CoNLL 2009 format</a> set with <code class="language-plaintext highlighter-rouge">setConll2009</code></li>
        <li>Dataset in the <a href="https://universaldependencies.org/format.html">CoNLL-U format</a> set with <code class="language-plaintext highlighter-rouge">setConllU</code></li>
      </ul>

      <p>Apart from that, no additional training data is needed.</p>

      <p>See <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproachTestSpec.scala">TypedDependencyParserApproachTestSpec</a> for further reference on this API.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, POS, DEPENDENCY</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">LABELED_DEPENDENCY</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach">TypedDependencyParserApproach</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach">TypedDependencyParserApproach</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach.scala">TypedDependencyParserApproach</a></td>
          </tr>
        </tbody>
      </table>

      <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

          <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">dependencyParser</span> <span class="o">=</span> <span class="n">DependencyParserModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependency"</span><span class="p">)</span>

<span class="n">typedDependencyParser</span> <span class="o">=</span> <span class="n">TypedDependencyParserApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"dependency"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependency_type"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setConllU</span><span class="p">(</span><span class="s">"src/test/resources/parser/labeled/train_small.conllu.txt"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setNumberOfIterations</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">posTagger</span><span class="p">,</span>
    <span class="n">dependencyParser</span><span class="p">,</span>
    <span class="n">typedDependencyParser</span>
<span class="p">])</span>

<span class="c1"># Additional training data is not needed, the dependency parser relies on CoNLL-U only.
</span><span class="n">emptyDataSet</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">emptyDataSet</span><span class="p">)</span>
</code></pre></div>          </div>

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sbd.pragmatic.SentenceDetector</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.pos.perceptron.PerceptronModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.parser.dep.DependencyParserModel</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.parser.typdep.TypedDependencyParserApproach</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependencyParser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependency"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">typedDependencyParser</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TypedDependencyParserApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"dependency"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependency_type"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setConllU</span><span class="o">(</span><span class="s">"src/test/resources/parser/labeled/train_small.conllu.txt"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNumberOfIterations</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">posTagger</span><span class="o">,</span>
  <span class="n">dependencyParser</span><span class="o">,</span>
  <span class="n">typedDependencyParser</span>
<span class="o">))</span>

<span class="c1">// Additional training data is not needed, the dependency parser relies on CoNLL-U only.</span>
<span class="k">val</span> <span class="nv">emptyDataSet</span> <span class="k">=</span> <span class="nv">Seq</span><span class="o">.</span><span class="py">empty</span><span class="o">[</span><span class="kt">String</span><span class="o">].</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">emptyDataSet</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

</details>

    </div>

    <div class="h3-box model-content" style="display: none;">

      <p>Labeled parser that finds a grammatical relation between two words in a sentence.
Its input is either a CoNLL2009 or ConllU dataset.</p>

      <p>Dependency parsers provide information about word relationship. For example, dependency parsing can tell you what
the subjects and objects of a verb are, as well as which words are modifying (describing) the subject. This can help
you find precise answers to specific questions.</p>

      <p>The parser requires the dependant tokens beforehand with e.g. <a href="/docs/en/annotators#dependencyparser">DependencyParser</a>.</p>

      <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val typedDependencyParser = TypedDependencyParserModel.pretrained()
  .setInputCols("dependency", "pos", "token")
  .setOutputCol("dependency_type")
</code></pre></div>      </div>
      <p>The default model is <code class="language-plaintext highlighter-rouge">"dependency_typed_conllu"</code>, if no name is provided.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models">Models Hub</a>.</p>

      <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyModelTestSpec.scala">TypedDependencyModelTestSpec</a>.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, POS, DEPENDENCY</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">LABELED_DEPENDENCY</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserModel">TypedDependencyParserModel</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel">TypedDependencyParserModel</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserModel.scala">TypedDependencyParserModel</a></td>
          </tr>
        </tbody>
      </table>

    </div>

  </div>

  <div class="tabs-box tabs-new">

    <h2 id="viveknsentiment">ViveknSentiment</h2>

    <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

    <div class="h3-box approach-content">

      <p>Trains a sentiment analyser inspired by the algorithm by Vivek Narayanan https://github.com/vivekn/sentiment/.</p>

      <p>The algorithm is based on the paper
<a href="https://arxiv.org/abs/1305.6143">“Fast and accurate sentiment classification using an enhanced Naive Bayes model”</a>.</p>

      <p>The analyzer requires sentence boundaries to give a score in context.
Tokenization is needed to make sure tokens are within bounds. Transitivity requirements are also required.</p>

      <p>The training data needs to consist of a column for normalized text and a label column (either <code class="language-plaintext highlighter-rouge">"positive"</code> or <code class="language-plaintext highlighter-rouge">"negative"</code>).</p>

      <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/vivekn-sentiment/VivekNarayanSentimentApproach.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/sda/vivekn">ViveknSentimentTestSpec</a>.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, DOCUMENT</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTIMENT</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.html#sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach">ViveknSentimentApproach</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentApproach">ViveknSentimentApproach</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentApproach.scala">ViveknSentimentApproach</a></td>
          </tr>
        </tbody>
      </table>

      <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

          <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">document</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normal"</span><span class="p">)</span>

<span class="n">vivekn</span> <span class="o">=</span> <span class="n">ViveknSentimentApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"normal"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setSentimentCol</span><span class="p">(</span><span class="s">"train_sentiment"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"result_sentiment"</span><span class="p">)</span>

<span class="n">finisher</span> <span class="o">=</span> <span class="n">Finisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"result_sentiment"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"final_sentiment"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">document</span><span class="p">,</span> <span class="n">token</span><span class="p">,</span> <span class="n">normalizer</span><span class="p">,</span> <span class="n">vivekn</span><span class="p">,</span> <span class="n">finisher</span><span class="p">])</span>

<span class="n">training</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="s">"I really liked this movie!"</span><span class="p">,</span> <span class="s">"positive"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"The cast was horrible"</span><span class="p">,</span> <span class="s">"negative"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"Never going to watch this again or recommend it to anyone"</span><span class="p">,</span> <span class="s">"negative"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"It's a waste of time"</span><span class="p">,</span> <span class="s">"negative"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"I loved the protagonist"</span><span class="p">,</span> <span class="s">"positive"</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"The music was really really good"</span><span class="p">,</span> <span class="s">"positive"</span><span class="p">)</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"train_sentiment"</span><span class="p">)</span>
<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"I recommend this movie"</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Dont waste your time!!!"</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipelineModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"final_sentiment"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------+</span>
<span class="o">|</span><span class="n">final_sentiment</span><span class="o">|</span>
<span class="o">+---------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">positive</span><span class="p">]</span>     <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">negative</span><span class="p">]</span>     <span class="o">|</span>
<span class="o">+---------------+</span>
</code></pre></div>          </div>

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Normalizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.sda.vivekn.ViveknSentimentApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.Finisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normal"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">vivekn</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ViveknSentimentApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"normal"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setSentimentCol</span><span class="o">(</span><span class="s">"train_sentiment"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"result_sentiment"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">finisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Finisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"result_sentiment"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"final_sentiment"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document</span><span class="o">,</span> <span class="n">token</span><span class="o">,</span> <span class="n">normalizer</span><span class="o">,</span> <span class="n">vivekn</span><span class="o">,</span> <span class="n">finisher</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">training</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">"I really liked this movie!"</span><span class="o">,</span> <span class="s">"positive"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"The cast was horrible"</span><span class="o">,</span> <span class="s">"negative"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"Never going to watch this again or recommend it to anyone"</span><span class="o">,</span> <span class="s">"negative"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"It's a waste of time"</span><span class="o">,</span> <span class="s">"negative"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"I loved the protagonist"</span><span class="o">,</span> <span class="s">"positive"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"The music was really really good"</span><span class="o">,</span> <span class="s">"positive"</span><span class="o">)</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"train_sentiment"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">training</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"I recommend this movie"</span><span class="o">,</span>
  <span class="s">"Dont waste your time!!!"</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipelineModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"final_sentiment"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------+</span>
<span class="o">|</span><span class="n">final_sentiment</span><span class="o">|</span>
<span class="o">+---------------+</span>
<span class="o">|[</span><span class="kt">positive</span><span class="o">]</span>     <span class="o">|</span>
<span class="o">|[</span><span class="kt">negative</span><span class="o">]</span>     <span class="o">|</span>
<span class="o">+---------------+</span>
</code></pre></div>          </div>

        </div>

</details>

    </div>

    <div class="h3-box model-content" style="display: none;">

      <p>Sentiment analyser inspired by the algorithm by Vivek Narayanan https://github.com/vivekn/sentiment/.</p>

      <p>The algorithm is based on the paper
<a href="https://arxiv.org/abs/1305.6143">“Fast and accurate sentiment classification using an enhanced Naive Bayes model”</a>.</p>

      <p>This is the instantiated model of the ViveknSentimentApproach.
For training your own model, please see the documentation of that class.</p>

      <p>The analyzer requires sentence boundaries to give a score in context.
Tokenization is needed to make sure tokens are within bounds. Transitivity requirements are also required.</p>

      <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/vivekn-sentiment/VivekNarayanSentimentApproach.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/test/scala/com/johnsnowlabs/nlp/annotators/sda/vivekn">ViveknSentimentTestSpec</a>.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, DOCUMENT</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTIMENT</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.html#sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentModel">ViveknSentimentModel</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel">ViveknSentimentModel</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentModel.scala">ViveknSentimentModel</a></td>
          </tr>
        </tbody>
      </table>

    </div>

  </div>

  <div class="tabs-box tabs-new">

    <h2 id="word2vec">Word2Vec</h2>

    <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

    <div class="h3-box approach-content">

      <p>Trains a Word2Vec model that creates vector representations of words in a text corpus.</p>

      <p>The algorithm first constructs a vocabulary from the corpus
and then learns vector representation of words in the vocabulary.
The vector representation can be used as features in
natural language processing and machine learning algorithms.</p>

      <p>We use Word2Vec implemented in Spark ML. It uses skip-gram model in our implementation and a hierarchical softmax
method to train the model. The variable names in the implementation match the original C implementation.</p>

      <p>For instantiated/pretrained models, see Word2VecModel.</p>

      <p><strong>Sources</strong> :</p>

      <p>For the original C implementation, see <a href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a></p>

      <p>For the research paper, see
<a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a>
and <a href="https://arxiv.org/pdf/1310.4546v1.pdf">Distributed Representations of Words and Phrases and their Compositionality</a>.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html#sparknlp.annotator.embeddings.word2vec.Word2VecApproach">Word2VecApproach</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/Word2VecApproach">Word2VecApproach</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/Word2VecApproach.scala">Word2VecApproach</a></td>
          </tr>
        </tbody>
      </table>

      <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

          <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">Word2VecApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span>
    <span class="p">])</span>

<span class="n">path</span> <span class="o">=</span> <span class="s">"sherlockholmes.txt"</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">path</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>          </div>

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.</span><span class="o">{</span><span class="nc">Tokenizer</span><span class="o">,</span> <span class="nc">Word2VecApproach</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Word2VecApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">path</span> <span class="k">=</span> <span class="s">"src/test/resources/spell/sherlockholmes.txt"</span>
<span class="k">val</span> <span class="nv">dataset</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">sparkContext</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="n">path</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

</details>

    </div>

    <div class="h3-box model-content" style="display: none;">

      <p>Word2Vec model that creates vector representations of words in a text corpus.</p>

      <p>The algorithm first constructs a vocabulary from the corpus
and then learns vector representation of words in the vocabulary.
The vector representation can be used as features in
natural language processing and machine learning algorithms.</p>

      <p>We use Word2Vec implemented in Spark ML. It uses skip-gram model in our implementation and a hierarchical softmax
method to train the model. The variable names in the implementation match the original C implementation.</p>

      <p>This is the instantiated model of the Word2VecApproach.
For training your own model, please see the documentation of that class.</p>

      <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = Word2VecModel.pretrained()
  .setInputCols("token")
  .setOutputCol("embeddings")
</code></pre></div>      </div>
      <p>The default model is <code class="language-plaintext highlighter-rouge">"word2vec_gigaword_300"</code>, if no name is provided.</p>

      <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models">Models Hub</a>.</p>

      <p><strong>Sources</strong> :</p>

      <p>For the original C implementation, see <a href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a></p>

      <p>For the research paper, see
<a href="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space</a>
and <a href="https://arxiv.org/pdf/1310.4546v1.pdf">Distributed Representations of Words and Phrases and their Compositionality</a>.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html#sparknlp.annotator.embeddings.word2vec.Word2VecModel">Word2VecModel</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/Word2VecModel">Word2VecModel</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/Word2VecModel.scala">Word2VecModel</a></td>
          </tr>
        </tbody>
      </table>

      <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

          <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">Word2VecModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">embeddingsFinisher</span>
<span class="p">])</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is a sentence."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.06222493574023247</span><span class="p">,</span><span class="mf">0.011579325422644615</span><span class="p">,</span><span class="mf">0.009919632226228714</span><span class="p">,</span><span class="mf">0.109361454844</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.</span><span class="o">{</span><span class="nc">Tokenizer</span><span class="o">,</span> <span class="nc">Word2VecModel</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>

<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">Word2VecModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">embeddingsFinisher</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is a sentence."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">80</span><span class="o">)</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">06222493574023247</span>,<span class="err">0</span><span class="kt">.</span><span class="err">011579325422644615</span>,<span class="err">0</span><span class="kt">.</span><span class="err">009919632226228714</span>,<span class="err">0</span><span class="kt">.</span><span class="err">109361454844</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

</details>

    </div>

  </div>

  <div class="tabs-box tabs-new">

    <h2 id="wordembeddings">WordEmbeddings</h2>

    <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

    <div class="h3-box approach-content">

      <p>Word Embeddings lookup annotator that maps tokens to vectors.</p>

      <p>For instantiated/pretrained models, see WordEmbeddingsModel.</p>

      <p>A custom token lookup dictionary for embeddings can be set with <code class="language-plaintext highlighter-rouge">setStoragePath</code>.
Each line of the provided file needs to have a token, followed by their vector representation, delimited by a spaces.</p>
      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
are 0.39658191506190343 0.630968081620067 0.5393722253731201 0.8428180123359783
were 0.7535235923631415 0.9699218875629833 0.10397182122983872 0.11833962569383116
stress 0.0492683418305907 0.9415954572751959 0.47624463167525755 0.16790967216778263
induced 0.1535748762292387 0.33498936903209897 0.9235178224122094 0.1158772920395934
...
</code></pre></div>      </div>
      <p>If a token is not found in the dictionary, then the result will be a zero vector of the same dimension.
Statistics about the rate of converted tokens, can be retrieved with<code class="language-plaintext highlighter-rouge">[WordEmbeddingsModel.withCoverageColumn</code>
and <code class="language-plaintext highlighter-rouge">WordEmbeddingsModel.overallCoverage</code>.</p>

      <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsTestSpec.scala">WordEmbeddingsTestSpec</a>.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index.html#sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings">WordEmbeddings</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddings">WordEmbeddings</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddings.scala">WordEmbeddings</a></td>
          </tr>
        </tbody>
      </table>

      <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

          <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># In this example, the file `random_embeddings_dim4.txt` has the form of the content above.
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStoragePath</span><span class="p">(</span><span class="s">"src/test/resources/random_embeddings_dim4.txt"</span><span class="p">,</span> <span class="n">ReadAs</span><span class="p">.</span><span class="n">TEXT</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStorageRef</span><span class="p">(</span><span class="s">"glove_4d"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDimension</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">embeddingsFinisher</span> <span class="o">=</span> <span class="n">EmbeddingsFinisher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"finished_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputAsVector</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">embeddingsFinisher</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"The patient was diagnosed with diabetes."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                            <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.9439099431037903</span><span class="p">,</span><span class="mf">0.4707513153553009</span><span class="p">,</span><span class="mf">0.806300163269043</span><span class="p">,</span><span class="mf">0.16176554560661316</span><span class="p">]</span>     <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.7966810464859009</span><span class="p">,</span><span class="mf">0.5551124811172485</span><span class="p">,</span><span class="mf">0.8861005902290344</span><span class="p">,</span><span class="mf">0.28284206986427307</span><span class="p">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.025029370561242104</span><span class="p">,</span><span class="mf">0.35177749395370483</span><span class="p">,</span><span class="mf">0.052506182342767715</span><span class="p">,</span><span class="mf">0.1887107789516449</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.08617766946554184</span><span class="p">,</span><span class="mf">0.8399239182472229</span><span class="p">,</span><span class="mf">0.5395117998123169</span><span class="p">,</span><span class="mf">0.7864698767662048</span><span class="p">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.6599600911140442</span><span class="p">,</span><span class="mf">0.16109347343444824</span><span class="p">,</span><span class="mf">0.6041093468666077</span><span class="p">,</span><span class="mf">0.8913561105728149</span><span class="p">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.5955275893211365</span><span class="p">,</span><span class="mf">0.01899011991918087</span><span class="p">,</span><span class="mf">0.4397728443145752</span><span class="p">,</span><span class="mf">0.8911281824111938</span><span class="p">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="mf">0.9840458631515503</span><span class="p">,</span><span class="mf">0.7599489092826843</span><span class="p">,</span><span class="mf">0.9417727589607239</span><span class="p">,</span><span class="mf">0.8624503016471863</span><span class="p">]</span>     <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, the file `random_embeddings_dim4.txt` has the form of the content above.</span>
<span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.Tokenizer</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.embeddings.WordEmbeddings</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.util.io.ReadAs</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.EmbeddingsFinisher</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">WordEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStoragePath</span><span class="o">(</span><span class="s">"src/test/resources/random_embeddings_dim4.txt"</span><span class="o">,</span> <span class="nv">ReadAs</span><span class="o">.</span><span class="py">TEXT</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStorageRef</span><span class="o">(</span><span class="s">"glove_4d"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDimension</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddingsFinisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EmbeddingsFinisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="s">"finished_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsVector</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">embeddingsFinisher</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The patient was diagnosed with diabetes."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(finished_embeddings) as result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                            <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">9439099431037903</span>,<span class="err">0</span><span class="kt">.</span><span class="err">4707513153553009</span>,<span class="err">0</span><span class="kt">.</span><span class="err">806300163269043</span>,<span class="err">0</span><span class="kt">.</span><span class="err">16176554560661316</span><span class="o">]</span>     <span class="o">|</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">7966810464859009</span>,<span class="err">0</span><span class="kt">.</span><span class="err">5551124811172485</span>,<span class="err">0</span><span class="kt">.</span><span class="err">8861005902290344</span>,<span class="err">0</span><span class="kt">.</span><span class="err">28284206986427307</span><span class="o">]</span>    <span class="o">|</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">025029370561242104</span>,<span class="err">0</span><span class="kt">.</span><span class="err">35177749395370483</span>,<span class="err">0</span><span class="kt">.</span><span class="err">052506182342767715</span>,<span class="err">0</span><span class="kt">.</span><span class="err">1887107789516449</span><span class="o">]|</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">08617766946554184</span>,<span class="err">0</span><span class="kt">.</span><span class="err">8399239182472229</span>,<span class="err">0</span><span class="kt">.</span><span class="err">5395117998123169</span>,<span class="err">0</span><span class="kt">.</span><span class="err">7864698767662048</span><span class="o">]</span>    <span class="o">|</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">6599600911140442</span>,<span class="err">0</span><span class="kt">.</span><span class="err">16109347343444824</span>,<span class="err">0</span><span class="kt">.</span><span class="err">6041093468666077</span>,<span class="err">0</span><span class="kt">.</span><span class="err">8913561105728149</span><span class="o">]</span>    <span class="o">|</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">5955275893211365</span>,<span class="err">0</span><span class="kt">.</span><span class="err">01899011991918087</span>,<span class="err">0</span><span class="kt">.</span><span class="err">4397728443145752</span>,<span class="err">0</span><span class="kt">.</span><span class="err">8911281824111938</span><span class="o">]</span>    <span class="o">|</span>
<span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">9840458631515503</span>,<span class="err">0</span><span class="kt">.</span><span class="err">7599489092826843</span>,<span class="err">0</span><span class="kt">.</span><span class="err">9417727589607239</span>,<span class="err">0</span><span class="kt">.</span><span class="err">8624503016471863</span><span class="o">]</span>     <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

</details>

    </div>

    <div class="h3-box model-content" style="display: none;">

      <p>Word Embeddings lookup annotator that maps tokens to vectors</p>

      <p>This is the instantiated model of WordEmbeddings.</p>

      <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val embeddings = WordEmbeddingsModel.pretrained()
    .setInputCols("document", "token")
    .setOutputCol("embeddings")
</code></pre></div>      </div>
      <p>The default model is <code class="language-plaintext highlighter-rouge">"glove_100d"</code>, if no name is provided.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Embeddings">Models Hub</a>.</p>

      <p>There are also two convenient functions to retrieve the embeddings coverage with respect to the transformed dataset:</p>
      <ul>
        <li><code class="language-plaintext highlighter-rouge">withCoverageColumn(dataset, embeddingsCol, outputCol)</code>:
Adds a custom column with word coverage stats for the embedded field:
(<code class="language-plaintext highlighter-rouge">coveredWords</code>, <code class="language-plaintext highlighter-rouge">totalWords</code>, <code class="language-plaintext highlighter-rouge">coveragePercentage</code>). This creates a new column with statistics for each row.
          <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val wordsCoverage = WordEmbeddingsModel.withCoverageColumn(resultDF, "embeddings", "cov_embeddings")
wordsCoverage.select("text","cov_embeddings").show(false)
+-------------------+--------------+
|text               |cov_embeddings|
+-------------------+--------------+
|This is a sentence.|[5, 5, 1.0]   |
+-------------------+--------------+
</code></pre></div>          </div>
        </li>
        <li><code class="language-plaintext highlighter-rouge">overallCoverage(dataset, embeddingsCol)</code>:
Calculates overall word coverage for the whole data in the embedded field.
This returns a single coverage object considering all rows in the field.
          <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val wordsOverallCoverage = WordEmbeddingsModel.overallCoverage(wordsCoverage,"embeddings").percentage
1.0
</code></pre></div>          </div>
        </li>
      </ul>

      <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsTestSpec.scala">WordEmbeddingsTestSpec</a>.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index.html#sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel">WordEmbeddingsModel</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel">WordEmbeddingsModel</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel.scala">WordEmbeddingsModel</a></td>
          </tr>
        </tbody>
      </table>

    </div>

  </div>

  <div class="tabs-box tabs-new">

    <h2 id="wordsegmenter">WordSegmenter</h2>

    <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

    <div class="h3-box approach-content">

      <p>Trains a WordSegmenter which tokenizes non-english or non-whitespace separated texts.</p>

      <p>Many languages are not whitespace separated and their sentences are a concatenation of many symbols, like Korean,
Japanese or Chinese. Without understanding the language, splitting the words into their corresponding tokens is
impossible. The WordSegmenter is trained to understand these languages and split them into semantically correct parts.</p>

      <p>For instantiated/pretrained models, see WordSegmenterModel.</p>

      <p>To train your own model, a training dataset consisting of
<a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">Part-Of-Speech tags</a> is required. The data has to be loaded
into a dataframe, where the column is an <a href="/api/com/johnsnowlabs/nlp/Annotation">Annotation</a> of type <code class="language-plaintext highlighter-rouge">"POS"</code>. This can be
set with <code class="language-plaintext highlighter-rouge">setPosColumn</code>.</p>

      <p><strong>Tip</strong>: The helper class <a href="/docs/en/training#pos-dataset">POS</a> might be useful to read training data into data frames.</p>

      <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/jupyter/annotation/chinese/word_segmentation">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/WordSegmenterTest.scala">WordSegmenterTest</a>.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach">WordSegmenterApproach</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach">WordSegmenterApproach</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach.scala">WordSegmenterApproach</a></td>
          </tr>
        </tbody>
      </table>

      <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

          <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># In this example, `"chinese_train.utf8"` is in the form of
#
# 十|LL 四|RR 不|LL 是|RR 四|LL 十|RR
#
# and is loaded with the `POS` class to create a dataframe of `"POS"` type Annotations.
</span>
<span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">wordSegmenter</span> <span class="o">=</span> <span class="n">WordSegmenterApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPosColumn</span><span class="p">(</span><span class="s">"tags"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setNIterations</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">wordSegmenter</span>
<span class="p">])</span>

<span class="n">trainingDataSet</span> <span class="o">=</span> <span class="n">POS</span><span class="p">().</span><span class="n">readDataset</span><span class="p">(</span>
    <span class="n">spark</span><span class="p">,</span>
    <span class="s">"src/test/resources/word-segmenter/chinese_train.utf8"</span>
<span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingDataSet</span><span class="p">)</span>
</code></pre></div>          </div>

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// In this example, `"chinese_train.utf8"` is in the form of</span>
<span class="c1">//</span>
<span class="c1">// 十|LL 四|RR 不|LL 是|RR 四|LL 十|RR</span>
<span class="c1">//</span>
<span class="c1">// and is loaded with the `POS` class to create a dataframe of `"POS"` type Annotations.</span>

<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.ws.WordSegmenterApproach</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.training.POS</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordSegmenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">WordSegmenterApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPosColumn</span><span class="o">(</span><span class="s">"tags"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNIterations</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">wordSegmenter</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">trainingDataSet</span> <span class="k">=</span> <span class="nc">POS</span><span class="o">().</span><span class="py">readDataset</span><span class="o">(</span>
  <span class="nv">ResourceHelper</span><span class="o">.</span><span class="py">spark</span><span class="o">,</span>
  <span class="s">"src/test/resources/word-segmenter/chinese_train.utf8"</span>
<span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingDataSet</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

</details>

    </div>

    <div class="h3-box model-content" style="display: none;">

      <p>WordSegmenter which tokenizes non-english or non-whitespace separated texts.</p>

      <p>Many languages are not whitespace separated and their sentences are a concatenation of many symbols, like Korean,
Japanese or Chinese. Without understanding the language, splitting the words into their corresponding tokens is
impossible. The WordSegmenter is trained to understand these languages and plit them into semantically correct parts.</p>

      <p>This is the instantiated model of the WordSegmenterApproach.
For training your own model, please see the documentation of that class.</p>

      <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
      <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val wordSegmenter = WordSegmenterModel.pretrained()
  .setInputCols("document")
  .setOutputCol("words_segmented")
</code></pre></div>      </div>
      <p>The default model is <code class="language-plaintext highlighter-rouge">"wordseg_pku"</code>, default language is <code class="language-plaintext highlighter-rouge">"zh"</code>, if no values are provided.
For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Word+Segmentation">Models Hub</a>.</p>

      <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/chinese/word_segmentation/words_segmenter_demo.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/WordSegmenterTest.scala">WordSegmenterTest</a>.</p>

      <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

      <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

      <table>
        <tbody>
          <tr>
            <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterModel">WordSegmenterModel</a></td>
            <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel">WordSegmenterModel</a></td>
            <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterModel.scala">WordSegmenterModel</a></td>
          </tr>
        </tbody>
      </table>

    </div>

  </div>

  <div class="h3-box model-content">

    <h2 id="yakekeywordextraction">YakeKeywordExtraction</h2>

    <p>Yake is an Unsupervised, Corpus-Independent, Domain and Language-Independent and Single-Document keyword extraction
algorithm.</p>

    <p>Extracting keywords from texts has become a challenge for individuals and organizations as the information grows in
complexity and size. The need to automate this task so that text can be processed in a timely and adequate manner has
led to the emergence of automatic keyword extraction tools. Yake is a novel feature-based system for multi-lingual
keyword extraction, which supports texts of different sizes, domain or languages. Unlike other approaches, Yake does
not rely on dictionaries nor thesauri, neither is trained against any corpora. Instead, it follows an unsupervised
approach which builds upon features extracted from the text, making it thus applicable to documents written in
different languages without the need for further knowledge. This can be beneficial for a large number of tasks and a
plethora of situations where access to training corpora is either limited or restricted.
The algorithm makes use of the position of a sentence and token. Therefore, to use the annotator, the text should be
first sent through a Sentence Boundary Detector and then a tokenizer.</p>

    <p>Note that each keyword will be given a keyword score greater than 0 (The lower the score better the keyword).
Therefore to filter the keywords, an upper bound for the score can be set with <code class="language-plaintext highlighter-rouge">setThreshold</code>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/8.Keyword_Extraction_YAKE.ipynb">Spark NLP Workshop</a>
and the <a href="https://github.com/JohnSnowLabs/spark-nlp/blob/master/src/test/scala/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeTestSpec.scala">YakeTestSpec</a>.</p>

    <p><strong>Sources</strong> :</p>

    <p><a href="https://www.sciencedirect.com/science/article/pii/S0020025519308588">Campos, R., Mangaravite, V., Pasquali, A., Jatowt, A., Jorge, A., Nunes, C. and Jatowt, A. (2020). YAKE! Keyword Extraction from Single Documents using Multiple Local Features. In Information Sciences Journal. Elsevier, Vol 509, pp 257-289</a></p>

    <p><strong>Paper abstract:</strong></p>

    <p><em>As the amount of generated information grows, reading and summarizing texts of large collections turns into a challenging task. Many documents do not come with descriptive terms,
thus requiring humans to generate keywords on-the-fly. The need to automate this kind of task demands the development of keyword extraction systems with the ability to automatically
identify keywords within the text. One approach is to resort to machine-learning algorithms. These, however, depend on large annotated text corpora, which are not always available.
An alternative solution is to consider an unsupervised approach. In this article, we describe YAKE!, a light-weight unsupervised automatic keyword extraction method which rests on
statistical text features extracted from single documents to select the most relevant keywords of a text. Our system does not need to be trained on a particular set of documents,
nor does it depend on dictionaries, external corpora, text size, language, or domain. To demonstrate the merits and significance of YAKE!, we compare it against ten state-of-the-art
unsupervised approaches and one supervised method. Experimental results carried out on top of twenty datasets show that YAKE! significantly outperforms other unsupervised methods on
texts of different sizes, languages, and domains.</em></p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="/api/python/reference/autosummary/sparknlp/annotator/keyword_extraction/yake_keyword_extraction/index.html#sparknlp.annotator.keyword_extraction.yake_keyword_extraction.YakeKeywordExtraction">YakeKeywordExtraction</a></td>
          <td><strong>Scala API:</strong> <a href="/api/com/johnsnowlabs/nlp/annotators/keyword/yake/YakeKeywordExtraction">YakeKeywordExtraction</a></td>
          <td><strong>Source:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/keyword.yake/YakeKeywordExtraction.scala">YakeKeywordExtraction</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box tabs-new">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setContextChars</span><span class="p">([</span><span class="s">"("</span><span class="p">,</span> <span class="s">"]"</span><span class="p">,</span> <span class="s">"?"</span><span class="p">,</span> <span class="s">"!"</span><span class="p">,</span> <span class="s">"."</span><span class="p">,</span> <span class="s">","</span><span class="p">])</span>

<span class="n">keywords</span> <span class="o">=</span> <span class="n">YakeKeywordExtraction</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"keywords"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mf">0.6</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMinNGrams</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setNKeywords</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">keywords</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span>
    <span class="s">"Sources tell us that Google is acquiring Kaggle, a platform that hosts data science and machine learning competitions. Details about the transaction remain somewhat vague, but given that Google is hosting its Cloud Next conference in San Francisco this week, the official announcement could come as early as tomorrow. Reached by phone, Kaggle co-founder CEO Anthony Goldbloom declined to deny that the acquisition is happening. Google itself declined 'to comment on rumors'. Kaggle, which has about half a million data scientists on its platform, was founded by Goldbloom  and Ben Hamner in 2010. The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, it has managed to stay well ahead of them by focusing on its specific niche. The service is basically the de facto home for running data science and machine learning competitions. With Kaggle, Google is buying one of the largest and most active communities for data scientists - and with that, it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow and other projects). Kaggle has a bit of a history with Google, too, but that's pretty recent. Earlier this month, Google and Kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos. That competition had some deep integrations with the Google Cloud Platform, too. Our understanding is that Google will keep the service running - likely under its current name. While the acquisition is probably more about Kaggle's community than technology, Kaggle did build some interesting tools for hosting its competition and 'kernels', too. On Kaggle, kernels are basically the source code for analyzing data sets and developers can share this code on the platform (the company previously called them 'scripts'). Like similar competition-centric sites, Kaggle also runs a job board, too. It's unclear what Google will do with that part of the service. According to Crunchbase, Kaggle raised $12.5 million (though PitchBook says it's $12.75) since its   launch in 2010. Investors in Kaggle include Index Ventures, SV Angel, Max Levchin, NaRavikant, Google chie economist Hal Varian, Khosla Ventures and Yuri Milner"</span>
<span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># combine the result and score (contained in keywords.metadata)
</span><span class="n">scores</span> <span class="o">=</span> <span class="n">result</span> \
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(arrays_zip(keywords.result, keywords.metadata)) as resultTuples"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"resultTuples['0'] as keyword"</span><span class="p">,</span> <span class="s">"resultTuples['1'].score as score"</span><span class="p">)</span>

<span class="c1"># Order ascending, as lower scores means higher importance
</span><span class="n">scores</span><span class="p">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s">"score"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------+-------------------+</span>
<span class="o">|</span><span class="n">keyword</span>              <span class="o">|</span><span class="n">score</span>              <span class="o">|</span>
<span class="o">+---------------------+-------------------+</span>
<span class="o">|</span><span class="n">google</span> <span class="n">cloud</span>         <span class="o">|</span><span class="mf">0.32051516486864573</span><span class="o">|</span>
<span class="o">|</span><span class="n">google</span> <span class="n">cloud</span> <span class="n">platform</span><span class="o">|</span><span class="mf">0.37786450577630676</span><span class="o">|</span>
<span class="o">|</span><span class="n">ceo</span> <span class="n">anthony</span> <span class="n">goldbloom</span><span class="o">|</span><span class="mf">0.39922830978423146</span><span class="o">|</span>
<span class="o">|</span><span class="n">san</span> <span class="n">francisco</span>        <span class="o">|</span><span class="mf">0.40224744669493756</span><span class="o">|</span>
<span class="o">|</span><span class="n">anthony</span> <span class="n">goldbloom</span>    <span class="o">|</span><span class="mf">0.41584827825302534</span><span class="o">|</span>
<span class="o">+---------------------+-------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotator.</span><span class="o">{</span><span class="nc">SentenceDetector</span><span class="o">,</span> <span class="nc">Tokenizer</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.keyword.yake.YakeKeywordExtraction</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setContextChars</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"("</span><span class="o">,</span> <span class="s">")"</span><span class="o">,</span> <span class="s">"?"</span><span class="o">,</span> <span class="s">"!"</span><span class="o">,</span> <span class="s">"."</span><span class="o">,</span> <span class="s">","</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">keywords</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">YakeKeywordExtraction</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"keywords"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mf">0.6f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMinNGrams</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNKeywords</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">token</span><span class="o">,</span>
  <span class="n">keywords</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Sources tell us that Google is acquiring Kaggle, a platform that hosts data science and machine learning competitions. Details about the transaction remain somewhat vague, but given that Google is hosting its Cloud Next conference in San Francisco this week, the official announcement could come as early as tomorrow. Reached by phone, Kaggle co-founder CEO Anthony Goldbloom declined to deny that the acquisition is happening. Google itself declined 'to comment on rumors'. Kaggle, which has about half a million data scientists on its platform, was founded by Goldbloom  and Ben Hamner in 2010. The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, it has managed to stay well ahead of them by focusing on its specific niche. The service is basically the de facto home for running data science and machine learning competitions. With Kaggle, Google is buying one of the largest and most active communities for data scientists - and with that, it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow and other projects). Kaggle has a bit of a history with Google, too, but that's pretty recent. Earlier this month, Google and Kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos. That competition had some deep integrations with the Google Cloud Platform, too. Our understanding is that Google will keep the service running - likely under its current name. While the acquisition is probably more about Kaggle's community than technology, Kaggle did build some interesting tools for hosting its competition and 'kernels', too. On Kaggle, kernels are basically the source code for analyzing data sets and developers can share this code on the platform (the company previously called them 'scripts'). Like similar competition-centric sites, Kaggle also runs a job board, too. It's unclear what Google will do with that part of the service. According to Crunchbase, Kaggle raised $12.5 million (though PitchBook says it's $12.75) since its   launch in 2010. Investors in Kaggle include Index Ventures, SV Angel, Max Levchin, Naval Ravikant, Google chief economist Hal Varian, Khosla Ventures and Yuri Milner"</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// combine the result and score (contained in keywords.metadata)</span>
<span class="k">val</span> <span class="nv">scores</span> <span class="k">=</span> <span class="n">result</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(arrays_zip(keywords.result, keywords.metadata)) as resultTuples"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="n">$</span><span class="s">"resultTuples.0"</span> <span class="n">as</span> <span class="s">"keyword"</span><span class="o">,</span> <span class="n">$</span><span class="s">"resultTuples.1.score"</span><span class="o">)</span>

<span class="c1">// Order ascending, as lower scores means higher importance</span>
<span class="nv">scores</span><span class="o">.</span><span class="py">orderBy</span><span class="o">(</span><span class="s">"score"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------+-------------------+</span>
<span class="o">|</span><span class="n">keyword</span>              <span class="o">|</span><span class="n">score</span>              <span class="o">|</span>
<span class="o">+---------------------+-------------------+</span>
<span class="o">|</span><span class="n">google</span> <span class="n">cloud</span>         <span class="o">|</span><span class="mf">0.32051516486864573</span><span class="o">|</span>
<span class="o">|</span><span class="n">google</span> <span class="n">cloud</span> <span class="n">platform</span><span class="o">|</span><span class="mf">0.37786450577630676</span><span class="o">|</span>
<span class="o">|</span><span class="n">ceo</span> <span class="n">anthony</span> <span class="n">goldbloom</span><span class="o">|</span><span class="mf">0.39922830978423146</span><span class="o">|</span>
<span class="o">|</span><span class="n">san</span> <span class="n">francisco</span>        <span class="o">|</span><span class="mf">0.40224744669493756</span><span class="o">|</span>
<span class="o">|</span><span class="n">anthony</span> <span class="n">goldbloom</span>    <span class="o">|</span><span class="mf">0.41584827825302534</span><span class="o">|</span>
<span class="o">+---------------------+-------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

</div>
</div><div class="d-print-none"><footer class="article__footer"><span class="footer_date">Last updated
      <time itemprop="dateModified" datetime="2021-04-17T00:00:00+00:00">Apr 17, 2021</time>
    </span><!-- start custom article footer snippet -->

<!-- end custom article footer snippet --></footer>

<script>

/* 
jQuery(document).ready(function(){  
    $( ".scala-button" ).click(function() {
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-scala" ).show();
        $(this).closest( ".tabs-box" ).find( ".language-python, .nlu-block" ).hide();
    });

    $( ".python-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-un-active').addClass( "code-selector-active" ); 

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');


        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-python" ).show();
        $(this).closest( ".tabs-box" ).find( ".nlu-block, .language-scala" ).hide();
    });

    $( ".nlu-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets        
        $(this).closest( ".tabs-box" ).find( ".language-python, .language-scala" ).hide();
        $(this).closest( ".tabs-box" ).find( ".nlu-block" ).show();
    });
}); */

/* function togglePython1() {

    //set current button to active class and remove unactive class
    $( ".python-button" ).addClass( "code-selector-active" );


    //toggle language snippets
    $( ".tabs-box .language-python" ).show();
    $( ".tabs-box .nlu-block" ).hide();
    $( ".tabs-box .language-scala" ).hide();
}

function defer(method) { //wait until jquery ready
    if (window.jQuery) {
        method();
    } else {
        setTimeout(function() { defer(method); }, 15);
    }
}

defer(function () { // load inital language
    togglePython1();
}); */


if((document.querySelectorAll('.model-wrap').length !== 0) || (document.querySelectorAll('.tabs-new').length !== 0)) {

    let tabLi = document.querySelectorAll('.tabs-new .tab-li');

    if((document.querySelectorAll('.model-wrap').length !== 0)) {
        tabLi = document.querySelectorAll('.model-wrap .tab-li');
    } 
    
    let tabLiTopF = document.querySelectorAll('.top_tab_li'),
        pythonInner = document.querySelectorAll('.python-inner');

    tabLiTopF.forEach(e => {        
        e.nextElementSibling.classList.add('active');
    });
    pythonInner.forEach(e => {
        e.firstElementChild.classList.remove('language-python');
    });

    tabLi.forEach(element => {
        element.addEventListener('click', function(e) {
            e.preventDefault();
            let tabAttribute = element.getAttribute('data-type'),
                tabLiInner = element.parentNode.querySelectorAll('.tab-li'),
                tabBoxInner = element.parentNode.parentNode.parentNode.querySelectorAll('.highlighter-rouge');
            
            //remove active class from NLU
            tabBoxInner.forEach(item => {
                item.classList.remove('active');
                if(item.classList.contains('nlu-block')) {
                    item.classList.remove('language-python');
                }  
                
            });
            tabLiInner.forEach(el => {
                el.classList.remove('active');
                el.classList.remove('code-selector-active');
            });
            element.classList.add('active');
    
            //add active class
            switch (tabAttribute) {
                case "python":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('language-python')) {
                            item.classList.add('active');
                        }                    
                    });
                    break;
                case "scala":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('language-scala')) {
                            item.classList.add('active');
                        }                    
                    });
                  break;
                  case "nlu":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('nlu-block')) {
                            item.classList.add('active');
                        }                    
                    });
                  break;
                default:              
              }
        });
    });
}

//Second tabs
if(document.querySelectorAll('.tab-li-second').length !== 0) {
    let tabLi = document.querySelectorAll('.tab-li-second');

    tabLi.forEach(element => {
        element.addEventListener('click', function(e) {
            e.preventDefault();
            let tabAttribute = element.getAttribute('data-type'),
                tabLiInner = element.parentNode.querySelectorAll('.tab-li-second'),
                tabBoxInner = element.parentNode.parentNode.parentNode.querySelectorAll('.tabs-box-medic-inner');
            

            //remove active class
            tabBoxInner.forEach(item => {
                item.classList.remove('active');
            });
            tabLiInner.forEach(el => {
                el.classList.remove('active');
            });
            element.classList.add('active');
    
            //add active class
            switch (tabAttribute) {
                case "python":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('language-python')) {
                            item.classList.add('active');
                        }                    
                    });
                    break;
                case "scala":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('language-scala')) {
                            item.classList.add('active');
                        }                    
                    });
                  break;
                default:              
              }
        });
    });
}

//Third tabs
if(document.querySelectorAll('.tab-li-inner').length !== 0) {

    let tabLiSecond = document.querySelectorAll('.tab-li-inner'),
        tabLiTop = document.querySelectorAll('.toptab-second'),
        tabLi = document.querySelectorAll('.toptab-second p');


    tabLiTop.forEach(e => {        
        e.nextElementSibling.classList.add('active');
    });

    tabLi.forEach(e => {        
        e.firstChild.classList.add('active');
    });


    tabLiSecond.forEach(element => {
        element.addEventListener('click', function(e) {
            e.preventDefault();
            let tabAttributeSecond = element.getAttribute('data-type'),
                tabLiInnerSecond = element.parentNode.querySelectorAll('.tab-li-inner'),
                tabBoxInnerSecond = element.parentNode.parentNode.parentNode.querySelectorAll('.tabs-box-medic-inner-second');
            
            //remove active class
            tabBoxInnerSecond.forEach(item => {
                item.classList.remove('active');
            });
            tabLiInnerSecond.forEach(el => {
                el.classList.remove('active');
            });
            element.classList.add('active');
    
            //add active class
            switch (tabAttributeSecond) {
                case "medical":
                    tabBoxInnerSecond.forEach(item => {
                        if(item.classList.contains('language-medical')) {
                            item.classList.add('active');
                        }                    
                    });
                    break;
                case "finance":
                    tabBoxInnerSecond.forEach(item => {
                        if(item.classList.contains('language-finance')) {
                            item.classList.add('active');
                        }                    
                    });
                  break;
                case "legal":
                tabBoxInnerSecond.forEach(item => {
                    if(item.classList.contains('language-legal')) {
                        item.classList.add('active');
                    }                    
                });
                break;
                default:              
              }
        });
    });
}

//Forth tabs
if(document.querySelectorAll('.tab-jsl').length !== 0) {
    let tabLiForth = document.querySelectorAll('.tab-jsl');

    tabLiForth.forEach(element => {
        element.addEventListener('click', function(e) {
            e.preventDefault();
            let tabAttribute = element.getAttribute('data-type'),
                tabLiInner = element.parentNode.querySelectorAll('.tab-jsl'),
                tabBoxInner = element.parentNode.parentNode.parentNode.querySelectorAll('.python-inner');
            

            //remove active class
            tabBoxInner.forEach(item => {
                item.classList.remove('active');
            });
            tabLiInner.forEach(el => {
                el.classList.remove('active');
            });
            element.classList.add('active');
    
            //add active class
            switch (tabAttribute) {
                case "spark-nlp-jsl":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('python-johnsnowlabs')) {
                            item.classList.add('active');
                        }                    
                    });
                    break;
                case "johnsnowlabs":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('python-spark-nlp-jsl')) {
                            item.classList.add('active');
                        }                    
                    });
                  break;
                default:              
              }
        });
    });
}

</script>


<style>
  /* Remove Scrollbar from Code Segments */
.article__content .highlighter-rouge > .highlight > pre > code, .article__content figure.highlight > pre > code  {
    overflow: auto;
}



button.code-selector-active {
 background-color: white;
 color: #08c;
 font-weight: bold;
 border-width: 1px;
 padding-left: 12px;
 padding-right: 12px;
 width: 90px;
 padding-top: 6px;
 margin-right: 2px;

 border-bottom: none;

 position: relative;
 z-index: 2;
}

button.code-selector-un-active {
    background-color: white;
    padding-left: 12px;
    padding-right: 12px;
    width: 90px;
    margin-right: 2px;
    padding-top: 8px;
    position: relative;
    border-bottom: none;

   }

hr.code-selector-underlie {
    border-top: 1px solid;
    background-color: black;
    width: fill;
    height: 1px;
    margin-top: -3px;
    position: relative;

}

</style><div class="article__section-navigator clearfix"><div class="previous nav_link"><span>PREVIOUS</span><a href="/docs/en/concepts">General Concepts</a></div><div class="next nav_link"><span>NEXT</span><a href="/docs/en/transformers">Transformers</a></div></div></div>

</div>
</div>

<script>/*! jQuery v1.12.3 | (c) jQuery Foundation | jquery.org/license */
!function(a,b){"object"==typeof module&&"object"==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error("jQuery requires a window with a document");return b(a)}:b(a)}("undefined"!=typeof window?window:this,function(a,b){var c=[],d=a.document,e=c.slice,f=c.concat,g=c.push,h=c.indexOf,i={},j=i.toString,k=i.hasOwnProperty,l={},m="1.12.3",n=function(a,b){return new n.fn.init(a,b)},o=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,p=/^-ms-/,q=/-([\da-z])/gi,r=function(a,b){return b.toUpperCase()};n.fn=n.prototype={jquery:m,constructor:n,selector:"",length:0,toArray:function(){return e.call(this)},get:function(a){return null!=a?0>a?this[a+this.length]:this[a]:e.call(this)},pushStack:function(a){var b=n.merge(this.constructor(),a);return b.prevObject=this,b.context=this.context,b},each:function(a){return n.each(this,a)},map:function(a){return this.pushStack(n.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushStack(e.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},eq:function(a){var b=this.length,c=+a+(0>a?b:0);return this.pushStack(c>=0&&b>c?[this[c]]:[])},end:function(){return this.prevObject||this.constructor()},push:g,sort:c.sort,splice:c.splice},n.extend=n.fn.extend=function(){var a,b,c,d,e,f,g=arguments[0]||{},h=1,i=arguments.length,j=!1;for("boolean"==typeof g&&(j=g,g=arguments[h]||{},h++),"object"==typeof g||n.isFunction(g)||(g={}),h===i&&(g=this,h--);i>h;h++)if(null!=(e=arguments[h]))for(d in e)a=g[d],c=e[d],g!==c&&(j&&c&&(n.isPlainObject(c)||(b=n.isArray(c)))?(b?(b=!1,f=a&&n.isArray(a)?a:[]):f=a&&n.isPlainObject(a)?a:{},g[d]=n.extend(j,f,c)):void 0!==c&&(g[d]=c));return g},n.extend({expando:"jQuery"+(m+Math.random()).replace(/\D/g,""),isReady:!0,error:function(a){throw new Error(a)},noop:function(){},isFunction:function(a){return"function"===n.type(a)},isArray:Array.isArray||function(a){return"array"===n.type(a)},isWindow:function(a){return null!=a&&a==a.window},isNumeric:function(a){var b=a&&a.toString();return!n.isArray(a)&&b-parseFloat(b)+1>=0},isEmptyObject:function(a){var b;for(b in a)return!1;return!0},isPlainObject:function(a){var b;if(!a||"object"!==n.type(a)||a.nodeType||n.isWindow(a))return!1;try{if(a.constructor&&!k.call(a,"constructor")&&!k.call(a.constructor.prototype,"isPrototypeOf"))return!1}catch(c){return!1}if(!l.ownFirst)for(b in a)return k.call(a,b);for(b in a);return void 0===b||k.call(a,b)},type:function(a){return null==a?a+"":"object"==typeof a||"function"==typeof a?i[j.call(a)]||"object":typeof a},globalEval:function(b){b&&n.trim(b)&&(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.replace(p,"ms-").replace(q,r)},nodeName:function(a,b){return a.nodeName&&a.nodeName.toLowerCase()===b.toLowerCase()},each:function(a,b){var c,d=0;if(s(a)){for(c=a.length;c>d;d++)if(b.call(a[d],d,a[d])===!1)break}else for(d in a)if(b.call(a[d],d,a[d])===!1)break;return a},trim:function(a){return null==a?"":(a+"").replace(o,"")},makeArray:function(a,b){var c=b||[];return null!=a&&(s(Object(a))?n.merge(c,"string"==typeof a?[a]:a):g.call(c,a)),c},inArray:function(a,b,c){var d;if(b){if(h)return h.call(b,a,c);for(d=b.length,c=c?0>c?Math.max(0,d+c):c:0;d>c;c++)if(c in b&&b[c]===a)return c}return-1},merge:function(a,b){var c=+b.length,d=0,e=a.length;while(c>d)a[e++]=b[d++];if(c!==c)while(void 0!==b[d])a[e++]=b[d++];return a.length=e,a},grep:function(a,b,c){for(var d,e=[],f=0,g=a.length,h=!c;g>f;f++)d=!b(a[f],f),d!==h&&e.push(a[f]);return e},map:function(a,b,c){var d,e,g=0,h=[];if(s(a))for(d=a.length;d>g;g++)e=b(a[g],g,c),null!=e&&h.push(e);else for(g in a)e=b(a[g],g,c),null!=e&&h.push(e);return f.apply([],h)},guid:1,proxy:function(a,b){var c,d,f;return"string"==typeof b&&(f=a[b],b=a,a=f),n.isFunction(a)?(c=e.call(arguments,2),d=function(){return a.apply(b||this,c.concat(e.call(arguments)))},d.guid=a.guid=a.guid||n.guid++,d):void 0},now:function(){return+new Date},support:l}),"function"==typeof Symbol&&(n.fn[Symbol.iterator]=c[Symbol.iterator]),n.each("Boolean Number String Function Array Date RegExp Object Error Symbol".split(" "),function(a,b){i["[object "+b+"]"]=b.toLowerCase()});function s(a){var b=!!a&&"length"in a&&a.length,c=n.type(a);return"function"===c||n.isWindow(a)?!1:"array"===c||0===b||"number"==typeof b&&b>0&&b-1 in a}var t=function(a){var b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u="sizzle"+1*new Date,v=a.document,w=0,x=0,y=ga(),z=ga(),A=ga(),B=function(a,b){return a===b&&(l=!0),0},C=1<<31,D={}.hasOwnProperty,E=[],F=E.pop,G=E.push,H=E.push,I=E.slice,J=function(a,b){for(var c=0,d=a.length;d>c;c++)if(a[c]===b)return c;return-1},K="checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|ismap|loop|multiple|open|readonly|required|scoped",L="[\\x20\\t\\r\\n\\f]",M="(?:\\\\.|[\\w-]|[^\\x00-\\xa0])+",N="\\["+L+"*("+M+")(?:"+L+"*([*^$|!~]?=)"+L+"*(?:'((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\"|("+M+"))|)"+L+"*\\]",O=":("+M+")(?:\\((('((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\")|((?:\\\\.|[^\\\\()[\\]]|"+N+")*)|.*)\\)|)",P=new RegExp(L+"+","g"),Q=new RegExp("^"+L+"+|((?:^|[^\\\\])(?:\\\\.)*)"+L+"+$","g"),R=new RegExp("^"+L+"*,"+L+"*"),S=new RegExp("^"+L+"*([>+~]|"+L+")"+L+"*"),T=new RegExp("="+L+"*([^\\]'\"]*?)"+L+"*\\]","g"),U=new RegExp(O),V=new RegExp("^"+M+"$"),W={ID:new RegExp("^#("+M+")"),CLASS:new RegExp("^\\.("+M+")"),TAG:new RegExp("^("+M+"|[*])"),ATTR:new RegExp("^"+N),PSEUDO:new RegExp("^"+O),CHILD:new RegExp("^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\("+L+"*(even|odd|(([+-]|)(\\d*)n|)"+L+"*(?:([+-]|)"+L+"*(\\d+)|))"+L+"*\\)|)","i"),bool:new RegExp("^(?:"+K+")$","i"),needsContext:new RegExp("^"+L+"*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\("+L+"*((?:-\\d)?\\d*)"+L+"*\\)|)(?=[^-]|$)","i")},X=/^(?:input|select|textarea|button)$/i,Y=/^h\d$/i,Z=/^[^{]+\{\s*\[native \w/,$=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,_=/[+~]/,aa=/'|\\/g,ba=new RegExp("\\\\([\\da-f]{1,6}"+L+"?|("+L+")|.)","ig"),ca=function(a,b,c){var d="0x"+b-65536;return d!==d||c?b:0>d?String.fromCharCode(d+65536):String.fromCharCode(d>>10|55296,1023&d|56320)},da=function(){m()};try{H.apply(E=I.call(v.childNodes),v.childNodes),E[v.childNodes.length].nodeType}catch(ea){H={apply:E.length?function(a,b){G.apply(a,I.call(b))}:function(a,b){var c=a.length,d=0;while(a[c++]=b[d++]);a.length=c-1}}}function fa(a,b,d,e){var f,h,j,k,l,o,r,s,w=b&&b.ownerDocument,x=b?b.nodeType:9;if(d=d||[],"string"!=typeof a||!a||1!==x&&9!==x&&11!==x)return d;if(!e&&((b?b.ownerDocument||b:v)!==n&&m(b),b=b||n,p)){if(11!==x&&(o=$.exec(a)))if(f=o[1]){if(9===x){if(!(j=b.getElementById(f)))return d;if(j.id===f)return d.push(j),d}else if(w&&(j=w.getElementById(f))&&t(b,j)&&j.id===f)return d.push(j),d}else{if(o[2])return H.apply(d,b.getElementsByTagName(a)),d;if((f=o[3])&&c.getElementsByClassName&&b.getElementsByClassName)return H.apply(d,b.getElementsByClassName(f)),d}if(c.qsa&&!A[a+" "]&&(!q||!q.test(a))){if(1!==x)w=b,s=a;else if("object"!==b.nodeName.toLowerCase()){(k=b.getAttribute("id"))?k=k.replace(aa,"\\$&"):b.setAttribute("id",k=u),r=g(a),h=r.length,l=V.test(k)?"#"+k:"[id='"+k+"']";while(h--)r[h]=l+" "+qa(r[h]);s=r.join(","),w=_.test(a)&&oa(b.parentNode)||b}if(s)try{return H.apply(d,w.querySelectorAll(s)),d}catch(y){}finally{k===u&&b.removeAttribute("id")}}}return i(a.replace(Q,"$1"),b,d,e)}function ga(){var a=[];function b(c,e){return a.push(c+" ")>d.cacheLength&&delete b[a.shift()],b[c+" "]=e}return b}function ha(a){return a[u]=!0,a}function ia(a){var b=n.createElement("div");try{return!!a(b)}catch(c){return!1}finally{b.parentNode&&b.parentNode.removeChild(b),b=null}}function ja(a,b){var c=a.split("|"),e=c.length;while(e--)d.attrHandle[c[e]]=b}function ka(a,b){var c=b&&a,d=c&&1===a.nodeType&&1===b.nodeType&&(~b.sourceIndex||C)-(~a.sourceIndex||C);if(d)return d;if(c)while(c=c.nextSibling)if(c===b)return-1;return a?1:-1}function la(a){return function(b){var c=b.nodeName.toLowerCase();return"input"===c&&b.type===a}}function ma(a){return function(b){var c=b.nodeName.toLowerCase();return("input"===c||"button"===c)&&b.type===a}}function na(a){return ha(function(b){return b=+b,ha(function(c,d){var e,f=a([],c.length,b),g=f.length;while(g--)c[e=f[g]]&&(c[e]=!(d[e]=c[e]))})})}function oa(a){return a&&"undefined"!=typeof a.getElementsByTagName&&a}c=fa.support={},f=fa.isXML=function(a){var b=a&&(a.ownerDocument||a).documentElement;return b?"HTML"!==b.nodeName:!1},m=fa.setDocument=function(a){var b,e,g=a?a.ownerDocument||a:v;return g!==n&&9===g.nodeType&&g.documentElement?(n=g,o=n.documentElement,p=!f(n),(e=n.defaultView)&&e.top!==e&&(e.addEventListener?e.addEventListener("unload",da,!1):e.attachEvent&&e.attachEvent("onunload",da)),c.attributes=ia(function(a){return a.className="i",!a.getAttribute("className")}),c.getElementsByTagName=ia(function(a){return a.appendChild(n.createComment("")),!a.getElementsByTagName("*").length}),c.getElementsByClassName=Z.test(n.getElementsByClassName),c.getById=ia(function(a){return o.appendChild(a).id=u,!n.getElementsByName||!n.getElementsByName(u).length}),c.getById?(d.find.ID=function(a,b){if("undefined"!=typeof b.getElementById&&p){var c=b.getElementById(a);return c?[c]:[]}},d.filter.ID=function(a){var b=a.replace(ba,ca);return function(a){return a.getAttribute("id")===b}}):(delete d.find.ID,d.filter.ID=function(a){var b=a.replace(ba,ca);return function(a){var c="undefined"!=typeof a.getAttributeNode&&a.getAttributeNode("id");return c&&c.value===b}}),d.find.TAG=c.getElementsByTagName?function(a,b){return"undefined"!=typeof b.getElementsByTagName?b.getElementsByTagName(a):c.qsa?b.querySelectorAll(a):void 0}:function(a,b){var c,d=[],e=0,f=b.getElementsByTagName(a);if("*"===a){while(c=f[e++])1===c.nodeType&&d.push(c);return d}return f},d.find.CLASS=c.getElementsByClassName&&function(a,b){return"undefined"!=typeof b.getElementsByClassName&&p?b.getElementsByClassName(a):void 0},r=[],q=[],(c.qsa=Z.test(n.querySelectorAll))&&(ia(function(a){o.appendChild(a).innerHTML="<a id='"+u+"'></a><select id='"+u+"-\r\\' msallowcapture=''><option selected=''></option></select>",a.querySelectorAll("[msallowcapture^='']").length&&q.push("[*^$]="+L+"*(?:''|\"\")"),a.querySelectorAll("[selected]").length||q.push("\\["+L+"*(?:value|"+K+")"),a.querySelectorAll("[id~="+u+"-]").length||q.push("~="),a.querySelectorAll(":checked").length||q.push(":checked"),a.querySelectorAll("a#"+u+"+*").length||q.push(".#.+[+~]")}),ia(function(a){var b=n.createElement("input");b.setAttribute("type","hidden"),a.appendChild(b).setAttribute("name","D"),a.querySelectorAll("[name=d]").length&&q.push("name"+L+"*[*^$|!~]?="),a.querySelectorAll(":enabled").length||q.push(":enabled",":disabled"),a.querySelectorAll("*,:x"),q.push(",.*:")})),(c.matchesSelector=Z.test(s=o.matches||o.webkitMatchesSelector||o.mozMatchesSelector||o.oMatchesSelector||o.msMatchesSelector))&&ia(function(a){c.disconnectedMatch=s.call(a,"div"),s.call(a,"[s!='']:x"),r.push("!=",O)}),q=q.length&&new RegExp(q.join("|")),r=r.length&&new RegExp(r.join("|")),b=Z.test(o.compareDocumentPosition),t=b||Z.test(o.contains)?function(a,b){var c=9===a.nodeType?a.documentElement:a,d=b&&b.parentNode;return a===d||!(!d||1!==d.nodeType||!(c.contains?c.contains(d):a.compareDocumentPosition&&16&a.compareDocumentPosition(d)))}:function(a,b){if(b)while(b=b.parentNode)if(b===a)return!0;return!1},B=b?function(a,b){if(a===b)return l=!0,0;var d=!a.compareDocumentPosition-!b.compareDocumentPosition;return d?d:(d=(a.ownerDocument||a)===(b.ownerDocument||b)?a.compareDocumentPosition(b):1,1&d||!c.sortDetached&&b.compareDocumentPosition(a)===d?a===n||a.ownerDocument===v&&t(v,a)?-1:b===n||b.ownerDocument===v&&t(v,b)?1:k?J(k,a)-J(k,b):0:4&d?-1:1)}:function(a,b){if(a===b)return l=!0,0;var c,d=0,e=a.parentNode,f=b.parentNode,g=[a],h=[b];if(!e||!f)return a===n?-1:b===n?1:e?-1:f?1:k?J(k,a)-J(k,b):0;if(e===f)return ka(a,b);c=a;while(c=c.parentNode)g.unshift(c);c=b;while(c=c.parentNode)h.unshift(c);while(g[d]===h[d])d++;return d?ka(g[d],h[d]):g[d]===v?-1:h[d]===v?1:0},n):n},fa.matches=function(a,b){return fa(a,null,null,b)},fa.matchesSelector=function(a,b){if((a.ownerDocument||a)!==n&&m(a),b=b.replace(T,"='$1']"),c.matchesSelector&&p&&!A[b+" "]&&(!r||!r.test(b))&&(!q||!q.test(b)))try{var d=s.call(a,b);if(d||c.disconnectedMatch||a.document&&11!==a.document.nodeType)return d}catch(e){}return fa(b,n,null,[a]).length>0},fa.contains=function(a,b){return(a.ownerDocument||a)!==n&&m(a),t(a,b)},fa.attr=function(a,b){(a.ownerDocument||a)!==n&&m(a);var e=d.attrHandle[b.toLowerCase()],f=e&&D.call(d.attrHandle,b.toLowerCase())?e(a,b,!p):void 0;return void 0!==f?f:c.attributes||!p?a.getAttribute(b):(f=a.getAttributeNode(b))&&f.specified?f.value:null},fa.error=function(a){throw new Error("Syntax error, unrecognized expression: "+a)},fa.uniqueSort=function(a){var b,d=[],e=0,f=0;if(l=!c.detectDuplicates,k=!c.sortStable&&a.slice(0),a.sort(B),l){while(b=a[f++])b===a[f]&&(e=d.push(f));while(e--)a.splice(d[e],1)}return k=null,a},e=fa.getText=function(a){var b,c="",d=0,f=a.nodeType;if(f){if(1===f||9===f||11===f){if("string"==typeof a.textContent)return a.textContent;for(a=a.firstChild;a;a=a.nextSibling)c+=e(a)}else if(3===f||4===f)return a.nodeValue}else while(b=a[d++])c+=e(b);return c},d=fa.selectors={cacheLength:50,createPseudo:ha,match:W,attrHandle:{},find:{},relative:{">":{dir:"parentNode",first:!0}," ":{dir:"parentNode"},"+":{dir:"previousSibling",first:!0},"~":{dir:"previousSibling"}},preFilter:{ATTR:function(a){return a[1]=a[1].replace(ba,ca),a[3]=(a[3]||a[4]||a[5]||"").replace(ba,ca),"~="===a[2]&&(a[3]=" "+a[3]+" "),a.slice(0,4)},CHILD:function(a){return a[1]=a[1].toLowerCase(),"nth"===a[1].slice(0,3)?(a[3]||fa.error(a[0]),a[4]=+(a[4]?a[5]+(a[6]||1):2*("even"===a[3]||"odd"===a[3])),a[5]=+(a[7]+a[8]||"odd"===a[3])):a[3]&&fa.error(a[0]),a},PSEUDO:function(a){var b,c=!a[6]&&a[2];return W.CHILD.test(a[0])?null:(a[3]?a[2]=a[4]||a[5]||"":c&&U.test(c)&&(b=g(c,!0))&&(b=c.indexOf(")",c.length-b)-c.length)&&(a[0]=a[0].slice(0,b),a[2]=c.slice(0,b)),a.slice(0,3))}},filter:{TAG:function(a){var b=a.replace(ba,ca).toLowerCase();return"*"===a?function(){return!0}:function(a){return a.nodeName&&a.nodeName.toLowerCase()===b}},CLASS:function(a){var b=y[a+" "];return b||(b=new RegExp("(^|"+L+")"+a+"("+L+"|$)"))&&y(a,function(a){return b.test("string"==typeof a.className&&a.className||"undefined"!=typeof a.getAttribute&&a.getAttribute("class")||"")})},ATTR:function(a,b,c){return function(d){var e=fa.attr(d,a);return null==e?"!="===b:b?(e+="","="===b?e===c:"!="===b?e!==c:"^="===b?c&&0===e.indexOf(c):"*="===b?c&&e.indexOf(c)>-1:"$="===b?c&&e.slice(-c.length)===c:"~="===b?(" "+e.replace(P," ")+" ").indexOf(c)>-1:"|="===b?e===c||e.slice(0,c.length+1)===c+"-":!1):!0}},CHILD:function(a,b,c,d,e){var f="nth"!==a.slice(0,3),g="last"!==a.slice(-4),h="of-type"===b;return 1===d&&0===e?function(a){return!!a.parentNode}:function(b,c,i){var j,k,l,m,n,o,p=f!==g?"nextSibling":"previousSibling",q=b.parentNode,r=h&&b.nodeName.toLowerCase(),s=!i&&!h,t=!1;if(q){if(f){while(p){m=b;while(m=m[p])if(h?m.nodeName.toLowerCase()===r:1===m.nodeType)return!1;o=p="only"===a&&!o&&"nextSibling"}return!0}if(o=[g?q.firstChild:q.lastChild],g&&s){m=q,l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),j=k[a]||[],n=j[0]===w&&j[1],t=n&&j[2],m=n&&q.childNodes[n];while(m=++n&&m&&m[p]||(t=n=0)||o.pop())if(1===m.nodeType&&++t&&m===b){k[a]=[w,n,t];break}}else if(s&&(m=b,l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),j=k[a]||[],n=j[0]===w&&j[1],t=n),t===!1)while(m=++n&&m&&m[p]||(t=n=0)||o.pop())if((h?m.nodeName.toLowerCase()===r:1===m.nodeType)&&++t&&(s&&(l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),k[a]=[w,t]),m===b))break;return t-=e,t===d||t%d===0&&t/d>=0}}},PSEUDO:function(a,b){var c,e=d.pseudos[a]||d.setFilters[a.toLowerCase()]||fa.error("unsupported pseudo: "+a);return e[u]?e(b):e.length>1?(c=[a,a,"",b],d.setFilters.hasOwnProperty(a.toLowerCase())?ha(function(a,c){var d,f=e(a,b),g=f.length;while(g--)d=J(a,f[g]),a[d]=!(c[d]=f[g])}):function(a){return e(a,0,c)}):e}},pseudos:{not:ha(function(a){var b=[],c=[],d=h(a.replace(Q,"$1"));return d[u]?ha(function(a,b,c,e){var f,g=d(a,null,e,[]),h=a.length;while(h--)(f=g[h])&&(a[h]=!(b[h]=f))}):function(a,e,f){return b[0]=a,d(b,null,f,c),b[0]=null,!c.pop()}}),has:ha(function(a){return function(b){return fa(a,b).length>0}}),contains:ha(function(a){return a=a.replace(ba,ca),function(b){return(b.textContent||b.innerText||e(b)).indexOf(a)>-1}}),lang:ha(function(a){return V.test(a||"")||fa.error("unsupported lang: "+a),a=a.replace(ba,ca).toLowerCase(),function(b){var c;do if(c=p?b.lang:b.getAttribute("xml:lang")||b.getAttribute("lang"))return c=c.toLowerCase(),c===a||0===c.indexOf(a+"-");while((b=b.parentNode)&&1===b.nodeType);return!1}}),target:function(b){var c=a.location&&a.location.hash;return c&&c.slice(1)===b.id},root:function(a){return a===o},focus:function(a){return a===n.activeElement&&(!n.hasFocus||n.hasFocus())&&!!(a.type||a.href||~a.tabIndex)},enabled:function(a){return a.disabled===!1},disabled:function(a){return a.disabled===!0},checked:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&!!a.checked||"option"===b&&!!a.selected},selected:function(a){return a.parentNode&&a.parentNode.selectedIndex,a.selected===!0},empty:function(a){for(a=a.firstChild;a;a=a.nextSibling)if(a.nodeType<6)return!1;return!0},parent:function(a){return!d.pseudos.empty(a)},header:function(a){return Y.test(a.nodeName)},input:function(a){return X.test(a.nodeName)},button:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&"button"===a.type||"button"===b},text:function(a){var b;return"input"===a.nodeName.toLowerCase()&&"text"===a.type&&(null==(b=a.getAttribute("type"))||"text"===b.toLowerCase())},first:na(function(){return[0]}),last:na(function(a,b){return[b-1]}),eq:na(function(a,b,c){return[0>c?c+b:c]}),even:na(function(a,b){for(var c=0;b>c;c+=2)a.push(c);return a}),odd:na(function(a,b){for(var c=1;b>c;c+=2)a.push(c);return a}),lt:na(function(a,b,c){for(var d=0>c?c+b:c;--d>=0;)a.push(d);return a}),gt:na(function(a,b,c){for(var d=0>c?c+b:c;++d<b;)a.push(d);return a})}},d.pseudos.nth=d.pseudos.eq;for(b in{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})d.pseudos[b]=la(b);for(b in{submit:!0,reset:!0})d.pseudos[b]=ma(b);function pa(){}pa.prototype=d.filters=d.pseudos,d.setFilters=new pa,g=fa.tokenize=function(a,b){var c,e,f,g,h,i,j,k=z[a+" "];if(k)return b?0:k.slice(0);h=a,i=[],j=d.preFilter;while(h){c&&!(e=R.exec(h))||(e&&(h=h.slice(e[0].length)||h),i.push(f=[])),c=!1,(e=S.exec(h))&&(c=e.shift(),f.push({value:c,type:e[0].replace(Q," ")}),h=h.slice(c.length));for(g in d.filter)!(e=W[g].exec(h))||j[g]&&!(e=j[g](e))||(c=e.shift(),f.push({value:c,type:g,matches:e}),h=h.slice(c.length));if(!c)break}return b?h.length:h?fa.error(a):z(a,i).slice(0)};function qa(a){for(var b=0,c=a.length,d="";c>b;b++)d+=a[b].value;return d}function ra(a,b,c){var d=b.dir,e=c&&"parentNode"===d,f=x++;return b.first?function(b,c,f){while(b=b[d])if(1===b.nodeType||e)return a(b,c,f)}:function(b,c,g){var h,i,j,k=[w,f];if(g){while(b=b[d])if((1===b.nodeType||e)&&a(b,c,g))return!0}else while(b=b[d])if(1===b.nodeType||e){if(j=b[u]||(b[u]={}),i=j[b.uniqueID]||(j[b.uniqueID]={}),(h=i[d])&&h[0]===w&&h[1]===f)return k[2]=h[2];if(i[d]=k,k[2]=a(b,c,g))return!0}}}function sa(a){return a.length>1?function(b,c,d){var e=a.length;while(e--)if(!a[e](b,c,d))return!1;return!0}:a[0]}function ta(a,b,c){for(var d=0,e=b.length;e>d;d++)fa(a,b[d],c);return c}function ua(a,b,c,d,e){for(var f,g=[],h=0,i=a.length,j=null!=b;i>h;h++)(f=a[h])&&(c&&!c(f,d,e)||(g.push(f),j&&b.push(h)));return g}function va(a,b,c,d,e,f){return d&&!d[u]&&(d=va(d)),e&&!e[u]&&(e=va(e,f)),ha(function(f,g,h,i){var j,k,l,m=[],n=[],o=g.length,p=f||ta(b||"*",h.nodeType?[h]:h,[]),q=!a||!f&&b?p:ua(p,m,a,h,i),r=c?e||(f?a:o||d)?[]:g:q;if(c&&c(q,r,h,i),d){j=ua(r,n),d(j,[],h,i),k=j.length;while(k--)(l=j[k])&&(r[n[k]]=!(q[n[k]]=l))}if(f){if(e||a){if(e){j=[],k=r.length;while(k--)(l=r[k])&&j.push(q[k]=l);e(null,r=[],j,i)}k=r.length;while(k--)(l=r[k])&&(j=e?J(f,l):m[k])>-1&&(f[j]=!(g[j]=l))}}else r=ua(r===g?r.splice(o,r.length):r),e?e(null,g,r,i):H.apply(g,r)})}function wa(a){for(var b,c,e,f=a.length,g=d.relative[a[0].type],h=g||d.relative[" "],i=g?1:0,k=ra(function(a){return a===b},h,!0),l=ra(function(a){return J(b,a)>-1},h,!0),m=[function(a,c,d){var e=!g&&(d||c!==j)||((b=c).nodeType?k(a,c,d):l(a,c,d));return b=null,e}];f>i;i++)if(c=d.relative[a[i].type])m=[ra(sa(m),c)];else{if(c=d.filter[a[i].type].apply(null,a[i].matches),c[u]){for(e=++i;f>e;e++)if(d.relative[a[e].type])break;return va(i>1&&sa(m),i>1&&qa(a.slice(0,i-1).concat({value:" "===a[i-2].type?"*":""})).replace(Q,"$1"),c,e>i&&wa(a.slice(i,e)),f>e&&wa(a=a.slice(e)),f>e&&qa(a))}m.push(c)}return sa(m)}function xa(a,b){var c=b.length>0,e=a.length>0,f=function(f,g,h,i,k){var l,o,q,r=0,s="0",t=f&&[],u=[],v=j,x=f||e&&d.find.TAG("*",k),y=w+=null==v?1:Math.random()||.1,z=x.length;for(k&&(j=g===n||g||k);s!==z&&null!=(l=x[s]);s++){if(e&&l){o=0,g||l.ownerDocument===n||(m(l),h=!p);while(q=a[o++])if(q(l,g||n,h)){i.push(l);break}k&&(w=y)}c&&((l=!q&&l)&&r--,f&&t.push(l))}if(r+=s,c&&s!==r){o=0;while(q=b[o++])q(t,u,g,h);if(f){if(r>0)while(s--)t[s]||u[s]||(u[s]=F.call(i));u=ua(u)}H.apply(i,u),k&&!f&&u.length>0&&r+b.length>1&&fa.uniqueSort(i)}return k&&(w=y,j=v),t};return c?ha(f):f}return h=fa.compile=function(a,b){var c,d=[],e=[],f=A[a+" "];if(!f){b||(b=g(a)),c=b.length;while(c--)f=wa(b[c]),f[u]?d.push(f):e.push(f);f=A(a,xa(e,d)),f.selector=a}return f},i=fa.select=function(a,b,e,f){var i,j,k,l,m,n="function"==typeof a&&a,o=!f&&g(a=n.selector||a);if(e=e||[],1===o.length){if(j=o[0]=o[0].slice(0),j.length>2&&"ID"===(k=j[0]).type&&c.getById&&9===b.nodeType&&p&&d.relative[j[1].type]){if(b=(d.find.ID(k.matches[0].replace(ba,ca),b)||[])[0],!b)return e;n&&(b=b.parentNode),a=a.slice(j.shift().value.length)}i=W.needsContext.test(a)?0:j.length;while(i--){if(k=j[i],d.relative[l=k.type])break;if((m=d.find[l])&&(f=m(k.matches[0].replace(ba,ca),_.test(j[0].type)&&oa(b.parentNode)||b))){if(j.splice(i,1),a=f.length&&qa(j),!a)return H.apply(e,f),e;break}}}return(n||h(a,o))(f,b,!p,e,!b||_.test(a)&&oa(b.parentNode)||b),e},c.sortStable=u.split("").sort(B).join("")===u,c.detectDuplicates=!!l,m(),c.sortDetached=ia(function(a){return 1&a.compareDocumentPosition(n.createElement("div"))}),ia(function(a){return a.innerHTML="<a href='#'></a>","#"===a.firstChild.getAttribute("href")})||ja("type|href|height|width",function(a,b,c){return c?void 0:a.getAttribute(b,"type"===b.toLowerCase()?1:2)}),c.attributes&&ia(function(a){return a.innerHTML="<input/>",a.firstChild.setAttribute("value",""),""===a.firstChild.getAttribute("value")})||ja("value",function(a,b,c){return c||"input"!==a.nodeName.toLowerCase()?void 0:a.defaultValue}),ia(function(a){return null==a.getAttribute("disabled")})||ja(K,function(a,b,c){var d;return c?void 0:a[b]===!0?b.toLowerCase():(d=a.getAttributeNode(b))&&d.specified?d.value:null}),fa}(a);n.find=t,n.expr=t.selectors,n.expr[":"]=n.expr.pseudos,n.uniqueSort=n.unique=t.uniqueSort,n.text=t.getText,n.isXMLDoc=t.isXML,n.contains=t.contains;var u=function(a,b,c){var d=[],e=void 0!==c;while((a=a[b])&&9!==a.nodeType)if(1===a.nodeType){if(e&&n(a).is(c))break;d.push(a)}return d},v=function(a,b){for(var c=[];a;a=a.nextSibling)1===a.nodeType&&a!==b&&c.push(a);return c},w=n.expr.match.needsContext,x=/^<([\w-]+)\s*\/?>(?:<\/\1>|)$/,y=/^.[^:#\[\.,]*$/;function z(a,b,c){if(n.isFunction(b))return n.grep(a,function(a,d){return!!b.call(a,d,a)!==c});if(b.nodeType)return n.grep(a,function(a){return a===b!==c});if("string"==typeof b){if(y.test(b))return n.filter(b,a,c);b=n.filter(b,a)}return n.grep(a,function(a){return n.inArray(a,b)>-1!==c})}n.filter=function(a,b,c){var d=b[0];return c&&(a=":not("+a+")"),1===b.length&&1===d.nodeType?n.find.matchesSelector(d,a)?[d]:[]:n.find.matches(a,n.grep(b,function(a){return 1===a.nodeType}))},n.fn.extend({find:function(a){var b,c=[],d=this,e=d.length;if("string"!=typeof a)return this.pushStack(n(a).filter(function(){for(b=0;e>b;b++)if(n.contains(d[b],this))return!0}));for(b=0;e>b;b++)n.find(a,d[b],c);return c=this.pushStack(e>1?n.unique(c):c),c.selector=this.selector?this.selector+" "+a:a,c},filter:function(a){return this.pushStack(z(this,a||[],!1))},not:function(a){return this.pushStack(z(this,a||[],!0))},is:function(a){return!!z(this,"string"==typeof a&&w.test(a)?n(a):a||[],!1).length}});var A,B=/^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]*))$/,C=n.fn.init=function(a,b,c){var e,f;if(!a)return this;if(c=c||A,"string"==typeof a){if(e="<"===a.charAt(0)&&">"===a.charAt(a.length-1)&&a.length>=3?[null,a,null]:B.exec(a),!e||!e[1]&&b)return!b||b.jquery?(b||c).find(a):this.constructor(b).find(a);if(e[1]){if(b=b instanceof n?b[0]:b,n.merge(this,n.parseHTML(e[1],b&&b.nodeType?b.ownerDocument||b:d,!0)),x.test(e[1])&&n.isPlainObject(b))for(e in b)n.isFunction(this[e])?this[e](b[e]):this.attr(e,b[e]);return this}if(f=d.getElementById(e[2]),f&&f.parentNode){if(f.id!==e[2])return A.find(a);this.length=1,this[0]=f}return this.context=d,this.selector=a,this}return a.nodeType?(this.context=this[0]=a,this.length=1,this):n.isFunction(a)?"undefined"!=typeof c.ready?c.ready(a):a(n):(void 0!==a.selector&&(this.selector=a.selector,this.context=a.context),n.makeArray(a,this))};C.prototype=n.fn,A=n(d);var D=/^(?:parents|prev(?:Until|All))/,E={children:!0,contents:!0,next:!0,prev:!0};n.fn.extend({has:function(a){var b,c=n(a,this),d=c.length;return this.filter(function(){for(b=0;d>b;b++)if(n.contains(this,c[b]))return!0})},closest:function(a,b){for(var c,d=0,e=this.length,f=[],g=w.test(a)||"string"!=typeof a?n(a,b||this.context):0;e>d;d++)for(c=this[d];c&&c!==b;c=c.parentNode)if(c.nodeType<11&&(g?g.index(c)>-1:1===c.nodeType&&n.find.matchesSelector(c,a))){f.push(c);break}return this.pushStack(f.length>1?n.uniqueSort(f):f)},index:function(a){return a?"string"==typeof a?n.inArray(this[0],n(a)):n.inArray(a.jquery?a[0]:a,this):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(a,b){return this.pushStack(n.uniqueSort(n.merge(this.get(),n(a,b))))},addBack:function(a){return this.add(null==a?this.prevObject:this.prevObject.filter(a))}});function F(a,b){do a=a[b];while(a&&1!==a.nodeType);return a}n.each({parent:function(a){var b=a.parentNode;return b&&11!==b.nodeType?b:null},parents:function(a){return u(a,"parentNode")},parentsUntil:function(a,b,c){return u(a,"parentNode",c)},next:function(a){return F(a,"nextSibling")},prev:function(a){return F(a,"previousSibling")},nextAll:function(a){return u(a,"nextSibling")},prevAll:function(a){return u(a,"previousSibling")},nextUntil:function(a,b,c){return u(a,"nextSibling",c)},prevUntil:function(a,b,c){return u(a,"previousSibling",c)},siblings:function(a){return v((a.parentNode||{}).firstChild,a)},children:function(a){return v(a.firstChild)},contents:function(a){return n.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:n.merge([],a.childNodes)}},function(a,b){n.fn[a]=function(c,d){var e=n.map(this,b,c);return"Until"!==a.slice(-5)&&(d=c),d&&"string"==typeof d&&(e=n.filter(d,e)),this.length>1&&(E[a]||(e=n.uniqueSort(e)),D.test(a)&&(e=e.reverse())),this.pushStack(e)}});var G=/\S+/g;function H(a){var b={};return n.each(a.match(G)||[],function(a,c){b[c]=!0}),b}n.Callbacks=function(a){a="string"==typeof a?H(a):n.extend({},a);var b,c,d,e,f=[],g=[],h=-1,i=function(){for(e=a.once,d=b=!0;g.length;h=-1){c=g.shift();while(++h<f.length)f[h].apply(c[0],c[1])===!1&&a.stopOnFalse&&(h=f.length,c=!1)}a.memory||(c=!1),b=!1,e&&(f=c?[]:"")},j={add:function(){return f&&(c&&!b&&(h=f.length-1,g.push(c)),function d(b){n.each(b,function(b,c){n.isFunction(c)?a.unique&&j.has(c)||f.push(c):c&&c.length&&"string"!==n.type(c)&&d(c)})}(arguments),c&&!b&&i()),this},remove:function(){return n.each(arguments,function(a,b){var c;while((c=n.inArray(b,f,c))>-1)f.splice(c,1),h>=c&&h--}),this},has:function(a){return a?n.inArray(a,f)>-1:f.length>0},empty:function(){return f&&(f=[]),this},disable:function(){return e=g=[],f=c="",this},disabled:function(){return!f},lock:function(){return e=!0,c||j.disable(),this},locked:function(){return!!e},fireWith:function(a,c){return e||(c=c||[],c=[a,c.slice?c.slice():c],g.push(c),b||i()),this},fire:function(){return j.fireWith(this,arguments),this},fired:function(){return!!d}};return j},n.extend({Deferred:function(a){var b=[["resolve","done",n.Callbacks("once memory"),"resolved"],["reject","fail",n.Callbacks("once memory"),"rejected"],["notify","progress",n.Callbacks("memory")]],c="pending",d={state:function(){return c},always:function(){return e.done(arguments).fail(arguments),this},then:function(){var a=arguments;return n.Deferred(function(c){n.each(b,function(b,f){var g=n.isFunction(a[b])&&a[b];e[f[1]](function(){var a=g&&g.apply(this,arguments);a&&n.isFunction(a.promise)?a.promise().progress(c.notify).done(c.resolve).fail(c.reject):c[f[0]+"With"](this===d?c.promise():this,g?[a]:arguments)})}),a=null}).promise()},promise:function(a){return null!=a?n.extend(a,d):d}},e={};return d.pipe=d.then,n.each(b,function(a,f){var g=f[2],h=f[3];d[f[1]]=g.add,h&&g.add(function(){c=h},b[1^a][2].disable,b[2][2].lock),e[f[0]]=function(){return e[f[0]+"With"](this===e?d:this,arguments),this},e[f[0]+"With"]=g.fireWith}),d.promise(e),a&&a.call(e,e),e},when:function(a){var b=0,c=e.call(arguments),d=c.length,f=1!==d||a&&n.isFunction(a.promise)?d:0,g=1===f?a:n.Deferred(),h=function(a,b,c){return function(d){b[a]=this,c[a]=arguments.length>1?e.call(arguments):d,c===i?g.notifyWith(b,c):--f||g.resolveWith(b,c)}},i,j,k;if(d>1)for(i=new Array(d),j=new Array(d),k=new Array(d);d>b;b++)c[b]&&n.isFunction(c[b].promise)?c[b].promise().progress(h(b,j,i)).done(h(b,k,c)).fail(g.reject):--f;return f||g.resolveWith(k,c),g.promise()}});var I;n.fn.ready=function(a){return n.ready.promise().done(a),this},n.extend({isReady:!1,readyWait:1,holdReady:function(a){a?n.readyWait++:n.ready(!0)},ready:function(a){(a===!0?--n.readyWait:n.isReady)||(n.isReady=!0,a!==!0&&--n.readyWait>0||(I.resolveWith(d,[n]),n.fn.triggerHandler&&(n(d).triggerHandler("ready"),n(d).off("ready"))))}});function J(){d.addEventListener?(d.removeEventListener("DOMContentLoaded",K),a.removeEventListener("load",K)):(d.detachEvent("onreadystatechange",K),a.detachEvent("onload",K))}function K(){(d.addEventListener||"load"===a.event.type||"complete"===d.readyState)&&(J(),n.ready())}n.ready.promise=function(b){if(!I)if(I=n.Deferred(),"complete"===d.readyState||"loading"!==d.readyState&&!d.documentElement.doScroll)a.setTimeout(n.ready);else if(d.addEventListener)d.addEventListener("DOMContentLoaded",K),a.addEventListener("load",K);else{d.attachEvent("onreadystatechange",K),a.attachEvent("onload",K);var c=!1;try{c=null==a.frameElement&&d.documentElement}catch(e){}c&&c.doScroll&&!function f(){if(!n.isReady){try{c.doScroll("left")}catch(b){return a.setTimeout(f,50)}J(),n.ready()}}()}return I.promise(b)},n.ready.promise();var L;for(L in n(l))break;l.ownFirst="0"===L,l.inlineBlockNeedsLayout=!1,n(function(){var a,b,c,e;c=d.getElementsByTagName("body")[0],c&&c.style&&(b=d.createElement("div"),e=d.createElement("div"),e.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(e).appendChild(b),"undefined"!=typeof b.style.zoom&&(b.style.cssText="display:inline;margin:0;border:0;padding:1px;width:1px;zoom:1",l.inlineBlockNeedsLayout=a=3===b.offsetWidth,a&&(c.style.zoom=1)),c.removeChild(e))}),function(){var a=d.createElement("div");l.deleteExpando=!0;try{delete a.test}catch(b){l.deleteExpando=!1}a=null}();var M=function(a){var b=n.noData[(a.nodeName+" ").toLowerCase()],c=+a.nodeType||1;return 1!==c&&9!==c?!1:!b||b!==!0&&a.getAttribute("classid")===b},N=/^(?:\{[\w\W]*\}|\[[\w\W]*\])$/,O=/([A-Z])/g;function P(a,b,c){if(void 0===c&&1===a.nodeType){var d="data-"+b.replace(O,"-$1").toLowerCase();if(c=a.getAttribute(d),"string"==typeof c){try{c="true"===c?!0:"false"===c?!1:"null"===c?null:+c+""===c?+c:N.test(c)?n.parseJSON(c):c}catch(e){}n.data(a,b,c)}else c=void 0;
}return c}function Q(a){var b;for(b in a)if(("data"!==b||!n.isEmptyObject(a[b]))&&"toJSON"!==b)return!1;return!0}function R(a,b,d,e){if(M(a)){var f,g,h=n.expando,i=a.nodeType,j=i?n.cache:a,k=i?a[h]:a[h]&&h;if(k&&j[k]&&(e||j[k].data)||void 0!==d||"string"!=typeof b)return k||(k=i?a[h]=c.pop()||n.guid++:h),j[k]||(j[k]=i?{}:{toJSON:n.noop}),"object"!=typeof b&&"function"!=typeof b||(e?j[k]=n.extend(j[k],b):j[k].data=n.extend(j[k].data,b)),g=j[k],e||(g.data||(g.data={}),g=g.data),void 0!==d&&(g[n.camelCase(b)]=d),"string"==typeof b?(f=g[b],null==f&&(f=g[n.camelCase(b)])):f=g,f}}function S(a,b,c){if(M(a)){var d,e,f=a.nodeType,g=f?n.cache:a,h=f?a[n.expando]:n.expando;if(g[h]){if(b&&(d=c?g[h]:g[h].data)){n.isArray(b)?b=b.concat(n.map(b,n.camelCase)):b in d?b=[b]:(b=n.camelCase(b),b=b in d?[b]:b.split(" ")),e=b.length;while(e--)delete d[b[e]];if(c?!Q(d):!n.isEmptyObject(d))return}(c||(delete g[h].data,Q(g[h])))&&(f?n.cleanData([a],!0):l.deleteExpando||g!=g.window?delete g[h]:g[h]=void 0)}}}n.extend({cache:{},noData:{"applet ":!0,"embed ":!0,"object ":"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000"},hasData:function(a){return a=a.nodeType?n.cache[a[n.expando]]:a[n.expando],!!a&&!Q(a)},data:function(a,b,c){return R(a,b,c)},removeData:function(a,b){return S(a,b)},_data:function(a,b,c){return R(a,b,c,!0)},_removeData:function(a,b){return S(a,b,!0)}}),n.fn.extend({data:function(a,b){var c,d,e,f=this[0],g=f&&f.attributes;if(void 0===a){if(this.length&&(e=n.data(f),1===f.nodeType&&!n._data(f,"parsedAttrs"))){c=g.length;while(c--)g[c]&&(d=g[c].name,0===d.indexOf("data-")&&(d=n.camelCase(d.slice(5)),P(f,d,e[d])));n._data(f,"parsedAttrs",!0)}return e}return"object"==typeof a?this.each(function(){n.data(this,a)}):arguments.length>1?this.each(function(){n.data(this,a,b)}):f?P(f,a,n.data(f,a)):void 0},removeData:function(a){return this.each(function(){n.removeData(this,a)})}}),n.extend({queue:function(a,b,c){var d;return a?(b=(b||"fx")+"queue",d=n._data(a,b),c&&(!d||n.isArray(c)?d=n._data(a,b,n.makeArray(c)):d.push(c)),d||[]):void 0},dequeue:function(a,b){b=b||"fx";var c=n.queue(a,b),d=c.length,e=c.shift(),f=n._queueHooks(a,b),g=function(){n.dequeue(a,b)};"inprogress"===e&&(e=c.shift(),d--),e&&("fx"===b&&c.unshift("inprogress"),delete f.stop,e.call(a,g,f)),!d&&f&&f.empty.fire()},_queueHooks:function(a,b){var c=b+"queueHooks";return n._data(a,c)||n._data(a,c,{empty:n.Callbacks("once memory").add(function(){n._removeData(a,b+"queue"),n._removeData(a,c)})})}}),n.fn.extend({queue:function(a,b){var c=2;return"string"!=typeof a&&(b=a,a="fx",c--),arguments.length<c?n.queue(this[0],a):void 0===b?this:this.each(function(){var c=n.queue(this,a,b);n._queueHooks(this,a),"fx"===a&&"inprogress"!==c[0]&&n.dequeue(this,a)})},dequeue:function(a){return this.each(function(){n.dequeue(this,a)})},clearQueue:function(a){return this.queue(a||"fx",[])},promise:function(a,b){var c,d=1,e=n.Deferred(),f=this,g=this.length,h=function(){--d||e.resolveWith(f,[f])};"string"!=typeof a&&(b=a,a=void 0),a=a||"fx";while(g--)c=n._data(f[g],a+"queueHooks"),c&&c.empty&&(d++,c.empty.add(h));return h(),e.promise(b)}}),function(){var a;l.shrinkWrapBlocks=function(){if(null!=a)return a;a=!1;var b,c,e;return c=d.getElementsByTagName("body")[0],c&&c.style?(b=d.createElement("div"),e=d.createElement("div"),e.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(e).appendChild(b),"undefined"!=typeof b.style.zoom&&(b.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:1px;width:1px;zoom:1",b.appendChild(d.createElement("div")).style.width="5px",a=3!==b.offsetWidth),c.removeChild(e),a):void 0}}();var T=/[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/.source,U=new RegExp("^(?:([+-])=|)("+T+")([a-z%]*)$","i"),V=["Top","Right","Bottom","Left"],W=function(a,b){return a=b||a,"none"===n.css(a,"display")||!n.contains(a.ownerDocument,a)};function X(a,b,c,d){var e,f=1,g=20,h=d?function(){return d.cur()}:function(){return n.css(a,b,"")},i=h(),j=c&&c[3]||(n.cssNumber[b]?"":"px"),k=(n.cssNumber[b]||"px"!==j&&+i)&&U.exec(n.css(a,b));if(k&&k[3]!==j){j=j||k[3],c=c||[],k=+i||1;do f=f||".5",k/=f,n.style(a,b,k+j);while(f!==(f=h()/i)&&1!==f&&--g)}return c&&(k=+k||+i||0,e=c[1]?k+(c[1]+1)*c[2]:+c[2],d&&(d.unit=j,d.start=k,d.end=e)),e}var Y=function(a,b,c,d,e,f,g){var h=0,i=a.length,j=null==c;if("object"===n.type(c)){e=!0;for(h in c)Y(a,b,h,c[h],!0,f,g)}else if(void 0!==d&&(e=!0,n.isFunction(d)||(g=!0),j&&(g?(b.call(a,d),b=null):(j=b,b=function(a,b,c){return j.call(n(a),c)})),b))for(;i>h;h++)b(a[h],c,g?d:d.call(a[h],h,b(a[h],c)));return e?a:j?b.call(a):i?b(a[0],c):f},Z=/^(?:checkbox|radio)$/i,$=/<([\w:-]+)/,_=/^$|\/(?:java|ecma)script/i,aa=/^\s+/,ba="abbr|article|aside|audio|bdi|canvas|data|datalist|details|dialog|figcaption|figure|footer|header|hgroup|main|mark|meter|nav|output|picture|progress|section|summary|template|time|video";function ca(a){var b=ba.split("|"),c=a.createDocumentFragment();if(c.createElement)while(b.length)c.createElement(b.pop());return c}!function(){var a=d.createElement("div"),b=d.createDocumentFragment(),c=d.createElement("input");a.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",l.leadingWhitespace=3===a.firstChild.nodeType,l.tbody=!a.getElementsByTagName("tbody").length,l.htmlSerialize=!!a.getElementsByTagName("link").length,l.html5Clone="<:nav></:nav>"!==d.createElement("nav").cloneNode(!0).outerHTML,c.type="checkbox",c.checked=!0,b.appendChild(c),l.appendChecked=c.checked,a.innerHTML="<textarea>x</textarea>",l.noCloneChecked=!!a.cloneNode(!0).lastChild.defaultValue,b.appendChild(a),c=d.createElement("input"),c.setAttribute("type","radio"),c.setAttribute("checked","checked"),c.setAttribute("name","t"),a.appendChild(c),l.checkClone=a.cloneNode(!0).cloneNode(!0).lastChild.checked,l.noCloneEvent=!!a.addEventListener,a[n.expando]=1,l.attributes=!a.getAttribute(n.expando)}();var da={option:[1,"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],area:[1,"<map>","</map>"],param:[1,"<object>","</object>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],_default:l.htmlSerialize?[0,"",""]:[1,"X<div>","</div>"]};da.optgroup=da.option,da.tbody=da.tfoot=da.colgroup=da.caption=da.thead,da.th=da.td;function ea(a,b){var c,d,e=0,f="undefined"!=typeof a.getElementsByTagName?a.getElementsByTagName(b||"*"):"undefined"!=typeof a.querySelectorAll?a.querySelectorAll(b||"*"):void 0;if(!f)for(f=[],c=a.childNodes||a;null!=(d=c[e]);e++)!b||n.nodeName(d,b)?f.push(d):n.merge(f,ea(d,b));return void 0===b||b&&n.nodeName(a,b)?n.merge([a],f):f}function fa(a,b){for(var c,d=0;null!=(c=a[d]);d++)n._data(c,"globalEval",!b||n._data(b[d],"globalEval"))}var ga=/<|&#?\w+;/,ha=/<tbody/i;function ia(a){Z.test(a.type)&&(a.defaultChecked=a.checked)}function ja(a,b,c,d,e){for(var f,g,h,i,j,k,m,o=a.length,p=ca(b),q=[],r=0;o>r;r++)if(g=a[r],g||0===g)if("object"===n.type(g))n.merge(q,g.nodeType?[g]:g);else if(ga.test(g)){i=i||p.appendChild(b.createElement("div")),j=($.exec(g)||["",""])[1].toLowerCase(),m=da[j]||da._default,i.innerHTML=m[1]+n.htmlPrefilter(g)+m[2],f=m[0];while(f--)i=i.lastChild;if(!l.leadingWhitespace&&aa.test(g)&&q.push(b.createTextNode(aa.exec(g)[0])),!l.tbody){g="table"!==j||ha.test(g)?"<table>"!==m[1]||ha.test(g)?0:i:i.firstChild,f=g&&g.childNodes.length;while(f--)n.nodeName(k=g.childNodes[f],"tbody")&&!k.childNodes.length&&g.removeChild(k)}n.merge(q,i.childNodes),i.textContent="";while(i.firstChild)i.removeChild(i.firstChild);i=p.lastChild}else q.push(b.createTextNode(g));i&&p.removeChild(i),l.appendChecked||n.grep(ea(q,"input"),ia),r=0;while(g=q[r++])if(d&&n.inArray(g,d)>-1)e&&e.push(g);else if(h=n.contains(g.ownerDocument,g),i=ea(p.appendChild(g),"script"),h&&fa(i),c){f=0;while(g=i[f++])_.test(g.type||"")&&c.push(g)}return i=null,p}!function(){var b,c,e=d.createElement("div");for(b in{submit:!0,change:!0,focusin:!0})c="on"+b,(l[b]=c in a)||(e.setAttribute(c,"t"),l[b]=e.attributes[c].expando===!1);e=null}();var ka=/^(?:input|select|textarea)$/i,la=/^key/,ma=/^(?:mouse|pointer|contextmenu|drag|drop)|click/,na=/^(?:focusinfocus|focusoutblur)$/,oa=/^([^.]*)(?:\.(.+)|)/;function pa(){return!0}function qa(){return!1}function ra(){try{return d.activeElement}catch(a){}}function sa(a,b,c,d,e,f){var g,h;if("object"==typeof b){"string"!=typeof c&&(d=d||c,c=void 0);for(h in b)sa(a,h,c,d,b[h],f);return a}if(null==d&&null==e?(e=c,d=c=void 0):null==e&&("string"==typeof c?(e=d,d=void 0):(e=d,d=c,c=void 0)),e===!1)e=qa;else if(!e)return a;return 1===f&&(g=e,e=function(a){return n().off(a),g.apply(this,arguments)},e.guid=g.guid||(g.guid=n.guid++)),a.each(function(){n.event.add(this,b,e,d,c)})}n.event={global:{},add:function(a,b,c,d,e){var f,g,h,i,j,k,l,m,o,p,q,r=n._data(a);if(r){c.handler&&(i=c,c=i.handler,e=i.selector),c.guid||(c.guid=n.guid++),(g=r.events)||(g=r.events={}),(k=r.handle)||(k=r.handle=function(a){return"undefined"==typeof n||a&&n.event.triggered===a.type?void 0:n.event.dispatch.apply(k.elem,arguments)},k.elem=a),b=(b||"").match(G)||[""],h=b.length;while(h--)f=oa.exec(b[h])||[],o=q=f[1],p=(f[2]||"").split(".").sort(),o&&(j=n.event.special[o]||{},o=(e?j.delegateType:j.bindType)||o,j=n.event.special[o]||{},l=n.extend({type:o,origType:q,data:d,handler:c,guid:c.guid,selector:e,needsContext:e&&n.expr.match.needsContext.test(e),namespace:p.join(".")},i),(m=g[o])||(m=g[o]=[],m.delegateCount=0,j.setup&&j.setup.call(a,d,p,k)!==!1||(a.addEventListener?a.addEventListener(o,k,!1):a.attachEvent&&a.attachEvent("on"+o,k))),j.add&&(j.add.call(a,l),l.handler.guid||(l.handler.guid=c.guid)),e?m.splice(m.delegateCount++,0,l):m.push(l),n.event.global[o]=!0);a=null}},remove:function(a,b,c,d,e){var f,g,h,i,j,k,l,m,o,p,q,r=n.hasData(a)&&n._data(a);if(r&&(k=r.events)){b=(b||"").match(G)||[""],j=b.length;while(j--)if(h=oa.exec(b[j])||[],o=q=h[1],p=(h[2]||"").split(".").sort(),o){l=n.event.special[o]||{},o=(d?l.delegateType:l.bindType)||o,m=k[o]||[],h=h[2]&&new RegExp("(^|\\.)"+p.join("\\.(?:.*\\.|)")+"(\\.|$)"),i=f=m.length;while(f--)g=m[f],!e&&q!==g.origType||c&&c.guid!==g.guid||h&&!h.test(g.namespace)||d&&d!==g.selector&&("**"!==d||!g.selector)||(m.splice(f,1),g.selector&&m.delegateCount--,l.remove&&l.remove.call(a,g));i&&!m.length&&(l.teardown&&l.teardown.call(a,p,r.handle)!==!1||n.removeEvent(a,o,r.handle),delete k[o])}else for(o in k)n.event.remove(a,o+b[j],c,d,!0);n.isEmptyObject(k)&&(delete r.handle,n._removeData(a,"events"))}},trigger:function(b,c,e,f){var g,h,i,j,l,m,o,p=[e||d],q=k.call(b,"type")?b.type:b,r=k.call(b,"namespace")?b.namespace.split("."):[];if(i=m=e=e||d,3!==e.nodeType&&8!==e.nodeType&&!na.test(q+n.event.triggered)&&(q.indexOf(".")>-1&&(r=q.split("."),q=r.shift(),r.sort()),h=q.indexOf(":")<0&&"on"+q,b=b[n.expando]?b:new n.Event(q,"object"==typeof b&&b),b.isTrigger=f?2:3,b.namespace=r.join("."),b.rnamespace=b.namespace?new RegExp("(^|\\.)"+r.join("\\.(?:.*\\.|)")+"(\\.|$)"):null,b.result=void 0,b.target||(b.target=e),c=null==c?[b]:n.makeArray(c,[b]),l=n.event.special[q]||{},f||!l.trigger||l.trigger.apply(e,c)!==!1)){if(!f&&!l.noBubble&&!n.isWindow(e)){for(j=l.delegateType||q,na.test(j+q)||(i=i.parentNode);i;i=i.parentNode)p.push(i),m=i;m===(e.ownerDocument||d)&&p.push(m.defaultView||m.parentWindow||a)}o=0;while((i=p[o++])&&!b.isPropagationStopped())b.type=o>1?j:l.bindType||q,g=(n._data(i,"events")||{})[b.type]&&n._data(i,"handle"),g&&g.apply(i,c),g=h&&i[h],g&&g.apply&&M(i)&&(b.result=g.apply(i,c),b.result===!1&&b.preventDefault());if(b.type=q,!f&&!b.isDefaultPrevented()&&(!l._default||l._default.apply(p.pop(),c)===!1)&&M(e)&&h&&e[q]&&!n.isWindow(e)){m=e[h],m&&(e[h]=null),n.event.triggered=q;try{e[q]()}catch(s){}n.event.triggered=void 0,m&&(e[h]=m)}return b.result}},dispatch:function(a){a=n.event.fix(a);var b,c,d,f,g,h=[],i=e.call(arguments),j=(n._data(this,"events")||{})[a.type]||[],k=n.event.special[a.type]||{};if(i[0]=a,a.delegateTarget=this,!k.preDispatch||k.preDispatch.call(this,a)!==!1){h=n.event.handlers.call(this,a,j),b=0;while((f=h[b++])&&!a.isPropagationStopped()){a.currentTarget=f.elem,c=0;while((g=f.handlers[c++])&&!a.isImmediatePropagationStopped())a.rnamespace&&!a.rnamespace.test(g.namespace)||(a.handleObj=g,a.data=g.data,d=((n.event.special[g.origType]||{}).handle||g.handler).apply(f.elem,i),void 0!==d&&(a.result=d)===!1&&(a.preventDefault(),a.stopPropagation()))}return k.postDispatch&&k.postDispatch.call(this,a),a.result}},handlers:function(a,b){var c,d,e,f,g=[],h=b.delegateCount,i=a.target;if(h&&i.nodeType&&("click"!==a.type||isNaN(a.button)||a.button<1))for(;i!=this;i=i.parentNode||this)if(1===i.nodeType&&(i.disabled!==!0||"click"!==a.type)){for(d=[],c=0;h>c;c++)f=b[c],e=f.selector+" ",void 0===d[e]&&(d[e]=f.needsContext?n(e,this).index(i)>-1:n.find(e,this,null,[i]).length),d[e]&&d.push(f);d.length&&g.push({elem:i,handlers:d})}return h<b.length&&g.push({elem:this,handlers:b.slice(h)}),g},fix:function(a){if(a[n.expando])return a;var b,c,e,f=a.type,g=a,h=this.fixHooks[f];h||(this.fixHooks[f]=h=ma.test(f)?this.mouseHooks:la.test(f)?this.keyHooks:{}),e=h.props?this.props.concat(h.props):this.props,a=new n.Event(g),b=e.length;while(b--)c=e[b],a[c]=g[c];return a.target||(a.target=g.srcElement||d),3===a.target.nodeType&&(a.target=a.target.parentNode),a.metaKey=!!a.metaKey,h.filter?h.filter(a,g):a},props:"altKey bubbles cancelable ctrlKey currentTarget detail eventPhase metaKey relatedTarget shiftKey target timeStamp view which".split(" "),fixHooks:{},keyHooks:{props:"char charCode key keyCode".split(" "),filter:function(a,b){return null==a.which&&(a.which=null!=b.charCode?b.charCode:b.keyCode),a}},mouseHooks:{props:"button buttons clientX clientY fromElement offsetX offsetY pageX pageY screenX screenY toElement".split(" "),filter:function(a,b){var c,e,f,g=b.button,h=b.fromElement;return null==a.pageX&&null!=b.clientX&&(e=a.target.ownerDocument||d,f=e.documentElement,c=e.body,a.pageX=b.clientX+(f&&f.scrollLeft||c&&c.scrollLeft||0)-(f&&f.clientLeft||c&&c.clientLeft||0),a.pageY=b.clientY+(f&&f.scrollTop||c&&c.scrollTop||0)-(f&&f.clientTop||c&&c.clientTop||0)),!a.relatedTarget&&h&&(a.relatedTarget=h===a.target?b.toElement:h),a.which||void 0===g||(a.which=1&g?1:2&g?3:4&g?2:0),a}},special:{load:{noBubble:!0},focus:{trigger:function(){if(this!==ra()&&this.focus)try{return this.focus(),!1}catch(a){}},delegateType:"focusin"},blur:{trigger:function(){return this===ra()&&this.blur?(this.blur(),!1):void 0},delegateType:"focusout"},click:{trigger:function(){return n.nodeName(this,"input")&&"checkbox"===this.type&&this.click?(this.click(),!1):void 0},_default:function(a){return n.nodeName(a.target,"a")}},beforeunload:{postDispatch:function(a){void 0!==a.result&&a.originalEvent&&(a.originalEvent.returnValue=a.result)}}},simulate:function(a,b,c){var d=n.extend(new n.Event,c,{type:a,isSimulated:!0});n.event.trigger(d,null,b),d.isDefaultPrevented()&&c.preventDefault()}},n.removeEvent=d.removeEventListener?function(a,b,c){a.removeEventListener&&a.removeEventListener(b,c)}:function(a,b,c){var d="on"+b;a.detachEvent&&("undefined"==typeof a[d]&&(a[d]=null),a.detachEvent(d,c))},n.Event=function(a,b){return this instanceof n.Event?(a&&a.type?(this.originalEvent=a,this.type=a.type,this.isDefaultPrevented=a.defaultPrevented||void 0===a.defaultPrevented&&a.returnValue===!1?pa:qa):this.type=a,b&&n.extend(this,b),this.timeStamp=a&&a.timeStamp||n.now(),void(this[n.expando]=!0)):new n.Event(a,b)},n.Event.prototype={constructor:n.Event,isDefaultPrevented:qa,isPropagationStopped:qa,isImmediatePropagationStopped:qa,preventDefault:function(){var a=this.originalEvent;this.isDefaultPrevented=pa,a&&(a.preventDefault?a.preventDefault():a.returnValue=!1)},stopPropagation:function(){var a=this.originalEvent;this.isPropagationStopped=pa,a&&!this.isSimulated&&(a.stopPropagation&&a.stopPropagation(),a.cancelBubble=!0)},stopImmediatePropagation:function(){var a=this.originalEvent;this.isImmediatePropagationStopped=pa,a&&a.stopImmediatePropagation&&a.stopImmediatePropagation(),this.stopPropagation()}},n.each({mouseenter:"mouseover",mouseleave:"mouseout",pointerenter:"pointerover",pointerleave:"pointerout"},function(a,b){n.event.special[a]={delegateType:b,bindType:b,handle:function(a){var c,d=this,e=a.relatedTarget,f=a.handleObj;return e&&(e===d||n.contains(d,e))||(a.type=f.origType,c=f.handler.apply(this,arguments),a.type=b),c}}}),l.submit||(n.event.special.submit={setup:function(){return n.nodeName(this,"form")?!1:void n.event.add(this,"click._submit keypress._submit",function(a){var b=a.target,c=n.nodeName(b,"input")||n.nodeName(b,"button")?n.prop(b,"form"):void 0;c&&!n._data(c,"submit")&&(n.event.add(c,"submit._submit",function(a){a._submitBubble=!0}),n._data(c,"submit",!0))})},postDispatch:function(a){a._submitBubble&&(delete a._submitBubble,this.parentNode&&!a.isTrigger&&n.event.simulate("submit",this.parentNode,a))},teardown:function(){return n.nodeName(this,"form")?!1:void n.event.remove(this,"._submit")}}),l.change||(n.event.special.change={setup:function(){return ka.test(this.nodeName)?("checkbox"!==this.type&&"radio"!==this.type||(n.event.add(this,"propertychange._change",function(a){"checked"===a.originalEvent.propertyName&&(this._justChanged=!0)}),n.event.add(this,"click._change",function(a){this._justChanged&&!a.isTrigger&&(this._justChanged=!1),n.event.simulate("change",this,a)})),!1):void n.event.add(this,"beforeactivate._change",function(a){var b=a.target;ka.test(b.nodeName)&&!n._data(b,"change")&&(n.event.add(b,"change._change",function(a){!this.parentNode||a.isSimulated||a.isTrigger||n.event.simulate("change",this.parentNode,a)}),n._data(b,"change",!0))})},handle:function(a){var b=a.target;return this!==b||a.isSimulated||a.isTrigger||"radio"!==b.type&&"checkbox"!==b.type?a.handleObj.handler.apply(this,arguments):void 0},teardown:function(){return n.event.remove(this,"._change"),!ka.test(this.nodeName)}}),l.focusin||n.each({focus:"focusin",blur:"focusout"},function(a,b){var c=function(a){n.event.simulate(b,a.target,n.event.fix(a))};n.event.special[b]={setup:function(){var d=this.ownerDocument||this,e=n._data(d,b);e||d.addEventListener(a,c,!0),n._data(d,b,(e||0)+1)},teardown:function(){var d=this.ownerDocument||this,e=n._data(d,b)-1;e?n._data(d,b,e):(d.removeEventListener(a,c,!0),n._removeData(d,b))}}}),n.fn.extend({on:function(a,b,c,d){return sa(this,a,b,c,d)},one:function(a,b,c,d){return sa(this,a,b,c,d,1)},off:function(a,b,c){var d,e;if(a&&a.preventDefault&&a.handleObj)return d=a.handleObj,n(a.delegateTarget).off(d.namespace?d.origType+"."+d.namespace:d.origType,d.selector,d.handler),this;if("object"==typeof a){for(e in a)this.off(e,b,a[e]);return this}return b!==!1&&"function"!=typeof b||(c=b,b=void 0),c===!1&&(c=qa),this.each(function(){n.event.remove(this,a,c,b)})},trigger:function(a,b){return this.each(function(){n.event.trigger(a,b,this)})},triggerHandler:function(a,b){var c=this[0];return c?n.event.trigger(a,b,c,!0):void 0}});var ta=/ jQuery\d+="(?:null|\d+)"/g,ua=new RegExp("<(?:"+ba+")[\\s/>]","i"),va=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:-]+)[^>]*)\/>/gi,wa=/<script|<style|<link/i,xa=/checked\s*(?:[^=]|=\s*.checked.)/i,ya=/^true\/(.*)/,za=/^\s*<!(?:\[CDATA\[|--)|(?:\]\]|--)>\s*$/g,Aa=ca(d),Ba=Aa.appendChild(d.createElement("div"));function Ca(a,b){return n.nodeName(a,"table")&&n.nodeName(11!==b.nodeType?b:b.firstChild,"tr")?a.getElementsByTagName("tbody")[0]||a.appendChild(a.ownerDocument.createElement("tbody")):a}function Da(a){return a.type=(null!==n.find.attr(a,"type"))+"/"+a.type,a}function Ea(a){var b=ya.exec(a.type);return b?a.type=b[1]:a.removeAttribute("type"),a}function Fa(a,b){if(1===b.nodeType&&n.hasData(a)){var c,d,e,f=n._data(a),g=n._data(b,f),h=f.events;if(h){delete g.handle,g.events={};for(c in h)for(d=0,e=h[c].length;e>d;d++)n.event.add(b,c,h[c][d])}g.data&&(g.data=n.extend({},g.data))}}function Ga(a,b){var c,d,e;if(1===b.nodeType){if(c=b.nodeName.toLowerCase(),!l.noCloneEvent&&b[n.expando]){e=n._data(b);for(d in e.events)n.removeEvent(b,d,e.handle);b.removeAttribute(n.expando)}"script"===c&&b.text!==a.text?(Da(b).text=a.text,Ea(b)):"object"===c?(b.parentNode&&(b.outerHTML=a.outerHTML),l.html5Clone&&a.innerHTML&&!n.trim(b.innerHTML)&&(b.innerHTML=a.innerHTML)):"input"===c&&Z.test(a.type)?(b.defaultChecked=b.checked=a.checked,b.value!==a.value&&(b.value=a.value)):"option"===c?b.defaultSelected=b.selected=a.defaultSelected:"input"!==c&&"textarea"!==c||(b.defaultValue=a.defaultValue)}}function Ha(a,b,c,d){b=f.apply([],b);var e,g,h,i,j,k,m=0,o=a.length,p=o-1,q=b[0],r=n.isFunction(q);if(r||o>1&&"string"==typeof q&&!l.checkClone&&xa.test(q))return a.each(function(e){var f=a.eq(e);r&&(b[0]=q.call(this,e,f.html())),Ha(f,b,c,d)});if(o&&(k=ja(b,a[0].ownerDocument,!1,a,d),e=k.firstChild,1===k.childNodes.length&&(k=e),e||d)){for(i=n.map(ea(k,"script"),Da),h=i.length;o>m;m++)g=k,m!==p&&(g=n.clone(g,!0,!0),h&&n.merge(i,ea(g,"script"))),c.call(a[m],g,m);if(h)for(j=i[i.length-1].ownerDocument,n.map(i,Ea),m=0;h>m;m++)g=i[m],_.test(g.type||"")&&!n._data(g,"globalEval")&&n.contains(j,g)&&(g.src?n._evalUrl&&n._evalUrl(g.src):n.globalEval((g.text||g.textContent||g.innerHTML||"").replace(za,"")));k=e=null}return a}function Ia(a,b,c){for(var d,e=b?n.filter(b,a):a,f=0;null!=(d=e[f]);f++)c||1!==d.nodeType||n.cleanData(ea(d)),d.parentNode&&(c&&n.contains(d.ownerDocument,d)&&fa(ea(d,"script")),d.parentNode.removeChild(d));return a}n.extend({htmlPrefilter:function(a){return a.replace(va,"<$1></$2>")},clone:function(a,b,c){var d,e,f,g,h,i=n.contains(a.ownerDocument,a);if(l.html5Clone||n.isXMLDoc(a)||!ua.test("<"+a.nodeName+">")?f=a.cloneNode(!0):(Ba.innerHTML=a.outerHTML,Ba.removeChild(f=Ba.firstChild)),!(l.noCloneEvent&&l.noCloneChecked||1!==a.nodeType&&11!==a.nodeType||n.isXMLDoc(a)))for(d=ea(f),h=ea(a),g=0;null!=(e=h[g]);++g)d[g]&&Ga(e,d[g]);if(b)if(c)for(h=h||ea(a),d=d||ea(f),g=0;null!=(e=h[g]);g++)Fa(e,d[g]);else Fa(a,f);return d=ea(f,"script"),d.length>0&&fa(d,!i&&ea(a,"script")),d=h=e=null,f},cleanData:function(a,b){for(var d,e,f,g,h=0,i=n.expando,j=n.cache,k=l.attributes,m=n.event.special;null!=(d=a[h]);h++)if((b||M(d))&&(f=d[i],g=f&&j[f])){if(g.events)for(e in g.events)m[e]?n.event.remove(d,e):n.removeEvent(d,e,g.handle);j[f]&&(delete j[f],k||"undefined"==typeof d.removeAttribute?d[i]=void 0:d.removeAttribute(i),c.push(f))}}}),n.fn.extend({domManip:Ha,detach:function(a){return Ia(this,a,!0)},remove:function(a){return Ia(this,a)},text:function(a){return Y(this,function(a){return void 0===a?n.text(this):this.empty().append((this[0]&&this[0].ownerDocument||d).createTextNode(a))},null,a,arguments.length)},append:function(){return Ha(this,arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=Ca(this,a);b.appendChild(a)}})},prepend:function(){return Ha(this,arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=Ca(this,a);b.insertBefore(a,b.firstChild)}})},before:function(){return Ha(this,arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this)})},after:function(){return Ha(this,arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this.nextSibling)})},empty:function(){for(var a,b=0;null!=(a=this[b]);b++){1===a.nodeType&&n.cleanData(ea(a,!1));while(a.firstChild)a.removeChild(a.firstChild);a.options&&n.nodeName(a,"select")&&(a.options.length=0)}return this},clone:function(a,b){return a=null==a?!1:a,b=null==b?a:b,this.map(function(){return n.clone(this,a,b)})},html:function(a){return Y(this,function(a){var b=this[0]||{},c=0,d=this.length;if(void 0===a)return 1===b.nodeType?b.innerHTML.replace(ta,""):void 0;if("string"==typeof a&&!wa.test(a)&&(l.htmlSerialize||!ua.test(a))&&(l.leadingWhitespace||!aa.test(a))&&!da[($.exec(a)||["",""])[1].toLowerCase()]){a=n.htmlPrefilter(a);try{for(;d>c;c++)b=this[c]||{},1===b.nodeType&&(n.cleanData(ea(b,!1)),b.innerHTML=a);b=0}catch(e){}}b&&this.empty().append(a)},null,a,arguments.length)},replaceWith:function(){var a=[];return Ha(this,arguments,function(b){var c=this.parentNode;n.inArray(this,a)<0&&(n.cleanData(ea(this)),c&&c.replaceChild(b,this))},a)}}),n.each({appendTo:"append",prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){n.fn[a]=function(a){for(var c,d=0,e=[],f=n(a),h=f.length-1;h>=d;d++)c=d===h?this:this.clone(!0),n(f[d])[b](c),g.apply(e,c.get());return this.pushStack(e)}});var Ja,Ka={HTML:"block",BODY:"block"};function La(a,b){var c=n(b.createElement(a)).appendTo(b.body),d=n.css(c[0],"display");return c.detach(),d}function Ma(a){var b=d,c=Ka[a];return c||(c=La(a,b),"none"!==c&&c||(Ja=(Ja||n("<iframe frameborder='0' width='0' height='0'/>")).appendTo(b.documentElement),b=(Ja[0].contentWindow||Ja[0].contentDocument).document,b.write(),b.close(),c=La(a,b),Ja.detach()),Ka[a]=c),c}var Na=/^margin/,Oa=new RegExp("^("+T+")(?!px)[a-z%]+$","i"),Pa=function(a,b,c,d){var e,f,g={};for(f in b)g[f]=a.style[f],a.style[f]=b[f];e=c.apply(a,d||[]);for(f in b)a.style[f]=g[f];return e},Qa=d.documentElement;!function(){var b,c,e,f,g,h,i=d.createElement("div"),j=d.createElement("div");if(j.style){j.style.cssText="float:left;opacity:.5",l.opacity="0.5"===j.style.opacity,l.cssFloat=!!j.style.cssFloat,j.style.backgroundClip="content-box",j.cloneNode(!0).style.backgroundClip="",l.clearCloneStyle="content-box"===j.style.backgroundClip,i=d.createElement("div"),i.style.cssText="border:0;width:8px;height:0;top:0;left:-9999px;padding:0;margin-top:1px;position:absolute",j.innerHTML="",i.appendChild(j),l.boxSizing=""===j.style.boxSizing||""===j.style.MozBoxSizing||""===j.style.WebkitBoxSizing,n.extend(l,{reliableHiddenOffsets:function(){return null==b&&k(),f},boxSizingReliable:function(){return null==b&&k(),e},pixelMarginRight:function(){return null==b&&k(),c},pixelPosition:function(){return null==b&&k(),b},reliableMarginRight:function(){return null==b&&k(),g},reliableMarginLeft:function(){return null==b&&k(),h}});function k(){var k,l,m=d.documentElement;m.appendChild(i),j.style.cssText="-webkit-box-sizing:border-box;box-sizing:border-box;position:relative;display:block;margin:auto;border:1px;padding:1px;top:1%;width:50%",b=e=h=!1,c=g=!0,a.getComputedStyle&&(l=a.getComputedStyle(j),b="1%"!==(l||{}).top,h="2px"===(l||{}).marginLeft,e="4px"===(l||{width:"4px"}).width,j.style.marginRight="50%",c="4px"===(l||{marginRight:"4px"}).marginRight,k=j.appendChild(d.createElement("div")),k.style.cssText=j.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:0",k.style.marginRight=k.style.width="0",j.style.width="1px",g=!parseFloat((a.getComputedStyle(k)||{}).marginRight),j.removeChild(k)),j.style.display="none",f=0===j.getClientRects().length,f&&(j.style.display="",j.innerHTML="<table><tr><td></td><td>t</td></tr></table>",k=j.getElementsByTagName("td"),k[0].style.cssText="margin:0;border:0;padding:0;display:none",f=0===k[0].offsetHeight,f&&(k[0].style.display="",k[1].style.display="none",f=0===k[0].offsetHeight)),m.removeChild(i)}}}();var Ra,Sa,Ta=/^(top|right|bottom|left)$/;a.getComputedStyle?(Ra=function(b){var c=b.ownerDocument.defaultView;return c&&c.opener||(c=a),c.getComputedStyle(b)},Sa=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ra(a),g=c?c.getPropertyValue(b)||c[b]:void 0,""!==g&&void 0!==g||n.contains(a.ownerDocument,a)||(g=n.style(a,b)),c&&!l.pixelMarginRight()&&Oa.test(g)&&Na.test(b)&&(d=h.width,e=h.minWidth,f=h.maxWidth,h.minWidth=h.maxWidth=h.width=g,g=c.width,h.width=d,h.minWidth=e,h.maxWidth=f),void 0===g?g:g+""}):Qa.currentStyle&&(Ra=function(a){return a.currentStyle},Sa=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ra(a),g=c?c[b]:void 0,null==g&&h&&h[b]&&(g=h[b]),Oa.test(g)&&!Ta.test(b)&&(d=h.left,e=a.runtimeStyle,f=e&&e.left,f&&(e.left=a.currentStyle.left),h.left="fontSize"===b?"1em":g,g=h.pixelLeft+"px",h.left=d,f&&(e.left=f)),void 0===g?g:g+""||"auto"});function Ua(a,b){return{get:function(){return a()?void delete this.get:(this.get=b).apply(this,arguments)}}}var Va=/alpha\([^)]*\)/i,Wa=/opacity\s*=\s*([^)]*)/i,Xa=/^(none|table(?!-c[ea]).+)/,Ya=new RegExp("^("+T+")(.*)$","i"),Za={position:"absolute",visibility:"hidden",display:"block"},$a={letterSpacing:"0",fontWeight:"400"},_a=["Webkit","O","Moz","ms"],ab=d.createElement("div").style;function bb(a){if(a in ab)return a;var b=a.charAt(0).toUpperCase()+a.slice(1),c=_a.length;while(c--)if(a=_a[c]+b,a in ab)return a}function cb(a,b){for(var c,d,e,f=[],g=0,h=a.length;h>g;g++)d=a[g],d.style&&(f[g]=n._data(d,"olddisplay"),c=d.style.display,b?(f[g]||"none"!==c||(d.style.display=""),""===d.style.display&&W(d)&&(f[g]=n._data(d,"olddisplay",Ma(d.nodeName)))):(e=W(d),(c&&"none"!==c||!e)&&n._data(d,"olddisplay",e?c:n.css(d,"display"))));for(g=0;h>g;g++)d=a[g],d.style&&(b&&"none"!==d.style.display&&""!==d.style.display||(d.style.display=b?f[g]||"":"none"));return a}function db(a,b,c){var d=Ya.exec(b);return d?Math.max(0,d[1]-(c||0))+(d[2]||"px"):b}function eb(a,b,c,d,e){for(var f=c===(d?"border":"content")?4:"width"===b?1:0,g=0;4>f;f+=2)"margin"===c&&(g+=n.css(a,c+V[f],!0,e)),d?("content"===c&&(g-=n.css(a,"padding"+V[f],!0,e)),"margin"!==c&&(g-=n.css(a,"border"+V[f]+"Width",!0,e))):(g+=n.css(a,"padding"+V[f],!0,e),"padding"!==c&&(g+=n.css(a,"border"+V[f]+"Width",!0,e)));return g}function fb(b,c,e){var f=!0,g="width"===c?b.offsetWidth:b.offsetHeight,h=Ra(b),i=l.boxSizing&&"border-box"===n.css(b,"boxSizing",!1,h);if(d.msFullscreenElement&&a.top!==a&&b.getClientRects().length&&(g=Math.round(100*b.getBoundingClientRect()[c])),0>=g||null==g){if(g=Sa(b,c,h),(0>g||null==g)&&(g=b.style[c]),Oa.test(g))return g;f=i&&(l.boxSizingReliable()||g===b.style[c]),g=parseFloat(g)||0}return g+eb(b,c,e||(i?"border":"content"),f,h)+"px"}n.extend({cssHooks:{opacity:{get:function(a,b){if(b){var c=Sa(a,"opacity");return""===c?"1":c}}}},cssNumber:{animationIterationCount:!0,columnCount:!0,fillOpacity:!0,flexGrow:!0,flexShrink:!0,fontWeight:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{"float":l.cssFloat?"cssFloat":"styleFloat"},style:function(a,b,c,d){if(a&&3!==a.nodeType&&8!==a.nodeType&&a.style){var e,f,g,h=n.camelCase(b),i=a.style;if(b=n.cssProps[h]||(n.cssProps[h]=bb(h)||h),g=n.cssHooks[b]||n.cssHooks[h],void 0===c)return g&&"get"in g&&void 0!==(e=g.get(a,!1,d))?e:i[b];if(f=typeof c,"string"===f&&(e=U.exec(c))&&e[1]&&(c=X(a,b,e),f="number"),null!=c&&c===c&&("number"===f&&(c+=e&&e[3]||(n.cssNumber[h]?"":"px")),l.clearCloneStyle||""!==c||0!==b.indexOf("background")||(i[b]="inherit"),!(g&&"set"in g&&void 0===(c=g.set(a,c,d)))))try{i[b]=c}catch(j){}}},css:function(a,b,c,d){var e,f,g,h=n.camelCase(b);return b=n.cssProps[h]||(n.cssProps[h]=bb(h)||h),g=n.cssHooks[b]||n.cssHooks[h],g&&"get"in g&&(f=g.get(a,!0,c)),void 0===f&&(f=Sa(a,b,d)),"normal"===f&&b in $a&&(f=$a[b]),""===c||c?(e=parseFloat(f),c===!0||isFinite(e)?e||0:f):f}}),n.each(["height","width"],function(a,b){n.cssHooks[b]={get:function(a,c,d){return c?Xa.test(n.css(a,"display"))&&0===a.offsetWidth?Pa(a,Za,function(){return fb(a,b,d)}):fb(a,b,d):void 0},set:function(a,c,d){var e=d&&Ra(a);return db(a,c,d?eb(a,b,d,l.boxSizing&&"border-box"===n.css(a,"boxSizing",!1,e),e):0)}}}),l.opacity||(n.cssHooks.opacity={get:function(a,b){return Wa.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?.01*parseFloat(RegExp.$1)+"":b?"1":""},set:function(a,b){var c=a.style,d=a.currentStyle,e=n.isNumeric(b)?"alpha(opacity="+100*b+")":"",f=d&&d.filter||c.filter||"";c.zoom=1,(b>=1||""===b)&&""===n.trim(f.replace(Va,""))&&c.removeAttribute&&(c.removeAttribute("filter"),""===b||d&&!d.filter)||(c.filter=Va.test(f)?f.replace(Va,e):f+" "+e)}}),n.cssHooks.marginRight=Ua(l.reliableMarginRight,function(a,b){return b?Pa(a,{display:"inline-block"},Sa,[a,"marginRight"]):void 0}),n.cssHooks.marginLeft=Ua(l.reliableMarginLeft,function(a,b){
return b?(parseFloat(Sa(a,"marginLeft"))||(n.contains(a.ownerDocument,a)?a.getBoundingClientRect().left-Pa(a,{marginLeft:0},function(){return a.getBoundingClientRect().left}):0))+"px":void 0}),n.each({margin:"",padding:"",border:"Width"},function(a,b){n.cssHooks[a+b]={expand:function(c){for(var d=0,e={},f="string"==typeof c?c.split(" "):[c];4>d;d++)e[a+V[d]+b]=f[d]||f[d-2]||f[0];return e}},Na.test(a)||(n.cssHooks[a+b].set=db)}),n.fn.extend({css:function(a,b){return Y(this,function(a,b,c){var d,e,f={},g=0;if(n.isArray(b)){for(d=Ra(a),e=b.length;e>g;g++)f[b[g]]=n.css(a,b[g],!1,d);return f}return void 0!==c?n.style(a,b,c):n.css(a,b)},a,b,arguments.length>1)},show:function(){return cb(this,!0)},hide:function(){return cb(this)},toggle:function(a){return"boolean"==typeof a?a?this.show():this.hide():this.each(function(){W(this)?n(this).show():n(this).hide()})}});function gb(a,b,c,d,e){return new gb.prototype.init(a,b,c,d,e)}n.Tween=gb,gb.prototype={constructor:gb,init:function(a,b,c,d,e,f){this.elem=a,this.prop=c,this.easing=e||n.easing._default,this.options=b,this.start=this.now=this.cur(),this.end=d,this.unit=f||(n.cssNumber[c]?"":"px")},cur:function(){var a=gb.propHooks[this.prop];return a&&a.get?a.get(this):gb.propHooks._default.get(this)},run:function(a){var b,c=gb.propHooks[this.prop];return this.options.duration?this.pos=b=n.easing[this.easing](a,this.options.duration*a,0,1,this.options.duration):this.pos=b=a,this.now=(this.end-this.start)*b+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),c&&c.set?c.set(this):gb.propHooks._default.set(this),this}},gb.prototype.init.prototype=gb.prototype,gb.propHooks={_default:{get:function(a){var b;return 1!==a.elem.nodeType||null!=a.elem[a.prop]&&null==a.elem.style[a.prop]?a.elem[a.prop]:(b=n.css(a.elem,a.prop,""),b&&"auto"!==b?b:0)},set:function(a){n.fx.step[a.prop]?n.fx.step[a.prop](a):1!==a.elem.nodeType||null==a.elem.style[n.cssProps[a.prop]]&&!n.cssHooks[a.prop]?a.elem[a.prop]=a.now:n.style(a.elem,a.prop,a.now+a.unit)}}},gb.propHooks.scrollTop=gb.propHooks.scrollLeft={set:function(a){a.elem.nodeType&&a.elem.parentNode&&(a.elem[a.prop]=a.now)}},n.easing={linear:function(a){return a},swing:function(a){return.5-Math.cos(a*Math.PI)/2},_default:"swing"},n.fx=gb.prototype.init,n.fx.step={};var hb,ib,jb=/^(?:toggle|show|hide)$/,kb=/queueHooks$/;function lb(){return a.setTimeout(function(){hb=void 0}),hb=n.now()}function mb(a,b){var c,d={height:a},e=0;for(b=b?1:0;4>e;e+=2-b)c=V[e],d["margin"+c]=d["padding"+c]=a;return b&&(d.opacity=d.width=a),d}function nb(a,b,c){for(var d,e=(qb.tweeners[b]||[]).concat(qb.tweeners["*"]),f=0,g=e.length;g>f;f++)if(d=e[f].call(c,b,a))return d}function ob(a,b,c){var d,e,f,g,h,i,j,k,m=this,o={},p=a.style,q=a.nodeType&&W(a),r=n._data(a,"fxshow");c.queue||(h=n._queueHooks(a,"fx"),null==h.unqueued&&(h.unqueued=0,i=h.empty.fire,h.empty.fire=function(){h.unqueued||i()}),h.unqueued++,m.always(function(){m.always(function(){h.unqueued--,n.queue(a,"fx").length||h.empty.fire()})})),1===a.nodeType&&("height"in b||"width"in b)&&(c.overflow=[p.overflow,p.overflowX,p.overflowY],j=n.css(a,"display"),k="none"===j?n._data(a,"olddisplay")||Ma(a.nodeName):j,"inline"===k&&"none"===n.css(a,"float")&&(l.inlineBlockNeedsLayout&&"inline"!==Ma(a.nodeName)?p.zoom=1:p.display="inline-block")),c.overflow&&(p.overflow="hidden",l.shrinkWrapBlocks()||m.always(function(){p.overflow=c.overflow[0],p.overflowX=c.overflow[1],p.overflowY=c.overflow[2]}));for(d in b)if(e=b[d],jb.exec(e)){if(delete b[d],f=f||"toggle"===e,e===(q?"hide":"show")){if("show"!==e||!r||void 0===r[d])continue;q=!0}o[d]=r&&r[d]||n.style(a,d)}else j=void 0;if(n.isEmptyObject(o))"inline"===("none"===j?Ma(a.nodeName):j)&&(p.display=j);else{r?"hidden"in r&&(q=r.hidden):r=n._data(a,"fxshow",{}),f&&(r.hidden=!q),q?n(a).show():m.done(function(){n(a).hide()}),m.done(function(){var b;n._removeData(a,"fxshow");for(b in o)n.style(a,b,o[b])});for(d in o)g=nb(q?r[d]:0,d,m),d in r||(r[d]=g.start,q&&(g.end=g.start,g.start="width"===d||"height"===d?1:0))}}function pb(a,b){var c,d,e,f,g;for(c in a)if(d=n.camelCase(c),e=b[d],f=a[c],n.isArray(f)&&(e=f[1],f=a[c]=f[0]),c!==d&&(a[d]=f,delete a[c]),g=n.cssHooks[d],g&&"expand"in g){f=g.expand(f),delete a[d];for(c in f)c in a||(a[c]=f[c],b[c]=e)}else b[d]=e}function qb(a,b,c){var d,e,f=0,g=qb.prefilters.length,h=n.Deferred().always(function(){delete i.elem}),i=function(){if(e)return!1;for(var b=hb||lb(),c=Math.max(0,j.startTime+j.duration-b),d=c/j.duration||0,f=1-d,g=0,i=j.tweens.length;i>g;g++)j.tweens[g].run(f);return h.notifyWith(a,[j,f,c]),1>f&&i?c:(h.resolveWith(a,[j]),!1)},j=h.promise({elem:a,props:n.extend({},b),opts:n.extend(!0,{specialEasing:{},easing:n.easing._default},c),originalProperties:b,originalOptions:c,startTime:hb||lb(),duration:c.duration,tweens:[],createTween:function(b,c){var d=n.Tween(a,j.opts,b,c,j.opts.specialEasing[b]||j.opts.easing);return j.tweens.push(d),d},stop:function(b){var c=0,d=b?j.tweens.length:0;if(e)return this;for(e=!0;d>c;c++)j.tweens[c].run(1);return b?(h.notifyWith(a,[j,1,0]),h.resolveWith(a,[j,b])):h.rejectWith(a,[j,b]),this}}),k=j.props;for(pb(k,j.opts.specialEasing);g>f;f++)if(d=qb.prefilters[f].call(j,a,k,j.opts))return n.isFunction(d.stop)&&(n._queueHooks(j.elem,j.opts.queue).stop=n.proxy(d.stop,d)),d;return n.map(k,nb,j),n.isFunction(j.opts.start)&&j.opts.start.call(a,j),n.fx.timer(n.extend(i,{elem:a,anim:j,queue:j.opts.queue})),j.progress(j.opts.progress).done(j.opts.done,j.opts.complete).fail(j.opts.fail).always(j.opts.always)}n.Animation=n.extend(qb,{tweeners:{"*":[function(a,b){var c=this.createTween(a,b);return X(c.elem,a,U.exec(b),c),c}]},tweener:function(a,b){n.isFunction(a)?(b=a,a=["*"]):a=a.match(G);for(var c,d=0,e=a.length;e>d;d++)c=a[d],qb.tweeners[c]=qb.tweeners[c]||[],qb.tweeners[c].unshift(b)},prefilters:[ob],prefilter:function(a,b){b?qb.prefilters.unshift(a):qb.prefilters.push(a)}}),n.speed=function(a,b,c){var d=a&&"object"==typeof a?n.extend({},a):{complete:c||!c&&b||n.isFunction(a)&&a,duration:a,easing:c&&b||b&&!n.isFunction(b)&&b};return d.duration=n.fx.off?0:"number"==typeof d.duration?d.duration:d.duration in n.fx.speeds?n.fx.speeds[d.duration]:n.fx.speeds._default,null!=d.queue&&d.queue!==!0||(d.queue="fx"),d.old=d.complete,d.complete=function(){n.isFunction(d.old)&&d.old.call(this),d.queue&&n.dequeue(this,d.queue)},d},n.fn.extend({fadeTo:function(a,b,c,d){return this.filter(W).css("opacity",0).show().end().animate({opacity:b},a,c,d)},animate:function(a,b,c,d){var e=n.isEmptyObject(a),f=n.speed(b,c,d),g=function(){var b=qb(this,n.extend({},a),f);(e||n._data(this,"finish"))&&b.stop(!0)};return g.finish=g,e||f.queue===!1?this.each(g):this.queue(f.queue,g)},stop:function(a,b,c){var d=function(a){var b=a.stop;delete a.stop,b(c)};return"string"!=typeof a&&(c=b,b=a,a=void 0),b&&a!==!1&&this.queue(a||"fx",[]),this.each(function(){var b=!0,e=null!=a&&a+"queueHooks",f=n.timers,g=n._data(this);if(e)g[e]&&g[e].stop&&d(g[e]);else for(e in g)g[e]&&g[e].stop&&kb.test(e)&&d(g[e]);for(e=f.length;e--;)f[e].elem!==this||null!=a&&f[e].queue!==a||(f[e].anim.stop(c),b=!1,f.splice(e,1));!b&&c||n.dequeue(this,a)})},finish:function(a){return a!==!1&&(a=a||"fx"),this.each(function(){var b,c=n._data(this),d=c[a+"queue"],e=c[a+"queueHooks"],f=n.timers,g=d?d.length:0;for(c.finish=!0,n.queue(this,a,[]),e&&e.stop&&e.stop.call(this,!0),b=f.length;b--;)f[b].elem===this&&f[b].queue===a&&(f[b].anim.stop(!0),f.splice(b,1));for(b=0;g>b;b++)d[b]&&d[b].finish&&d[b].finish.call(this);delete c.finish})}}),n.each(["toggle","show","hide"],function(a,b){var c=n.fn[b];n.fn[b]=function(a,d,e){return null==a||"boolean"==typeof a?c.apply(this,arguments):this.animate(mb(b,!0),a,d,e)}}),n.each({slideDown:mb("show"),slideUp:mb("hide"),slideToggle:mb("toggle"),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){n.fn[a]=function(a,c,d){return this.animate(b,a,c,d)}}),n.timers=[],n.fx.tick=function(){var a,b=n.timers,c=0;for(hb=n.now();c<b.length;c++)a=b[c],a()||b[c]!==a||b.splice(c--,1);b.length||n.fx.stop(),hb=void 0},n.fx.timer=function(a){n.timers.push(a),a()?n.fx.start():n.timers.pop()},n.fx.interval=13,n.fx.start=function(){ib||(ib=a.setInterval(n.fx.tick,n.fx.interval))},n.fx.stop=function(){a.clearInterval(ib),ib=null},n.fx.speeds={slow:600,fast:200,_default:400},n.fn.delay=function(b,c){return b=n.fx?n.fx.speeds[b]||b:b,c=c||"fx",this.queue(c,function(c,d){var e=a.setTimeout(c,b);d.stop=function(){a.clearTimeout(e)}})},function(){var a,b=d.createElement("input"),c=d.createElement("div"),e=d.createElement("select"),f=e.appendChild(d.createElement("option"));c=d.createElement("div"),c.setAttribute("className","t"),c.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",a=c.getElementsByTagName("a")[0],b.setAttribute("type","checkbox"),c.appendChild(b),a=c.getElementsByTagName("a")[0],a.style.cssText="top:1px",l.getSetAttribute="t"!==c.className,l.style=/top/.test(a.getAttribute("style")),l.hrefNormalized="/a"===a.getAttribute("href"),l.checkOn=!!b.value,l.optSelected=f.selected,l.enctype=!!d.createElement("form").enctype,e.disabled=!0,l.optDisabled=!f.disabled,b=d.createElement("input"),b.setAttribute("value",""),l.input=""===b.getAttribute("value"),b.value="t",b.setAttribute("type","radio"),l.radioValue="t"===b.value}();var rb=/\r/g,sb=/[\x20\t\r\n\f]+/g;n.fn.extend({val:function(a){var b,c,d,e=this[0];{if(arguments.length)return d=n.isFunction(a),this.each(function(c){var e;1===this.nodeType&&(e=d?a.call(this,c,n(this).val()):a,null==e?e="":"number"==typeof e?e+="":n.isArray(e)&&(e=n.map(e,function(a){return null==a?"":a+""})),b=n.valHooks[this.type]||n.valHooks[this.nodeName.toLowerCase()],b&&"set"in b&&void 0!==b.set(this,e,"value")||(this.value=e))});if(e)return b=n.valHooks[e.type]||n.valHooks[e.nodeName.toLowerCase()],b&&"get"in b&&void 0!==(c=b.get(e,"value"))?c:(c=e.value,"string"==typeof c?c.replace(rb,""):null==c?"":c)}}}),n.extend({valHooks:{option:{get:function(a){var b=n.find.attr(a,"value");return null!=b?b:n.trim(n.text(a)).replace(sb," ")}},select:{get:function(a){for(var b,c,d=a.options,e=a.selectedIndex,f="select-one"===a.type||0>e,g=f?null:[],h=f?e+1:d.length,i=0>e?h:f?e:0;h>i;i++)if(c=d[i],(c.selected||i===e)&&(l.optDisabled?!c.disabled:null===c.getAttribute("disabled"))&&(!c.parentNode.disabled||!n.nodeName(c.parentNode,"optgroup"))){if(b=n(c).val(),f)return b;g.push(b)}return g},set:function(a,b){var c,d,e=a.options,f=n.makeArray(b),g=e.length;while(g--)if(d=e[g],n.inArray(n.valHooks.option.get(d),f)>-1)try{d.selected=c=!0}catch(h){d.scrollHeight}else d.selected=!1;return c||(a.selectedIndex=-1),e}}}}),n.each(["radio","checkbox"],function(){n.valHooks[this]={set:function(a,b){return n.isArray(b)?a.checked=n.inArray(n(a).val(),b)>-1:void 0}},l.checkOn||(n.valHooks[this].get=function(a){return null===a.getAttribute("value")?"on":a.value})});var tb,ub,vb=n.expr.attrHandle,wb=/^(?:checked|selected)$/i,xb=l.getSetAttribute,yb=l.input;n.fn.extend({attr:function(a,b){return Y(this,n.attr,a,b,arguments.length>1)},removeAttr:function(a){return this.each(function(){n.removeAttr(this,a)})}}),n.extend({attr:function(a,b,c){var d,e,f=a.nodeType;if(3!==f&&8!==f&&2!==f)return"undefined"==typeof a.getAttribute?n.prop(a,b,c):(1===f&&n.isXMLDoc(a)||(b=b.toLowerCase(),e=n.attrHooks[b]||(n.expr.match.bool.test(b)?ub:tb)),void 0!==c?null===c?void n.removeAttr(a,b):e&&"set"in e&&void 0!==(d=e.set(a,c,b))?d:(a.setAttribute(b,c+""),c):e&&"get"in e&&null!==(d=e.get(a,b))?d:(d=n.find.attr(a,b),null==d?void 0:d))},attrHooks:{type:{set:function(a,b){if(!l.radioValue&&"radio"===b&&n.nodeName(a,"input")){var c=a.value;return a.setAttribute("type",b),c&&(a.value=c),b}}}},removeAttr:function(a,b){var c,d,e=0,f=b&&b.match(G);if(f&&1===a.nodeType)while(c=f[e++])d=n.propFix[c]||c,n.expr.match.bool.test(c)?yb&&xb||!wb.test(c)?a[d]=!1:a[n.camelCase("default-"+c)]=a[d]=!1:n.attr(a,c,""),a.removeAttribute(xb?c:d)}}),ub={set:function(a,b,c){return b===!1?n.removeAttr(a,c):yb&&xb||!wb.test(c)?a.setAttribute(!xb&&n.propFix[c]||c,c):a[n.camelCase("default-"+c)]=a[c]=!0,c}},n.each(n.expr.match.bool.source.match(/\w+/g),function(a,b){var c=vb[b]||n.find.attr;yb&&xb||!wb.test(b)?vb[b]=function(a,b,d){var e,f;return d||(f=vb[b],vb[b]=e,e=null!=c(a,b,d)?b.toLowerCase():null,vb[b]=f),e}:vb[b]=function(a,b,c){return c?void 0:a[n.camelCase("default-"+b)]?b.toLowerCase():null}}),yb&&xb||(n.attrHooks.value={set:function(a,b,c){return n.nodeName(a,"input")?void(a.defaultValue=b):tb&&tb.set(a,b,c)}}),xb||(tb={set:function(a,b,c){var d=a.getAttributeNode(c);return d||a.setAttributeNode(d=a.ownerDocument.createAttribute(c)),d.value=b+="","value"===c||b===a.getAttribute(c)?b:void 0}},vb.id=vb.name=vb.coords=function(a,b,c){var d;return c?void 0:(d=a.getAttributeNode(b))&&""!==d.value?d.value:null},n.valHooks.button={get:function(a,b){var c=a.getAttributeNode(b);return c&&c.specified?c.value:void 0},set:tb.set},n.attrHooks.contenteditable={set:function(a,b,c){tb.set(a,""===b?!1:b,c)}},n.each(["width","height"],function(a,b){n.attrHooks[b]={set:function(a,c){return""===c?(a.setAttribute(b,"auto"),c):void 0}}})),l.style||(n.attrHooks.style={get:function(a){return a.style.cssText||void 0},set:function(a,b){return a.style.cssText=b+""}});var zb=/^(?:input|select|textarea|button|object)$/i,Ab=/^(?:a|area)$/i;n.fn.extend({prop:function(a,b){return Y(this,n.prop,a,b,arguments.length>1)},removeProp:function(a){return a=n.propFix[a]||a,this.each(function(){try{this[a]=void 0,delete this[a]}catch(b){}})}}),n.extend({prop:function(a,b,c){var d,e,f=a.nodeType;if(3!==f&&8!==f&&2!==f)return 1===f&&n.isXMLDoc(a)||(b=n.propFix[b]||b,e=n.propHooks[b]),void 0!==c?e&&"set"in e&&void 0!==(d=e.set(a,c,b))?d:a[b]=c:e&&"get"in e&&null!==(d=e.get(a,b))?d:a[b]},propHooks:{tabIndex:{get:function(a){var b=n.find.attr(a,"tabindex");return b?parseInt(b,10):zb.test(a.nodeName)||Ab.test(a.nodeName)&&a.href?0:-1}}},propFix:{"for":"htmlFor","class":"className"}}),l.hrefNormalized||n.each(["href","src"],function(a,b){n.propHooks[b]={get:function(a){return a.getAttribute(b,4)}}}),l.optSelected||(n.propHooks.selected={get:function(a){var b=a.parentNode;return b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex),null},set:function(a){var b=a.parentNode;b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex)}}),n.each(["tabIndex","readOnly","maxLength","cellSpacing","cellPadding","rowSpan","colSpan","useMap","frameBorder","contentEditable"],function(){n.propFix[this.toLowerCase()]=this}),l.enctype||(n.propFix.enctype="encoding");var Bb=/[\t\r\n\f]/g;function Cb(a){return n.attr(a,"class")||""}n.fn.extend({addClass:function(a){var b,c,d,e,f,g,h,i=0;if(n.isFunction(a))return this.each(function(b){n(this).addClass(a.call(this,b,Cb(this)))});if("string"==typeof a&&a){b=a.match(G)||[];while(c=this[i++])if(e=Cb(c),d=1===c.nodeType&&(" "+e+" ").replace(Bb," ")){g=0;while(f=b[g++])d.indexOf(" "+f+" ")<0&&(d+=f+" ");h=n.trim(d),e!==h&&n.attr(c,"class",h)}}return this},removeClass:function(a){var b,c,d,e,f,g,h,i=0;if(n.isFunction(a))return this.each(function(b){n(this).removeClass(a.call(this,b,Cb(this)))});if(!arguments.length)return this.attr("class","");if("string"==typeof a&&a){b=a.match(G)||[];while(c=this[i++])if(e=Cb(c),d=1===c.nodeType&&(" "+e+" ").replace(Bb," ")){g=0;while(f=b[g++])while(d.indexOf(" "+f+" ")>-1)d=d.replace(" "+f+" "," ");h=n.trim(d),e!==h&&n.attr(c,"class",h)}}return this},toggleClass:function(a,b){var c=typeof a;return"boolean"==typeof b&&"string"===c?b?this.addClass(a):this.removeClass(a):n.isFunction(a)?this.each(function(c){n(this).toggleClass(a.call(this,c,Cb(this),b),b)}):this.each(function(){var b,d,e,f;if("string"===c){d=0,e=n(this),f=a.match(G)||[];while(b=f[d++])e.hasClass(b)?e.removeClass(b):e.addClass(b)}else void 0!==a&&"boolean"!==c||(b=Cb(this),b&&n._data(this,"__className__",b),n.attr(this,"class",b||a===!1?"":n._data(this,"__className__")||""))})},hasClass:function(a){var b,c,d=0;b=" "+a+" ";while(c=this[d++])if(1===c.nodeType&&(" "+Cb(c)+" ").replace(Bb," ").indexOf(b)>-1)return!0;return!1}}),n.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu".split(" "),function(a,b){n.fn[b]=function(a,c){return arguments.length>0?this.on(b,null,a,c):this.trigger(b)}}),n.fn.extend({hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)}});var Db=a.location,Eb=n.now(),Fb=/\?/,Gb=/(,)|(\[|{)|(}|])|"(?:[^"\\\r\n]|\\["\\\/bfnrt]|\\u[\da-fA-F]{4})*"\s*:?|true|false|null|-?(?!0\d)\d+(?:\.\d+|)(?:[eE][+-]?\d+|)/g;n.parseJSON=function(b){if(a.JSON&&a.JSON.parse)return a.JSON.parse(b+"");var c,d=null,e=n.trim(b+"");return e&&!n.trim(e.replace(Gb,function(a,b,e,f){return c&&b&&(d=0),0===d?a:(c=e||b,d+=!f-!e,"")}))?Function("return "+e)():n.error("Invalid JSON: "+b)},n.parseXML=function(b){var c,d;if(!b||"string"!=typeof b)return null;try{a.DOMParser?(d=new a.DOMParser,c=d.parseFromString(b,"text/xml")):(c=new a.ActiveXObject("Microsoft.XMLDOM"),c.async="false",c.loadXML(b))}catch(e){c=void 0}return c&&c.documentElement&&!c.getElementsByTagName("parsererror").length||n.error("Invalid XML: "+b),c};var Hb=/#.*$/,Ib=/([?&])_=[^&]*/,Jb=/^(.*?):[ \t]*([^\r\n]*)\r?$/gm,Kb=/^(?:about|app|app-storage|.+-extension|file|res|widget):$/,Lb=/^(?:GET|HEAD)$/,Mb=/^\/\//,Nb=/^([\w.+-]+:)(?:\/\/(?:[^\/?#]*@|)([^\/?#:]*)(?::(\d+)|)|)/,Ob={},Pb={},Qb="*/".concat("*"),Rb=Db.href,Sb=Nb.exec(Rb.toLowerCase())||[];function Tb(a){return function(b,c){"string"!=typeof b&&(c=b,b="*");var d,e=0,f=b.toLowerCase().match(G)||[];if(n.isFunction(c))while(d=f[e++])"+"===d.charAt(0)?(d=d.slice(1)||"*",(a[d]=a[d]||[]).unshift(c)):(a[d]=a[d]||[]).push(c)}}function Ub(a,b,c,d){var e={},f=a===Pb;function g(h){var i;return e[h]=!0,n.each(a[h]||[],function(a,h){var j=h(b,c,d);return"string"!=typeof j||f||e[j]?f?!(i=j):void 0:(b.dataTypes.unshift(j),g(j),!1)}),i}return g(b.dataTypes[0])||!e["*"]&&g("*")}function Vb(a,b){var c,d,e=n.ajaxSettings.flatOptions||{};for(d in b)void 0!==b[d]&&((e[d]?a:c||(c={}))[d]=b[d]);return c&&n.extend(!0,a,c),a}function Wb(a,b,c){var d,e,f,g,h=a.contents,i=a.dataTypes;while("*"===i[0])i.shift(),void 0===e&&(e=a.mimeType||b.getResponseHeader("Content-Type"));if(e)for(g in h)if(h[g]&&h[g].test(e)){i.unshift(g);break}if(i[0]in c)f=i[0];else{for(g in c){if(!i[0]||a.converters[g+" "+i[0]]){f=g;break}d||(d=g)}f=f||d}return f?(f!==i[0]&&i.unshift(f),c[f]):void 0}function Xb(a,b,c,d){var e,f,g,h,i,j={},k=a.dataTypes.slice();if(k[1])for(g in a.converters)j[g.toLowerCase()]=a.converters[g];f=k.shift();while(f)if(a.responseFields[f]&&(c[a.responseFields[f]]=b),!i&&d&&a.dataFilter&&(b=a.dataFilter(b,a.dataType)),i=f,f=k.shift())if("*"===f)f=i;else if("*"!==i&&i!==f){if(g=j[i+" "+f]||j["* "+f],!g)for(e in j)if(h=e.split(" "),h[1]===f&&(g=j[i+" "+h[0]]||j["* "+h[0]])){g===!0?g=j[e]:j[e]!==!0&&(f=h[0],k.unshift(h[1]));break}if(g!==!0)if(g&&a["throws"])b=g(b);else try{b=g(b)}catch(l){return{state:"parsererror",error:g?l:"No conversion from "+i+" to "+f}}}return{state:"success",data:b}}n.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:Rb,type:"GET",isLocal:Kb.test(Sb[1]),global:!0,processData:!0,async:!0,contentType:"application/x-www-form-urlencoded; charset=UTF-8",accepts:{"*":Qb,text:"text/plain",html:"text/html",xml:"application/xml, text/xml",json:"application/json, text/javascript"},contents:{xml:/\bxml\b/,html:/\bhtml/,json:/\bjson\b/},responseFields:{xml:"responseXML",text:"responseText",json:"responseJSON"},converters:{"* text":String,"text html":!0,"text json":n.parseJSON,"text xml":n.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(a,b){return b?Vb(Vb(a,n.ajaxSettings),b):Vb(n.ajaxSettings,a)},ajaxPrefilter:Tb(Ob),ajaxTransport:Tb(Pb),ajax:function(b,c){"object"==typeof b&&(c=b,b=void 0),c=c||{};var d,e,f,g,h,i,j,k,l=n.ajaxSetup({},c),m=l.context||l,o=l.context&&(m.nodeType||m.jquery)?n(m):n.event,p=n.Deferred(),q=n.Callbacks("once memory"),r=l.statusCode||{},s={},t={},u=0,v="canceled",w={readyState:0,getResponseHeader:function(a){var b;if(2===u){if(!k){k={};while(b=Jb.exec(g))k[b[1].toLowerCase()]=b[2]}b=k[a.toLowerCase()]}return null==b?null:b},getAllResponseHeaders:function(){return 2===u?g:null},setRequestHeader:function(a,b){var c=a.toLowerCase();return u||(a=t[c]=t[c]||a,s[a]=b),this},overrideMimeType:function(a){return u||(l.mimeType=a),this},statusCode:function(a){var b;if(a)if(2>u)for(b in a)r[b]=[r[b],a[b]];else w.always(a[w.status]);return this},abort:function(a){var b=a||v;return j&&j.abort(b),y(0,b),this}};if(p.promise(w).complete=q.add,w.success=w.done,w.error=w.fail,l.url=((b||l.url||Rb)+"").replace(Hb,"").replace(Mb,Sb[1]+"//"),l.type=c.method||c.type||l.method||l.type,l.dataTypes=n.trim(l.dataType||"*").toLowerCase().match(G)||[""],null==l.crossDomain&&(d=Nb.exec(l.url.toLowerCase()),l.crossDomain=!(!d||d[1]===Sb[1]&&d[2]===Sb[2]&&(d[3]||("http:"===d[1]?"80":"443"))===(Sb[3]||("http:"===Sb[1]?"80":"443")))),l.data&&l.processData&&"string"!=typeof l.data&&(l.data=n.param(l.data,l.traditional)),Ub(Ob,l,c,w),2===u)return w;i=n.event&&l.global,i&&0===n.active++&&n.event.trigger("ajaxStart"),l.type=l.type.toUpperCase(),l.hasContent=!Lb.test(l.type),f=l.url,l.hasContent||(l.data&&(f=l.url+=(Fb.test(f)?"&":"?")+l.data,delete l.data),l.cache===!1&&(l.url=Ib.test(f)?f.replace(Ib,"$1_="+Eb++):f+(Fb.test(f)?"&":"?")+"_="+Eb++)),l.ifModified&&(n.lastModified[f]&&w.setRequestHeader("If-Modified-Since",n.lastModified[f]),n.etag[f]&&w.setRequestHeader("If-None-Match",n.etag[f])),(l.data&&l.hasContent&&l.contentType!==!1||c.contentType)&&w.setRequestHeader("Content-Type",l.contentType),w.setRequestHeader("Accept",l.dataTypes[0]&&l.accepts[l.dataTypes[0]]?l.accepts[l.dataTypes[0]]+("*"!==l.dataTypes[0]?", "+Qb+"; q=0.01":""):l.accepts["*"]);for(e in l.headers)w.setRequestHeader(e,l.headers[e]);if(l.beforeSend&&(l.beforeSend.call(m,w,l)===!1||2===u))return w.abort();v="abort";for(e in{success:1,error:1,complete:1})w[e](l[e]);if(j=Ub(Pb,l,c,w)){if(w.readyState=1,i&&o.trigger("ajaxSend",[w,l]),2===u)return w;l.async&&l.timeout>0&&(h=a.setTimeout(function(){w.abort("timeout")},l.timeout));try{u=1,j.send(s,y)}catch(x){if(!(2>u))throw x;y(-1,x)}}else y(-1,"No Transport");function y(b,c,d,e){var k,s,t,v,x,y=c;2!==u&&(u=2,h&&a.clearTimeout(h),j=void 0,g=e||"",w.readyState=b>0?4:0,k=b>=200&&300>b||304===b,d&&(v=Wb(l,w,d)),v=Xb(l,v,w,k),k?(l.ifModified&&(x=w.getResponseHeader("Last-Modified"),x&&(n.lastModified[f]=x),x=w.getResponseHeader("etag"),x&&(n.etag[f]=x)),204===b||"HEAD"===l.type?y="nocontent":304===b?y="notmodified":(y=v.state,s=v.data,t=v.error,k=!t)):(t=y,!b&&y||(y="error",0>b&&(b=0))),w.status=b,w.statusText=(c||y)+"",k?p.resolveWith(m,[s,y,w]):p.rejectWith(m,[w,y,t]),w.statusCode(r),r=void 0,i&&o.trigger(k?"ajaxSuccess":"ajaxError",[w,l,k?s:t]),q.fireWith(m,[w,y]),i&&(o.trigger("ajaxComplete",[w,l]),--n.active||n.event.trigger("ajaxStop")))}return w},getJSON:function(a,b,c){return n.get(a,b,c,"json")},getScript:function(a,b){return n.get(a,void 0,b,"script")}}),n.each(["get","post"],function(a,b){n[b]=function(a,c,d,e){return n.isFunction(c)&&(e=e||d,d=c,c=void 0),n.ajax(n.extend({url:a,type:b,dataType:e,data:c,success:d},n.isPlainObject(a)&&a))}}),n._evalUrl=function(a){return n.ajax({url:a,type:"GET",dataType:"script",cache:!0,async:!1,global:!1,"throws":!0})},n.fn.extend({wrapAll:function(a){if(n.isFunction(a))return this.each(function(b){n(this).wrapAll(a.call(this,b))});if(this[0]){var b=n(a,this[0].ownerDocument).eq(0).clone(!0);this[0].parentNode&&b.insertBefore(this[0]),b.map(function(){var a=this;while(a.firstChild&&1===a.firstChild.nodeType)a=a.firstChild;return a}).append(this)}return this},wrapInner:function(a){return n.isFunction(a)?this.each(function(b){n(this).wrapInner(a.call(this,b))}):this.each(function(){var b=n(this),c=b.contents();c.length?c.wrapAll(a):b.append(a)})},wrap:function(a){var b=n.isFunction(a);return this.each(function(c){n(this).wrapAll(b?a.call(this,c):a)})},unwrap:function(){return this.parent().each(function(){n.nodeName(this,"body")||n(this).replaceWith(this.childNodes)}).end()}});function Yb(a){return a.style&&a.style.display||n.css(a,"display")}function Zb(a){while(a&&1===a.nodeType){if("none"===Yb(a)||"hidden"===a.type)return!0;a=a.parentNode}return!1}n.expr.filters.hidden=function(a){return l.reliableHiddenOffsets()?a.offsetWidth<=0&&a.offsetHeight<=0&&!a.getClientRects().length:Zb(a)},n.expr.filters.visible=function(a){return!n.expr.filters.hidden(a)};var $b=/%20/g,_b=/\[\]$/,ac=/\r?\n/g,bc=/^(?:submit|button|image|reset|file)$/i,cc=/^(?:input|select|textarea|keygen)/i;function dc(a,b,c,d){var e;if(n.isArray(b))n.each(b,function(b,e){c||_b.test(a)?d(a,e):dc(a+"["+("object"==typeof e&&null!=e?b:"")+"]",e,c,d)});else if(c||"object"!==n.type(b))d(a,b);else for(e in b)dc(a+"["+e+"]",b[e],c,d)}n.param=function(a,b){var c,d=[],e=function(a,b){b=n.isFunction(b)?b():null==b?"":b,d[d.length]=encodeURIComponent(a)+"="+encodeURIComponent(b)};if(void 0===b&&(b=n.ajaxSettings&&n.ajaxSettings.traditional),n.isArray(a)||a.jquery&&!n.isPlainObject(a))n.each(a,function(){e(this.name,this.value)});else for(c in a)dc(c,a[c],b,e);return d.join("&").replace($b,"+")},n.fn.extend({serialize:function(){return n.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var a=n.prop(this,"elements");return a?n.makeArray(a):this}).filter(function(){var a=this.type;return this.name&&!n(this).is(":disabled")&&cc.test(this.nodeName)&&!bc.test(a)&&(this.checked||!Z.test(a))}).map(function(a,b){var c=n(this).val();return null==c?null:n.isArray(c)?n.map(c,function(a){return{name:b.name,value:a.replace(ac,"\r\n")}}):{name:b.name,value:c.replace(ac,"\r\n")}}).get()}}),n.ajaxSettings.xhr=void 0!==a.ActiveXObject?function(){return this.isLocal?ic():d.documentMode>8?hc():/^(get|post|head|put|delete|options)$/i.test(this.type)&&hc()||ic()}:hc;var ec=0,fc={},gc=n.ajaxSettings.xhr();a.attachEvent&&a.attachEvent("onunload",function(){for(var a in fc)fc[a](void 0,!0)}),l.cors=!!gc&&"withCredentials"in gc,gc=l.ajax=!!gc,gc&&n.ajaxTransport(function(b){if(!b.crossDomain||l.cors){var c;return{send:function(d,e){var f,g=b.xhr(),h=++ec;if(g.open(b.type,b.url,b.async,b.username,b.password),b.xhrFields)for(f in b.xhrFields)g[f]=b.xhrFields[f];b.mimeType&&g.overrideMimeType&&g.overrideMimeType(b.mimeType),b.crossDomain||d["X-Requested-With"]||(d["X-Requested-With"]="XMLHttpRequest");for(f in d)void 0!==d[f]&&g.setRequestHeader(f,d[f]+"");g.send(b.hasContent&&b.data||null),c=function(a,d){var f,i,j;if(c&&(d||4===g.readyState))if(delete fc[h],c=void 0,g.onreadystatechange=n.noop,d)4!==g.readyState&&g.abort();else{j={},f=g.status,"string"==typeof g.responseText&&(j.text=g.responseText);try{i=g.statusText}catch(k){i=""}f||!b.isLocal||b.crossDomain?1223===f&&(f=204):f=j.text?200:404}j&&e(f,i,j,g.getAllResponseHeaders())},b.async?4===g.readyState?a.setTimeout(c):g.onreadystatechange=fc[h]=c:c()},abort:function(){c&&c(void 0,!0)}}}});function hc(){try{return new a.XMLHttpRequest}catch(b){}}function ic(){try{return new a.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}}n.ajaxSetup({accepts:{script:"text/javascript, application/javascript, application/ecmascript, application/x-ecmascript"},contents:{script:/\b(?:java|ecma)script\b/},converters:{"text script":function(a){return n.globalEval(a),a}}}),n.ajaxPrefilter("script",function(a){void 0===a.cache&&(a.cache=!1),a.crossDomain&&(a.type="GET",a.global=!1)}),n.ajaxTransport("script",function(a){if(a.crossDomain){var b,c=d.head||n("head")[0]||d.documentElement;return{send:function(e,f){b=d.createElement("script"),b.async=!0,a.scriptCharset&&(b.charset=a.scriptCharset),b.src=a.url,b.onload=b.onreadystatechange=function(a,c){(c||!b.readyState||/loaded|complete/.test(b.readyState))&&(b.onload=b.onreadystatechange=null,b.parentNode&&b.parentNode.removeChild(b),b=null,c||f(200,"success"))},c.insertBefore(b,c.firstChild)},abort:function(){b&&b.onload(void 0,!0)}}}});var jc=[],kc=/(=)\?(?=&|$)|\?\?/;n.ajaxSetup({jsonp:"callback",jsonpCallback:function(){var a=jc.pop()||n.expando+"_"+Eb++;return this[a]=!0,a}}),n.ajaxPrefilter("json jsonp",function(b,c,d){var e,f,g,h=b.jsonp!==!1&&(kc.test(b.url)?"url":"string"==typeof b.data&&0===(b.contentType||"").indexOf("application/x-www-form-urlencoded")&&kc.test(b.data)&&"data");return h||"jsonp"===b.dataTypes[0]?(e=b.jsonpCallback=n.isFunction(b.jsonpCallback)?b.jsonpCallback():b.jsonpCallback,h?b[h]=b[h].replace(kc,"$1"+e):b.jsonp!==!1&&(b.url+=(Fb.test(b.url)?"&":"?")+b.jsonp+"="+e),b.converters["script json"]=function(){return g||n.error(e+" was not called"),g[0]},b.dataTypes[0]="json",f=a[e],a[e]=function(){g=arguments},d.always(function(){void 0===f?n(a).removeProp(e):a[e]=f,b[e]&&(b.jsonpCallback=c.jsonpCallback,jc.push(e)),g&&n.isFunction(f)&&f(g[0]),g=f=void 0}),"script"):void 0}),n.parseHTML=function(a,b,c){if(!a||"string"!=typeof a)return null;"boolean"==typeof b&&(c=b,b=!1),b=b||d;var e=x.exec(a),f=!c&&[];return e?[b.createElement(e[1])]:(e=ja([a],b,f),f&&f.length&&n(f).remove(),n.merge([],e.childNodes))};var lc=n.fn.load;n.fn.load=function(a,b,c){if("string"!=typeof a&&lc)return lc.apply(this,arguments);var d,e,f,g=this,h=a.indexOf(" ");return h>-1&&(d=n.trim(a.slice(h,a.length)),a=a.slice(0,h)),n.isFunction(b)?(c=b,b=void 0):b&&"object"==typeof b&&(e="POST"),g.length>0&&n.ajax({url:a,type:e||"GET",dataType:"html",data:b}).done(function(a){f=arguments,g.html(d?n("<div>").append(n.parseHTML(a)).find(d):a)}).always(c&&function(a,b){g.each(function(){c.apply(this,f||[a.responseText,b,a])})}),this},n.each(["ajaxStart","ajaxStop","ajaxComplete","ajaxError","ajaxSuccess","ajaxSend"],function(a,b){n.fn[b]=function(a){return this.on(b,a)}}),n.expr.filters.animated=function(a){return n.grep(n.timers,function(b){return a===b.elem}).length};function mc(a){return n.isWindow(a)?a:9===a.nodeType?a.defaultView||a.parentWindow:!1}n.offset={setOffset:function(a,b,c){var d,e,f,g,h,i,j,k=n.css(a,"position"),l=n(a),m={};"static"===k&&(a.style.position="relative"),h=l.offset(),f=n.css(a,"top"),i=n.css(a,"left"),j=("absolute"===k||"fixed"===k)&&n.inArray("auto",[f,i])>-1,j?(d=l.position(),g=d.top,e=d.left):(g=parseFloat(f)||0,e=parseFloat(i)||0),n.isFunction(b)&&(b=b.call(a,c,n.extend({},h))),null!=b.top&&(m.top=b.top-h.top+g),null!=b.left&&(m.left=b.left-h.left+e),"using"in b?b.using.call(a,m):l.css(m)}},n.fn.extend({offset:function(a){if(arguments.length)return void 0===a?this:this.each(function(b){n.offset.setOffset(this,a,b)});var b,c,d={top:0,left:0},e=this[0],f=e&&e.ownerDocument;if(f)return b=f.documentElement,n.contains(b,e)?("undefined"!=typeof e.getBoundingClientRect&&(d=e.getBoundingClientRect()),c=mc(f),{top:d.top+(c.pageYOffset||b.scrollTop)-(b.clientTop||0),left:d.left+(c.pageXOffset||b.scrollLeft)-(b.clientLeft||0)}):d},position:function(){if(this[0]){var a,b,c={top:0,left:0},d=this[0];return"fixed"===n.css(d,"position")?b=d.getBoundingClientRect():(a=this.offsetParent(),b=this.offset(),n.nodeName(a[0],"html")||(c=a.offset()),c.top+=n.css(a[0],"borderTopWidth",!0),c.left+=n.css(a[0],"borderLeftWidth",!0)),{top:b.top-c.top-n.css(d,"marginTop",!0),left:b.left-c.left-n.css(d,"marginLeft",!0)}}},offsetParent:function(){return this.map(function(){var a=this.offsetParent;while(a&&!n.nodeName(a,"html")&&"static"===n.css(a,"position"))a=a.offsetParent;return a||Qa})}}),n.each({scrollLeft:"pageXOffset",scrollTop:"pageYOffset"},function(a,b){var c=/Y/.test(b);n.fn[a]=function(d){return Y(this,function(a,d,e){var f=mc(a);return void 0===e?f?b in f?f[b]:f.document.documentElement[d]:a[d]:void(f?f.scrollTo(c?n(f).scrollLeft():e,c?e:n(f).scrollTop()):a[d]=e)},a,d,arguments.length,null)}}),n.each(["top","left"],function(a,b){n.cssHooks[b]=Ua(l.pixelPosition,function(a,c){return c?(c=Sa(a,b),Oa.test(c)?n(a).position()[b]+"px":c):void 0;
})}),n.each({Height:"height",Width:"width"},function(a,b){n.each({padding:"inner"+a,content:b,"":"outer"+a},function(c,d){n.fn[d]=function(d,e){var f=arguments.length&&(c||"boolean"!=typeof d),g=c||(d===!0||e===!0?"margin":"border");return Y(this,function(b,c,d){var e;return n.isWindow(b)?b.document.documentElement["client"+a]:9===b.nodeType?(e=b.documentElement,Math.max(b.body["scroll"+a],e["scroll"+a],b.body["offset"+a],e["offset"+a],e["client"+a])):void 0===d?n.css(b,c,g):n.style(b,c,d,g)},b,f?d:void 0,f,null)}})}),n.fn.extend({bind:function(a,b,c){return this.on(a,null,b,c)},unbind:function(a,b){return this.off(a,null,b)},delegate:function(a,b,c,d){return this.on(b,a,c,d)},undelegate:function(a,b,c){return 1===arguments.length?this.off(a,"**"):this.off(b,a||"**",c)}}),n.fn.size=function(){return this.length},n.fn.andSelf=n.fn.addBack,"function"==typeof define&&define.amd&&define("jquery",[],function(){return n});var nc=a.jQuery,oc=a.$;return n.noConflict=function(b){return a.$===n&&(a.$=oc),b&&a.jQuery===n&&(a.jQuery=nc),n},b||(a.jQuery=a.$=n),n});
/**
 * Owl Carousel v2.3.4
 * Copyright 2013-2018 David Deutsch
 * Licensed under: SEE LICENSE IN https://github.com/OwlCarousel2/OwlCarousel2/blob/master/LICENSE
 */
!function(a,b,c,d){function e(b,c){this.settings=null,this.options=a.extend({},e.Defaults,c),this.$element=a(b),this._handlers={},this._plugins={},this._supress={},this._current=null,this._speed=null,this._coordinates=[],this._breakpoint=null,this._width=null,this._items=[],this._clones=[],this._mergers=[],this._widths=[],this._invalidated={},this._pipe=[],this._drag={time:null,target:null,pointer:null,stage:{start:null,current:null},direction:null},this._states={current:{},tags:{initializing:["busy"],animating:["busy"],dragging:["interacting"]}},a.each(["onResize","onThrottledResize"],a.proxy(function(b,c){this._handlers[c]=a.proxy(this[c],this)},this)),a.each(e.Plugins,a.proxy(function(a,b){this._plugins[a.charAt(0).toLowerCase()+a.slice(1)]=new b(this)},this)),a.each(e.Workers,a.proxy(function(b,c){this._pipe.push({filter:c.filter,run:a.proxy(c.run,this)})},this)),this.setup(),this.initialize()}e.Defaults={items:3,loop:!1,center:!1,rewind:!1,checkVisibility:!0,mouseDrag:!0,touchDrag:!0,pullDrag:!0,freeDrag:!1,margin:0,stagePadding:0,merge:!1,mergeFit:!0,autoWidth:!1,startPosition:0,rtl:!1,smartSpeed:250,fluidSpeed:!1,dragEndSpeed:!1,responsive:{},responsiveRefreshRate:200,responsiveBaseElement:b,fallbackEasing:"swing",slideTransition:"",info:!1,nestedItemSelector:!1,itemElement:"div",stageElement:"div",refreshClass:"owl-refresh",loadedClass:"owl-loaded",loadingClass:"owl-loading",rtlClass:"owl-rtl",responsiveClass:"owl-responsive",dragClass:"owl-drag",itemClass:"owl-item",stageClass:"owl-stage",stageOuterClass:"owl-stage-outer",grabClass:"owl-grab"},e.Width={Default:"default",Inner:"inner",Outer:"outer"},e.Type={Event:"event",State:"state"},e.Plugins={},e.Workers=[{filter:["width","settings"],run:function(){this._width=this.$element.width()}},{filter:["width","items","settings"],run:function(a){a.current=this._items&&this._items[this.relative(this._current)]}},{filter:["items","settings"],run:function(){this.$stage.children(".cloned").remove()}},{filter:["width","items","settings"],run:function(a){var b=this.settings.margin||"",c=!this.settings.autoWidth,d=this.settings.rtl,e={width:"auto","margin-left":d?b:"","margin-right":d?"":b};!c&&this.$stage.children().css(e),a.css=e}},{filter:["width","items","settings"],run:function(a){var b=(this.width()/this.settings.items).toFixed(3)-this.settings.margin,c=null,d=this._items.length,e=!this.settings.autoWidth,f=[];for(a.items={merge:!1,width:b};d--;)c=this._mergers[d],c=this.settings.mergeFit&&Math.min(c,this.settings.items)||c,a.items.merge=c>1||a.items.merge,f[d]=e?b*c:this._items[d].width();this._widths=f}},{filter:["items","settings"],run:function(){var b=[],c=this._items,d=this.settings,e=Math.max(2*d.items,4),f=2*Math.ceil(c.length/2),g=d.loop&&c.length?d.rewind?e:Math.max(e,f):0,h="",i="";for(g/=2;g>0;)b.push(this.normalize(b.length/2,!0)),h+=c[b[b.length-1]][0].outerHTML,b.push(this.normalize(c.length-1-(b.length-1)/2,!0)),i=c[b[b.length-1]][0].outerHTML+i,g-=1;this._clones=b,a(h).addClass("cloned").appendTo(this.$stage),a(i).addClass("cloned").prependTo(this.$stage)}},{filter:["width","items","settings"],run:function(){for(var a=this.settings.rtl?1:-1,b=this._clones.length+this._items.length,c=-1,d=0,e=0,f=[];++c<b;)d=f[c-1]||0,e=this._widths[this.relative(c)]+this.settings.margin,f.push(d+e*a);this._coordinates=f}},{filter:["width","items","settings"],run:function(){var a=this.settings.stagePadding,b=this._coordinates,c={width:Math.ceil(Math.abs(b[b.length-1]))+2*a,"padding-left":a||"","padding-right":a||""};this.$stage.css(c)}},{filter:["width","items","settings"],run:function(a){var b=this._coordinates.length,c=!this.settings.autoWidth,d=this.$stage.children();if(c&&a.items.merge)for(;b--;)a.css.width=this._widths[this.relative(b)],d.eq(b).css(a.css);else c&&(a.css.width=a.items.width,d.css(a.css))}},{filter:["items"],run:function(){this._coordinates.length<1&&this.$stage.removeAttr("style")}},{filter:["width","items","settings"],run:function(a){a.current=a.current?this.$stage.children().index(a.current):0,a.current=Math.max(this.minimum(),Math.min(this.maximum(),a.current)),this.reset(a.current)}},{filter:["position"],run:function(){this.animate(this.coordinates(this._current))}},{filter:["width","position","items","settings"],run:function(){var a,b,c,d,e=this.settings.rtl?1:-1,f=2*this.settings.stagePadding,g=this.coordinates(this.current())+f,h=g+this.width()*e,i=[];for(c=0,d=this._coordinates.length;c<d;c++)a=this._coordinates[c-1]||0,b=Math.abs(this._coordinates[c])+f*e,(this.op(a,"<=",g)&&this.op(a,">",h)||this.op(b,"<",g)&&this.op(b,">",h))&&i.push(c);this.$stage.children(".active").removeClass("active"),this.$stage.children(":eq("+i.join("), :eq(")+")").addClass("active"),this.$stage.children(".center").removeClass("center"),this.settings.center&&this.$stage.children().eq(this.current()).addClass("center")}}],e.prototype.initializeStage=function(){this.$stage=this.$element.find("."+this.settings.stageClass),this.$stage.length||(this.$element.addClass(this.options.loadingClass),this.$stage=a("<"+this.settings.stageElement+">",{class:this.settings.stageClass}).wrap(a("<div/>",{class:this.settings.stageOuterClass})),this.$element.append(this.$stage.parent()))},e.prototype.initializeItems=function(){var b=this.$element.find(".owl-item");if(b.length)return this._items=b.get().map(function(b){return a(b)}),this._mergers=this._items.map(function(){return 1}),void this.refresh();this.replace(this.$element.children().not(this.$stage.parent())),this.isVisible()?this.refresh():this.invalidate("width"),this.$element.removeClass(this.options.loadingClass).addClass(this.options.loadedClass)},e.prototype.initialize=function(){if(this.enter("initializing"),this.trigger("initialize"),this.$element.toggleClass(this.settings.rtlClass,this.settings.rtl),this.settings.autoWidth&&!this.is("pre-loading")){var a,b,c;a=this.$element.find("img"),b=this.settings.nestedItemSelector?"."+this.settings.nestedItemSelector:d,c=this.$element.children(b).width(),a.length&&c<=0&&this.preloadAutoWidthImages(a)}this.initializeStage(),this.initializeItems(),this.registerEventHandlers(),this.leave("initializing"),this.trigger("initialized")},e.prototype.isVisible=function(){return!this.settings.checkVisibility||this.$element.is(":visible")},e.prototype.setup=function(){var b=this.viewport(),c=this.options.responsive,d=-1,e=null;c?(a.each(c,function(a){a<=b&&a>d&&(d=Number(a))}),e=a.extend({},this.options,c[d]),"function"==typeof e.stagePadding&&(e.stagePadding=e.stagePadding()),delete e.responsive,e.responsiveClass&&this.$element.attr("class",this.$element.attr("class").replace(new RegExp("("+this.options.responsiveClass+"-)\\S+\\s","g"),"$1"+d))):e=a.extend({},this.options),this.trigger("change",{property:{name:"settings",value:e}}),this._breakpoint=d,this.settings=e,this.invalidate("settings"),this.trigger("changed",{property:{name:"settings",value:this.settings}})},e.prototype.optionsLogic=function(){this.settings.autoWidth&&(this.settings.stagePadding=!1,this.settings.merge=!1)},e.prototype.prepare=function(b){var c=this.trigger("prepare",{content:b});return c.data||(c.data=a("<"+this.settings.itemElement+"/>").addClass(this.options.itemClass).append(b)),this.trigger("prepared",{content:c.data}),c.data},e.prototype.update=function(){for(var b=0,c=this._pipe.length,d=a.proxy(function(a){return this[a]},this._invalidated),e={};b<c;)(this._invalidated.all||a.grep(this._pipe[b].filter,d).length>0)&&this._pipe[b].run(e),b++;this._invalidated={},!this.is("valid")&&this.enter("valid")},e.prototype.width=function(a){switch(a=a||e.Width.Default){case e.Width.Inner:case e.Width.Outer:return this._width;default:return this._width-2*this.settings.stagePadding+this.settings.margin}},e.prototype.refresh=function(){this.enter("refreshing"),this.trigger("refresh"),this.setup(),this.optionsLogic(),this.$element.addClass(this.options.refreshClass),this.update(),this.$element.removeClass(this.options.refreshClass),this.leave("refreshing"),this.trigger("refreshed")},e.prototype.onThrottledResize=function(){b.clearTimeout(this.resizeTimer),this.resizeTimer=b.setTimeout(this._handlers.onResize,this.settings.responsiveRefreshRate)},e.prototype.onResize=function(){return!!this._items.length&&(this._width!==this.$element.width()&&(!!this.isVisible()&&(this.enter("resizing"),this.trigger("resize").isDefaultPrevented()?(this.leave("resizing"),!1):(this.invalidate("width"),this.refresh(),this.leave("resizing"),void this.trigger("resized")))))},e.prototype.registerEventHandlers=function(){a.support.transition&&this.$stage.on(a.support.transition.end+".owl.core",a.proxy(this.onTransitionEnd,this)),!1!==this.settings.responsive&&this.on(b,"resize",this._handlers.onThrottledResize),this.settings.mouseDrag&&(this.$element.addClass(this.options.dragClass),this.$stage.on("mousedown.owl.core",a.proxy(this.onDragStart,this)),this.$stage.on("dragstart.owl.core selectstart.owl.core",function(){return!1})),this.settings.touchDrag&&(this.$stage.on("touchstart.owl.core",a.proxy(this.onDragStart,this)),this.$stage.on("touchcancel.owl.core",a.proxy(this.onDragEnd,this)))},e.prototype.onDragStart=function(b){var d=null;3!==b.which&&(a.support.transform?(d=this.$stage.css("transform").replace(/.*\(|\)| /g,"").split(","),d={x:d[16===d.length?12:4],y:d[16===d.length?13:5]}):(d=this.$stage.position(),d={x:this.settings.rtl?d.left+this.$stage.width()-this.width()+this.settings.margin:d.left,y:d.top}),this.is("animating")&&(a.support.transform?this.animate(d.x):this.$stage.stop(),this.invalidate("position")),this.$element.toggleClass(this.options.grabClass,"mousedown"===b.type),this.speed(0),this._drag.time=(new Date).getTime(),this._drag.target=a(b.target),this._drag.stage.start=d,this._drag.stage.current=d,this._drag.pointer=this.pointer(b),a(c).on("mouseup.owl.core touchend.owl.core",a.proxy(this.onDragEnd,this)),a(c).one("mousemove.owl.core touchmove.owl.core",a.proxy(function(b){var d=this.difference(this._drag.pointer,this.pointer(b));a(c).on("mousemove.owl.core touchmove.owl.core",a.proxy(this.onDragMove,this)),Math.abs(d.x)<Math.abs(d.y)&&this.is("valid")||(b.preventDefault(),this.enter("dragging"),this.trigger("drag"))},this)))},e.prototype.onDragMove=function(a){var b=null,c=null,d=null,e=this.difference(this._drag.pointer,this.pointer(a)),f=this.difference(this._drag.stage.start,e);this.is("dragging")&&(a.preventDefault(),this.settings.loop?(b=this.coordinates(this.minimum()),c=this.coordinates(this.maximum()+1)-b,f.x=((f.x-b)%c+c)%c+b):(b=this.settings.rtl?this.coordinates(this.maximum()):this.coordinates(this.minimum()),c=this.settings.rtl?this.coordinates(this.minimum()):this.coordinates(this.maximum()),d=this.settings.pullDrag?-1*e.x/5:0,f.x=Math.max(Math.min(f.x,b+d),c+d)),this._drag.stage.current=f,this.animate(f.x))},e.prototype.onDragEnd=function(b){var d=this.difference(this._drag.pointer,this.pointer(b)),e=this._drag.stage.current,f=d.x>0^this.settings.rtl?"left":"right";a(c).off(".owl.core"),this.$element.removeClass(this.options.grabClass),(0!==d.x&&this.is("dragging")||!this.is("valid"))&&(this.speed(this.settings.dragEndSpeed||this.settings.smartSpeed),this.current(this.closest(e.x,0!==d.x?f:this._drag.direction)),this.invalidate("position"),this.update(),this._drag.direction=f,(Math.abs(d.x)>3||(new Date).getTime()-this._drag.time>300)&&this._drag.target.one("click.owl.core",function(){return!1})),this.is("dragging")&&(this.leave("dragging"),this.trigger("dragged"))},e.prototype.closest=function(b,c){var e=-1,f=30,g=this.width(),h=this.coordinates();return this.settings.freeDrag||a.each(h,a.proxy(function(a,i){return"left"===c&&b>i-f&&b<i+f?e=a:"right"===c&&b>i-g-f&&b<i-g+f?e=a+1:this.op(b,"<",i)&&this.op(b,">",h[a+1]!==d?h[a+1]:i-g)&&(e="left"===c?a+1:a),-1===e},this)),this.settings.loop||(this.op(b,">",h[this.minimum()])?e=b=this.minimum():this.op(b,"<",h[this.maximum()])&&(e=b=this.maximum())),e},e.prototype.animate=function(b){var c=this.speed()>0;this.is("animating")&&this.onTransitionEnd(),c&&(this.enter("animating"),this.trigger("translate")),a.support.transform3d&&a.support.transition?this.$stage.css({transform:"translate3d("+b+"px,0px,0px)",transition:this.speed()/1e3+"s"+(this.settings.slideTransition?" "+this.settings.slideTransition:"")}):c?this.$stage.animate({left:b+"px"},this.speed(),this.settings.fallbackEasing,a.proxy(this.onTransitionEnd,this)):this.$stage.css({left:b+"px"})},e.prototype.is=function(a){return this._states.current[a]&&this._states.current[a]>0},e.prototype.current=function(a){if(a===d)return this._current;if(0===this._items.length)return d;if(a=this.normalize(a),this._current!==a){var b=this.trigger("change",{property:{name:"position",value:a}});b.data!==d&&(a=this.normalize(b.data)),this._current=a,this.invalidate("position"),this.trigger("changed",{property:{name:"position",value:this._current}})}return this._current},e.prototype.invalidate=function(b){return"string"===a.type(b)&&(this._invalidated[b]=!0,this.is("valid")&&this.leave("valid")),a.map(this._invalidated,function(a,b){return b})},e.prototype.reset=function(a){(a=this.normalize(a))!==d&&(this._speed=0,this._current=a,this.suppress(["translate","translated"]),this.animate(this.coordinates(a)),this.release(["translate","translated"]))},e.prototype.normalize=function(a,b){var c=this._items.length,e=b?0:this._clones.length;return!this.isNumeric(a)||c<1?a=d:(a<0||a>=c+e)&&(a=((a-e/2)%c+c)%c+e/2),a},e.prototype.relative=function(a){return a-=this._clones.length/2,this.normalize(a,!0)},e.prototype.maximum=function(a){var b,c,d,e=this.settings,f=this._coordinates.length;if(e.loop)f=this._clones.length/2+this._items.length-1;else if(e.autoWidth||e.merge){if(b=this._items.length)for(c=this._items[--b].width(),d=this.$element.width();b--&&!((c+=this._items[b].width()+this.settings.margin)>d););f=b+1}else f=e.center?this._items.length-1:this._items.length-e.items;return a&&(f-=this._clones.length/2),Math.max(f,0)},e.prototype.minimum=function(a){return a?0:this._clones.length/2},e.prototype.items=function(a){return a===d?this._items.slice():(a=this.normalize(a,!0),this._items[a])},e.prototype.mergers=function(a){return a===d?this._mergers.slice():(a=this.normalize(a,!0),this._mergers[a])},e.prototype.clones=function(b){var c=this._clones.length/2,e=c+this._items.length,f=function(a){return a%2==0?e+a/2:c-(a+1)/2};return b===d?a.map(this._clones,function(a,b){return f(b)}):a.map(this._clones,function(a,c){return a===b?f(c):null})},e.prototype.speed=function(a){return a!==d&&(this._speed=a),this._speed},e.prototype.coordinates=function(b){var c,e=1,f=b-1;return b===d?a.map(this._coordinates,a.proxy(function(a,b){return this.coordinates(b)},this)):(this.settings.center?(this.settings.rtl&&(e=-1,f=b+1),c=this._coordinates[b],c+=(this.width()-c+(this._coordinates[f]||0))/2*e):c=this._coordinates[f]||0,c=Math.ceil(c))},e.prototype.duration=function(a,b,c){return 0===c?0:Math.min(Math.max(Math.abs(b-a),1),6)*Math.abs(c||this.settings.smartSpeed)},e.prototype.to=function(a,b){var c=this.current(),d=null,e=a-this.relative(c),f=(e>0)-(e<0),g=this._items.length,h=this.minimum(),i=this.maximum();this.settings.loop?(!this.settings.rewind&&Math.abs(e)>g/2&&(e+=-1*f*g),a=c+e,(d=((a-h)%g+g)%g+h)!==a&&d-e<=i&&d-e>0&&(c=d-e,a=d,this.reset(c))):this.settings.rewind?(i+=1,a=(a%i+i)%i):a=Math.max(h,Math.min(i,a)),this.speed(this.duration(c,a,b)),this.current(a),this.isVisible()&&this.update()},e.prototype.next=function(a){a=a||!1,this.to(this.relative(this.current())+1,a)},e.prototype.prev=function(a){a=a||!1,this.to(this.relative(this.current())-1,a)},e.prototype.onTransitionEnd=function(a){if(a!==d&&(a.stopPropagation(),(a.target||a.srcElement||a.originalTarget)!==this.$stage.get(0)))return!1;this.leave("animating"),this.trigger("translated")},e.prototype.viewport=function(){var d;return this.options.responsiveBaseElement!==b?d=a(this.options.responsiveBaseElement).width():b.innerWidth?d=b.innerWidth:c.documentElement&&c.documentElement.clientWidth?d=c.documentElement.clientWidth:console.warn("Can not detect viewport width."),d},e.prototype.replace=function(b){this.$stage.empty(),this._items=[],b&&(b=b instanceof jQuery?b:a(b)),this.settings.nestedItemSelector&&(b=b.find("."+this.settings.nestedItemSelector)),b.filter(function(){return 1===this.nodeType}).each(a.proxy(function(a,b){b=this.prepare(b),this.$stage.append(b),this._items.push(b),this._mergers.push(1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)},this)),this.reset(this.isNumeric(this.settings.startPosition)?this.settings.startPosition:0),this.invalidate("items")},e.prototype.add=function(b,c){var e=this.relative(this._current);c=c===d?this._items.length:this.normalize(c,!0),b=b instanceof jQuery?b:a(b),this.trigger("add",{content:b,position:c}),b=this.prepare(b),0===this._items.length||c===this._items.length?(0===this._items.length&&this.$stage.append(b),0!==this._items.length&&this._items[c-1].after(b),this._items.push(b),this._mergers.push(1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)):(this._items[c].before(b),this._items.splice(c,0,b),this._mergers.splice(c,0,1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)),this._items[e]&&this.reset(this._items[e].index()),this.invalidate("items"),this.trigger("added",{content:b,position:c})},e.prototype.remove=function(a){(a=this.normalize(a,!0))!==d&&(this.trigger("remove",{content:this._items[a],position:a}),this._items[a].remove(),this._items.splice(a,1),this._mergers.splice(a,1),this.invalidate("items"),this.trigger("removed",{content:null,position:a}))},e.prototype.preloadAutoWidthImages=function(b){b.each(a.proxy(function(b,c){this.enter("pre-loading"),c=a(c),a(new Image).one("load",a.proxy(function(a){c.attr("src",a.target.src),c.css("opacity",1),this.leave("pre-loading"),!this.is("pre-loading")&&!this.is("initializing")&&this.refresh()},this)).attr("src",c.attr("src")||c.attr("data-src")||c.attr("data-src-retina"))},this))},e.prototype.destroy=function(){this.$element.off(".owl.core"),this.$stage.off(".owl.core"),a(c).off(".owl.core"),!1!==this.settings.responsive&&(b.clearTimeout(this.resizeTimer),this.off(b,"resize",this._handlers.onThrottledResize));for(var d in this._plugins)this._plugins[d].destroy();this.$stage.children(".cloned").remove(),this.$stage.unwrap(),this.$stage.children().contents().unwrap(),this.$stage.children().unwrap(),this.$stage.remove(),this.$element.removeClass(this.options.refreshClass).removeClass(this.options.loadingClass).removeClass(this.options.loadedClass).removeClass(this.options.rtlClass).removeClass(this.options.dragClass).removeClass(this.options.grabClass).attr("class",this.$element.attr("class").replace(new RegExp(this.options.responsiveClass+"-\\S+\\s","g"),"")).removeData("owl.carousel")},e.prototype.op=function(a,b,c){var d=this.settings.rtl;switch(b){case"<":return d?a>c:a<c;case">":return d?a<c:a>c;case">=":return d?a<=c:a>=c;case"<=":return d?a>=c:a<=c}},e.prototype.on=function(a,b,c,d){a.addEventListener?a.addEventListener(b,c,d):a.attachEvent&&a.attachEvent("on"+b,c)},e.prototype.off=function(a,b,c,d){a.removeEventListener?a.removeEventListener(b,c,d):a.detachEvent&&a.detachEvent("on"+b,c)},e.prototype.trigger=function(b,c,d,f,g){var h={item:{count:this._items.length,index:this.current()}},i=a.camelCase(a.grep(["on",b,d],function(a){return a}).join("-").toLowerCase()),j=a.Event([b,"owl",d||"carousel"].join(".").toLowerCase(),a.extend({relatedTarget:this},h,c));return this._supress[b]||(a.each(this._plugins,function(a,b){b.onTrigger&&b.onTrigger(j)}),this.register({type:e.Type.Event,name:b}),this.$element.trigger(j),this.settings&&"function"==typeof this.settings[i]&&this.settings[i].call(this,j)),j},e.prototype.enter=function(b){a.each([b].concat(this._states.tags[b]||[]),a.proxy(function(a,b){this._states.current[b]===d&&(this._states.current[b]=0),this._states.current[b]++},this))},e.prototype.leave=function(b){a.each([b].concat(this._states.tags[b]||[]),a.proxy(function(a,b){this._states.current[b]--},this))},e.prototype.register=function(b){if(b.type===e.Type.Event){if(a.event.special[b.name]||(a.event.special[b.name]={}),!a.event.special[b.name].owl){var c=a.event.special[b.name]._default;a.event.special[b.name]._default=function(a){return!c||!c.apply||a.namespace&&-1!==a.namespace.indexOf("owl")?a.namespace&&a.namespace.indexOf("owl")>-1:c.apply(this,arguments)},a.event.special[b.name].owl=!0}}else b.type===e.Type.State&&(this._states.tags[b.name]?this._states.tags[b.name]=this._states.tags[b.name].concat(b.tags):this._states.tags[b.name]=b.tags,this._states.tags[b.name]=a.grep(this._states.tags[b.name],a.proxy(function(c,d){return a.inArray(c,this._states.tags[b.name])===d},this)))},e.prototype.suppress=function(b){a.each(b,a.proxy(function(a,b){this._supress[b]=!0},this))},e.prototype.release=function(b){a.each(b,a.proxy(function(a,b){delete this._supress[b]},this))},e.prototype.pointer=function(a){var c={x:null,y:null};return a=a.originalEvent||a||b.event,a=a.touches&&a.touches.length?a.touches[0]:a.changedTouches&&a.changedTouches.length?a.changedTouches[0]:a,a.pageX?(c.x=a.pageX,c.y=a.pageY):(c.x=a.clientX,c.y=a.clientY),c},e.prototype.isNumeric=function(a){return!isNaN(parseFloat(a))},e.prototype.difference=function(a,b){return{x:a.x-b.x,y:a.y-b.y}},a.fn.owlCarousel=function(b){var c=Array.prototype.slice.call(arguments,1);return this.each(function(){var d=a(this),f=d.data("owl.carousel");f||(f=new e(this,"object"==typeof b&&b),d.data("owl.carousel",f),a.each(["next","prev","to","destroy","refresh","replace","add","remove"],function(b,c){f.register({type:e.Type.Event,name:c}),f.$element.on(c+".owl.carousel.core",a.proxy(function(a){a.namespace&&a.relatedTarget!==this&&(this.suppress([c]),f[c].apply(this,[].slice.call(arguments,1)),this.release([c]))},f))})),"string"==typeof b&&"_"!==b.charAt(0)&&f[b].apply(f,c)})},a.fn.owlCarousel.Constructor=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._interval=null,this._visible=null,this._handlers={"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoRefresh&&this.watch()},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers)};e.Defaults={autoRefresh:!0,autoRefreshInterval:500},e.prototype.watch=function(){this._interval||(this._visible=this._core.isVisible(),this._interval=b.setInterval(a.proxy(this.refresh,this),this._core.settings.autoRefreshInterval))},e.prototype.refresh=function(){this._core.isVisible()!==this._visible&&(this._visible=!this._visible,this._core.$element.toggleClass("owl-hidden",!this._visible),this._visible&&this._core.invalidate("width")&&this._core.refresh())},e.prototype.destroy=function(){var a,c;b.clearInterval(this._interval);for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(c in Object.getOwnPropertyNames(this))"function"!=typeof this[c]&&(this[c]=null)},a.fn.owlCarousel.Constructor.Plugins.AutoRefresh=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._loaded=[],this._handlers={"initialized.owl.carousel change.owl.carousel resized.owl.carousel":a.proxy(function(b){if(b.namespace&&this._core.settings&&this._core.settings.lazyLoad&&(b.property&&"position"==b.property.name||"initialized"==b.type)){var c=this._core.settings,e=c.center&&Math.ceil(c.items/2)||c.items,f=c.center&&-1*e||0,g=(b.property&&b.property.value!==d?b.property.value:this._core.current())+f,h=this._core.clones().length,i=a.proxy(function(a,b){this.load(b)},this);for(c.lazyLoadEager>0&&(e+=c.lazyLoadEager,c.loop&&(g-=c.lazyLoadEager,e++));f++<e;)this.load(h/2+this._core.relative(g)),h&&a.each(this._core.clones(this._core.relative(g)),i),g++}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers)};e.Defaults={lazyLoad:!1,lazyLoadEager:0},e.prototype.load=function(c){var d=this._core.$stage.children().eq(c),e=d&&d.find(".owl-lazy");!e||a.inArray(d.get(0),this._loaded)>-1||(e.each(a.proxy(function(c,d){var e,f=a(d),g=b.devicePixelRatio>1&&f.attr("data-src-retina")||f.attr("data-src")||f.attr("data-srcset");this._core.trigger("load",{element:f,url:g},"lazy"),f.is("img")?f.one("load.owl.lazy",a.proxy(function(){f.css("opacity",1),this._core.trigger("loaded",{element:f,url:g},"lazy")},this)).attr("src",g):f.is("source")?f.one("load.owl.lazy",a.proxy(function(){this._core.trigger("loaded",{element:f,url:g},"lazy")},this)).attr("srcset",g):(e=new Image,e.onload=a.proxy(function(){f.css({"background-image":'url("'+g+'")',opacity:"1"}),this._core.trigger("loaded",{element:f,url:g},"lazy")},this),e.src=g)},this)),this._loaded.push(d.get(0)))},e.prototype.destroy=function(){var a,b;for(a in this.handlers)this._core.$element.off(a,this.handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Lazy=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(c){this._core=c,this._previousHeight=null,this._handlers={"initialized.owl.carousel refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&this.update()},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&"position"===a.property.name&&this.update()},this),"loaded.owl.lazy":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&a.element.closest("."+this._core.settings.itemClass).index()===this._core.current()&&this.update()},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers),this._intervalId=null;var d=this;a(b).on("load",function(){d._core.settings.autoHeight&&d.update()}),a(b).resize(function(){d._core.settings.autoHeight&&(null!=d._intervalId&&clearTimeout(d._intervalId),d._intervalId=setTimeout(function(){d.update()},250))})};e.Defaults={autoHeight:!1,autoHeightClass:"owl-height"},e.prototype.update=function(){var b=this._core._current,c=b+this._core.settings.items,d=this._core.settings.lazyLoad,e=this._core.$stage.children().toArray().slice(b,c),f=[],g=0;a.each(e,function(b,c){f.push(a(c).height())}),g=Math.max.apply(null,f),g<=1&&d&&this._previousHeight&&(g=this._previousHeight),this._previousHeight=g,this._core.$stage.parent().height(g).addClass(this._core.settings.autoHeightClass)},e.prototype.destroy=function(){var a,b;for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.AutoHeight=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._videos={},this._playing=null,this._handlers={"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.register({type:"state",name:"playing",tags:["interacting"]})},this),"resize.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.video&&this.isInFullScreen()&&a.preventDefault()},this),"refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.is("resizing")&&this._core.$stage.find(".cloned .owl-video-frame").remove()},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&"position"===a.property.name&&this._playing&&this.stop()},this),"prepared.owl.carousel":a.proxy(function(b){if(b.namespace){var c=a(b.content).find(".owl-video");c.length&&(c.css("display","none"),this.fetch(c,a(b.content)))}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers),this._core.$element.on("click.owl.video",".owl-video-play-icon",a.proxy(function(a){this.play(a)},this))};e.Defaults={video:!1,videoHeight:!1,videoWidth:!1},e.prototype.fetch=function(a,b){var c=function(){return a.attr("data-vimeo-id")?"vimeo":a.attr("data-vzaar-id")?"vzaar":"youtube"}(),d=a.attr("data-vimeo-id")||a.attr("data-youtube-id")||a.attr("data-vzaar-id"),e=a.attr("data-width")||this._core.settings.videoWidth,f=a.attr("data-height")||this._core.settings.videoHeight,g=a.attr("href");if(!g)throw new Error("Missing video URL.");if(d=g.match(/(http:|https:|)\/\/(player.|www.|app.)?(vimeo\.com|youtu(be\.com|\.be|be\.googleapis\.com|be\-nocookie\.com)|vzaar\.com)\/(video\/|videos\/|embed\/|channels\/.+\/|groups\/.+\/|watch\?v=|v\/)?([A-Za-z0-9._%-]*)(\&\S+)?/),d[3].indexOf("youtu")>-1)c="youtube";else if(d[3].indexOf("vimeo")>-1)c="vimeo";else{if(!(d[3].indexOf("vzaar")>-1))throw new Error("Video URL not supported.");c="vzaar"}d=d[6],this._videos[g]={type:c,id:d,width:e,height:f},b.attr("data-video",g),this.thumbnail(a,this._videos[g])},e.prototype.thumbnail=function(b,c){var d,e,f,g=c.width&&c.height?"width:"+c.width+"px;height:"+c.height+"px;":"",h=b.find("img"),i="src",j="",k=this._core.settings,l=function(c){e='<div class="owl-video-play-icon"></div>',d=k.lazyLoad?a("<div/>",{class:"owl-video-tn "+j,srcType:c}):a("<div/>",{class:"owl-video-tn",style:"opacity:1;background-image:url("+c+")"}),b.after(d),b.after(e)};if(b.wrap(a("<div/>",{class:"owl-video-wrapper",style:g})),this._core.settings.lazyLoad&&(i="data-src",j="owl-lazy"),h.length)return l(h.attr(i)),h.remove(),!1;"youtube"===c.type?(f="//img.youtube.com/vi/"+c.id+"/hqdefault.jpg",l(f)):"vimeo"===c.type?a.ajax({type:"GET",url:"//vimeo.com/api/v2/video/"+c.id+".json",jsonp:"callback",dataType:"jsonp",success:function(a){f=a[0].thumbnail_large,l(f)}}):"vzaar"===c.type&&a.ajax({type:"GET",url:"//vzaar.com/api/videos/"+c.id+".json",jsonp:"callback",dataType:"jsonp",success:function(a){f=a.framegrab_url,l(f)}})},e.prototype.stop=function(){this._core.trigger("stop",null,"video"),this._playing.find(".owl-video-frame").remove(),this._playing.removeClass("owl-video-playing"),this._playing=null,this._core.leave("playing"),this._core.trigger("stopped",null,"video")},e.prototype.play=function(b){var c,d=a(b.target),e=d.closest("."+this._core.settings.itemClass),f=this._videos[e.attr("data-video")],g=f.width||"100%",h=f.height||this._core.$stage.height();this._playing||(this._core.enter("playing"),this._core.trigger("play",null,"video"),e=this._core.items(this._core.relative(e.index())),this._core.reset(e.index()),c=a('<iframe frameborder="0" allowfullscreen mozallowfullscreen webkitAllowFullScreen ></iframe>'),c.attr("height",h),c.attr("width",g),"youtube"===f.type?c.attr("src","//www.youtube.com/embed/"+f.id+"?autoplay=1&rel=0&v="+f.id):"vimeo"===f.type?c.attr("src","//player.vimeo.com/video/"+f.id+"?autoplay=1"):"vzaar"===f.type&&c.attr("src","//view.vzaar.com/"+f.id+"/player?autoplay=true"),a(c).wrap('<div class="owl-video-frame" />').insertAfter(e.find(".owl-video")),this._playing=e.addClass("owl-video-playing"))},e.prototype.isInFullScreen=function(){var b=c.fullscreenElement||c.mozFullScreenElement||c.webkitFullscreenElement;return b&&a(b).parent().hasClass("owl-video-frame")},e.prototype.destroy=function(){var a,b;this._core.$element.off("click.owl.video");for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Video=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this.core=b,this.core.options=a.extend({},e.Defaults,this.core.options),this.swapping=!0,this.previous=d,this.next=d,this.handlers={"change.owl.carousel":a.proxy(function(a){a.namespace&&"position"==a.property.name&&(this.previous=this.core.current(),this.next=a.property.value)},this),"drag.owl.carousel dragged.owl.carousel translated.owl.carousel":a.proxy(function(a){a.namespace&&(this.swapping="translated"==a.type)},this),"translate.owl.carousel":a.proxy(function(a){a.namespace&&this.swapping&&(this.core.options.animateOut||this.core.options.animateIn)&&this.swap()},this)},this.core.$element.on(this.handlers)};e.Defaults={animateOut:!1,
animateIn:!1},e.prototype.swap=function(){if(1===this.core.settings.items&&a.support.animation&&a.support.transition){this.core.speed(0);var b,c=a.proxy(this.clear,this),d=this.core.$stage.children().eq(this.previous),e=this.core.$stage.children().eq(this.next),f=this.core.settings.animateIn,g=this.core.settings.animateOut;this.core.current()!==this.previous&&(g&&(b=this.core.coordinates(this.previous)-this.core.coordinates(this.next),d.one(a.support.animation.end,c).css({left:b+"px"}).addClass("animated owl-animated-out").addClass(g)),f&&e.one(a.support.animation.end,c).addClass("animated owl-animated-in").addClass(f))}},e.prototype.clear=function(b){a(b.target).css({left:""}).removeClass("animated owl-animated-out owl-animated-in").removeClass(this.core.settings.animateIn).removeClass(this.core.settings.animateOut),this.core.onTransitionEnd()},e.prototype.destroy=function(){var a,b;for(a in this.handlers)this.core.$element.off(a,this.handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Animate=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._call=null,this._time=0,this._timeout=0,this._paused=!0,this._handlers={"changed.owl.carousel":a.proxy(function(a){a.namespace&&"settings"===a.property.name?this._core.settings.autoplay?this.play():this.stop():a.namespace&&"position"===a.property.name&&this._paused&&(this._time=0)},this),"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoplay&&this.play()},this),"play.owl.autoplay":a.proxy(function(a,b,c){a.namespace&&this.play(b,c)},this),"stop.owl.autoplay":a.proxy(function(a){a.namespace&&this.stop()},this),"mouseover.owl.autoplay":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.pause()},this),"mouseleave.owl.autoplay":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.play()},this),"touchstart.owl.core":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.pause()},this),"touchend.owl.core":a.proxy(function(){this._core.settings.autoplayHoverPause&&this.play()},this)},this._core.$element.on(this._handlers),this._core.options=a.extend({},e.Defaults,this._core.options)};e.Defaults={autoplay:!1,autoplayTimeout:5e3,autoplayHoverPause:!1,autoplaySpeed:!1},e.prototype._next=function(d){this._call=b.setTimeout(a.proxy(this._next,this,d),this._timeout*(Math.round(this.read()/this._timeout)+1)-this.read()),this._core.is("interacting")||c.hidden||this._core.next(d||this._core.settings.autoplaySpeed)},e.prototype.read=function(){return(new Date).getTime()-this._time},e.prototype.play=function(c,d){var e;this._core.is("rotating")||this._core.enter("rotating"),c=c||this._core.settings.autoplayTimeout,e=Math.min(this._time%(this._timeout||c),c),this._paused?(this._time=this.read(),this._paused=!1):b.clearTimeout(this._call),this._time+=this.read()%c-e,this._timeout=c,this._call=b.setTimeout(a.proxy(this._next,this,d),c-e)},e.prototype.stop=function(){this._core.is("rotating")&&(this._time=0,this._paused=!0,b.clearTimeout(this._call),this._core.leave("rotating"))},e.prototype.pause=function(){this._core.is("rotating")&&!this._paused&&(this._time=this.read(),this._paused=!0,b.clearTimeout(this._call))},e.prototype.destroy=function(){var a,b;this.stop();for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.autoplay=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){"use strict";var e=function(b){this._core=b,this._initialized=!1,this._pages=[],this._controls={},this._templates=[],this.$element=this._core.$element,this._overrides={next:this._core.next,prev:this._core.prev,to:this._core.to},this._handlers={"prepared.owl.carousel":a.proxy(function(b){b.namespace&&this._core.settings.dotsData&&this._templates.push('<div class="'+this._core.settings.dotClass+'">'+a(b.content).find("[data-dot]").addBack("[data-dot]").attr("data-dot")+"</div>")},this),"added.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.dotsData&&this._templates.splice(a.position,0,this._templates.pop())},this),"remove.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.dotsData&&this._templates.splice(a.position,1)},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&"position"==a.property.name&&this.draw()},this),"initialized.owl.carousel":a.proxy(function(a){a.namespace&&!this._initialized&&(this._core.trigger("initialize",null,"navigation"),this.initialize(),this.update(),this.draw(),this._initialized=!0,this._core.trigger("initialized",null,"navigation"))},this),"refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._initialized&&(this._core.trigger("refresh",null,"navigation"),this.update(),this.draw(),this._core.trigger("refreshed",null,"navigation"))},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this.$element.on(this._handlers)};e.Defaults={nav:!1,navText:['<span aria-label="Previous">&#x2039;</span>','<span aria-label="Next">&#x203a;</span>'],navSpeed:!1,navElement:'button type="button" role="presentation"',navContainer:!1,navContainerClass:"owl-nav",navClass:["owl-prev","owl-next"],slideBy:1,dotClass:"owl-dot",dotsClass:"owl-dots",dots:!0,dotsEach:!1,dotsData:!1,dotsSpeed:!1,dotsContainer:!1},e.prototype.initialize=function(){var b,c=this._core.settings;this._controls.$relative=(c.navContainer?a(c.navContainer):a("<div>").addClass(c.navContainerClass).appendTo(this.$element)).addClass("disabled"),this._controls.$previous=a("<"+c.navElement+">").addClass(c.navClass[0]).html(c.navText[0]).prependTo(this._controls.$relative).on("click",a.proxy(function(a){this.prev(c.navSpeed)},this)),this._controls.$next=a("<"+c.navElement+">").addClass(c.navClass[1]).html(c.navText[1]).appendTo(this._controls.$relative).on("click",a.proxy(function(a){this.next(c.navSpeed)},this)),c.dotsData||(this._templates=[a('<button role="button">').addClass(c.dotClass).append(a("<span>")).prop("outerHTML")]),this._controls.$absolute=(c.dotsContainer?a(c.dotsContainer):a("<div>").addClass(c.dotsClass).appendTo(this.$element)).addClass("disabled"),this._controls.$absolute.on("click","button",a.proxy(function(b){var d=a(b.target).parent().is(this._controls.$absolute)?a(b.target).index():a(b.target).parent().index();b.preventDefault(),this.to(d,c.dotsSpeed)},this));for(b in this._overrides)this._core[b]=a.proxy(this[b],this)},e.prototype.destroy=function(){var a,b,c,d,e;e=this._core.settings;for(a in this._handlers)this.$element.off(a,this._handlers[a]);for(b in this._controls)"$relative"===b&&e.navContainer?this._controls[b].html(""):this._controls[b].remove();for(d in this.overides)this._core[d]=this._overrides[d];for(c in Object.getOwnPropertyNames(this))"function"!=typeof this[c]&&(this[c]=null)},e.prototype.update=function(){var a,b,c,d=this._core.clones().length/2,e=d+this._core.items().length,f=this._core.maximum(!0),g=this._core.settings,h=g.center||g.autoWidth||g.dotsData?1:g.dotsEach||g.items;if("page"!==g.slideBy&&(g.slideBy=Math.min(g.slideBy,g.items)),g.dots||"page"==g.slideBy)for(this._pages=[],a=d,b=0,c=0;a<e;a++){if(b>=h||0===b){if(this._pages.push({start:Math.min(f,a-d),end:a-d+h-1}),Math.min(f,a-d)===f)break;b=0,++c}b+=this._core.mergers(this._core.relative(a))}},e.prototype.draw=function(){var b,c=this._core.settings,d=this._core.items().length<=c.items,e=this._core.relative(this._core.current()),f=c.loop||c.rewind;this._controls.$relative.toggleClass("disabled",!c.nav||d),c.nav&&(this._controls.$previous.toggleClass("disabled",!f&&e<=this._core.minimum(!0)),this._controls.$next.toggleClass("disabled",!f&&e>=this._core.maximum(!0))),this._controls.$absolute.toggleClass("disabled",!c.dots||d),c.dots&&(b=this._pages.length-this._controls.$absolute.children().length,c.dotsData&&0!==b?this._controls.$absolute.html(this._templates.join("")):b>0?this._controls.$absolute.append(new Array(b+1).join(this._templates[0])):b<0&&this._controls.$absolute.children().slice(b).remove(),this._controls.$absolute.find(".active").removeClass("active"),this._controls.$absolute.children().eq(a.inArray(this.current(),this._pages)).addClass("active"))},e.prototype.onTrigger=function(b){var c=this._core.settings;b.page={index:a.inArray(this.current(),this._pages),count:this._pages.length,size:c&&(c.center||c.autoWidth||c.dotsData?1:c.dotsEach||c.items)}},e.prototype.current=function(){var b=this._core.relative(this._core.current());return a.grep(this._pages,a.proxy(function(a,c){return a.start<=b&&a.end>=b},this)).pop()},e.prototype.getPosition=function(b){var c,d,e=this._core.settings;return"page"==e.slideBy?(c=a.inArray(this.current(),this._pages),d=this._pages.length,b?++c:--c,c=this._pages[(c%d+d)%d].start):(c=this._core.relative(this._core.current()),d=this._core.items().length,b?c+=e.slideBy:c-=e.slideBy),c},e.prototype.next=function(b){a.proxy(this._overrides.to,this._core)(this.getPosition(!0),b)},e.prototype.prev=function(b){a.proxy(this._overrides.to,this._core)(this.getPosition(!1),b)},e.prototype.to=function(b,c,d){var e;!d&&this._pages.length?(e=this._pages.length,a.proxy(this._overrides.to,this._core)(this._pages[(b%e+e)%e].start,c)):a.proxy(this._overrides.to,this._core)(b,c)},a.fn.owlCarousel.Constructor.Plugins.Navigation=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){"use strict";var e=function(c){this._core=c,this._hashes={},this.$element=this._core.$element,this._handlers={"initialized.owl.carousel":a.proxy(function(c){c.namespace&&"URLHash"===this._core.settings.startPosition&&a(b).trigger("hashchange.owl.navigation")},this),"prepared.owl.carousel":a.proxy(function(b){if(b.namespace){var c=a(b.content).find("[data-hash]").addBack("[data-hash]").attr("data-hash");if(!c)return;this._hashes[c]=b.content}},this),"changed.owl.carousel":a.proxy(function(c){if(c.namespace&&"position"===c.property.name){var d=this._core.items(this._core.relative(this._core.current())),e=a.map(this._hashes,function(a,b){return a===d?b:null}).join();if(!e||b.location.hash.slice(1)===e)return;b.location.hash=e}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this.$element.on(this._handlers),a(b).on("hashchange.owl.navigation",a.proxy(function(a){var c=b.location.hash.substring(1),e=this._core.$stage.children(),f=this._hashes[c]&&e.index(this._hashes[c]);f!==d&&f!==this._core.current()&&this._core.to(this._core.relative(f),!1,!0)},this))};e.Defaults={URLhashListener:!1},e.prototype.destroy=function(){var c,d;a(b).off("hashchange.owl.navigation");for(c in this._handlers)this._core.$element.off(c,this._handlers[c]);for(d in Object.getOwnPropertyNames(this))"function"!=typeof this[d]&&(this[d]=null)},a.fn.owlCarousel.Constructor.Plugins.Hash=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){function e(b,c){var e=!1,f=b.charAt(0).toUpperCase()+b.slice(1);return a.each((b+" "+h.join(f+" ")+f).split(" "),function(a,b){if(g[b]!==d)return e=!c||b,!1}),e}function f(a){return e(a,!0)}var g=a("<support>").get(0).style,h="Webkit Moz O ms".split(" "),i={transition:{end:{WebkitTransition:"webkitTransitionEnd",MozTransition:"transitionend",OTransition:"oTransitionEnd",transition:"transitionend"}},animation:{end:{WebkitAnimation:"webkitAnimationEnd",MozAnimation:"animationend",OAnimation:"oAnimationEnd",animation:"animationend"}}},j={csstransforms:function(){return!!e("transform")},csstransforms3d:function(){return!!e("perspective")},csstransitions:function(){return!!e("transition")},cssanimations:function(){return!!e("animation")}};j.csstransitions()&&(a.support.transition=new String(f("transition")),a.support.transition.end=i.transition.end[a.support.transition]),j.cssanimations()&&(a.support.animation=new String(f("animation")),a.support.animation.end=i.animation.end[a.support.animation]),j.csstransforms()&&(a.support.transform=new String(f("transform")),a.support.transform3d=j.csstransforms3d())}(window.Zepto||window.jQuery,window,document);(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    $(function() {
      var $this ,$scroll;
      var $articleContent = $('.js-article-content');
      var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
      var scroll = hasSidebar ? '.js-page-main' : 'html, body';
      $scroll = $(scroll);

      $articleContent.find('.highlight').each(function() {
        $this = $(this);
        $this.attr('data-lang', $this.find('code').attr('data-lang'));
      });
      $articleContent.find('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]').each(function() {
        $this = $(this);
        $this.append($('<a class="anchor d-print-none" aria-hidden="true"></a>').html('<i class="fas fa-anchor"></i>'));
      });
      $articleContent.on('click', '.anchor', function() {
        $scroll.scrollToAnchor('#' + $(this).parent().attr('id'), 400);
      });
    });
  });
})();

$(document).ready(function () {

  /* Versions Pagination*/
  $('.pagination_big').owlCarousel({
      margin:10,
      nav:true,
      dots:false,
      responsive:{
          0:{
              items:3
          },
          400:{
              items:4
          },
          500:{
              items:6
          },
          1600:{
              items:11
          }
      }
  });
});

</script></div><section class="page__comments d-print-none"></section></article><!-- start custom main bottom snippet -->

<!-- end custom main bottom snippet --></div>
            </div></div></div><div class="page__footer d-print-none">
<footer class="footer py-4 js-page-footer">
  <div class="main"><div itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content=""><meta itemprop="url" content="/"></div><div class="site-info mt-2">
      <div>© 2022 John Snow Labs Inc.
        <a href="http://www.johnsnowlabs.com/terms-of-service">Terms of Service</a> | <a href="http://www.johnsnowlabs.com/privacy-policy/">Privacy Policy</a>
      </div>
    </div>
  </div>
</footer>

<script>

/* Responsive menu
	 ========================================================*/
jQuery(document).ready(function($) {
	jQuery('#responsive_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.top_navigation').toggleClass('open');
  });
  jQuery('#aside_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.js-col-aside').toggleClass('open');
      if (jQuery(window).width() <= 1023)
      {
        jQuery('.page__sidebar').toggleClass('open'); 
      jQuery('.demomenu').toggleClass('open');
      }
  });
  jQuery('.toc--ellipsis a').click(function(e) {
    if (jQuery(window).width() <= 767)
      {
        jQuery('.js-col-aside').removeClass('open');
        jQuery('.page__sidebar').removeClass('open');    
        jQuery('#aside_menu').removeClass('close');  
      }       
  });
});

/*OPen by URL*/
jQuery(document).ready(function () {  
  const tabName = (window.location.hash || '').replace('#', '');
  const tab = document.getElementById(tabName || 'opensource');
  if (tab) {
    tab.click();
  }
});

//Accordion demos categories
if(document.querySelector(".acc-top")) {
  let acc = document.getElementsByClassName("acc-top"),
    isResizeble = false;

  if(!isResizeble && document.querySelector(".acc-top")) {
      let accBody = document.querySelector('.acc-body li.active');
      accBody.parentElement.style.maxHeight = accBody.parentElement.scrollHeight + 20 + "px";
      accBody.parentElement.classList.add('open');
      accBody.parentElement.previousElementSibling.classList.add('active');
      isResizeble = true;
  }

for (let i = 0; i < acc.length; i++) {
  acc[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var panel = this.nextElementSibling;
    if (panel.style.maxHeight) {
      panel.style.maxHeight = null;
      panel.classList.remove('open');
    } else {
      panel.style.maxHeight = panel.scrollHeight + 20 + "px";
      panel.classList.add('open');
    }
  });
}
}


//Show more in demos description
if(document.querySelector('.tab-description')) {
  let tabDescription = document.querySelectorAll('.tab-description');

  tabDescription.forEach(element => {
    let tabDescriptionInner = element.querySelector('.tab-description-inner');
    if(element.offsetHeight < tabDescriptionInner.offsetHeight) {
      element.classList.add('big-descr');
    }
  });

  let showMore = document.querySelectorAll('.show_more');

  showMore.forEach(element => {
    element.addEventListener("click", function(e) {
      e.preventDefault();
      this.parentElement.parentElement.classList.remove('big-descr');
      this.parentElement.parentElement.classList.add('big-descr-close');
    });
  });
}


//disable Colab link
if(document.querySelector('.btn.disable')) {
  let btnDisable = document.querySelectorAll('.btn.disable');

  btnDisable.forEach(element => {
    element.addEventListener("click", function(e) {
      e.preventDefault();
    });
  });
}


// Ancor click
const anchors = [].slice.call(document.querySelectorAll('.btn-box-install a')),
      animationTime = 300,
      framesCount = 20;

anchors.forEach(function(item) {
    item.addEventListener('click', function(e) {
        e.preventDefault();
        let coordY = document.querySelector(item.getAttribute('href')).getBoundingClientRect().top + window.pageYOffset -100;
    
        let scroller = setInterval(function() {
            let scrollBy = coordY / framesCount;
      
      if(scrollBy > window.pageYOffset - coordY && window.innerHeight + window.pageYOffset < document.body.offsetHeight) {
          window.scrollBy(0, scrollBy);
      } else {
                window.scrollTo(0, coordY);
        clearInterval(scroller);
      }
        }, animationTime / framesCount);
  });
}); 


//Pagination active
if(document.querySelector('.pagination_big')) {
  let paginationItems = document.querySelectorAll('.pagination_big li'),
      nextVersionContainer = document.querySelector('#nextver'),
      previosVersionContainer = document.querySelector('#previosver'),
      currentVersionContainer = document.querySelector('#currversion'),
      currentPageTitle = document.querySelector('#section').innerText;

  // Set active page and update version containers
  for (let i = 0; i < paginationItems.length; i++) {
    const item = paginationItems[i];
    const itemTitle = item.firstElementChild.innerHTML;
    if (itemTitle === currentPageTitle) {
      item.classList.add('active');
      currentVersionContainer.textContent = itemTitle;       
      if(item.previousElementSibling) {
        previosVersionContainer.textContent = item.previousElementSibling.innerText; 
        previosVersionContainer.parentElement.href += item.previousElementSibling.innerText.replaceAll('.', '_');
      } else {
        previosVersionContainer.parentElement.parentElement.classList.add('hide');
      }
      if(item.nextElementSibling) {
        nextVersionContainer.textContent = item.nextElementSibling.innerText;
        nextVersionContainer.parentElement.href += item.nextElementSibling.innerText.replaceAll('.', '_');
      } else {
        nextVersionContainer.parentElement.parentElement.classList.add('hide');
      }         
      break;
    }
  }
}
// copy to clipboard
if (document.querySelector('.button-copy-s3')) {
  let btnCopy = document.querySelectorAll('.button-copy-s3');

  btnCopy.forEach((element) => {
    //add span Copied!
    element.insertAdjacentHTML('beforeend', '<span>Copied!</span>');

    element.addEventListener('click', function (e) {
      e.preventDefault();
      element.classList.add('copied');
      setTimeout(function () {
        element.classList.remove('copied');
      }, 3000);
      navigator.clipboard.writeText(element.href);
    });
  });
}


</script></div></div>
    </div></div></div><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $body = $('body'), $window = $(window);
    var $pageRoot = $('.js-page-root'), $pageMain = $('.js-page-main');
    var activeCount = 0;
    function modal(options) {
      var $root = this, visible, onChange, hideWhenWindowScroll = false;
      var scrollTop;
      function setOptions(options) {
        var _options = options || {};
        visible = _options.initialVisible === undefined ? false : show;
        onChange = _options.onChange;
        hideWhenWindowScroll = _options.hideWhenWindowScroll;
      }
      function init() {
        setState(visible);
      }
      function setState(isShow) {
        if (isShow === visible) {
          return;
        }
        visible = isShow;
        if (visible) {
          activeCount++;
          scrollTop = $(window).scrollTop() || $pageMain.scrollTop();
          $root.addClass('modal--show');
          $pageMain.scrollTop(scrollTop);
          activeCount === 1 && ($pageRoot.addClass('show-modal'), $body.addClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.on('scroll', hide);
          $window.on('keyup', handleKeyup);
        } else {
          activeCount > 0 && activeCount--;
          $root.removeClass('modal--show');
          $window.scrollTop(scrollTop);
          activeCount === 0 && ($pageRoot.removeClass('show-modal'), $body.removeClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.off('scroll', hide);
          $window.off('keyup', handleKeyup);
        }
        onChange && onChange(visible);
      }
      function show() {
        setState(true);
      }
      function hide() {
        setState(false);
      }
      function handleKeyup(e) {
        // Char Code: 27  ESC
        if (e.which ===  27) {
          hide();
        }
      }
      setOptions(options);
      init();
      return {
        show: show,
        hide: hide,
        $el: $root
      };
    }
    $.fn.modal = modal;
  });
})();
</script><div class="modal modal--overflow page__search-modal d-print-none js-page-search-modal"></div></div>


<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function scrollToAnchor(anchor, duration, callback) {
      var $root = this;
      $root.animate({ scrollTop: $(anchor).position().top }, duration, function() {
        window.history.replaceState(null, '', window.location.href.split('#')[0] + anchor);
        callback && callback();
      });
    }
    $.fn.scrollToAnchor = scrollToAnchor;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function affix(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroll,
        offsetBottom = 0, scrollTarget = window, scroll = window.document, disabled = false, isOverallScroller = true,
        rootTop, rootLeft, rootHeight, scrollBottom, rootBottomTop,
        hasInit = false, curState;

      function setOptions(options) {
        var _options = options || {};
        _options.offsetBottom && (offsetBottom = _options.offsetBottom);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroll && (scroll = _options.scroll);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $scrollTarget = $(scrollTarget);
        isOverallScroller = window.isOverallScroller($scrollTarget[0]);
        $scroll = $(scroll);
      }
      function preCalc() {
        top();
        rootHeight = $root.outerHeight();
        rootTop = $root.offset().top + (isOverallScroller ? 0 :  $scrollTarget.scrollTop());
        rootLeft = $root.offset().left;
      }
      function calc(needPreCalc) {
        needPreCalc && preCalc();
        scrollBottom = $scroll.outerHeight() - offsetBottom - rootHeight;
        rootBottomTop = scrollBottom - rootTop;
      }
      function top() {
        if (curState !== 'top') {
          $root.removeClass('fixed').css({
            left: 0,
            top: 0
          });
          curState = 'top';
        }
      }
      function fixed() {
        if (curState !== 'fixed') {
          $root.addClass('fixed').css({
            left: rootLeft + 'px',
            top: 0
          });
          curState = 'fixed';
        }
      }
      function bottom() {
        if (curState !== 'bottom') {
          $root.removeClass('fixed').css({
            left: 0,
            top: rootBottomTop + 'px'
          });
          curState = 'bottom';
        }
      }
      function setState() {
        var scrollTop = $scrollTarget.scrollTop();
        if (scrollTop >= rootTop && scrollTop <= scrollBottom) {
          fixed();
        } else if (scrollTop < rootTop) {
          top();
        } else {
          bottom();
        }
      }
      function init() {
        if(!hasInit) {
          var interval, timeout;
          calc(true); setState();
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState();
          });
          $window.on('resize', function() {
            disabled || (calc(true), setState());
          });
          hasInit = true;
        }
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions,
        refresh: function() {
          calc(true, { animation: false }); setState();
        }
      };
    }
    $.fn.affix = affix;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function toc(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroller, $tocUl = $('<ul class="toc toc--ellipsis"></ul>'), $tocLi, $headings, $activeLast, $activeCur,
        selectors = 'h1,h2,h3',  container = 'body', scrollTarget = window, scroller = 'html, body', disabled = false,
        headingsPos, scrolling = false, hasRendered = false, hasInit = false;

        

      function setOptions(options) {
        var _options = options || {};
        _options.selectors && (selectors = _options.selectors);
        _options.container && (container = _options.container);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroller && (scroller = _options.scroller);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $headings = $(container).find(selectors).filter('[id]');
        $scrollTarget = $(scrollTarget);
        $scroller = $(scroller);
      }
      function calc() {
        headingsPos = [];
        $headings.each(function() {
          headingsPos.push(Math.floor($(this).position().top));
        });
      }
      function setState(element, disabled) {
        var scrollTop = $scrollTarget.scrollTop(), i;
        if (disabled || !headingsPos || headingsPos.length < 1) { return; }
        if (element) {
          $activeCur = element;
        } else {
          for (i = 0; i < headingsPos.length; i++) {
            if (scrollTop >= headingsPos[i]) {
              $activeCur = $tocLi.eq(i);
            } else {
              $activeCur || ($activeCur = $tocLi.eq(i));
              break;
            }
          }
        }
        $activeLast && $activeLast.removeClass('active');
        ($activeLast = $activeCur).addClass('active');
      }
      function render() {
        if(!hasRendered) {
          $root.append($tocUl);
          $headings.each(function() {
            var $this = $(this);
            $tocUl.append($('<li></li>').addClass('toc-' + $this.prop('tagName')
              .toLowerCase() + ' ' + $this.prop('className'))
              .append($('<a></a>').text($this.text()).attr('href', '#' + $this.prop('id'))));
          });
          $tocLi = $tocUl.children('li');
          $tocUl.on('click', 'a', function(e) {
            e.preventDefault();
            var $this = $(this);
            scrolling = true;
            setState($this.parent());
            $scroller.scrollToAnchor($this.attr('href'), 400, function() {
              scrolling = false;
            });
          });
        }
        hasRendered = true;
      }
      function init() {
        var interval, timeout;
        if(!hasInit) {
          render(); calc(); setState(null, scrolling);
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState(null, scrolling);
          });
          $window.on('resize', window.throttle(function() {
            if (!disabled) {
              render(); calc(); setState(null, scrolling);
            }
          }, 100));
        }
        hasInit = true;
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions
      };
    }
    $.fn.toc = toc;
  });
})();
/*(function () {

})();*/
</script><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;

  window.Lazyload.js(SOURCES.jquery, function() {
    var $pageMask = $('.js-page-mask');
    var $pageRoot = $('.js-page-root');
    var $sidebarShow = $('.js-sidebar-show');
    var $sidebarHide = $('.js-sidebar-hide');

    function freeze(e) {
      if (e.target === $pageMask[0]) {
        e.preventDefault();
      }
    }
    function stopBodyScrolling(bool) {
      if (bool === true) {
        window.addEventListener('touchmove', freeze, { passive: false });
      } else {
        window.removeEventListener('touchmove', freeze, { passive: false });
      }
    }

    $sidebarShow.on('click', function() {
      stopBodyScrolling(true); $pageRoot.addClass('show-sidebar');
    });
    $sidebarHide.on('click', function() {
      stopBodyScrolling(false); $pageRoot.removeClass('show-sidebar');
    });
  });
})();
</script><script>
  /* toc must before affix, since affix need to konw toc' height. */(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  var TOC_SELECTOR = window.TEXT_VARIABLES.site.toc.selectors;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window);
    var $articleContent = $('.js-article-content');
    var $tocRoot = $('.js-toc-root'), $col2 = $('.js-col-aside');
    var toc;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
    var hasToc = $articleContent.find(TOC_SELECTOR).length > 0;

    function disabled() {
      return $col2.css('display') === 'none' || !hasToc;
    }

    tocDisabled = disabled();

    toc = $tocRoot.toc({
      selectors: TOC_SELECTOR,
      container: $articleContent,
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      tocDisabled = disabled();
      toc && toc.setOptions({
        disabled: tocDisabled
      });
    }, 100));

  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window), $pageFooter = $('.js-page-footer');
    var $pageAside = $('.js-page-aside');
    var affix;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');

    affix = $pageAside.affix({
      offsetBottom: $pageFooter.outerHeight(),
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      scroll: hasSidebar ? $('.js-page-main').children() : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      affix && affix.setOptions({
        disabled: tocDisabled
      });
    }, 100));

    window.pageAsideAffix = affix;
  });
})();
</script>
    </div>
    <script>(function () {
  var $root = document.getElementsByClassName('root')[0];
  if (window.hasEvent('touchstart')) {
    $root.dataset.isTouch = true;
    document.addEventListener('touchstart', function(){}, false);
  }
})();
</script>
  </body>
</html>