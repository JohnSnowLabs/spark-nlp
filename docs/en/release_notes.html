<!DOCTYPE html><html lang="en">
  <head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-59JLR64');</script>
<!-- End Google Tag Manager --><title>Spark NLP</title><meta name="description" content="High Performance NLP with Apache Spark
">
<link rel="canonical" href="/docs/en/release_notes"><link rel="alternate" type="application/rss+xml" title="Spark NLP" href="/feed.xml"><!-- start favicons snippet, use https://realfavicongenerator.net/ -->
<!---->
<!-- <link rel="apple-touch-icon" sizes="180x180" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="32x32" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="16x16" href="/fav.ico"> -->

<!---->
<!-- <link rel="manifest" href="/fav.ico"> --><link rel="mask-icon" href="/fav.ico" color="#fc4d50"><link rel="shortcut icon" href="/fav.ico">

<meta name="msapplication-TileColor" content="#ffc40d"><meta name="msapplication-config" content="/assets/browserconfig.xml">

<meta name="theme-color" content="#ffffff">
<!-- end favicons snippet --><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" >
<link rel="stylesheet" href="/static/models.css" /><!-- start custom head snippets -->
 <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800&display=swap" rel="stylesheet"> 
 <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
<!-- end custom head snippets -->
<script>(function() {
  window.isArray = function(val) {
    return Object.prototype.toString.call(val) === '[object Array]';
  };
  window.isString = function(val) {
    return typeof val === 'string';
  };

  window.decodeUrl = function(str) {
    return str ? decodeURIComponent(str.replace(/\+/g, '%20')) : '';
  };

  window.hasEvent = function(event) {
    return 'on'.concat(event) in window.document;
  };

  window.isOverallScroller = function(node) {
    return node === document.documentElement || node === document.body || node === window;
  };

  window.isFormElement = function(node) {
    var tagName = node.tagName;
    return tagName === 'INPUT' || tagName === 'SELECT' || tagName === 'TEXTAREA';
  };

  window.pageLoad = (function () {
    var loaded = false, cbs = [];
    window.addEventListener('load', function () {
      var i;
      loaded = true;
      if (cbs.length > 0) {
        for (i = 0; i < cbs.length; i++) {
          cbs[i]();
        }
      }
    });
    return {
      then: function(cb) {
        cb && (loaded ? cb() : (cbs.push(cb)));
      }
    };
  })();
})();
(function() {
  window.throttle = function(func, wait) {
    var args, result, thisArg, timeoutId, lastCalled = 0;

    function trailingCall() {
      lastCalled = new Date;
      timeoutId = null;
      result = func.apply(thisArg, args);
    }
    return function() {
      var now = new Date,
        remaining = wait - (now - lastCalled);

      args = arguments;
      thisArg = this;

      if (remaining <= 0) {
        clearTimeout(timeoutId);
        timeoutId = null;
        lastCalled = now;
        result = func.apply(thisArg, args);
      } else if (!timeoutId) {
        timeoutId = setTimeout(trailingCall, remaining);
      }
      return result;
    };
  };
})();
(function() {
  var Set = (function() {
    var add = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (data[i] === item) {
          return;
        }
      }
      this.size ++;
      data.push(item);
      return data;
    };

    var Set = function(data) {
      this.size = 0;
      this._data = [];
      var i;
      if (data.length > 0) {
        for (i = 0; i < data.length; i++) {
          add.call(this, data[i]);
        }
      }
    };
    Set.prototype.add = add;
    Set.prototype.get = function(index) { return this._data[index]; };
    Set.prototype.has = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (this.get(i) === item) {
          return true;
        }
      }
      return false;
    };
    Set.prototype.is = function(map) {
      if (map._data.length !== this._data.length) { return false; }
      var i, j, flag, tData = this._data, mData = map._data;
      for (i = 0; i < tData.length; i++) {
        for (flag = false, j = 0; j < mData.length; j++) {
          if (tData[i] === mData[j]) {
            flag = true;
            break;
          }
        }
        if (!flag) { return false; }
      }
      return true;
    };
    Set.prototype.values = function() {
      return this._data;
    };
    return Set;
  })();

  window.Lazyload = (function(doc) {
    var queue = {js: [], css: []}, sources = {js: {}, css: {}}, context = this;
    var createNode = function(name, attrs) {
      var node = doc.createElement(name), attr;
      for (attr in attrs) {
        if (attrs.hasOwnProperty(attr)) {
          node.setAttribute(attr, attrs[attr]);
        }
      }
      return node;
    };
    var end = function(type, url) {
      var s, q, qi, cbs, i, j, cur, val, flag;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        s[url] = true;
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (cur.urls.has(url)) {
            qi = cur, val = qi.urls.values();
            qi && (cbs = qi.callbacks);
            for (flag = true, j = 0; j < val.length; j++) {
              cur = val[j];
              if (!s[cur]) {
                flag = false;
              }
            }
            if (flag && cbs && cbs.length > 0) {
              for (j = 0; j < cbs.length; j++) {
                cbs[j].call(context);
              }
              qi.load = true;
            }
          }
        }
      }
    };
    var load = function(type, urls, callback) {
      var s, q, qi, node, i, cur,
        _urls = typeof urls === 'string' ? new Set([urls]) : new Set(urls), val, url;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (_urls.is(cur.urls)) {
            qi = cur;
            break;
          }
        }
        val = _urls.values();
        if (qi) {
          callback && (qi.load || qi.callbacks.push(callback));
          callback && (qi.load && callback());
        } else {
          q.push({
            urls: _urls,
            callbacks: callback ? [callback] : [],
            load: false
          });
          for (i = 0; i < val.length; i++) {
            node = null, url = val[i];
            if (s[url] === undefined) {
              (type === 'js' ) && (node = createNode('script', { src: url }));
              (type === 'css') && (node = createNode('link', { rel: 'stylesheet', href: url }));
              if (node) {
                node.onload = (function(type, url) {
                  return function() {
                    end(type, url);
                  };
                })(type, url);
                (doc.head || doc.body).appendChild(node);
                s[url] = false;
              }
            }
          }
        }
      }
    };
    return {
      js: function(url, callback) {
        load('js', url, callback);
      },
      css: function(url, callback) {
        load('css', url, callback);
      }
    };
  })(this.document);
})();
</script><script>
  (function() {
    var TEXT_VARIABLES = {
      version: '2.2.4',
      sources: {
        font_awesome: 'https://use.fontawesome.com/releases/v5.0.13/css/all.css',
        jquery: 'https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js',
        leancloud_js_sdk: '//cdn1.lncld.net/static/js/3.4.1/av-min.js',
        chart: 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js',
        gitalk: {
          js: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.js',
          css: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.css'
        },
        valine: 'https://unpkg.com/valine/dist/Valine.min.js',
        mathjax: 'https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML',
        mermaid: 'https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js'
      },
      site: {
        toc: {
          selectors: 'h1,h2,h3'
        }
      },
      paths: {
        search_js: '/assets/search.js'
      }
    };
    window.TEXT_VARIABLES = TEXT_VARIABLES;
  })();
</script></head>
  <body>
    <div class="root" data-is-touch="false">
      <div class="layout--page layout--page--sidebar clearfix js-page-root&nbsp; layout--page--aside">
  <div class="page__mask d-print-none js-page-mask js-sidebar-hide"></div>
  <div class="page__viewport">
    <div class="page__actions d-print-none">
      <div class="js-sidebar-show">
        <i class="fas fa-bars icon--show"></i>
      </div>
    </div>

    <div class="grid page__grid">

      <div class="page__sidebar d-print-none"><a title="High Performance NLP with Apache Spark
" href="/">
    <!--<svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
-->
</a><div class="sidebar-toc"><ul class="toc toc--navigator"><li class="toc-h1">Spark NLP</li><li class="toc-h2"><a href="/docs/en/quickstart">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/install">Install Spark NLP</a></li><li class="toc-h2"><a href="/docs/en/concepts">General Concepts</a></li><li class="toc-h2"><a href="/docs/en/annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/transformers">Transformers</a></li><li class="toc-h2"><a href="/docs/en/training">Training</a></li><li class="toc-h2"><a href="/docs/en/display">Spark NLP Display</a></li><li class="toc-h2"><a href="/docs/en/mlflow">Experiment Tracking</a></li><li class="toc-h2"><a href="/docs/en/production-readiness">Productionizing Spark NLP</a></li><li class="toc-h2"><a href="/docs/en/CPUvsGPUbenchmark">GPU vs CPU benchmarks</a></li><li class="toc-h2"><a href="/docs/en/auxiliary">Helpers</a></li><li class="toc-h2"><a href="/api/">Scala API (Scaladoc)</a></li><li class="toc-h2"><a href="/api/python/">Python API (Sphinx)</a></li><li class="toc-h2"><a href="/docs/en/developers">Developers</a></li><li class="toc-h2"><a href="/docs/en/third-party-projects">Third Party Projects</a></li><li class="toc-h2 active"><a href="/docs/en/release_notes">Release Notes</a></li></ul></div></div><div class="page__main js-page-main has-aside cell cell--auto">

      <div class="page__main-inner"><div class="page__header d-print-none"><!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-59JLR64"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) --><header class="header"><div class="main">
      <div class="header__title">
        <a class="responsive_btn" href="#" id="responsive_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
        <div class="header__brand">
          <a title="High Performance NLP with Apache Spark
" href="https://www.johnsnowlabs.com" target="_blank"><svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
</a><!---->
            <!-- <a title="High Performance NLP with Apache Spark
" href="/">Spark NLP</a> -->
          <!---->
        </div></div><nav class="navigation top_navigation">
        <ul class="top-menu"><li class="navigation__item "><a href="/">Home</a></li><li class="navigation__item navigation__item--active"><a href="/docs">Docs</a></li><li class="navigation__item "><a href="/learn">Learn</a></li><li class="navigation__item "><a href="/models">Models</a></li><li class="navigation__item "><a href="/demos">Demo</a></li><li class="navigation__item "><a href="https://github.com/JohnSnowLabs/spark-nlp"><span style="color: #FF8A00;"><i class="fab fa-github fa-2x"></i></span></a></li><li class="navigation__item "><a href="https://www.johnsnowlabs.com/slack-redirect/"><span style="color: #FF8A00;"><i class="fab fa-slack-hash fa-2x"></i></span></a></li></ul>
      </nav><a class="responsive_btn" href="#" id="aside_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
    </div>
  </header>
</div><div class="page__content "><div class ="main"><div class="grid grid--reverse">

              <div class="col-aside d-print-none js-col-aside"><aside class="page__aside js-page-aside"><div class="toc-aside js-toc-root"></div></aside></div>

              <div class="col-main cell cell--auto"><!-- start custom main top snippet -->

<!-- end custom main top snippet --><article itemscope itemtype="http://schema.org/Article"><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script><div class="article__header"><div class="header-nav"><div class="main-docs">
  <ul class="breadcrambs">
    <li><a href="/docs">Documentation</a></li>
    <li>Spark NLP release notes</li>
  </ul>
</div></div><header><h1>Spark NLP release notes</h1></header><span class="split-space">&nbsp;</span>
          <a class="edit-on-github"
            title="Edit on Github"
            href="https://github.com/johnsnowlabs/spark-nlp/tree/master/docs/en/release_notes.md">
            <i class="far fa-edit"></i></a></div><meta itemprop="headline" content="Spark NLP release notes"><meta itemprop="author" content=""/><div class="js-article-content"><div class="docs-wrapper">
<div class="layout--article"><!-- start custom article top snippet -->

<!-- end custom article top snippet --><div class="article__content" itemprop="articleBody"><h3 id="340">3.4.0</h3>

<h4 id="john-snow-labs-spark-nlp-340-new-openai-gpt-2-new-albert-xlnet-roberta-xlm-roberta-and-longformer-for-sequence-classification-support-for-spark-32-new-distributed-word2vec-extend-support-to-more-databricks--emr-runtimes-new-state-of-the-art-transformer-models-bug-fixes-and-lots-more">John Snow Labs Spark-NLP 3.4.0: New OpenAI GPT-2, new ALBERT, XLNet, RoBERTa, XLM-RoBERTa, and Longformer for Sequence Classification, support for Spark 3.2, new distributed Word2Vec, extend support to more Databricks &amp; EMR runtimes, new state-of-the-art transformer models, bug fixes, and lots more!</h4>

<p>Overview</p>

<p>We are very excited to release Spark NLP 3.4.0! This has been one of the biggest releases we have ever done and we are so proud to share this with our community at the dawn of 2022! ðŸŽ‰</p>

<p>Spark NLP 3.4.0 extends the support for Apache Spark 3.2.x major releases on Scala 2.12. We now support all 5 major Apache Spark and PySpark releases of 2.3.x, 2.4.x, 3.0.x, 3.1.x, and 3.2.x at once helping our community to migrate from earlier Apache Spark versions to newer releases without being worried about Spark NLP end of life support. We also extend support for new Databricks and EMR instances on Spark 3.2.x clusters.</p>

<p>This release also comes with a brand new GPT2Transformer using OpenAI GPT-2 models for prediction at scale,  new ALBERT, XLNet, RoBERTa, XLM-RoBERTa, and Longformer annotators to use existing or fine-tuned models for Sequence Classification, new distributed and trainable Word2Vec annotators, new state-of-the-art transformer models in many languages, a new param to useBestModel in NerDL during training, bug fixes, and lots more!</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>Major features and improvements</p>

<ul>
  <li><strong>NEW:</strong> Introducing <strong>GPT2Transformer</strong> annotator in Spark NLP ðŸš€  for Text Generation purposes. <code class="language-plaintext highlighter-rouge">GPT2Transformer</code> uses OpenAI GPT-2 models from HuggingFace ðŸ¤—  for prediction at scale in Spark NLP ðŸš€ . <code class="language-plaintext highlighter-rouge">GPT-2</code> is a transformer model trained on a very large corpus of English data in a self-supervised fashion. This means it was trained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences</li>
  <li><strong>NEW:</strong> Introducing <strong>RoBertaForSequenceClassification</strong> annotator in Spark NLP ðŸš€. <code class="language-plaintext highlighter-rouge">RoBertaForSequenceClassification</code> can load RoBERTa Models with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">RobertaForSequenceClassification</code> for <strong>PyTorch</strong> or <code class="language-plaintext highlighter-rouge">TFRobertaForSequenceClassification</code> for <strong>TensorFlow</strong> models in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing <strong>XlmRoBertaForSequenceClassification</strong> annotator in Spark NLP ðŸš€. <code class="language-plaintext highlighter-rouge">XlmRoBertaForSequenceClassification</code> can load XLM-RoBERTa Models with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">XLMRobertaForSequenceClassification</code> for <strong>PyTorch</strong> or <code class="language-plaintext highlighter-rouge">TFXLMRobertaForSequenceClassification</code> for <strong>TensorFlow</strong> models in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing <strong>LongformerForSequenceClassification</strong> annotator in Spark NLP ðŸš€. <code class="language-plaintext highlighter-rouge">LongformerForSequenceClassification</code> can load ALBERT Models with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">LongformerForSequenceClassification</code> for <strong>PyTorch</strong> or <code class="language-plaintext highlighter-rouge">TFLongformerForSequenceClassification</code> for <strong>TensorFlow</strong> models in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing <strong>AlbertForSequenceClassification</strong> annotator in Spark NLP ðŸš€. <code class="language-plaintext highlighter-rouge">AlbertForSequenceClassification</code> can load ALBERT Models with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">AlbertForSequenceClassification</code> for <strong>PyTorch</strong> or <code class="language-plaintext highlighter-rouge">TFAlbertForSequenceClassification</code> for <strong>TensorFlow</strong> models in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing <strong>XlnetForSequenceClassification</strong> annotator in Spark NLP ðŸš€. <code class="language-plaintext highlighter-rouge">XlnetForSequenceClassification</code> can load XLNet Models with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">XLNetForSequenceClassification</code> for <strong>PyTorch</strong> or <code class="language-plaintext highlighter-rouge">TFXLNetForSequenceClassification</code> for <strong>TensorFlow</strong> models in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing trainable and distributed Word2Vec annotators based on Word2Vec in Spark ML. You can train Word2Vec in a cluster on multiple machines to handle large-scale datasets and use the trained model for token-level classifications such as NerDL</li>
  <li>Introducing <code class="language-plaintext highlighter-rouge">useBestModel</code> param in NerDLApproach annotator. This param in the NerDLApproach preserves and restores the model that has achieved the best performance at the end of the training. The priority is metrics from testDataset (micro F1), metrics from validationSplit (micro F1), and if none is set it will keep track of loss during the training</li>
  <li>Support Apache Spark and PySpark 3.2.x on Scala 2.12. Spark NLP by default is shipped for Spark 3.0.x/3.1.x, but now you have <code class="language-plaintext highlighter-rouge">spark-nlp-spark32</code> and <code class="language-plaintext highlighter-rouge">spark-nlp-gpu-spark32</code> packages</li>
  <li>Adding a new param to sparknlp.start() function in Python for Apache Spark 3.2.x (<code class="language-plaintext highlighter-rouge">spark32=True</code>)</li>
  <li>Update Colab and Kaggle scripts for faster setup. We no longer need to remove Java 11 in order to install Java 8 since Spark NLP works on Java 11. This makes the installation of Spark NLP on Colab and Kaggle as fast as <code class="language-plaintext highlighter-rouge">pip install spark-nlp pyspark==3.1.2</code></li>
  <li>Add new scripts/notebook to generate custom TensroFlow graphs for <code class="language-plaintext highlighter-rouge">ContextSpellCheckerApproach</code> annotator</li>
  <li>Add a new <code class="language-plaintext highlighter-rouge">graphFolder</code> param to <code class="language-plaintext highlighter-rouge">ContextSpellCheckerApproach</code> annotator. This param allows to train ContextSpellChecker from a custom made TensorFlow graph</li>
  <li>Support DBFS file system in <code class="language-plaintext highlighter-rouge">graphFolder</code> param. Starting Spark NLP 3.4.0 you can point NerDLApproach or ContextSpellCheckerApproach to a TF graph hosted on Databricks</li>
  <li>Add a new feature to all classifiers (<code class="language-plaintext highlighter-rouge">ForTokenClassification</code> and <code class="language-plaintext highlighter-rouge">ForSequenceClassification</code>) to retrieve classes from the pretrained models
```python
sequenceClassifier = XlmRoBertaForSequenceClassification <br />
    .pretrained(â€˜xlm_roberta_base_sequence_classifier_ag_newsâ€™, â€˜enâ€™) <br />
    .setInputCols([â€˜tokenâ€™, â€˜documentâ€™]) <br />
    .setOutputCol(â€˜classâ€™)</li>
</ul>

<p>print(sequenceClassifier.getClasses())</p>

<p>#Sports, Business, World, Sci/Tech</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
* Add `inputFormats` param to DateMatcher and MultiDateMatcher annotators. DateMatcher and MultiDateMatcher can now define a list of acceptable input formats via date patterns to search in the text. Consequently, the output format will be defining the output pattern for the unique output format.

```python
date_matcher = DateMatcher() \
    .setInputCols(['document']) \
    .setOutputCol("date") \
    .setInputFormats(["yyyy", "yyyy/dd/MM", "MM/yyyy"]) \
    .setOutputFormat("yyyyMM") \ #previously called `.setDateFormat`
    .setSourceLanguage("en")

</code></pre></div></div>
<ul>
  <li>Enable batch processing in T5Transformer and MarianTransformer annotators</li>
  <li>Add Schema to <code class="language-plaintext highlighter-rouge">readDataset</code> in CoNLL() class</li>
  <li>Welcoming 6x new Databricks runtimes to our Spark NLP family:
    <ul>
      <li>Databricks 10.0</li>
      <li>Databricks 10.0 ML GPU</li>
      <li>Databricks 10.1</li>
      <li>Databricks 10.1 ML GPU</li>
      <li>Databricks 10.2</li>
      <li>Databricks 10.2 ML GPU</li>
    </ul>
  </li>
  <li>Welcoming 3x new EMR 6.x series to our Spark NLP family:
    <ul>
      <li>EMR 5.33.1 (Apache Spark 2.4.7 / Hadoop 2.10.1)</li>
      <li>EMR 6.3.1 (Apache Spark 3.1.1 / Hadoop 3.2.1)</li>
      <li>EMR 6.4.0 (Apache Spark 3.1.2 / Hadoop 3.2.1)</li>
    </ul>
  </li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.4.0">release notes</a></strong></p>

<h3 id="334">3.3.4</h3>

<h4 id="john-snow-labs-spark-nlp-334-patch-release">John Snow Labs Spark-NLP 3.3.4: Patch release</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.3.4">release notes</a></strong></p>

<h3 id="333">3.3.3</h3>

<h4 id="john-snow-labs-spark-nlp-333-new-distilbert-for-sequence-classification-new-trainable-and-distributed-doc2vec-bert-improvements-on-gpu-new-state-of-the-art-distilbert-models-for-topic-and-sentiment-detection-enhancements-and-bug-fixes">John Snow Labs Spark-NLP 3.3.3: New DistilBERT for Sequence Classification, new trainable and distributed Doc2Vec, BERT improvements on GPU, new state-of-the-art DistilBERT models for topic and sentiment detection, enhancements, and bug fixes!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.3.3">release notes</a></strong></p>

<h3 id="332">3.3.2</h3>

<h4 id="john-snow-labs-spark-nlp-332-new-bert-for-sequence-classification-cometml-logging-integration-new-state-of-the-art-bert-topic-and-sentiment-detection-models-and-bug-fixes">John Snow Labs Spark-NLP 3.3.2: New BERT for Sequence Classification, Comet.ml logging integration, new state-of-the-art BERT topic and sentiment detection models, and bug fixes!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.3.2">release notes</a></strong></p>

<h3 id="331">3.3.1</h3>

<h4 id="john-snow-labs-spark-nlp-331-new-entityruler-annotator-better-integration-with-tokenclassification-annotators-new-state-of-the-art-xlm-roberta-models-in-african-languages-and-bug-fixes">John Snow Labs Spark-NLP 3.3.1: New EntityRuler annotator, better integration with TokenClassification annotators, new state-of-the-art XLM-RoBERTa models in African Languages, and bug fixes!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.3.1">release notes</a></strong></p>

<h3 id="330">3.3.0</h3>

<h4 id="john-snow-labs-spark-nlp-330-new-albert-xlnet-roberta-xlm-roberta-and-longformer-for-token-classification-50x-times-faster-to-save-models-new-ways-to-discover-pretrained-models-and-pipelines-new-state-of-the-art-models-and-lots-more">John Snow Labs Spark-NLP 3.3.0: New ALBERT, XLNet, RoBERTa, XLM-RoBERTa, and Longformer for Token Classification, 50x times faster to save models, new ways to discover pretrained models and pipelines, new state-of-the-art models, and lots more!</h4>

<p>Overview</p>

<p>We are very excited to release Spark NLP ðŸš€ 3.3.0! This release comes with new ALBERT, XLNet, RoBERTa, XLM-RoBERTa, and Longformer existing or fine-tuned models for Token Classification on HuggingFace ðŸ¤— , up to 50x times faster saving Spark NLP models &amp; pipelines, no more 2G limitation for the size of imported TensorFlow models, lots of new functions to filter and display pretrained models &amp; pipelines inside Spark NLP, bug fixes, and more!</p>

<p>We are proud to say Spark NLP 3.3.0 is still compatible across all major releases of Apache Spark used locally, by all Cloud providers such as EMR, and all managed services such as Databricks. The major releases of Apache Spark include Apache Spark 3.0.x/3.1.x (<code class="language-plaintext highlighter-rouge">spark-nlp</code>), Apache Spark 2.4.x (<code class="language-plaintext highlighter-rouge">spark-nlp-spark24</code>), and Apache Spark 2.3.x (<code class="language-plaintext highlighter-rouge">spark-nlp-spark23</code>).</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>Major features and improvements</p>

<ul>
  <li><strong>NEW:</strong> Starting Spark NLP 3.3.0 release there will be <code class="language-plaintext highlighter-rouge">no limitation of size</code> when you import TensorFlow models! You can now import TF Hub &amp; HuggingFace models larger than 2 Gigabytes of size.</li>
  <li><strong>NEW:</strong> Up to <strong>50x faster</strong> saving Spark NLP models and pipelines!  We have improved the way we package TensorFlow SavedModel while saving Spark NLP models &amp; pipelines. For instance, it used to take up to 10 minutes to save the <code class="language-plaintext highlighter-rouge">xlm_roberta_base</code> model before Spark NLP 3.3.0, and now it only takes up to 15 seconds!</li>
  <li><strong>NEW:</strong> Introducing <strong>AlbertForTokenClassification</strong> annotator in Spark NLP ðŸš€. <code class="language-plaintext highlighter-rouge">AlbertForTokenClassification</code> can load ALBERT Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">AlbertForTokenClassification</code> or <code class="language-plaintext highlighter-rouge">TFAlbertForTokenClassification</code> in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing <strong>XlnetForTokenClassification</strong> annotator in Spark NLP ðŸš€. <code class="language-plaintext highlighter-rouge">XlnetForTokenClassification</code> can load XLNet Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">XLNetForTokenClassificationet</code> or <code class="language-plaintext highlighter-rouge">TFXLNetForTokenClassificationet</code> in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing <strong>RoBertaForTokenClassification</strong> annotator in Spark NLP ðŸš€. <code class="language-plaintext highlighter-rouge">RoBertaForTokenClassification</code> can load RoBERTa Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">RobertaForTokenClassification</code> or <code class="language-plaintext highlighter-rouge">TFRobertaForTokenClassification</code> in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing <strong>XlmRoBertaForTokenClassification</strong> annotator in Spark NLP ðŸš€. <code class="language-plaintext highlighter-rouge">XlmRoBertaForTokenClassification</code> can load XLM-RoBERTa Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">XLMRobertaForTokenClassification</code> or <code class="language-plaintext highlighter-rouge">TFXLMRobertaForTokenClassification</code> in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing <strong>LongformerForTokenClassification</strong> annotator in Spark NLP ðŸš€. <code class="language-plaintext highlighter-rouge">LongformerForTokenClassification</code> can load Longformer Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">LongformerForTokenClassification</code> or <code class="language-plaintext highlighter-rouge">TFLongformerForTokenClassification</code> in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing new ResourceDownloader functions to easily look for pretrained models &amp; pipelines inside Spark NLP (Python and Scala). You can filter models or pipelines via <code class="language-plaintext highlighter-rouge">language</code>, <code class="language-plaintext highlighter-rouge">version</code>, or the name of the <code class="language-plaintext highlighter-rouge">annotator</code></li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.3.0">release notes</a></strong></p>

<h3 id="323">3.2.3</h3>

<h4 id="john-snow-labs-spark-nlp-323-new-transformers-and-training-documentation-improved-graphextraction-new-japanese-models-new-multilingual-transformer-models-enhancements-and-bug-fixes">John Snow Labs Spark-NLP 3.2.3: New Transformers and Training documentation, Improved GraphExtraction, new Japanese models, new multilingual Transformer models, enhancements, and bug fixes</h4>

<p>Overview</p>

<p>We are pleased to release Spark NLP ðŸš€ 3.2.3! This release comes with new and completed documentation for all Transformers and Trainable annotators in Spark NLP, new Japanese NER and Embeddings models, new multilingual Transformer models, code enhancements, and bug fixes.</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>New Features</p>

<ul>
  <li>Add delimiter feature to CoNLL() class to support other delimiters in CoNLL files https://github.com/JohnSnowLabs/spark-nlp/pull/5934</li>
  <li>Add support for IOB in addition to IOB2 format in GraphExtraction annotator https://github.com/JohnSnowLabs/spark-nlp/pull/6101</li>
  <li>Change YakeModel output type from KEYWORD to CHUNK to have more available features after the YakeModel annotator such as Chunk2Doc or ChunkEmbeddings https://github.com/JohnSnowLabs/spark-nlp/pull/6065</li>
  <li>Welcoming <a href="https://docs.databricks.com/release-notes/runtime/9.0.html">Databricks Runtime 9.0</a>, 9.0 ML, and 9.0 ML with GPU</li>
  <li>A new and completed <a href="https://nlp.johnsnowlabs.com/docs/en/transformers">Transformer page</a>
    <ul>
      <li>description</li>
      <li>default modelâ€™s name</li>
      <li>link to Models Hub</li>
      <li>link to notebook on Spark NLP Workshop</li>
      <li>link to Python APIs</li>
      <li>link to Scala APIs</li>
      <li>link to source code and unit test</li>
      <li>Examples in Python and Scala for
        <ul>
          <li>Prediction</li>
          <li>Training</li>
          <li>Raw Embeddings</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>A new and completed <a href="https://nlp.johnsnowlabs.com/docs/en/training">Training page</a>
    <ul>
      <li>Training Datasets</li>
      <li>Text Processing</li>
      <li>Spell Checkers</li>
      <li>Token Classification</li>
      <li>Text Classification</li>
      <li>External Trainable Models</li>
    </ul>
  </li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.2.3">release notes</a></strong></p>

<h3 id="322">3.2.2</h3>

<h4 id="john-snow-labs-spark-nlp-322-models-hub-for-the-community-by-the-community-new-roberta-and-xlm-roberta-sentence-embeddings-40-new-models-in-20-languages-bug-fixes-and-more">John Snow Labs Spark-NLP 3.2.2: Models Hub for the community by the community, new RoBERTa and XLM-RoBERTa Sentence Embeddings, 40 new models in 20 languages, bug fixes, and more!</h4>

<p>Overview</p>

<p>We are pleased to release Spark NLP ðŸš€ 3.2.2! This release comes with accessible Models Hub to our community to host their models and pipelines for free, new RoBERTa and XLM-RoBERTa Sentence Embeddings, over 40 new models and pipelines in 20+ languages, bug fixes, and more</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>New Features</p>

<ul>
  <li>A new RoBertaSentenceEmbeddings annotator for sentence embeddings used in SentimentDL, ClassifierDL, and MultiClassifierDL annotators</li>
  <li>A new XlmRoBertaSentenceEmbeddings annotator for sentence embeddings used in SentimentDL, ClassifierDL, and MultiClassifierDL annotators</li>
  <li>Add support for AWS MFA via Spark NLP configuration</li>
  <li>Add new AWS configs to Spark NLP configuration when using a private S3 bucket to store logs for training models or access TF graphs needed in NerDLApproach
    <ul>
      <li>spark.jsl.settings.aws.credentials.access_key_id</li>
      <li>spark.jsl.settings.aws.credentials.secret_access_key</li>
      <li>spark.jsl.settings.aws.credentials.session_token</li>
      <li>spark.jsl.settings.aws.s3_bucket</li>
      <li>spark.jsl.settings.aws.region</li>
    </ul>
  </li>
</ul>

<p>Models Hub for the community, by the community</p>

<p>Serve Your Spark NLP Models for Free! You can host and share your Spark NLP models &amp; pipelines publicly with everyone to reuse them with one line of code!</p>

<p>We are opening Models Hub to everyone to upload their models and pipelines, showcase their work, and share them with others.</p>

<p>Please visit the following page for more information: <a href="https://modelshub.johnsnowlabs.com/">https://modelshub.johnsnowlabs.com/</a></p>

<p><img src="https://user-images.githubusercontent.com/5762953/131699383-96fe7637-3a1b-460e-bf4a-43b44c815951.png" alt="image" /></p>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.2.2">release notes</a></strong></p>
<h3 id="321">3.2.1</h3>

<h4 id="john-snow-labs-spark-nlp-321-patch-release">John Snow Labs Spark-NLP 3.2.1: Patch release</h4>

<p>Patch release</p>

<ul>
  <li>Fix <code class="language-plaintext highlighter-rouge">unsupported model</code> error in pretrained function for <strong>LongformerEmbeddings</strong>, <strong>BertForTokenClassification</strong>, and <strong>DistilBertForTokenClassification</strong> https://github.com/JohnSnowLabs/spark-nlp/issues/5947</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.2.3">release notes</a></strong></p>
<h3 id="320">3.2.0</h3>

<h4 id="john-snow-labs-spark-nlp-320-new-longformer-embeddings-bert-and-distilbert-for-token-classification-graphexctraction-spark-nlp-configurations-new-state-of-the-art-multilingual-ner-models-and-lots-more">John Snow Labs Spark-NLP 3.2.0: New Longformer embeddings, BERT and DistilBERT for Token Classification, GraphExctraction, Spark NLP Configurations, new state-of-the-art multilingual NER models, and lots more!</h4>

<p>Overview</p>

<p>We are very excited to release Spark NLP ðŸš€ 3.2.0! This is a big release with new Longformer models for long documents, BertForTokenClassification &amp; DistilBertForTokenClassification for existing or fine-tuned models on HuggingFace, GraphExctraction &amp; GraphFinisher to find relevant relationships between words, support for multilingual Date Matching, new Pydoc for Python APIs, and so many more!</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>Major features and improvements</p>

<ul>
  <li><strong>NEW:</strong> Introducing <strong>LongformerEmbeddings</strong> annotator. <code class="language-plaintext highlighter-rouge">Longformer</code> is a transformer model for long documents. Longformer is a BERT-like model started from the RoBERTa checkpoint and pretrained for MLM on long documents. It supports sequences of length up to 4,096.</li>
</ul>

<p>We have trained two NER models based on Longformer Base and Large embeddings:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Model</th>
      <th style="text-align: left">Accuracy</th>
      <th style="text-align: left">F1 Test</th>
      <th style="text-align: left">F1 Dev</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">ner_conll_longformer_base_4096</td>
      <td style="text-align: left">94.75%</td>
      <td style="text-align: left">90.09</td>
      <td style="text-align: left">94.22</td>
    </tr>
    <tr>
      <td style="text-align: left">ner_conll_longformer_large_4096</td>
      <td style="text-align: left">95.79%</td>
      <td style="text-align: left">91.25</td>
      <td style="text-align: left">94.82</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><strong>NEW:</strong> Introducing <strong>BertForTokenClassification</strong> annotator. <code class="language-plaintext highlighter-rouge">BertForTokenClassification</code> can load BERT Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">BertForTokenClassification</code> or <code class="language-plaintext highlighter-rouge">TFBertForTokenClassification</code> in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing <strong>DistilBertForTokenClassification</strong> annotator. <code class="language-plaintext highlighter-rouge">DistilBertForTokenClassification</code> can load BERT Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. This annotator is compatible with all the models trained/fine-tuned by using <code class="language-plaintext highlighter-rouge">DistilBertForTokenClassification</code> or <code class="language-plaintext highlighter-rouge">TFDistilBertForTokenClassification</code> in HuggingFace ðŸ¤—</li>
  <li><strong>NEW:</strong> Introducing <strong>GraphExctraction</strong> and <strong>GraphFinisher</strong> annotators to extract a dependency graph between entities. The <strong>GraphExtraction</strong> class takes e.g. extracted entities from a <code class="language-plaintext highlighter-rouge">NerDLModel</code> and creates a dependency tree that describes how the entities relate to each other. For that, a triple store format is used. Nodes represent the entities and the edges represent the relations between those entities. The graph can then be used to find relevant relationships between words</li>
  <li><strong>NEW:</strong> Introducing support for multilingual <strong>DateMatcher</strong> and <strong>MultiDateMatcher</strong> annotators. These two annotators will support <strong>English</strong>, <strong>French</strong>, <strong>Italian</strong>, <strong>Spanish</strong>, <strong>German</strong>, and <strong>Portuguese</strong> languages</li>
  <li><strong>NEW:</strong> Introducing new <strong>Python APIs</strong> and fully documented <strong>Pydoc</strong></li>
  <li><strong>NEW:</strong> Introducing new <strong>Spark NLP configurations</strong> via spark.conf() by deprecating <code class="language-plaintext highlighter-rouge">application.conf</code> usage. You can easily change Spark NLP configurations in SparkSession. For more examples please visti <a href="https://github.com/JohnSnowLabs/spark-nlp#spark-nlp-configuration">Spark NLP Configuration</a></li>
  <li>Add support for Amazon S3 to <code class="language-plaintext highlighter-rouge">log_folder</code> Spark NLP config and <code class="language-plaintext highlighter-rouge">outputLogsPath</code> param in <code class="language-plaintext highlighter-rouge">NerDLApproach</code>, <code class="language-plaintext highlighter-rouge">ClassifierDlApproach</code>, <code class="language-plaintext highlighter-rouge">MultiClassifierDlApproach</code>, and <code class="language-plaintext highlighter-rouge">SentimentDlApproach</code> annotators</li>
  <li>Added examples to all Spark NLP Scaladoc</li>
  <li>Added examples to all Spark NLP Pydoc</li>
  <li>Welcoming new Databricks runtimes to our Spark NLP family:
    <ul>
      <li>Databricks 8.4 ML &amp; GPU</li>
    </ul>
  </li>
  <li>Fix printing a wrong version return in sparknlp.version()</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.2.0">release notes</a></strong></p>
<h3 id="313">3.1.3</h3>

<h4 id="john-snow-labs-spark-nlp-313-tf-hub-support-new-multilingual-ner-models-for-40-languages-state-of-the-art-multilingual-sentence-embeddings-for-100-languages-and-bug-fixes">John Snow Labs Spark-NLP 3.1.3: TF Hub support, new multilingual NER models for 40 languages, state-of-the-art multilingual sentence embeddings for 100+ languages, and bug fixes!</h4>

<p>Overview</p>

<p>We are pleased to release Spark NLP ðŸš€  3.1.3! In this release, we bring notebooks to easily import models for BERT and ALBERT models from TF Hub into Spark NLP, new multilingual NER models for 40 languages with a fine-tuned XLM-RoBERTa model, and new state-of-the-art document/sentence embeddings models for English and 100+ languages!</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>New Features</p>

<ul>
  <li>Support BERT models from TF Hub to Spark NLP</li>
  <li>Support BERT for sentence embeddings from TF Hub to Spark NLP</li>
  <li>Support ALBERT models from TF Hub to Spark NLP</li>
  <li>Welcoming new Databricks 8.4 / 8.4 ML/GPU runtimes to Spark NLP platforms</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.1.3">release notes</a></strong></p>
<h3 id="312">3.1.2</h3>

<h4 id="john-snow-labs-spark-nlp-312-new-and-improved-xlnet-with-support-for-external-transformers-better-documentation-bug-fixes-and-other-improvements">John Snow Labs Spark-NLP 3.1.2: New and improved XLNet with support for external Transformers, better documentation, bug fixes, and other improvements!</h4>

<p>Overview</p>

<p>We are pleased to release Spark NLP ðŸš€  3.1.2! We have a new and much-improved XLNet annotator with support for HuggingFace ðŸ¤—  models in Spark NLP. We managed to make XlnetEmbeddings almost 5x times faster on GPU compare to prior releases!</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>New Features</p>

<ul>
  <li>Migrate XlnetEmbeddings to TensorFlow v2. This allows the importing of HuggingFace XLNet models to Spark NLP</li>
  <li>Migrate XlnetEmbeddings to BatchAnnotate to allow better performance on accelerated hardware such as GPU</li>
  <li>Dynamically extract special tokens from SentencePiece model in XlmRoBertaEmbeddings</li>
  <li>Add setIncludeAllConfidenceScores param in NerDLModel to merge confidence scores per label to only predicted label</li>
  <li>Fully updated <a href="https://nlp.johnsnowlabs.com/docs/en/annotators">Annotators page</a> with full examples in Python and Scala</li>
  <li>Fully update <a href="https://nlp.johnsnowlabs.com/docs/en/transformers">Transformers page</a> for all the transformers in Spark NLP</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.1.3">release notes</a></strong></p>
<h3 id="311">3.1.1</h3>

<h4 id="john-snow-labs-spark-nlp-311-new-and-improved-albert-with-support-for-external-transformers-real-time-metrics-in-python-notebooks-bug-fixes-and-many-more-improvements">John Snow Labs Spark-NLP 3.1.1: New and improved ALBERT with support for external Transformers, real-time metrics in Python notebooks, bug fixes, and many more improvements!</h4>

<p>Overview</p>

<p>We are pleased to release Spark NLP ðŸš€  3.1.1! We have a new and much-improved ALBERT annotator with support for HuggingFace ðŸ¤—  models in Spark NLP. We managed to make AlbertEmbeddings almost 7x times faster on GPU compare to prior releases!</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>New Features</p>

<ul>
  <li>Migrate AlbertEmbeddings to TensorFlow v2. This allows the importing of HuggingFace ALBERT models to Spark NLP</li>
  <li>Migrate AlbertEmbeddings to BatchAnnotate to allow better performance on accelerated hardware such as GPU</li>
  <li>Enable stdout/stderr in real-time for child processes via <code class="language-plaintext highlighter-rouge">sparknlp.start()</code>. Thanks to PySpark 3.x, this is now possible with <code class="language-plaintext highlighter-rouge">sparknlp.start(real_time_output=True)</code> to have the outputs of Spark NLP (such as metrics during training) right in your Jupyter, Colab, and Kaggle notebooks.</li>
  <li>Complete examples for all annotators in Scaladoc APIs https://github.com/JohnSnowLabs/spark-nlp/pull/5668</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.1.2">release notes</a></strong></p>

<h3 id="310">3.1.0</h3>

<h4 id="john-snow-labs-spark-nlp-310-over-2600-new-models-and-pipelines-in-200-languages-new-distilbert-roberta-and-xlm-roberta-transformers-support-for-external-transformers-and-lots-more">John Snow Labs Spark-NLP 3.1.0: Over 2600+ new models and pipelines in 200+ languages, new DistilBERT, RoBERTa, and XLM-RoBERTa transformers, support for external Transformers, and lots more!</h4>

<p>Overview</p>

<p>We are very excited to release Spark NLP ðŸš€  3.1.0! This is one of our biggest releases with lots of models, pipelines, and groundworks for future features that we are so proud to share it with our community.</p>

<p>Spark NLP 3.1.0 comes with over 2600+ new pretrained models and pipelines in over 200+ languages, new DistilBERT, RoBERTa, and XLM-RoBERTa annotators, support for HuggingFace ðŸ¤— (Autoencoding) models in Spark NLP, and extends support for new Databricks and EMR instances.</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>Major features and improvements</p>

<ul>
  <li><strong>NEW:</strong> Introducing DistiBertEmbeddings annotator. DistilBERT is a small, fast, cheap, and light Transformer model trained by distilling BERT base. It has 40% fewer parameters than <code class="language-plaintext highlighter-rouge">bert-base-uncased</code>, runs 60% faster while preserving over 95% of BERTâ€™s performances</li>
  <li><strong>NEW:</strong> Introducing RoBERTaEmbeddings annotator. RoBERTa (Robustly Optimized BERT-Pretraining Approach) models deliver state-of-the-art performance on NLP/NLU tasks and a sizable performance improvement on the GLUE benchmark. With a score of 88.5, RoBERTa reached the top position on the GLUE leaderboard</li>
  <li><strong>NEW:</strong> Introducing XlmRoBERTaEmbeddings annotator. XLM-RoBERTa (Unsupervised Cross-lingual Representation Learning at Scale) is a large multi-lingual language model, trained on 2.5TB of filtered CommonCrawl data with 100 different languages. It also outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +13.8% average accuracy on XNLI, +12.3% average F1 score on MLQA, and +2.1% average F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 11.8% in XNLI accuracy for Swahili and 9.2% for Urdu over the previous XLM model</li>
  <li><strong>NEW:</strong> Introducing support for HuggingFace exported models in equivalent Spark NLP annotators. Starting this release, you can easily use the <code class="language-plaintext highlighter-rouge">saved_model</code> feature in HuggingFace within a few lines of codes and import any BERT, DistilBERT, RoBERTa, and XLM-RoBERTa models to Spark NLP. We will work on the remaining annotators and extend this support to the rest with each release - For more information please visit <a href="https://github.com/JohnSnowLabs/spark-nlp/discussions/5669">this discussion</a></li>
  <li><strong>NEW:</strong> Migrate MarianTransformer to BatchAnnotate to control the throughput when you are on accelerated hardware such as GPU to fully utilize it</li>
  <li>Upgrade to TensorFlow v2.4.1 with native support for Java to take advantage of many optimizations for CPU/GPU and new features/models introduced in TF v2.x</li>
  <li>Update to CUDA11 and cuDNN 8.0.2 for GPU support</li>
  <li>Implement ModelSignatureManager to automatically detect inputs, outputs, save and restore tensors from SavedModel in TF v2. This allows Spark NLP 3.1.x to extend support for external Encoders such as HuggingFace and TF Hub (coming soon!)</li>
  <li>Implement a new BPE tokenizer for RoBERTa and XLM models. This tokenizer will use the custom tokens from <code class="language-plaintext highlighter-rouge">Tokenizer</code> or <code class="language-plaintext highlighter-rouge">RegexTokenizer</code> and generates token pieces, encodes, and decodes the results</li>
  <li>Welcoming new Databricks runtimes to our Spark NLP family:
    <ul>
      <li>Databricks 8.1 ML &amp; GPU</li>
      <li>Databricks 8.2 ML &amp; GPU</li>
      <li>Databricks 8.3 ML &amp; GPU</li>
    </ul>
  </li>
  <li>Welcoming a new EMR 6.x series to our Spark NLP family:
    <ul>
      <li>EMR 6.3.0 (Apache Spark 3.1.1 / Hadoop 3.2.1)</li>
    </ul>
  </li>
  <li>Added examples to Spark NLP Scaladoc</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.1.0">release notes</a></strong></p>
<h3 id="303">3.0.3</h3>

<h4 id="john-snow-labs-spark-nlp-303-new-t5-features-for-longer-and-more-accurate-text-generation-new-multi-lingual-models--pipelines-bug-fixes-and-other-improvements">John Snow Labs Spark-NLP 3.0.3: New T5 features for longer and more accurate text generation, new multi-lingual models &amp; pipelines, bug fixes, and other improvements!</h4>

<p>Overview</p>

<p>We are glad to release Spark NLP 3.0.3! We have added some new features to our T5 Transformer annotator to help with longer and more accurate text generation, trained some new multi-lingual models and pipelines in <code class="language-plaintext highlighter-rouge">Farsi</code>, <code class="language-plaintext highlighter-rouge">Hebrew</code>, <code class="language-plaintext highlighter-rouge">Korean</code>, and <code class="language-plaintext highlighter-rouge">Turkish</code>, and fixed some bugs in this release.</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>New Features</p>

<ul>
  <li>Add 6 new features to T5Transformer for longer and better text generation
    <ul>
      <li>doSample: Whether or not to use sampling; use greedy decoding otherwise</li>
      <li>temperature: The value used to module the next token probabilities</li>
      <li>topK: The number of highest probability vocabulary tokens to keep for top-k-filtering</li>
      <li>topP: If set to float &lt; 1, only the most probable tokens with probabilities that add up to <code class="language-plaintext highlighter-rouge">top_p</code> or higher are kept for generation</li>
      <li>repetitionPenalty: The parameter for repetition penalty. 1.0 means no penalty. See <a href="https://arxiv.org/abs/1909.05858">CTRL: A Conditional Transformer Language Model for Controllable Generation</a> paper for more details</li>
      <li>noRepeatNgramSize: If set to int &gt; 0, all ngrams of that size can only occur once</li>
    </ul>
  </li>
  <li>Spark NLP 3.0.3 is compatible with the new Databricks 8.2 (ML) runtime</li>
  <li>Spark NLP 3.0.3 is compatible with the new EMR 5.33.0 (with Zeppelin 0.9.0) release</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.3">release notes</a></strong></p>
<h3 id="302">3.0.2</h3>

<h4 id="john-snow-labs-spark-nlp-302-new-multilingual-models-confidence-scores-for-entities-and-all-ner-tags-first-support-for-community-models-bug-fixes-and-other-improvements">John Snow Labs Spark-NLP 3.0.2: New multilingual models, confidence scores for entities and all NER tags, first support for community models, bug fixes, and other improvements!</h4>

<p>Overview</p>

<p>We are glad to release Spark NLP 3.0.2! We have added some new features, improvements, trained some new multi-lingual models, and fixed some bugs in this release.</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>New Features</p>

<ul>
  <li>Experimental support for community models and pipelines (uploaded by users) https://github.com/JohnSnowLabs/spark-nlp/pull/2743</li>
  <li>Provide confidence scores for all available tags in NerDLModel and NerCrfModel https://github.com/JohnSnowLabs/spark-nlp/pull/2760</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># NerDLModel and NerCrfModel before 3.0.2
</span><span class="p">[[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="p">[</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">Japan</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.9998</span><span class="p">],</span> <span class="p">[]]</span>

<span class="c1"># Now in Spark NLP 3.0.2
</span><span class="p">[[</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">LOC</span><span class="p">,</span> <span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">LOC</span> <span class="o">-&gt;</span> <span class="mf">0.9998</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">ORG</span> <span class="o">-&gt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">MISC</span> <span class="o">-&gt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">LOC</span> <span class="o">-&gt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PER</span> <span class="o">-&gt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">MISC</span> <span class="o">-&gt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">ORG</span> <span class="o">-&gt;</span> <span class="mf">1.0E-4</span><span class="p">,</span> <span class="n">word</span> <span class="o">-&gt;</span> <span class="n">Japan</span><span class="p">,</span> <span class="n">O</span> <span class="o">-&gt;</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">PER</span> <span class="o">-&gt;</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[]]</span>
</code></pre></div></div>
<ul>
  <li>Calculate confidence score for entities in NerConverter https://github.com/JohnSnowLabs/spark-nlp/pull/2784
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">41</span><span class="p">,</span> <span class="n">Barack</span> <span class="n">Obama</span><span class="p">,</span> <span class="p">[</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">PERSON</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.94035</span><span class="p">]</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.2">release notes</a></strong></p>

<h3 id="301">3.0.1</h3>

<h4 id="john-snow-labs-spark-nlp-301-new-parameters-in-normalizer-bug-fixes-and-other-improvements">John Snow Labs Spark-NLP 3.0.1: New parameters in Normalizer, bug fixes and other improvements!</h4>

<p>Overview</p>

<p>We are glad to release Spark NLP 3.0.1! We have made some improvements, added 1 line bash script to set up Google Colab and Kaggle kernel for Spark NLP 3.x, and improved our Models Hub filtering to help our community to have easier access to over 1300 pretrained models and pipelines in over 200+ languages.</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>New Features</p>

<ul>
  <li>Add minLength and maxLength parameters to Normalizer annotator https://github.com/JohnSnowLabs/spark-nlp/pull/2614</li>
  <li>1 line to setup <a href="https://github.com/JohnSnowLabs/spark-nlp#google-colab-notebook">Google Colab</a></li>
  <li>1 line to setup <a href="https://github.com/JohnSnowLabs/spark-nlp#kaggle-kernel">Kaggle Kernel</a></li>
</ul>

<p>Enhancements</p>

<ul>
  <li>Adjust shading rule for amazon AWS to support sub-projects from Spark NLP Fat JAR https://github.com/JohnSnowLabs/spark-nlp/pull/2613</li>
  <li>Fix the missing variables in BertSentenceEmbeddings https://github.com/JohnSnowLabs/spark-nlp/pull/2615</li>
  <li>Restrict loading Sentencepiece ops only to supported models https://github.com/JohnSnowLabs/spark-nlp/pull/2623</li>
  <li>improve dependency management and resolvers https://github.com/JohnSnowLabs/spark-nlp/pull/2479</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.1">release notes</a></strong></p>

<h3 id="300">3.0.0</h3>

<h4 id="john-snow-labs-spark-nlp-300-supporting-spark-3x-scala-212-more-databricks-runtimes-more-emr-versions-performance-improvements--lots-more">John Snow Labs Spark-NLP 3.0.0: Supporting Spark 3.x, Scala 2.12, more Databricks runtimes, more EMR versions, performance improvements &amp; lots more</h4>

<p>Overview</p>

<p>We are very excited to release Spark NLP 3.0.0! This has been one of the biggest releases we have ever done and we are so proud to share this with our community.</p>

<p>Spark NLP 3.0.0 extends the support for Apache Spark 3.0.x and 3.1.x major releases on Scala 2.12 with both Hadoop 2.7. and 3.2. We will support all 4 major Apache Spark and PySpark releases of 2.3.x, 2.4.x, 3.0.x, and 3.1.x helping the community to migrate from earlier Apache Spark versions to newer releases without being worried about Spark NLP support.</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>New Features</p>

<ul>
  <li>Support for Apache Spark and PySpark 3.0.x on Scala 2.12</li>
  <li>Support for Apache Spark and PySpark 3.1.x on Scala 2.12</li>
  <li>Migrate to TensorFlow v2.3.1 with native support for Java to take advantage of many optimizations for CPU/GPU and new features/models introduced in TF v2.x</li>
  <li>Welcoming 9x new Databricks runtimes to our Spark NLP family:
    <ul>
      <li>Databricks 7.3</li>
      <li>Databricks 7.3 ML GPU</li>
      <li>Databricks 7.4</li>
      <li>Databricks 7.4 ML GPU</li>
      <li>Databricks 7.5</li>
      <li>Databricks 7.5 ML GPU</li>
      <li>Databricks 7.6</li>
      <li>Databricks 7.6 ML GPU</li>
      <li>Databricks 8.0</li>
      <li>Databricks 8.0 ML (there is no GPU in 8.0)</li>
      <li>Databricks 8.1 Beta</li>
    </ul>
  </li>
  <li>Welcoming 2x new EMR 6.x series to our Spark NLP family:
    <ul>
      <li>EMR 6.1.0 (Apache Spark 3.0.0 / Hadoop 3.2.1)</li>
      <li>EMR 6.2.0 (Apache Spark 3.0.1 / Hadoop 3.2.1)</li>
    </ul>
  </li>
  <li>Starting Spark NLP 3.0.0 the default packages  for CPU and GPU will be based on Apache Spark 3.x and Scala 2.12 (<code class="language-plaintext highlighter-rouge">spark-nlp</code> and <code class="language-plaintext highlighter-rouge">spark-nlp-gpu</code> will be compatible only with Apache Spark 3.x and Scala 2.12)</li>
  <li>Starting Spark NLP 3.0.0 we have two new packages to support Apache Spark 2.4.x and Scala 2.11 (<code class="language-plaintext highlighter-rouge">spark-nlp-spark24</code> and <code class="language-plaintext highlighter-rouge">spark-nlp-gpu-spark24</code>)</li>
  <li>Spark NLP 3.0.0 still is and will be compatible with Apache Spark 2.3.x and Scala 2.11 (<code class="language-plaintext highlighter-rouge">spark-nlp-spark23</code> and <code class="language-plaintext highlighter-rouge">spark-nlp-gpu-spark23</code>)</li>
  <li>Adding a new param to sparknlp.start() function in Python for Apache Spark 2.4.x (<code class="language-plaintext highlighter-rouge">spark24=True</code>)</li>
  <li>Adding a new param to adjust Driver memory in sparknlp.start() function (<code class="language-plaintext highlighter-rouge">memory="16G"</code>)</li>
</ul>

<p>Performance Improvements</p>

<p>Introducing a new batch annotation technique implemented in Spark NLP 3.0.0 for <code class="language-plaintext highlighter-rouge">NerDLModel</code>, <code class="language-plaintext highlighter-rouge">BertEmbeddings</code>, and <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> annotators to radically improve prediction/inferencing performance. From now on the <code class="language-plaintext highlighter-rouge">batchSize</code> for these annotators means the number of rows that can be fed into the models for prediction instead of sentences per row. You can control the throughput when you are on accelerated hardware such as GPU to fully utilize it.</p>

<p><strong>Performance achievements by using Spark NLP 3.0.0 vs. Spark NLP 2.7.x on CPU and GPU:</strong></p>

<p>(Performed on a Databricks cluster)</p>

<table>
  <thead>
    <tr>
      <th>Spark NLP 3.0.0 vs. 2.7.x</th>
      <th>PySpark 3.x on CPU</th>
      <th>PySpark 3.x on GPU</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>BertEmbeddings (bert-base)</td>
      <td>+10%</td>
      <td>+550% (6.6x)</td>
    </tr>
    <tr>
      <td>BertEmbeddings (bert-large)</td>
      <td>+12%.</td>
      <td>+690% (7.9x)</td>
    </tr>
    <tr>
      <td>NerDLModel</td>
      <td>+185%</td>
      <td>+327% (4.2x)</td>
    </tr>
  </tbody>
</table>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.0">release notes</a></strong></p>

<h3 id="275">2.7.5</h3>

<h4 id="john-snow-labs-spark-nlp-275-supporting-more-emr-versions-and-other-improvements">John Snow Labs Spark-NLP 2.7.5: Supporting more EMR versions and other improvements!</h4>

<p>Overview</p>

<p>We are glad to release Spark NLP 2.7.5 release! Starting this release we no longer ship Hadoop AWS and AWS Java SDK dependencies. This change allows users to avoid any conflicts in AWS environments and also results in more EMR 5.x versions support.</p>

<p>As always, we would like to thank our community for their feedback, questions, and feature requests.</p>

<p>New Features</p>

<ul>
  <li>Support more EMR 5.x versions
    <ul>
      <li>emr-5.20.0</li>
      <li>emr-5.21.0</li>
      <li>emr-5.21.1</li>
      <li>emr-5.22.0</li>
      <li>emr-5.23.0</li>
      <li>emr-5.24.0</li>
      <li>emr-5.24.1</li>
      <li>emr-5.25.0</li>
      <li>emr-5.26.0</li>
      <li>emr-5.27.0</li>
      <li>emr-5.28.0</li>
      <li>emr-5.29.0</li>
      <li>emr-5.30.0</li>
      <li>emr-5.30.1</li>
      <li>emr-5.31.0</li>
      <li>emr-5.32.0</li>
    </ul>
  </li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.5">release notes</a></strong></p>

<h3 id="274">2.7.4</h3>

<h4 id="john-snow-labs-spark-nlp-274-new-bengali-ner-and-word-embeddings-models-new-intent-prediction-models-bug-fixes-and-other-improvements">John Snow Labs Spark-NLP 2.7.4: New Bengali NER and Word Embeddings models, new Intent Prediction models, bug fixes, and other improvements!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.4">release notes</a></strong></p>

<h3 id="273">2.7.3</h3>

<h4 id="john-snow-labs-spark-nlp-273-18-new-state-of-the-art-transformer-based-ontonotes-models-and-pipelines-new-support-for-bengali-ner-and-hindi-word-embeddings-and-other-improvements">John Snow Labs Spark-NLP 2.7.3: 18 new state-of-the-art transformer-based OntoNotes models and pipelines, new support for Bengali NER and Hindi Word Embeddings, and other improvements!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.3">release notes</a></strong></p>

<h3 id="272">2.7.2</h3>

<h4 id="john-snow-labs-spark-nlp-272-new-multilingual-models-gpu-support-to-train-a-spell-checker-bug-fixes-and-other-improvements">John Snow Labs Spark-NLP 2.7.2: New multilingual models, GPU support to train a Spell Checker, bug fixes, and other improvements!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.2">release notes</a></strong></p>

<h3 id="271">2.7.1</h3>

<h4 id="john-snow-labs-spark-nlp-271-new-t5-models-new-trec-pipelines-bug-fixes-and-other-improvements">John Snow Labs Spark-NLP 2.7.1: New T5 models, new TREC pipelines, bug fixes, and other improvements!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.1">release notes</a></strong></p>

<h3 id="270">2.7.0</h3>

<h4 id="john-snow-labs-spark-nlp-270-new-t5-and-marianmt-seq2seq-transformers-detect-up-to-375-languages-word-segmentation-over-720-models-and-pipelines-support-for-192-languages-and-many-more">John Snow Labs Spark-NLP 2.7.0: New T5 and MarianMT seq2seq transformers, detect up to 375 languages, word segmentation, over 720+ models and pipelines, support for 192+ languages, and many more!</h4>

<p>Overview</p>

<p>We are very excited to release Spark NLP 2.7.0! This has been one of the biggest releases we have ever done that we are so proud to share it with our community!</p>

<p>In this release, we are bringing support to state-of-the-art Seq2Seq and Text2Text transformers. We have developed annotators for Google T5 (Text-To-Text Transfer Transformer) and MarianMNT for Neural Machine Translation with over 646 pretrained models and pipelines.</p>

<p>This release also comes with a refactored and brand new models for language detection and identification. They are more accurate, faster, and support up to 375 languages.</p>

<p>The 2.7.0 release has over 720+ new pretrained models and pipelines while extending our support of multi-lingual models to 192+ languages such as Chinese, Japanese, Korean, Arabic, Persian, Urdu, and Hebrew.</p>

<p>As always, we would like to thank our community for their feedback and support.</p>

<p>Major features and improvements</p>

<ul>
  <li><strong>NEW:</strong> Introducing MarianTransformer annotator for machine translation based on MarianNMT models. Marian is an efficient, free Neural Machine Translation framework mainly being developed by the Microsoft Translator team (646+ pretrained models &amp; pipelines in 192+ languages)</li>
  <li><strong>NEW:</strong> Introducing T5Transformer annotator for Text-To-Text Transfer Transformer (Google T5) models to achieve state-of-the-art results on multiple NLP tasks such as Translation, Summarization, Question Answering, Sentence Similarity, and so on</li>
  <li><strong>NEW:</strong> Introducing brand new and refactored language detection and identification models. The new LanguageDetectorDL is faster, more accurate, and supports up to 375 languages</li>
  <li><strong>NEW:</strong> Introducing WordSegmenter annotator, a trainable annotator for word segmentation of languages without any rule-based tokenization such as Chinese, Japanese, or Korean</li>
  <li><strong>NEW:</strong> Introducing DocumentNormalizer annotator cleaning content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters</li>
  <li><strong>NEW:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-display">Spark NLP Display</a> for visualization of different types of annotations</li>
  <li>Add support for new multi-lingual models in UniversalSentenceEncoder annotator</li>
  <li>Add support to Lemmatizer to be trained directly from a DataFrame instead of a text file</li>
  <li>Add training helper to transform CoNLL-U into Spark NLP annotator type columns</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.0">release notes</a></strong></p>

<h3 id="265">2.6.5</h3>

<h4 id="john-snow-labs-spark-nlp-265-a-few-bug-fixes-and-other-improvements">John Snow Labs Spark-NLP 2.6.5: A few bug fixes and other improvements!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.5">release notes</a></strong></p>

<h3 id="264">2.6.4</h3>

<h4 id="john-snow-labs-spark-nlp-264-a-few-bug-fixes-and-other-improvements">John Snow Labs Spark-NLP 2.6.4: A few bug fixes and other improvements!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.4">release notes</a></strong></p>

<h3 id="263">2.6.3</h3>

<h4 id="john-snow-labs-spark-nlp-263-new-refactored-nerdl-with-memory-optimization-bug-fixes-and-other-improvements">John Snow Labs Spark-NLP 2.6.3: New refactored NerDL with memory optimization, bug fixes, and other improvements!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.3">release notes</a></strong></p>

<h3 id="262">2.6.2</h3>

<h4 id="john-snow-labs-spark-nlp-262-new-sentencedetectordl-improved-biobert-models-new-models-hub-and-other-improvements">John Snow Labs Spark-NLP 2.6.2: New SentenceDetectorDL, improved BioBERT models, new Models Hub, and other improvements!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.2">release notes</a></strong></p>

<h3 id="261">2.6.1</h3>

<h4 id="john-snow-labs-spark-nlp-261-new-portuguese-bert-models-import-any-bert-models-to-spark-nlp-and-a-bug-fix-for-classifierdl">John Snow Labs Spark-NLP 2.6.1: New Portuguese BERT models, import any BERT models to Spark NLP, and a bug-fix for ClassifierDL</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.1">release notes</a></strong></p>

<h3 id="260">2.6.0</h3>

<h4 id="john-snow-labs-spark-nlp-260-new-multi-label-classifier-bert-sentence-embeddings-unsupervised-keyword-extractions-over-110-pretrained-pipelines-models-transformers-and-more">John Snow Labs Spark-NLP 2.6.0: New multi-label classifier, BERT sentence embeddings, unsupervised keyword extractions, over 110 pretrained pipelines, models, Transformers, and more!</h4>

<p>Overview</p>

<p>We are very excited to finally release Spark NLP 2.6.0! This has been one of the biggest releases we have ever made and we are so proud to share it with our community!</p>

<p>This release comes with a brand new MultiClassifierDL for multi-label text classification, BertSentenceEmbeddings with 42 models, unsupervised keyword extractions annotator, and adding 28 new pretrained Transformers such as Small BERT, CovidBERT, ELECTRA, and the state-of-the-art language-agnostic BERT Sentence Embedding model(LaBSE).</p>

<p>The 2.6.0 release has over 110 new pretrained models, pipelines, and Transformers with extending full support for Danish, Finnish, and Swedish languages.</p>

<p>Major features and improvements</p>

<ul>
  <li><strong>NEW:</strong> A new MultiClassifierDL annotator for multi-label text classification built by using Bidirectional GRU and CNN inside TensorFlow that supports up to 100 classes</li>
  <li><strong>NEW:</strong> A new BertSentenceEmbeddings annotator with 42 available pre-trained models for sentence embeddings used in SentimentDL, ClassifierDL, and MultiClassifierDL annotators</li>
  <li><strong>NEW:</strong> A new YakeModel annotator for an unsupervised, corpus-independent, domain, and language-independent and single-document keyword extraction algorithm</li>
  <li><strong>NEW:</strong> Integrate 24 new Small BERT models where the smallest model is 24x times smaller and 28x times faster compare to BERT base models</li>
  <li><strong>NEW:</strong> Add 3 new ELECTRA small, base, and large models</li>
  <li><strong>NEW:</strong> Add 4 new Finnish BERT models for BertEmbeddings and BertSentenceEmbeddings</li>
  <li>Improve BertEmbeddings memory consumption by 30%</li>
  <li>Improve BertEmbeddings performance by more than 70% with a new built-in dynamic shape inputs</li>
  <li>Remove the poolingLayer parameter in BertEmbeddings in favor of sequence_output that is provided by TF Hub models for new BERT models</li>
  <li>Add validation loss, validation accuracy, validation F1, and validation True Positive Rate during the training in MultiClassifierDL</li>
  <li>Add parameter to enable/disable list detection in SentenceDetector</li>
  <li>Unify the loggings in ClassifierDL and SentimentDL during training</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.6.0">release notes</a></strong></p>

<h3 id="255">2.5.5</h3>

<h4 id="john-snow-labs-spark-nlp-255-28-new-lemma-and-pos-models-in-14-languages-bug-fixes-and-lots-of-new-notebooks">John Snow Labs Spark-NLP 2.5.5: 28 new Lemma and POS models in 14 languages, bug fixes, and lots of new notebooks!</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.5.5">release notes</a></strong></p>

<h3 id="254">2.5.4</h3>

<h4 id="john-snow-labs-spark-nlp-254-supporting-apache-spark-23-43-new-models-and-26-new-languages-new-regextokenizer-lots-of-new-notebooks-and-more">John Snow Labs Spark-NLP 2.5.4: Supporting Apache Spark 2.3, 43 new models and 26 new languages, new RegexTokenizer, lots of new notebooks, and more</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.5.4">release notes</a></strong></p>

<h3 id="253">2.5.3</h3>

<h4 id="john-snow-labs-spark-nlp-253-detect-fake-news-emotions-spams-and-more-classification-models-enhancements-and-bug-fixes">John Snow Labs Spark-NLP 2.5.3: Detect Fake news, emotions, spams, and more classification models, enhancements, and bug fixes</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.5.3">release notes</a></strong></p>

<h3 id="252">2.5.2</h3>

<h4 id="john-snow-labs-spark-nlp-252-new-language-detection-annotator-enhancements-and-bug-fixes">John Snow Labs Spark-NLP 2.5.2: New Language Detection annotator, enhancements, and bug fixes</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.5.2">release notes</a></strong></p>

<h3 id="251">2.5.1</h3>

<h4 id="john-snow-labs-spark-nlp-251-adding-support-for-6-new-biobert-and-clinicalbert-models">John Snow Labs Spark-NLP 2.5.1: Adding support for 6 new BioBERT and ClinicalBERT models</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.5.1">release notes</a></strong></p>

<h3 id="250">2.5.0</h3>

<h4 id="john-snow-labs-spark-nlp-250-albert--xlnet-transformers-state-of-the-art-spell-checker-multi-class-sentiment-detector-80-new-models--pipelines-in-14-new-languages--more">John Snow Labs Spark-NLP 2.5.0: ALBERT &amp; XLNet transformers, state-of-the-art spell checker, multi-class sentiment detector, 80+ new models &amp; pipelines in 14 new languages &amp; more</h4>

<p>Overview</p>

<p>When we started planning for Spark NLP 2.5.0 release a few months ago the world was a different place!</p>

<p>We have been blown away by the use of Natural Language Processing for early outbreak detections, question-answering chatbot services, text analysis of medical records, monitoring efforts to minimize the virus spread, and many more.</p>

<p>In that spirit, we are honored to announce Spark NLP 2.5.0 release! Witnessing the world coming together to fight coronavirus has driven us to deliver perhaps one of the biggest releases we have ever made.</p>

<p>As always, we thank our community for their feedback, bug reports, and contributions that made this release possible.</p>

<p>Major features and improvements</p>

<ul>
  <li><strong>NEW:</strong> A new AlbertEmbeddings annotator with 4 available pre-trained models</li>
  <li><strong>NEW:</strong> A new XlnetEmbeddings annotator with 2 available pre-trained models</li>
  <li><strong>NEW:</strong> A new ContextSpellChecker annotator, the state-of-the-art annotator for spell checking</li>
  <li><strong>NEW:</strong> A new SentimentDL annotator for multi-class sentiment analysis. This annotator comes with 2 available pre-trained models trained on IMDB and Twitter datasets</li>
  <li><strong>NEW:</strong> Support for 14 new languages with 80+ pretrained models and pipelines!</li>
  <li>Add new PubTator reader to convert automatic annotations of the biomedical datasets into DataFrame</li>
  <li>Introducing a new outputLogsPath param for NerDLApproach, ClassifierDLApproach and SentimentDLApproach annotators</li>
  <li>Refactored CoNLLGenerator to actually use NER labels from the DataFrame</li>
  <li>Unified params in NerDLModel in both Scala and Python</li>
  <li>Extend and complete Scaladoc APIs for all the annotators</li>
</ul>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.5.0">release notes</a></strong></p>

<h3 id="245">2.4.5</h3>

<h4 id="john-snow-labs-spark-nlp-245-supporting-more-databricks-runtimes-and-yarn-in-cluster-mode">John Snow Labs Spark-NLP 2.4.5: Supporting more Databricks runtimes and YARN in cluster mode</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.4.5">release notes</a></strong></p>

<h3 id="244">2.4.4</h3>

<h4 id="john-snow-labs-spark-nlp-244-the-very-first-native-multi-class-text-classifier-and-pre-trained-models-and-pipelines-in-russian">John Snow Labs Spark-NLP 2.4.4: The very first native multi-class text classifier and pre-trained models and pipelines in Russian</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.4.4">release notes</a></strong></p>

<h3 id="243">2.4.3</h3>

<h4 id="john-snow-labs-spark-nlp-243-minor-bug-fix-in-python">John Snow Labs Spark-NLP 2.4.3: Minor bug fix in Python</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.4.3">release notes</a></strong></p>

<h3 id="242">2.4.2</h3>

<h4 id="john-snow-labs-spark-nlp-242-minor-bug-fixes-and-improvements">John Snow Labs Spark-NLP 2.4.2: Minor bug fixes and improvements</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.4.2">release notes</a></strong></p>

<h3 id="241">2.4.1</h3>

<h4 id="john-snow-labs-spark-nlp-241-bug-fixes-and-the-very-first-spanish-models--pipelines">John Snow Labs Spark-NLP 2.4.1: Bug fixes and the very first Spanish models &amp; pipelines</h4>

<p><strong>For more details please check the official <a href="https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.4.1">release notes</a></strong></p>

<h3 id="240">2.4.0</h3>

<h4 id="john-snow-labs-spark-nlp-240-new-tensorflow-115-universal-sentence-encoder-elmo-faster-word-embeddings--more">John Snow Labs Spark-NLP 2.4.0: New TensorFlow 1.15, Universal Sentence Encoder, Elmo, faster Word Embeddings &amp; more</h4>

<p>We are very excited to finally release Spark NLP v2.4.0! This has been one of the largest releases we have ever made since the inception of the library! The new release of Spark NLP <code class="language-plaintext highlighter-rouge">2.4.0</code> has been migrated to TensorFlow <code class="language-plaintext highlighter-rouge">1.15.0</code> which takes advantage of the latest deep learning technologies and pre-trained models.</p>

<p>Major features and improvements</p>

<ul>
  <li><strong>NEW:</strong> TensorFlow 1.15.0 now works behind Spark NLP. This brings implicit improvements in performance, accuracy, and functionalities</li>
  <li><strong>NEW:</strong> UniversalSentenceEncoder annotator with 2 pre-trained models from TF Hub</li>
  <li><strong>NEW:</strong> ElmoEmbeddings with a pre-trained model from TF Hub</li>
  <li><strong>NEW:</strong> All our pre-trained models are now cross-platform!</li>
  <li><strong>NEW:</strong> For the first time, all the multi-lingual models and pipelines are available for Windows users (French, German and Italian)</li>
  <li><strong>NEW:</strong> MultiDateMatcher capable of matching more than one date per sentence (Extends DateMatcher algorithm)</li>
  <li><strong>NEW:</strong> BigTextMatcher works best with large amounts of input data</li>
  <li>BertEmbeddings improvements with 5 new models from TF Hub</li>
  <li>RecursivePipelineModel as an enhanced PipelineModel allows Annotators to access previous annotators in the pipeline for more ML strategies</li>
  <li>LazyAnnotators: A new Param in Annotators allows them to stand idle in the Pipeline and do nothing. Can be called by other Annotators in a RecursivePipeline</li>
  <li>RocksDB is now available as a flexible API called <code class="language-plaintext highlighter-rouge">Storage</code>. Allows any annotator to have itâ€™s own distributed local index database</li>
  <li>Now our Tensorflow pre-trained models are cross-platform. Enabling multi-language models and other improvements to Windows users.</li>
  <li>Improved IO performance in general for handling embeddings</li>
  <li>Improved cache cleanup and GC by liberating open files utilized in RocksDB (to be improved further)</li>
  <li>Tokenizer and SentenceDetector Params minLength and MaxLength to filter out annotations outside these bounds</li>
  <li>Tokenizer improvements in splitChars and simplified rules</li>
  <li>DateMatcher improvements</li>
  <li>TextMatcher improvements preload algorithm information within the model for faster prediction</li>
  <li>Annotators the utilize embeddings have now a strict validation to be using exactly the embeddings they were trained with</li>
  <li>Improvements in the API allow Annotators with Storage to save and load their RocksDB database independently and let it be shared across Annotators and let it be shared across Annotators</li>
</ul>
</div><div class="d-print-none"><footer class="article__footer"><span class="footer_date">Last updated
      <time itemprop="dateModified" datetime="2022-01-06T00:00:00+00:00">Jan 06, 2022</time>
    </span><!-- start custom article footer snippet -->

<!-- end custom article footer snippet --></footer>

<script>


jQuery(document).ready(function(){  
    $( ".scala-button" ).click(function() {
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-scala" ).show();
        $(this).closest( ".tabs-box" ).find( ".language-python, .nlu-block" ).hide();
    });

    $( ".python-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-un-active').addClass( "code-selector-active" ); 

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');


        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-python" ).show();
        $(this).closest( ".tabs-box" ).find( ".nlu-block, .language-scala" ).hide();
    });

    $( ".nlu-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets        
        $(this).closest( ".tabs-box" ).find( ".language-python, .language-scala" ).hide();
        $(this).closest( ".tabs-box" ).find( ".nlu-block" ).show();
    });
});

function togglePython1() {

    //set current button to active class and remove unactive class
    $( ".python-button" ).addClass( "code-selector-active" );


    //toggle language snippets
    $( ".tabs-box .language-python" ).show() 
    $( ".tabs-box .nlu-block" ).hide()
    $( ".tabs-box .language-scala" ).hide()
}

function defer(method) { //wait until jquery ready
    if (window.jQuery) {
        method();
    } else {
        setTimeout(function() { defer(method) }, 15);
    }
}

defer(function () { // load inital language
    togglePython1()
});




</script>


<style>
  /* Remove Scrollbar from Code Segments */
.article__content .highlighter-rouge > .highlight > pre > code, .article__content figure.highlight > pre > code  {
    overflow: auto;
}



button.code-selector-active {
 background-color: white;
 color: #08c;
 font-weight: bold;
 border-width: 1px;
 padding-left: 12px;
 padding-right: 12px;
 width: 90px;
 padding-top: 6px;
 margin-right: 2px;

 border-bottom: none;

 position: relative;
 z-index: 2;
}

button.code-selector-un-active {
    background-color: white;
    padding-left: 12px;
    padding-right: 12px;
    width: 90px;
    margin-right: 2px;
    padding-top: 8px;
    position: relative;
    border-bottom: none;

   }

hr.code-selector-underlie {
    border-top: 1px solid;
    background-color: black;
    width: fill;
    height: 1px;
    margin-top: -3px;
    position: relative;

}

</style><div class="article__section-navigator clearfix"><div class="previous nav_link"><span>PREVIOUS</span><a href="/docs/en/third-party-projects">Third Party Projects</a></div></div></div>

</div>
</div>

<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    $(function() {
      var $this ,$scroll;
      var $articleContent = $('.js-article-content');
      var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
      var scroll = hasSidebar ? '.js-page-main' : 'html, body';
      $scroll = $(scroll);

      $articleContent.find('.highlight').each(function() {
        $this = $(this);
        $this.attr('data-lang', $this.find('code').attr('data-lang'));
      });
      $articleContent.find('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]').each(function() {
        $this = $(this);
        $this.append($('<a class="anchor d-print-none" aria-hidden="true"></a>').html('<i class="fas fa-anchor"></i>'));
      });
      $articleContent.on('click', '.anchor', function() {
        $scroll.scrollToAnchor('#' + $(this).parent().attr('id'), 400);
      });
    });
  });
})();
</script></div><section class="page__comments d-print-none"></section></article><!-- start custom main bottom snippet -->

<!-- end custom main bottom snippet --></div>
            </div></div></div><div class="page__footer d-print-none">
<footer class="footer py-4 js-page-footer">
  <div class="main"><div itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content=""><meta itemprop="url" content="/"></div><div class="site-info mt-2">
      <div>Â© 2022 John Snow Labs Inc.
        <a href="http://www.johnsnowlabs.com/terms-of-service">Terms of Service</a> | <a href="http://www.johnsnowlabs.com/privacy-policy/">Privacy Policy</a>
      </div>
    </div>
  </div>
</footer>

<script>

/* Responsive menu
	 ========================================================*/
jQuery(document).ready(function($) {
	jQuery('#responsive_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.top_navigation').toggleClass('open');
  });
  jQuery('#aside_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.js-col-aside').toggleClass('open');
      if (jQuery(window).width() <= 1023)
      {
        jQuery('.page__sidebar').toggleClass('open'); 
      jQuery('.demopage-sidemenu').toggleClass('open');
      }
  });
  jQuery('.toc--ellipsis a').click(function(e) {
    if (jQuery(window).width() <= 767)
      {
        jQuery('.js-col-aside').removeClass('open');
        jQuery('.page__sidebar').removeClass('open');    
        jQuery('#aside_menu').removeClass('close');  
      }       
  });
});

/*TABS*/
function openTabCall(cityName){
  // Declare all variables
  var i, tabcontent, tablinks;

  // Get all elements with class="tabcontent" and hide them
  tabcontent = document.getElementsByClassName("tabcontent");
  for (i = 0; i < tabcontent.length; i++) {
    tabcontent[i].style.display = "none";
  }

  // Get all elements with class="tablinks" and remove the class "active"
  tablinks = document.getElementsByClassName("tablinks");
  for (i = 0; i < tablinks.length; i++) {
    tablinks[i].className = tablinks[i].className.replace(" active", "");
  }

  // Show the current tab, and add an "active" class to the button that opened the tab
  document.getElementById(cityName).style.display = "block";
}

function openTab(evt, cityName) {
  openTabCall(cityName);
  evt.currentTarget.className += " active";
}

/*OPen by URL*/
$(document).ready(function () {  
  const tabName = (window.location.hash || '').replace('#', '');
  const tab = document.getElementById(tabName || 'opensource');
  if (tab) {
    tab.click();
  }
});

jQuery(document).ready(function(){
	jQuery('.tab-item').click(function(event) {		
		if (($(window).width() > 400) && ($(window).width() < 1199))
	    {
	    	jQuery('.tab-item').removeClass('open');
	        jQuery(this).toggleClass('open');
	    }
  });
  

});


 

</script></div></div>
    </div></div></div><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $body = $('body'), $window = $(window);
    var $pageRoot = $('.js-page-root'), $pageMain = $('.js-page-main');
    var activeCount = 0;
    function modal(options) {
      var $root = this, visible, onChange, hideWhenWindowScroll = false;
      var scrollTop;
      function setOptions(options) {
        var _options = options || {};
        visible = _options.initialVisible === undefined ? false : show;
        onChange = _options.onChange;
        hideWhenWindowScroll = _options.hideWhenWindowScroll;
      }
      function init() {
        setState(visible);
      }
      function setState(isShow) {
        if (isShow === visible) {
          return;
        }
        visible = isShow;
        if (visible) {
          activeCount++;
          scrollTop = $(window).scrollTop() || $pageMain.scrollTop();
          $root.addClass('modal--show');
          $pageMain.scrollTop(scrollTop);
          activeCount === 1 && ($pageRoot.addClass('show-modal'), $body.addClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.on('scroll', hide);
          $window.on('keyup', handleKeyup);
        } else {
          activeCount > 0 && activeCount--;
          $root.removeClass('modal--show');
          $window.scrollTop(scrollTop);
          activeCount === 0 && ($pageRoot.removeClass('show-modal'), $body.removeClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.off('scroll', hide);
          $window.off('keyup', handleKeyup);
        }
        onChange && onChange(visible);
      }
      function show() {
        setState(true);
      }
      function hide() {
        setState(false);
      }
      function handleKeyup(e) {
        // Char Code: 27  ESC
        if (e.which ===  27) {
          hide();
        }
      }
      setOptions(options);
      init();
      return {
        show: show,
        hide: hide,
        $el: $root
      };
    }
    $.fn.modal = modal;
  });
})();
</script><div class="modal modal--overflow page__search-modal d-print-none js-page-search-modal"></div></div>


<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function scrollToAnchor(anchor, duration, callback) {
      var $root = this;
      $root.animate({ scrollTop: $(anchor).position().top }, duration, function() {
        window.history.replaceState(null, '', window.location.href.split('#')[0] + anchor);
        callback && callback();
      });
    }
    $.fn.scrollToAnchor = scrollToAnchor;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function affix(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroll,
        offsetBottom = 0, scrollTarget = window, scroll = window.document, disabled = false, isOverallScroller = true,
        rootTop, rootLeft, rootHeight, scrollBottom, rootBottomTop,
        hasInit = false, curState;

      function setOptions(options) {
        var _options = options || {};
        _options.offsetBottom && (offsetBottom = _options.offsetBottom);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroll && (scroll = _options.scroll);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $scrollTarget = $(scrollTarget);
        isOverallScroller = window.isOverallScroller($scrollTarget[0]);
        $scroll = $(scroll);
      }
      function preCalc() {
        top();
        rootHeight = $root.outerHeight();
        rootTop = $root.offset().top + (isOverallScroller ? 0 :  $scrollTarget.scrollTop());
        rootLeft = $root.offset().left;
      }
      function calc(needPreCalc) {
        needPreCalc && preCalc();
        scrollBottom = $scroll.outerHeight() - offsetBottom - rootHeight;
        rootBottomTop = scrollBottom - rootTop;
      }
      function top() {
        if (curState !== 'top') {
          $root.removeClass('fixed').css({
            left: 0,
            top: 0
          });
          curState = 'top';
        }
      }
      function fixed() {
        if (curState !== 'fixed') {
          $root.addClass('fixed').css({
            left: rootLeft + 'px',
            top: 0
          });
          curState = 'fixed';
        }
      }
      function bottom() {
        if (curState !== 'bottom') {
          $root.removeClass('fixed').css({
            left: 0,
            top: rootBottomTop + 'px'
          });
          curState = 'bottom';
        }
      }
      function setState() {
        var scrollTop = $scrollTarget.scrollTop();
        if (scrollTop >= rootTop && scrollTop <= scrollBottom) {
          fixed();
        } else if (scrollTop < rootTop) {
          top();
        } else {
          bottom();
        }
      }
      function init() {
        if(!hasInit) {
          var interval, timeout;
          calc(true); setState();
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState();
          });
          $window.on('resize', function() {
            disabled || (calc(true), setState());
          });
          hasInit = true;
        }
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions,
        refresh: function() {
          calc(true, { animation: false }); setState();
        }
      };
    }
    $.fn.affix = affix;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function toc(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroller, $tocUl = $('<ul class="toc toc--ellipsis"></ul>'), $tocLi, $headings, $activeLast, $activeCur,
        selectors = 'h1,h2,h3', container = 'body', scrollTarget = window, scroller = 'html, body', disabled = false,
        headingsPos, scrolling = false, hasRendered = false, hasInit = false;

      function setOptions(options) {
        var _options = options || {};
        _options.selectors && (selectors = _options.selectors);
        _options.container && (container = _options.container);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroller && (scroller = _options.scroller);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $headings = $(container).find(selectors).filter('[id]');
        $scrollTarget = $(scrollTarget);
        $scroller = $(scroller);
      }
      function calc() {
        headingsPos = [];
        $headings.each(function() {
          headingsPos.push(Math.floor($(this).position().top));
        });
      }
      function setState(element, disabled) {
        var scrollTop = $scrollTarget.scrollTop(), i;
        if (disabled || !headingsPos || headingsPos.length < 1) { return; }
        if (element) {
          $activeCur = element;
        } else {
          for (i = 0; i < headingsPos.length; i++) {
            if (scrollTop >= headingsPos[i]) {
              $activeCur = $tocLi.eq(i);
            } else {
              $activeCur || ($activeCur = $tocLi.eq(i));
              break;
            }
          }
        }
        $activeLast && $activeLast.removeClass('active');
        ($activeLast = $activeCur).addClass('active');
      }
      function render() {
        if(!hasRendered) {
          $root.append($tocUl);
          $headings.each(function() {
            var $this = $(this);
            $tocUl.append($('<li></li>').addClass('toc-' + $this.prop('tagName').toLowerCase())
              .append($('<a></a>').text($this.text()).attr('href', '#' + $this.prop('id'))));
          });
          $tocLi = $tocUl.children('li');
          $tocUl.on('click', 'a', function(e) {
            e.preventDefault();
            var $this = $(this);
            scrolling = true;
            setState($this.parent());
            $scroller.scrollToAnchor($this.attr('href'), 400, function() {
              scrolling = false;
            });
          });
        }
        hasRendered = true;
      }
      function init() {
        var interval, timeout;
        if(!hasInit) {
          render(); calc(); setState(null, scrolling);
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState(null, scrolling);
          });
          $window.on('resize', window.throttle(function() {
            if (!disabled) {
              render(); calc(); setState(null, scrolling);
            }
          }, 100));
        }
        hasInit = true;
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions
      };
    }
    $.fn.toc = toc;
  });
})();
/*(function () {

})();*/
</script><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;

  window.Lazyload.js(SOURCES.jquery, function() {
    var $pageMask = $('.js-page-mask');
    var $pageRoot = $('.js-page-root');
    var $sidebarShow = $('.js-sidebar-show');
    var $sidebarHide = $('.js-sidebar-hide');

    function freeze(e) {
      if (e.target === $pageMask[0]) {
        e.preventDefault();
      }
    }
    function stopBodyScrolling(bool) {
      if (bool === true) {
        window.addEventListener('touchmove', freeze, { passive: false });
      } else {
        window.removeEventListener('touchmove', freeze, { passive: false });
      }
    }

    $sidebarShow.on('click', function() {
      stopBodyScrolling(true); $pageRoot.addClass('show-sidebar');
    });
    $sidebarHide.on('click', function() {
      stopBodyScrolling(false); $pageRoot.removeClass('show-sidebar');
    });
  });
})();
</script><script>
  /* toc must before affix, since affix need to konw toc' height. */(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  var TOC_SELECTOR = window.TEXT_VARIABLES.site.toc.selectors;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window);
    var $articleContent = $('.js-article-content');
    var $tocRoot = $('.js-toc-root'), $col2 = $('.js-col-aside');
    var toc;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
    var hasToc = $articleContent.find(TOC_SELECTOR).length > 0;

    function disabled() {
      return $col2.css('display') === 'none' || !hasToc;
    }

    tocDisabled = disabled();

    toc = $tocRoot.toc({
      selectors: TOC_SELECTOR,
      container: $articleContent,
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      tocDisabled = disabled();
      toc && toc.setOptions({
        disabled: tocDisabled
      });
    }, 100));

  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window), $pageFooter = $('.js-page-footer');
    var $pageAside = $('.js-page-aside');
    var affix;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');

    affix = $pageAside.affix({
      offsetBottom: $pageFooter.outerHeight(),
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      scroll: hasSidebar ? $('.js-page-main').children() : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      affix && affix.setOptions({
        disabled: tocDisabled
      });
    }, 100));

    window.pageAsideAffix = affix;
  });
})();
</script><script>
  window.Lazyload.js(['https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js', 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js'], function() {
    var $canvas = null, $this = null, _ctx = null, _text = '';
    $('.language-chart').each(function(){
      $this = $(this);
      $canvas = $('<canvas></canvas>');
      _text = $this.text();
      $this.text('').append($canvas);
      _ctx = $canvas.get(0).getContext('2d');
      (_ctx && _text) && (new Chart(_ctx, JSON.parse(_text)) && $this.attr('data-processed', true));
    });
  });
</script><script type="text/x-mathjax-config">
	var _config = { tex2jax: {
		inlineMath: [['$','$'], ['\\(','\\)']]
	}};_config.TeX = { equationNumbers: { autoNumber: "all" } };MathJax.Hub.Config(_config);
</script>
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script>
  window.Lazyload.js('https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js', function() {
    mermaid.initialize({
      startOnLoad: true
    });
    mermaid.init(undefined, '.language-mermaid');
  });
</script>
    </div>
    <script>(function () {
  var $root = document.getElementsByClassName('root')[0];
  if (window.hasEvent('touchstart')) {
    $root.dataset.isTouch = true;
    document.addEventListener('touchstart', function(){}, false);
  }
})();
</script>
  </body>
</html>