<!DOCTYPE html><html lang="en">
  <head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-59JLR64');</script>
<!-- End Google Tag Manager --><title>Enterprise NLP Annotators</title><meta property="og:title" content="Spark NLP | John Snow Labs"/>

<meta name="description" content="High Performance NLP with Apache Spark
">
<link rel="canonical" href="/docs/en/licensed_annotators"><link rel="alternate" type="application/rss+xml" title="Spark NLP" href="/feed.xml"><!-- start favicons snippet, use https://realfavicongenerator.net/ -->
<!---->
<!-- <link rel="apple-touch-icon" sizes="180x180" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="32x32" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="16x16" href="/fav.ico"> -->

<!---->
<!-- <link rel="manifest" href="/fav.ico"> --><link rel="mask-icon" href="/fav.ico" color="#fc4d50"><link rel="shortcut icon" href="/fav.ico">

<meta name="msapplication-TileColor" content="#ffc40d"><meta name="msapplication-config" content="/assets/browserconfig.xml">

<meta name="theme-color" content="#ffffff">
<!-- end favicons snippet --><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" >
<link rel="stylesheet" href="/static/models.css" /><!-- start custom head snippets -->
 <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800&display=swap" rel="stylesheet"> 
 <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
<!-- end custom head snippets -->
<script>(function() {
  window.isArray = function(val) {
    return Object.prototype.toString.call(val) === '[object Array]';
  };
  window.isString = function(val) {
    return typeof val === 'string';
  };

  window.decodeUrl = function(str) {
    return str ? decodeURIComponent(str.replace(/\+/g, '%20')) : '';
  };

  window.hasEvent = function(event) {
    return 'on'.concat(event) in window.document;
  };

  window.isOverallScroller = function(node) {
    return node === document.documentElement || node === document.body || node === window;
  };

  window.isFormElement = function(node) {
    var tagName = node.tagName;
    return tagName === 'INPUT' || tagName === 'SELECT' || tagName === 'TEXTAREA';
  };

  window.pageLoad = (function () {
    var loaded = false, cbs = [];
    window.addEventListener('load', function () {
      var i;
      loaded = true;
      if (cbs.length > 0) {
        for (i = 0; i < cbs.length; i++) {
          cbs[i]();
        }
      }
    });
    return {
      then: function(cb) {
        cb && (loaded ? cb() : (cbs.push(cb)));
      }
    };
  })();
})();
(function() {
  window.throttle = function(func, wait) {
    var args, result, thisArg, timeoutId, lastCalled = 0;

    function trailingCall() {
      lastCalled = new Date;
      timeoutId = null;
      result = func.apply(thisArg, args);
    }
    return function() {
      var now = new Date,
        remaining = wait - (now - lastCalled);

      args = arguments;
      thisArg = this;

      if (remaining <= 0) {
        clearTimeout(timeoutId);
        timeoutId = null;
        lastCalled = now;
        result = func.apply(thisArg, args);
      } else if (!timeoutId) {
        timeoutId = setTimeout(trailingCall, remaining);
      }
      return result;
    };
  };
})();
(function() {
  var Set = (function() {
    var add = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (data[i] === item) {
          return;
        }
      }
      this.size ++;
      data.push(item);
      return data;
    };

    var Set = function(data) {
      this.size = 0;
      this._data = [];
      var i;
      if (data.length > 0) {
        for (i = 0; i < data.length; i++) {
          add.call(this, data[i]);
        }
      }
    };
    Set.prototype.add = add;
    Set.prototype.get = function(index) { return this._data[index]; };
    Set.prototype.has = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (this.get(i) === item) {
          return true;
        }
      }
      return false;
    };
    Set.prototype.is = function(map) {
      if (map._data.length !== this._data.length) { return false; }
      var i, j, flag, tData = this._data, mData = map._data;
      for (i = 0; i < tData.length; i++) {
        for (flag = false, j = 0; j < mData.length; j++) {
          if (tData[i] === mData[j]) {
            flag = true;
            break;
          }
        }
        if (!flag) { return false; }
      }
      return true;
    };
    Set.prototype.values = function() {
      return this._data;
    };
    return Set;
  })();

  window.Lazyload = (function(doc) {
    var queue = {js: [], css: []}, sources = {js: {}, css: {}}, context = this;
    var createNode = function(name, attrs) {
      var node = doc.createElement(name), attr;
      for (attr in attrs) {
        if (attrs.hasOwnProperty(attr)) {
          node.setAttribute(attr, attrs[attr]);
        }
      }
      return node;
    };
    var end = function(type, url) {
      var s, q, qi, cbs, i, j, cur, val, flag;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        s[url] = true;
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (cur.urls.has(url)) {
            qi = cur, val = qi.urls.values();
            qi && (cbs = qi.callbacks);
            for (flag = true, j = 0; j < val.length; j++) {
              cur = val[j];
              if (!s[cur]) {
                flag = false;
              }
            }
            if (flag && cbs && cbs.length > 0) {
              for (j = 0; j < cbs.length; j++) {
                cbs[j].call(context);
              }
              qi.load = true;
            }
          }
        }
      }
    };
    var load = function(type, urls, callback) {
      var s, q, qi, node, i, cur,
        _urls = typeof urls === 'string' ? new Set([urls]) : new Set(urls), val, url;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (_urls.is(cur.urls)) {
            qi = cur;
            break;
          }
        }
        val = _urls.values();
        if (qi) {
          callback && (qi.load || qi.callbacks.push(callback));
          callback && (qi.load && callback());
        } else {
          q.push({
            urls: _urls,
            callbacks: callback ? [callback] : [],
            load: false
          });
          for (i = 0; i < val.length; i++) {
            node = null, url = val[i];
            if (s[url] === undefined) {
              (type === 'js' ) && (node = createNode('script', { src: url }));
              (type === 'css') && (node = createNode('link', { rel: 'stylesheet', href: url }));
              if (node) {
                node.onload = (function(type, url) {
                  return function() {
                    end(type, url);
                  };
                })(type, url);
                (doc.head || doc.body).appendChild(node);
                s[url] = false;
              }
            }
          }
        }
      }
    };
    return {
      js: function(url, callback) {
        load('js', url, callback);
      },
      css: function(url, callback) {
        load('css', url, callback);
      }
    };
  })(this.document);
})();
</script><script>
  (function() {
    var TEXT_VARIABLES = {
      version: '2.2.4',
      sources: {
        font_awesome: 'https://use.fontawesome.com/releases/v5.0.13/css/all.css',
        jquery: 'https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js',
        leancloud_js_sdk: '//cdn1.lncld.net/static/js/3.4.1/av-min.js',
        chart: 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js',
        gitalk: {
          js: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.js',
          css: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.css'
        },
        valine: 'https://unpkg.com/valine/dist/Valine.min.js',
        mathjax: 'https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML',
        mermaid: 'https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js'
      },
      site: {
        toc: {
          selectors: 'h1,h2,h3'
        }
      },
      paths: {
        search_js: '/assets/search.js'
      }
    };
    window.TEXT_VARIABLES = TEXT_VARIABLES;
  })();
</script></head>
  <body>
    <div class="root" data-is-touch="false">
      <div class="layout--page layout--page--sidebar clearfix js-page-root&nbsp; layout--page--aside">
  <div class="page__mask d-print-none js-page-mask js-sidebar-hide"></div>
  <div class="page__viewport">
    <div class="page__actions d-print-none">
      <div class="js-sidebar-show">
        <i class="fas fa-bars icon--show"></i>
      </div>
    </div>

    <div class="grid page__grid">

      <div class="page__sidebar d-print-none"><a title="High Performance NLP with Apache Spark
" href="/">
    <!--<svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
-->
</a><div class="sidebar-toc"><ul class="toc toc--navigator"><li class="toc-h1">All Enterprise libraries</li><li class="toc-h2"><a href="/docs/en/license_getting_started">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/licensed_install">Installation</a></li><li class="toc-h2 active"><a href="/docs/en/licensed_annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/licensed_training">Training</a></li><li class="toc-h2"><a href="/docs/en/evaluation">Evaluation</a></li><li class="toc-h2"><a href="/docs/en/healthcare_risk_adjustments_score_calculation">Risk Adjustments Score Calculation</a></li><li class="toc-h2"><a href="/docs/en/utility_helper_modules">Utility & Helper Modules</a></li><li class="toc-h2"><a href="/docs/en/licensed_serving_spark_nlp_via_api_synapseml">Serving Spark NLP&#58 SynapseML</a></li><li class="toc-h2"><a href="/docs/en/licensed_serving_spark_nlp_via_api_fastapi">Serving Spark NLP&#58 FastAPI</a></li><li class="toc-h2"><a href="/licensed/api/">Scala API (Scaladoc)</a></li><li class="toc-h2"><a href="/licensed/api/python">Python API (Sphinx)</a></li><li class="toc-h2"><a href="/docs/en/wiki">Wiki</a></li><li class="toc-h2"><a href="/docs/en/benchmark">Cluster Speed Benchmarks</a></li><li class="toc-h2"><a href="/docs/en/cpu-ner-benchmark">CPU NER Benchmarks</a></li><li class="toc-h2"><a href="/docs/en/CPUvsGPUbenchmark_healthcare">GPU vs CPU benchmarks</a></li><li class="toc-h2"><a href="/docs/en/best_practices_pretrained_models">Best Practices Using Pretrained Models Together</a></li><li class="toc-h1">Healthcare NLP</li><li class="toc-h2"><a href="/docs/en/spark_nlp_healthcare_versions/licensed_release_notes">Release Notes</a></li><li class="toc-h2"><a href="/models?edition=Spark+NLP+for+Healthcare">Healthcare Models</a></li><li class="toc-h2"><a href="/docs/en/licensed_version_compatibility">Version Compatibility</a></li><li class="toc-h1">Finance NLP</li><li class="toc-h2"><a href="/docs/en/financial_release_notes">Release Notes</a></li><li class="toc-h2"><a href="/models?edition=Spark+NLP+for+Finance">Financial Models</a></li><li class="toc-h2"><a href="/docs/en/financial_version_compatibility">Version Compatibility</a></li><li class="toc-h1">Legal NLP</li><li class="toc-h2"><a href="/docs/en/legal_release_notes">Release Notes</a></li><li class="toc-h2"><a href="/models?edition=Spark+NLP+for+Legal">Legal Models</a></li><li class="toc-h2"><a href="/docs/en/legal_version_compatibility">Version Compatibility</a></li></ul></div></div><div class="page__main js-page-main has-aside cell cell--auto">

      <div class="page__main-inner"><div class="page__header d-print-none"><!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-59JLR64"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) --><header class="header"><div class="main">
      <div class="header__title">
        <a class="responsive_btn" href="#" id="responsive_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
        <div class="header__brand">
          <a title="High Performance NLP with Apache Spark
" href="https://www.johnsnowlabs.com" target="_blank"><svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
</a><!---->
            <!-- <a title="High Performance NLP with Apache Spark
" href="/">Spark NLP</a> -->
          <!---->
        </div></div><nav class="navigation top_navigation">
        <ul class="top-menu"><li class="navigation__item "><a href="/">Home</a></li><li class="navigation__item navigation__item--active"><a href="/docs">Docs</a></li><li class="navigation__item "><a href="/learn">Learn</a></li><li class="navigation__item "><a href="/models">Models</a></li><li class="navigation__item "><a href="/demos">Demo</a></li><li class="navigation__item "><a href="https://github.com/JohnSnowLabs/spark-nlp"><span style="color: #FF8A00;"><i class = "fab fa-github fa-2x"></i></span></a></li><li class="navigation__item "><a href="https://www.johnsnowlabs.com/slack-redirect/"><span style="color: #FF8A00;"><i class="fab fa-slack-hash fa-2x"></i></span></a></li></ul>
      </nav><a class="responsive_btn" href="#" id="aside_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
    </div>
  </header>
</div><div class="page__content "><div class ="main"><div class="grid grid--reverse">

              <div class="col-aside d-print-none js-col-aside"><aside class="page__aside js-page-aside"><div class="toc-aside js-toc-root"></div></aside></div>

              <div class="col-main cell cell--auto"><!-- start custom main top snippet -->

<!-- end custom main top snippet --><article itemscope itemtype="http://schema.org/Article"><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script><div class="article__header"><div class="header-nav"><div class="main-docs">
  <ul class="breadcrambs">
    <li><a href="/docs">Documentation</a></li>
    <li>Enterprise NLP Annotators</li>
  </ul>
</div></div><header class="main-docs have_subtitle">
          <h1>Enterprise NLP Annotators</h1><div class="top-subtitle mont"></div></header><span class="split-space">&nbsp;</span>
          <a class="edit-on-github"
            title="Edit on Github"
            href="https://github.com/johnsnowlabs/spark-nlp/tree/master/docs/en/licensed_annotators.md">
            <i class="far fa-edit"></i></a></div><meta itemprop="headline" content="Enterprise NLP Annotators"><meta itemprop="author" content=""/><div class="js-article-content"><div class="docs-wrapper">
<div class="layout--article"><!-- start custom article top snippet -->

<!-- end custom article top snippet --><div class="article__content" itemprop="articleBody"><div class="h3-box">

  <p>A Spark NLP Enterprise license includes access to unique annotators.
At the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings_JSL">Spark NLP Workshop</a> you can see different types of annotators in action.</p>

  <p>By clicking on any annotator, you will see different sections:</p>
  <ul>
    <li>The <code class="language-plaintext highlighter-rouge">Approach</code>, or class to train models.</li>
    <li>The <code class="language-plaintext highlighter-rouge">Model</code>, to infer using pretrained models.</li>
  </ul>

  <p>Also, for most of the annotators, you will find examples for the different enterprise libraries:</p>
  <ul>
    <li>Healthcare NLP</li>
    <li>Finance NLP</li>
    <li>Legal NLP</li>
  </ul>

  <p>Check out the <a href="https://nlp.johnsnowlabs.com/docs/en/annotators">Spark NLP Annotators page</a> for more information on how to read this page.</p>

</div>

<h2 id="available-annotators">Available Annotators</h2>

<table class="table-model-big">
  <thead>
    <tr>
      <th>Annotators</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="#assertiondl">AssertionDL</a></td>
      <td>AssertionDL is a deep Learning based approach used to extract Assertion Status from extracted entities and text.</td>
    </tr>
    <tr>
      <td><a href="#assertionfilterer">AssertionFilterer</a></td>
      <td>Filters entities coming from ASSERTION type annotations and returns the CHUNKS.</td>
    </tr>
    <tr>
      <td><a href="#assertionlogreg">AssertionLogReg</a></td>
      <td>Logistic Regression is used to extract Assertion Status from extracted entities and text.</td>
    </tr>
    <tr>
      <td><a href="#chunk2token">Chunk2Token</a></td>
      <td>A feature transformer that converts the input array of strings (annotatorType CHUNK) into an array of chunk-based tokens (annotatorType TOKEN).</td>
    </tr>
    <tr>
      <td><a href="#chunkentityresolver">ChunkEntityResolver</a></td>
      <td>Returns a normalized entity for a particular trained ontology / curated dataset (e.g. clinical ICD-10, RxNorm, SNOMED; financial SEC’s EDGAR database,  etc).</td>
    </tr>
    <tr>
      <td><a href="#chunkfilterer">ChunkFilterer</a></td>
      <td>Filters entities coming from CHUNK annotations.</td>
    </tr>
    <tr>
      <td><a href="#chunkkeyphraseextraction">ChunkKeyPhraseExtraction</a></td>
      <td>Uses Bert Sentence Embeddings to determine the most relevant key phrases describing a text.</td>
    </tr>
    <tr>
      <td><a href="#chunkmerge">ChunkMerge</a></td>
      <td>Merges entities coming from different CHUNK annotations.</td>
    </tr>
    <tr>
      <td><a href="#contextualparser">ContextualParser</a></td>
      <td>Extracts entity from a document based on user defined rules.</td>
    </tr>
    <tr>
      <td><a href="#deidentification">DeIdentification</a></td>
      <td>Deidentifies Input Annotations of types DOCUMENT, TOKEN and CHUNK, by either masking or obfuscating the given CHUNKS.</td>
    </tr>
    <tr>
      <td><a href="#documentlogregclassifier">DocumentLogRegClassifier</a></td>
      <td>Classifies documents with a Logarithmic Regression algorithm.</td>
    </tr>
    <tr>
      <td><a href="#drugnormalizer">DrugNormalizer</a></td>
      <td>Annotator which normalizes raw text from documents, e.g. scraped web pages or xml documents</td>
    </tr>
    <tr>
      <td><a href="#featuresassembler">FeaturesAssembler</a></td>
      <td>Collects features from different columns.</td>
    </tr>
    <tr>
      <td><a href="#genericclassifier">GenericClassifier</a></td>
      <td>Creates a generic single-label classifier which uses pre-generated Tensorflow graphs.</td>
    </tr>
    <tr>
      <td><a href="#iobtagger">IOBTagger</a></td>
      <td>Merges token tags and NER labels from chunks in the specified format.</td>
    </tr>
    <tr>
      <td><a href="#nerchunker">NerChunker</a></td>
      <td>Extracts phrases that fits into a known pattern using the NER tags.</td>
    </tr>
    <tr>
      <td><a href="#nerconverterinternal">NerConverterInternal</a></td>
      <td>Converts a IOB or IOB2 representation of NER to a user-friendly one, by associating the tokens of recognized entities and their label.</td>
    </tr>
    <tr>
      <td><a href="#nerdisambiguator">NerDisambiguator</a></td>
      <td>Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB).</td>
    </tr>
    <tr>
      <td><a href="#medicalner">MedicalNer</a></td>
      <td>This Named Entity recognition annotator is a generic NER model based on Neural Networks..</td>
    </tr>
    <tr>
      <td><a href="#renerchunksfilter">RENerChunksFilter</a></td>
      <td>Filters and outputs combinations of relations between extracted entities, for further processing.</td>
    </tr>
    <tr>
      <td><a href="#reidentification">ReIdentification</a></td>
      <td>Reidentifies obfuscated entities by DeIdentification.</td>
    </tr>
    <tr>
      <td><a href="#relationextraction">RelationExtraction</a></td>
      <td>Extracts and classifies instances of relations between named entities.</td>
    </tr>
    <tr>
      <td><a href="#relationextractiondl">RelationExtractionDL</a></td>
      <td>Extracts and classifies instances of relations between named entities.</td>
    </tr>
    <tr>
      <td><a href="#sentenceentityresolver">SentenceEntityResolver</a></td>
      <td>Returns the normalized entity for a particular trained ontology / curated dataset (e.g. clinical ICD-10, RxNorm, SNOMED; financial SEC’s EDGAR database,  etc) based on sentence embeddings.</td>
    </tr>
  </tbody>
</table>

<script> jQuery(document).ready(function () {
    $(".model-button").click(function () {
        $(this).closest(".tabs-box").find(".model-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        //remove  active class from all other buttons
        $(this).closest(".tabs-box").find(".approach-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".h3-box.approach-content").hide()
        $(this.parentNode).siblings(".h3-box.model-content").show()
    });

    $(".approach-button").click(function () {
        //set current button to active class and remove unactive class
        $(this).closest(".tabs-box").find(".approach-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        //remove  active class from all other buttons
        $(this).closest(".tabs-box").find(".model-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".h3-box.model-content").hide()
        $(this.parentNode).siblings(".h3-box.approach-content").show()
    });
});
 </script>

<div class="tabs-box">

  <h2 id="annotationmerger">AnnotationMerger</h2>

  <div class="h3-box model-content">

    <p>Merge annotations from different pipeline steps that have the same annotation type into a unified annotation. Possible annotations that can be merged include:</p>
    <ul>
      <li>document (e.g., output of <code class="language-plaintext highlighter-rouge">DocumentAssembler</code> annotator)</li>
      <li>token (e.g., output of <code class="language-plaintext highlighter-rouge">Tokenizer</code> annotator)</li>
      <li>word_embeddings (e.g., output of <code class="language-plaintext highlighter-rouge">WordEmbeddingsModel</code> annotator)</li>
      <li>sentence_embeddings (e.g., output of <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> annotator)</li>
      <li>category (e.g., output of <code class="language-plaintext highlighter-rouge">RelationExtractionModel</code> annotator)</li>
      <li>date (e.g., output of <code class="language-plaintext highlighter-rouge">DateMatcher</code> annotator)</li>
      <li>sentiment (e.g., output of <code class="language-plaintext highlighter-rouge">SentimentDLModel</code> annotator)</li>
      <li>pos (e.g., output of <code class="language-plaintext highlighter-rouge">PerceptronModel</code> annotator)</li>
      <li>chunk (e.g., output of <code class="language-plaintext highlighter-rouge">NerConverter</code> annotator)</li>
      <li>named_entity (e.g., output of <code class="language-plaintext highlighter-rouge">NerDLModel</code> annotator)</li>
      <li>regex (e.g., output of <code class="language-plaintext highlighter-rouge">RegexTokenizer</code> annotator)</li>
      <li>dependency (e.g., output of <code class="language-plaintext highlighter-rouge">DependencyParserModel</code> annotator)</li>
      <li>language (e.g., output of <code class="language-plaintext highlighter-rouge">LanguageDetectorDL</code> annotator)</li>
      <li>keyword (e.g., output of <code class="language-plaintext highlighter-rouge">YakeModel</code> annotator)</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">ANY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ANY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/annotation_merger/index.html#sparknlp_jsl.annotator.annotation_merger.AnnotationMerger">AnnotationMerger</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/annotator/AnnotationMerger.html">AnnotationMerger</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create the pipeline with two RE models
</span><span class="n">documenter</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">PerceptronModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">pos_ner_tagger</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_pos"</span><span class="p">)</span>

<span class="n">pos_ner_chunker</span> <span class="o">=</span> <span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_pos"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_ner_chunks"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">DependencyParserModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">pos_reModel</span> <span class="o">=</span> <span class="n">RelationExtractionModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"posology_re"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"pos_ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="n">ade_ner_tagger</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_ade_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ade_ner_tags"</span><span class="p">)</span>  

<span class="n">ade_ner_chunker</span> <span class="o">=</span> <span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ade_ner_tags"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ade_ner_chunks"</span><span class="p">)</span>

<span class="n">ade_reModel</span> <span class="o">=</span> <span class="n">RelationExtractionModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"re_ade_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ade_ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ade_relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"drug-ade, ade-drug"</span><span class="p">])</span>

<span class="n">annotation_merger</span> <span class="o">=</span> <span class="n">AnnotationMerger</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ade_relations"</span><span class="p">,</span> <span class="s">"pos_relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputType</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"all_relations"</span><span class="p">)</span>

<span class="n">merger_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documenter</span><span class="p">,</span>
    <span class="n">sentencer</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span> 
    <span class="n">words_embedder</span><span class="p">,</span> 
    <span class="n">pos_tagger</span><span class="p">,</span> 
    <span class="n">pos_ner_tagger</span><span class="p">,</span>
    <span class="n">pos_ner_chunker</span><span class="p">,</span>
    <span class="n">dependency_parser</span><span class="p">,</span>
    <span class="n">pos_reModel</span><span class="p">,</span>
    <span class="n">ade_ner_tagger</span><span class="p">,</span>
    <span class="n">ade_ner_chunker</span><span class="p">,</span>
    <span class="n">ade_reModel</span><span class="p">,</span>
    <span class="n">annotation_merger</span>
<span class="p">])</span>

<span class="n">empty_df</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">merger_model</span><span class="o">=</span> <span class="n">merger_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_df</span><span class="p">)</span>

<span class="c1"># Show example result
</span><span class="n">text</span> <span class="o">=</span> <span class="s">"""
The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.. 
"""</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">merger_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="o">+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+</span>
                <span class="n">text</span><span class="o">|</span>            <span class="n">document</span><span class="o">|</span>           <span class="n">sentences</span><span class="o">|</span>              <span class="n">tokens</span><span class="o">|</span>          <span class="n">embeddings</span><span class="o">|</span>            <span class="n">pos_tags</span><span class="o">|</span>             <span class="n">ner_pos</span><span class="o">|</span>      <span class="n">pos_ner_chunks</span><span class="o">|</span>        <span class="n">dependencies</span><span class="o">|</span>       <span class="n">pos_relations</span><span class="o">|</span>        <span class="n">ade_ner_tags</span><span class="o">|</span>      <span class="n">ade_ner_chunks</span><span class="o">|</span>       <span class="n">ade_relations</span><span class="o">|</span>       <span class="n">all_relations</span><span class="o">|</span>
<span class="o">+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+</span>

<span class="n">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="p">...</span><span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">26.</span><span class="p">..</span><span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">95.</span><span class="p">..</span><span class="o">|</span><span class="p">[{</span><span class="n">token</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">Th</span><span class="p">...</span><span class="o">|</span><span class="p">[{</span><span class="n">word_embeddings</span><span class="p">...</span><span class="o">|</span><span class="p">[{</span><span class="n">pos</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">DD</span><span class="p">,</span> <span class="p">...</span><span class="o">|</span><span class="p">[{</span><span class="n">named_entity</span><span class="p">,</span> <span class="mf">1.</span><span class="p">..</span><span class="o">|</span><span class="p">[{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="p">...</span><span class="o">|</span><span class="p">[{</span><span class="n">dependency</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">...</span><span class="o">|</span><span class="p">[{</span><span class="n">category</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mf">4.</span><span class="p">..</span><span class="o">|</span><span class="p">[{</span><span class="n">named_entity</span><span class="p">,</span> <span class="mf">1.</span><span class="p">..</span><span class="o">|</span><span class="p">[{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">38</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="p">...</span><span class="o">|</span><span class="p">[{</span><span class="n">category</span><span class="p">,</span> <span class="mi">134</span><span class="p">,</span> <span class="p">...</span><span class="o">|</span><span class="p">[{</span><span class="n">category</span><span class="p">,</span> <span class="mi">134</span><span class="p">,</span> <span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="assertionchunkconverter">AssertionChunkConverter</h2>

  <div class="h3-box model-content">

    <p>This annotator creates a <code class="language-plaintext highlighter-rouge">CHUNK</code> column with metadata useful for training an Assertion Status Detection model (see <a href="https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#assertiondl">AssertionDL</a>).</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertion_chunk_converter/index.html#sparknlp_jsl.annotator.assertion.assertion_chunk_converter.AssertionChunkConverter">AssertionChunkConverter</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/AssertionChunkConverter.html">AssertionChunkConverter</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="s">"An angiography showed bleeding in two vessels off of the Minnie supplying the sigmoid that were succesfully embolized."</span><span class="p">,</span>
            <span class="s">"Minnie"</span><span class="p">,</span>
            <span class="mi">57</span><span class="p">,</span>
            <span class="mi">64</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="p">[</span>
            <span class="s">"After discussing this with his PCP, Leon was clear that the patient had had recurrent DVTs and ultimately a PE and his PCP felt strongly that he required long-term anticoagulation "</span><span class="p">,</span>
            <span class="s">"PCP"</span><span class="p">,</span>
            <span class="mi">31</span><span class="p">,</span>
            <span class="mi">34</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"target"</span><span class="p">,</span> <span class="s">"char_begin"</span><span class="p">,</span> <span class="s">"char_end"</span><span class="p">)</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">converter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">AssertionChunkConverter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setChunkTextCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setChunkBeginCol</span><span class="p">(</span><span class="s">"char_begin"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setChunkEndCol</span><span class="p">(</span><span class="s">"char_end"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputTokenBeginCol</span><span class="p">(</span><span class="s">"token_begin"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputTokenEndCol</span><span class="p">(</span><span class="s">"token_end"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">(</span>
    <span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">sentenceDetector</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">converter</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"target"</span><span class="p">,</span>
    <span class="s">"char_begin"</span><span class="p">,</span>
    <span class="s">"char_end"</span><span class="p">,</span>
    <span class="s">"token_begin"</span><span class="p">,</span>
    <span class="s">"token_end"</span><span class="p">,</span>
    <span class="s">"tokens[token_begin].result"</span><span class="p">,</span>
    <span class="s">"tokens[token_end].result"</span><span class="p">,</span>
    <span class="s">"target"</span><span class="p">,</span>
    <span class="s">"chunk"</span><span class="p">,</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">target</span><span class="o">|</span><span class="n">char_begin</span><span class="o">|</span><span class="n">char_end</span><span class="o">|</span><span class="n">token_begin</span><span class="o">|</span><span class="n">token_end</span><span class="o">|</span><span class="n">tokens</span><span class="p">[</span><span class="n">token_begin</span><span class="p">].</span><span class="n">result</span><span class="o">|</span><span class="n">tokens</span><span class="p">[</span><span class="n">token_end</span><span class="p">].</span><span class="n">result</span><span class="o">|</span><span class="n">target</span><span class="o">|</span><span class="n">chunk</span>                                         <span class="o">|</span>
<span class="o">+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">Minnie</span><span class="o">|</span><span class="mi">57</span>        <span class="o">|</span><span class="mi">64</span>      <span class="o">|</span><span class="mi">10</span>         <span class="o">|</span><span class="mi">10</span>       <span class="o">|</span><span class="n">Minnie</span>                    <span class="o">|</span><span class="n">Minnie</span>                  <span class="o">|</span><span class="n">Minnie</span><span class="o">|</span><span class="p">[{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">57</span><span class="p">,</span> <span class="mi">62</span><span class="p">,</span> <span class="n">Minnie</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span><span class="o">|</span>
<span class="o">|</span><span class="n">PCP</span>   <span class="o">|</span><span class="mi">31</span>        <span class="o">|</span><span class="mi">34</span>      <span class="o">|</span><span class="mi">5</span>          <span class="o">|</span><span class="mi">5</span>        <span class="o">|</span><span class="n">PCP</span>                       <span class="o">|</span><span class="n">PCP</span>                     <span class="o">|</span><span class="n">PCP</span>   <span class="o">|</span><span class="p">[{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="n">PCP</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span>   <span class="o">|</span>
<span class="o">+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="assertiondl">AssertionDL</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains AssertionDL, a deep Learning based approach used to extract Assertion Status
from extracted entities and text.
Contains all the methods for training an AssertionDLModel.
For pretrained models please use AssertionDLModel and see the
<a href="https://nlp.johnsnowlabs.com/models?task=Assertion+Status">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertionDL/index.html#sparknlp_jsl.annotator.assertion.assertionDL.AssertionDLApproach">AssertionDLApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/dl/AssertionDLApproach">AssertionDLApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined.
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>
<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Define AssertionDLApproach with parameters and start training
</span><span class="n">assertionStatus</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.012</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.015</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxSentLen</span><span class="p">(</span><span class="mi">250</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document</span><span class="p">,</span>
    <span class="n">chunk</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">assertionStatus</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">assertionResults</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined.
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>
<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Define AssertionDLApproach with parameters and start training
</span><span class="n">assertionStatus</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AssertionDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.012</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.015</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxSentLen</span><span class="p">(</span><span class="mi">250</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document</span><span class="p">,</span>
    <span class="n">chunk</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">assertionStatus</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">assertionResults</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined.
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"doc_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"tkn_start"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStartColByTokenIndex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setFailOnMissing</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLowerCase</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'token'</span><span class="p">)</span>
<span class="n">roberta_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

<span class="c1"># Define AssertionDLApproach with parameters and start training
</span><span class="n">assertionStatus</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AssertionDLApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"assertion_label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"doc_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEpochs</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"tkn_start"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"tkn_end"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSentLen</span><span class="p">(</span><span class="mi">1200</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEnableOutputLogs</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">'training_logs/'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="n">graph_folder</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFile</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">graph_folder</span><span class="si">}</span><span class="s">/assertion_graph.pb"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setTestDataset</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">"test_data.parquet"</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="s">'SPARK'</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s">'format'</span><span class="p">:</span> <span class="s">'parquet'</span><span class="p">})</span>\
    <span class="p">.</span><span class="n">setScopeWindow</span><span class="p">(</span><span class="n">scope_window</span><span class="p">)</span>
    <span class="c1">#.setValidationSplit(0.2)\    
</span>    <span class="c1">#.setDropout(0.1)\    
</span>
<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document</span><span class="p">,</span>
    <span class="n">chunk</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">roberta_embeddings</span><span class="p">,</span>
    <span class="n">assertionStatus</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">assertionResults</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

// </span><span class="nn">First</span><span class="o">,</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="k">for</span> <span class="n">pre</span><span class="o">-</span><span class="n">processing</span> <span class="n">the</span> <span class="nf">dataset</span> <span class="o">(</span><span class="n">containing</span> <span class="n">columns</span> <span class="k">for</span> <span class="n">text</span> <span class="n">and</span> <span class="n">label</span><span class="o">)</span> <span class="n">are</span> <span class="n">defined</span><span class="o">.</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Define AssertionDLApproach with parameters and start training</span>
<span class="k">val</span> <span class="nv">assertionStatus</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">AssertionDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">128</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.012f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLearningRate</span><span class="o">(</span><span class="mf">0.015f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSentLen</span><span class="o">(</span><span class="mi">250</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">chunk</span><span class="o">,</span>
  <span class="n">token</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">assertionStatus</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">assertionResults</span> <span class="k">=</span> <span class="nv">assertionModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

// </span><span class="nn">First</span><span class="o">,</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="k">for</span> <span class="n">pre</span><span class="o">-</span><span class="n">processing</span> <span class="n">the</span> <span class="nf">dataset</span> <span class="o">(</span><span class="n">containing</span> <span class="n">columns</span> <span class="k">for</span> <span class="n">text</span> <span class="n">and</span> <span class="n">label</span><span class="o">)</span> <span class="n">are</span> <span class="n">defined</span><span class="o">.</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Define AssertionDLApproach with parameters and start training</span>
<span class="k">val</span> <span class="nv">assertionStatus</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">AssertionDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">128</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.012f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLearningRate</span><span class="o">(</span><span class="mf">0.015f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSentLen</span><span class="o">(</span><span class="mi">250</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">chunk</span><span class="o">,</span>
  <span class="n">token</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">assertionStatus</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">assertionResults</span> <span class="k">=</span> <span class="nv">assertionModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

</span><span class="nn">val</span> <span class="n">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()\</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Doc2Chunk</span><span class="o">()\</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"doc_chunk"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"tkn_start"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setStartColByTokenIndex</span><span class="o">(</span><span class="nc">True</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setFailOnMissing</span><span class="o">(</span><span class="nc">False</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setLowerCase</span><span class="o">(</span><span class="nc">False</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()\</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="kt">'document'</span><span class="o">])\</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="ss">'toke</span><span class="n">n</span><span class="o">')</span>
<span class="k">val</span> <span class="nv">roberta_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span> <span class="o">\</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">document</span><span class="err">"</span>, <span class="err">"</span><span class="kt">token</span><span class="err">"</span><span class="o">])</span> <span class="o">\</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> <span class="o">\</span>
    <span class="o">.</span><span class="py">setMaxSentenceLength</span><span class="o">(</span><span class="mi">512</span><span class="o">)</span>

<span class="k">#</span> <span class="nc">Define</span> <span class="nc">AssertionDLApproach</span> <span class="k">with</span> <span class="n">parameters</span> <span class="n">and</span> <span class="n">start</span> <span class="n">training</span>
<span class="k">val</span> <span class="nv">assertionStatus</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">AssertionDLApproach</span><span class="o">()\</span>
    <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"assertion_label"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"doc_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">128</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setLearningRate</span><span class="o">(</span><span class="mf">0.001</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setEpochs</span><span class="o">(</span><span class="mi">2</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"tkn_start"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"tkn_end"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setMaxSentLen</span><span class="o">(</span><span class="mi">1200</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setEnableOutputLogs</span><span class="o">(</span><span class="nc">True</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="ss">'training_logs</span><span class="o">/')\</span>
    <span class="o">.</span><span class="py">setGraphFolder</span><span class="o">(</span><span class="n">graph_folder</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setGraphFile</span><span class="o">(</span><span class="n">f</span><span class="s">"{graph_folder}/assertion_graph.pb"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setTestDataset</span><span class="o">(</span><span class="n">path</span><span class="o">=</span><span class="s">"test_data.parquet"</span><span class="o">,</span> <span class="n">read_as</span><span class="o">='</span><span class="nc">SPARK</span><span class="o">',</span> <span class="n">options</span><span class="o">={</span><span class="ss">'forma</span><span class="n">t</span><span class="o">':</span> <span class="ss">'parque</span><span class="n">t</span><span class="o">'})\</span>
    <span class="o">.</span><span class="py">setScopeWindow</span><span class="o">(</span><span class="n">scope_window</span><span class="o">)</span>
    <span class="o">#.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2</span><span class="o">)\</span>    
    <span class="o">#.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)\</span>    

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">chunk</span><span class="o">,</span>
  <span class="n">token</span><span class="o">,</span>
  <span class="n">roberta_embeddings</span><span class="o">,</span>
  <span class="n">assertionStatus</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">assertionResults</span> <span class="k">=</span> <span class="nv">assertionModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>AssertionDL is a deep Learning based approach used to extract Assertion Status
from extracted entities and text. AssertionDLModel requires DOCUMENT, CHUNK and WORD_EMBEDDINGS type
annotator inputs, which can be obtained by e.g a
<a href="/docs/en/annotators#documentassembler">DocumentAssembler</a>,
<a href="/docs/en/annotators#nerconverter">NerConverter</a>
and <a href="/docs/en/annotators#wordembeddings">WordEmbeddingsModel</a>.
The result is an assertion status annotation for each recognized entity.
Possible values include <code class="language-plaintext highlighter-rouge">“present”, “absent”, “hypothetical”, “conditional”, “associated_with_other_person”</code> etc.</p>

    <p>For pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Assertion+Status">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertionDL/index.html#sparknlp_jsl.annotator.assertion.assertionDL.AssertionDLModel">AssertionDLModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/dl/AssertionDLModel">AssertionDLModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Define pipeline stages to extract NER chunks first
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
  <span class="p">[</span><span class="s">"Patient with severe fever and sore throat"</span><span class="p">],</span>
  <span class="p">[</span><span class="s">"Patient shows no stomach pain"</span><span class="p">],</span>
  <span class="p">[</span><span class="s">"She was maintained on an epidural and PCA for pain control."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="n">nerModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1"># Then a pretrained AssertionDLModel is used to extract the assertion status
</span><span class="n">clinicalAssertion</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"assertion_dl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">nerModel</span><span class="p">,</span>
  <span class="n">nerConverter</span><span class="p">,</span>
  <span class="n">clinicalAssertion</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"ner_chunk.result"</span><span class="p">,</span> <span class="s">"assertion.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                          <span class="o">|</span><span class="n">result</span>                          <span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">severe</span> <span class="n">fever</span><span class="p">,</span> <span class="n">sore</span> <span class="n">throat</span><span class="p">]</span>     <span class="o">|</span><span class="p">[</span><span class="n">present</span><span class="p">,</span> <span class="n">present</span><span class="p">]</span>              <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">stomach</span> <span class="n">pain</span><span class="p">]</span>                  <span class="o">|</span><span class="p">[</span><span class="n">absent</span><span class="p">]</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">an</span> <span class="n">epidural</span><span class="p">,</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">pain</span> <span class="n">control</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">present</span><span class="p">,</span> <span class="n">present</span><span class="p">,</span> <span class="n">hypothetical</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\

<span class="n">assertion</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finassertion_competitors"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>
    
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span> 
    <span class="n">sentence_detector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">assertion</span>
    <span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">assertion</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sent_id"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------+------------+---------+----------+</span>
<span class="o">|</span><span class="n">sent_id</span><span class="o">|</span><span class="n">chunk</span>       <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">assertion</span> <span class="o">|</span>
<span class="o">+-------+------------+---------+----------+</span>
<span class="o">|</span><span class="mi">0</span>      <span class="o">|</span><span class="n">McAfee</span> <span class="n">LLC</span>  <span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span><span class="n">COMPETITOR</span><span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>      <span class="o">|</span><span class="n">Broadcom</span> <span class="n">Inc</span><span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span><span class="n">COMPETITOR</span><span class="o">|</span>
<span class="o">+-------+------------+---------+----------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings_ner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings_ner"</span><span class="p">)</span>\

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'legner_contract_doc_parties'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'legal/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings_ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"DOC"</span><span class="p">,</span> <span class="s">"EFFDATE"</span><span class="p">,</span> <span class="s">"PARTY"</span><span class="p">])</span>

<span class="n">embeddings_ass</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings_ass"</span><span class="p">)</span>

<span class="n">assertion</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legassertion_time"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"embeddings_ass"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>


<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
            <span class="n">document_assembler</span><span class="p">,</span> 
            <span class="n">sentence_detector</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">embeddings_ner</span><span class="p">,</span>
            <span class="n">ner_model</span><span class="p">,</span>
            <span class="n">ner_converter</span><span class="p">,</span>
            <span class="n">embeddings_ass</span><span class="p">,</span>
            <span class="n">assertion</span>
            <span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>  
                                     <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">begin</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">end</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">assertion</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"begin"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"end"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['3']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['4']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------+-----+---+---------+---------+</span>
<span class="o">|</span><span class="n">chunk</span>                          <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">assertion</span><span class="o">|</span>
<span class="o">+-------------------------------+-----+---+---------+---------+</span>
<span class="o">|</span><span class="n">Intellectual</span> <span class="n">Property</span> <span class="n">Agreement</span><span class="o">|</span><span class="mi">11</span>   <span class="o">|</span><span class="mi">41</span> <span class="o">|</span><span class="n">DOC</span>      <span class="o">|</span><span class="n">PRESENT</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">Amazon</span> <span class="n">Inc</span>                     <span class="o">|</span><span class="mi">51</span>   <span class="o">|</span><span class="mi">60</span> <span class="o">|</span><span class="n">PARTY</span>    <span class="o">|</span><span class="n">PRESENT</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">Atlantic</span> <span class="n">Inc</span>                   <span class="o">|</span><span class="mi">67</span>   <span class="o">|</span><span class="mi">78</span> <span class="o">|</span><span class="n">PARTY</span>    <span class="o">|</span><span class="n">PRESENT</span>  <span class="o">|</span>
<span class="o">+-------------------------------+-----+---+---------+---------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

// </span><span class="nn">Define</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="n">to</span> <span class="n">extract</span> <span class="nc">NER</span> <span class="n">chunks</span> <span class="n">first</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Patient with severe fever and sore throat"</span><span class="o">,</span>
  <span class="s">"Patient shows no stomach pain"</span><span class="o">,</span>
  <span class="s">"She was maintained on an epidural and PCA for pain control."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">).</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="c1">// Then a pretrained AssertionDLModel is used to extract the assertion status</span>
<span class="k">val</span> <span class="nv">clinicalAssertion</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"assertion_dl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">clinicalAssertion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">assertionModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"ner_chunk.result"</span><span class="o">,</span> <span class="s">"assertion.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                          <span class="o">|</span><span class="n">result</span>                          <span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|[</span><span class="kt">severe</span> <span class="kt">fever</span>, <span class="kt">sore</span> <span class="kt">throat</span><span class="o">]</span>     <span class="o">|[</span><span class="kt">present</span>, <span class="kt">present</span><span class="o">]</span>              <span class="o">|</span>
<span class="o">|[</span><span class="kt">stomach</span> <span class="kt">pain</span><span class="o">]</span>                  <span class="o">|[</span><span class="kt">absent</span><span class="o">]</span>                        <span class="o">|</span>
<span class="o">|[</span><span class="kt">an</span> <span class="kt">epidural</span>, <span class="kt">PCA</span>, <span class="kt">pain</span> <span class="kt">control</span><span class="o">]|[</span><span class="kt">present</span>, <span class="kt">present</span>, <span class="kt">hypothetical</span><span class="o">]|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

</span><span class="nn">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span>  <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span>  <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span>  <span class="nv">nlp</span><span class="o">.</span><span class="py">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finassertion_competitors"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
    
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">sentence_detector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">ner_model</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">assertion</span>
    <span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

</span><span class="nn">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings_ner</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'legner_contract_doc_partie</span><span class="n">s</span><span class="o">',</span> <span class="ss">'e</span><span class="n">n</span><span class="o">',</span> <span class="ss">'legal</span><span class="o">/</span><span class="n">models</span><span class="o">')</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings_ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"DOC"</span><span class="o">,</span> <span class="s">"EFFDATE"</span><span class="o">,</span> <span class="s">"PARTY"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">embeddings_ass</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings_ass"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legassertion_time"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"embeddings_ass"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
    
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">sentence_detector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings_ner</span><span class="o">,</span>
    <span class="n">ner_model</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">embeddings_ass</span><span class="o">,</span>
    <span class="n">assertion</span>
    <span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="assertionfilterer">AssertionFilterer</h2>

  <div class="h3-box model-content">

    <p>Filters entities coming from ASSERTION type annotations and returns the CHUNKS.
Filters can be set via a white list on the extracted chunk, the assertion or a regular expression.
White list for assertion is enabled by default. To use chunk white list, <code class="language-plaintext highlighter-rouge">criteria</code> has to be set to <code class="language-plaintext highlighter-rouge">"isin"</code>.
For regex, <code class="language-plaintext highlighter-rouge">criteria</code> has to be set to <code class="language-plaintext highlighter-rouge">"regex"</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, ASSERTION</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/assertion_filterer/index.html#sparknlp_jsl.annotator.chunker.assertion_filterer.AssertionFilterer">AssertionFilterer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/AssertionFilterer">AssertionFilterer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># To see how the assertions are extracted, see the example for AssertionDLModel.
# Define an extra step where the assertions are filtered
</span><span class="n">assertionFilterer</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">,</span><span class="s">"assertion"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"present"</span><span class="p">])</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">nerModel</span><span class="p">,</span>
  <span class="n">nerConverter</span><span class="p">,</span>
  <span class="n">clinicalAssertion</span><span class="p">,</span>
  <span class="n">assertionFilterer</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results:
</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"ner_chunk.result"</span><span class="p">,</span> <span class="s">"assertion.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                          <span class="o">|</span><span class="n">result</span>                          <span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">severe</span> <span class="n">fever</span><span class="p">,</span> <span class="n">sore</span> <span class="n">throat</span><span class="p">]</span>     <span class="o">|</span><span class="p">[</span><span class="n">present</span><span class="p">,</span> <span class="n">present</span><span class="p">]</span>              <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">stomach</span> <span class="n">pain</span><span class="p">]</span>                  <span class="o">|</span><span class="p">[</span><span class="n">absent</span><span class="p">]</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">an</span> <span class="n">epidural</span><span class="p">,</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">pain</span> <span class="n">control</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">present</span><span class="p">,</span> <span class="n">present</span><span class="p">,</span> <span class="n">hypothetical</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"filtered.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="n">result</span>                     <span class="o">|</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">severe</span> <span class="n">fever</span><span class="p">,</span> <span class="n">sore</span> <span class="n">throat</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[]</span>                         <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">an</span> <span class="n">epidural</span><span class="p">,</span> <span class="n">PCA</span><span class="p">]</span>         <span class="o">|</span>
<span class="o">+---------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># To see how the assertions are extracted, see the example for AssertionDLModel.
# Define an extra step where the assertions are filtered
</span><span class="n">assertionFilterer</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AssertionFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">,</span><span class="s">"assertion"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"present"</span><span class="p">])</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">nerModel</span><span class="p">,</span>
  <span class="n">nerConverter</span><span class="p">,</span>
  <span class="n">clinicalAssertion</span><span class="p">,</span>
  <span class="n">assertionFilterer</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># To see how the assertions are extracted, see the example for AssertionDLModel.
# Define an extra step where the assertions are filtered
</span><span class="n">assertionFilterer</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AssertionFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">,</span><span class="s">"assertion"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"present"</span><span class="p">])</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">nerModel</span><span class="p">,</span>
  <span class="n">nerConverter</span><span class="p">,</span>
  <span class="n">clinicalAssertion</span><span class="p">,</span>
  <span class="n">assertionFilterer</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

// </span><span class="nn">To</span> <span class="n">see</span> <span class="n">how</span> <span class="n">the</span> <span class="n">assertions</span> <span class="n">are</span> <span class="n">extracted</span><span class="o">,</span> <span class="n">see</span> <span class="n">the</span> <span class="n">example</span> <span class="k">for</span>
<span class="c1">// [[com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel AssertionDLModel]].</span>
<span class="c1">// Define an extra step where the assertions are filtered</span>
<span class="k">val</span> <span class="nv">assertionFilterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">AssertionFilterer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"present"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">clinicalAssertion</span><span class="o">,</span>
  <span class="n">assertionFilterer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">assertionModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results:</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("ner_chunk.result", "assertion.result").show(3, truncate=false)</span>
<span class="c1">// +--------------------------------+--------------------------------+</span>
<span class="c1">// |result                          |result                          |</span>
<span class="c1">// +--------------------------------+--------------------------------+</span>
<span class="c1">// |[severe fever, sore throat]     |[present, present]              |</span>
<span class="c1">// |[stomach pain]                  |[absent]                        |</span>
<span class="c1">// |[an epidural, PCA, pain control]|[present, present, hypothetical]|</span>
<span class="c1">// +--------------------------------+--------------------------------+</span>
<span class="c1">// result.select("filtered.result").show(3, truncate=false)</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">// |result                     |</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">// |[severe fever, sore throat]|</span>
<span class="c1">// |[]                         |</span>
<span class="c1">// |[an epidural, PCA]         |</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

// </span><span class="nn">To</span> <span class="n">see</span> <span class="n">how</span> <span class="n">the</span> <span class="n">assertions</span> <span class="n">are</span> <span class="n">extracted</span><span class="o">,</span> <span class="n">see</span> <span class="n">the</span> <span class="n">example</span> <span class="k">for</span>
<span class="c1">// [[com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel AssertionDLModel]].</span>
<span class="c1">// Define an extra step where the assertions are filtered</span>
<span class="k">val</span> <span class="nv">assertionFilterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">AssertionFilterer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"present"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">clinicalAssertion</span><span class="o">,</span>
  <span class="n">assertionFilterer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">assertionModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

// </span><span class="nn">To</span> <span class="n">see</span> <span class="n">how</span> <span class="n">the</span> <span class="n">assertions</span> <span class="n">are</span> <span class="n">extracted</span><span class="o">,</span> <span class="n">see</span> <span class="n">the</span> <span class="n">example</span> <span class="k">for</span>
<span class="c1">// [[com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel AssertionDLModel]].</span>
<span class="c1">// Define an extra step where the assertions are filtered</span>
<span class="k">val</span> <span class="nv">assertionFilterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">AssertionFilterer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"present"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">clinicalAssertion</span><span class="o">,</span>
  <span class="n">assertionFilterer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">assertionModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="assertionlogreg">AssertionLogReg</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a classification method, which uses the Logarithmic Regression Algorithm. It is used to extract Assertion Status
from extracted entities and text.
Contains all the methods for training a AssertionLogRegModel, together with trainWithChunk, trainWithStartEnd.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertion_dl_reg/index.html#sparknlp_jsl.annotator.assertion.assertion_dl_reg.AssertionLogRegApproach">AssertionLogRegApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/logreg/AssertionLogRegApproach">AssertionLogRegApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Training with Glove Embeddings
</span>
<span class="c1"># First define pipeline stages to extract embeddings and text chunks
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">glove</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="c1"># Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.
</span>
<span class="n">assertion</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionLogRegApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setReg</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBefore</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAfter</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerModel</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">assertion</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Training with Glove Embeddings
</span>
<span class="c1"># First define pipeline stages to extract embeddings and text chunks
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">glove</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="c1"># Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.
</span>
<span class="n">assertion</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AssertionLogRegApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setReg</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBefore</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAfter</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerModel</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">assertion</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Training with Glove Embeddings
</span>
<span class="c1"># First define pipeline stages to extract embeddings and text chunks
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">glove</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="c1"># Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.
</span>
<span class="n">assertion</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AssertionLogRegApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setReg</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBefore</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAfter</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerModel</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">assertion</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

// </span><span class="nn">Training</span> <span class="k">with</span> <span class="nc">Glove</span> <span class="nc">Embeddings</span>
<span class="c1">// First define pipeline stages to extract embeddings and text chunks</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">glove</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="c1">// Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.</span>
<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">AssertionLogRegApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReg</span><span class="o">(</span><span class="mf">0.01</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBefore</span><span class="o">(</span><span class="mi">11</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAfter</span><span class="o">(</span><span class="mi">13</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">assertion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

// </span><span class="nn">Training</span> <span class="k">with</span> <span class="nc">Glove</span> <span class="nc">Embeddings</span>
<span class="c1">// First define pipeline stages to extract embeddings and text chunks</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">glove</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="c1">// Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.</span>
<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">AssertionLogRegApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReg</span><span class="o">(</span><span class="mf">0.01</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBefore</span><span class="o">(</span><span class="mi">11</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAfter</span><span class="o">(</span><span class="mi">13</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">assertion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

// </span><span class="nn">Training</span> <span class="k">with</span> <span class="nc">Glove</span> <span class="nc">Embeddings</span>
<span class="c1">// First define pipeline stages to extract embeddings and text chunks</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">glove</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="c1">// Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.</span>
<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">AssertionLogRegApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReg</span><span class="o">(</span><span class="mf">0.01</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBefore</span><span class="o">(</span><span class="mi">11</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAfter</span><span class="o">(</span><span class="mi">13</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">assertion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>This is a main class in AssertionLogReg family. Logarithmic Regression is used to extract Assertion Status
from extracted entities and text. AssertionLogRegModel requires DOCUMENT, CHUNK and WORD_EMBEDDINGS type
annotator inputs, which can be obtained by e.g a
<a href="/docs/en/annotators#documentassembler">DocumentAssembler</a>,
<a href="/docs/en/annotators#nerconverter">NerConverter</a>
and <a href="/docs/en/annotators#wordembeddings">WordEmbeddingsModel</a>.
The result is an assertion status annotation for each recognized entity.
Possible values are <code class="language-plaintext highlighter-rouge">"Negated", "Affirmed" and "Historical"</code>.</p>

    <p>Unlike the DL Model, this class does not extend AnnotatorModel.
Instead it extends the RawAnnotator, that’s why the main point of interest is method transform().</p>

    <p>At the moment there are no pretrained models available for this class. Please refer to AssertionLogRegApproach to
train your own model.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertion_dl_reg/index.html#sparknlp_jsl.annotator.assertion.assertion_dl_reg.AssertionLogRegModel">AssertionLogRegModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/logreg/AssertionLogRegModel">AssertionLogRegModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box">

  <h2 id="bertsentencechunkembeddings">BertSentenceChunkEmbeddings</h2>

  <div class="h3-box model-content">

    <p>This annotator allows aggregating sentence embeddings with ner chunk embeddings to get specific and more accurate resolution codes. It works by averaging sentence and chunk embeddings add contextual information in the embedding value. Input to this annotator is the context (sentence) and ner chunks, while the output is embedding for each chunk that can be fed to the resolver model.</p>

    <p>The <code class="language-plaintext highlighter-rouge">setChunkWeight</code> parameter can be used to control the influence of surrounding context.</p>

    <blockquote>
      <p>For more information and examples of <code class="language-plaintext highlighter-rouge">BertSentenceChunkEmbeddings</code> annotator, you can check the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop">Spark NLP Workshop</a>, and in special, the notebook <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb">24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb</a>.</p>
    </blockquote>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/embeddings/bert_sentence_embeddings/index.html#sparknlp_jsl.annotator.embeddings.bert_sentence_embeddings.BertSentenceChunkEmbeddings">BertSentenceChunkEmbeddings</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/embeddings/BertSentenceChunkEmbeddings.html">BertSentenceChunkEmbeddings</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define the pipeline
</span>
<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_abbreviation_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">'ABBR'</span><span class="p">])</span>

<span class="n">sentence_chunk_embeddings</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">BertSentenceChunkEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setChunkWeight</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">abbr_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_clinical_abbreviation_acronym"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"abbr_meaning"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>
    

<span class="n">resolver_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">word_embeddings</span><span class="p">,</span>
        <span class="n">clinical_ner</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">sentence_chunk_embeddings</span><span class="p">,</span>
        <span class="n">abbr_resolver</span>
  <span class="p">])</span>


<span class="c1"># Example results
</span>
<span class="n">sample_text</span> <span class="o">=</span> <span class="p">[</span>
<span class="s">"""The patient admitted from the IR for aggressive irrigation of the Miami pouch. DISCHARGE DIAGNOSES: 1. A 58-year-old female with a history of stage 2 squamous cell carcinoma of the cervix status post total pelvic exenteration in 1991."""</span><span class="p">,</span>
<span class="s">"""Gravid with estimated fetal weight of 6-6/12 pounds. LOWER EXTREMITIES: No edema. LABORATORY DATA: Laboratory tests include a CBC which is normal. 
Blood Type: AB positive. Rubella: Immune. VDRL: Nonreactive. Hepatitis C surface antigen: Negative. HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet."""</span><span class="p">]</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">IntegerType</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sample_text</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>

<span class="o">+----------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                                                <span class="n">text</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">admitted</span> <span class="k">from</span> <span class="n">the</span> <span class="n">IR</span> <span class="k">for</span> <span class="n">aggressive</span> <span class="n">irrigation</span> <span class="n">of</span> <span class="n">the</span> <span class="n">Miami</span> <span class="n">pouch</span><span class="p">.</span> <span class="n">DISCHARGE</span> <span class="n">DIAGNOSE</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="n">Gravid</span> <span class="k">with</span> <span class="n">estimated</span> <span class="n">fetal</span> <span class="n">weight</span> <span class="n">of</span> <span class="mi">6</span><span class="o">-</span><span class="mi">6</span><span class="o">/</span><span class="mi">12</span> <span class="n">pounds</span><span class="p">.</span> <span class="n">LOWER</span> <span class="n">EXTREMITIES</span><span class="p">:</span> <span class="n">No</span> <span class="n">edema</span><span class="p">.</span> <span class="n">LABORATORY</span> <span class="n">DATA</span><span class="p">...</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nc">BertEmbeddings</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"biobert_pubmed_base_cased"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nc">MedicalNerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical_biobert"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

  <span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">sentenceChunkEmbeddings</span> <span class="k">=</span> <span class="nc">BertSentenceChunkEmbeddings</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbluebert_base_uncased_mli"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_chunk_embeddings"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
          <span class="n">documentAssembler</span><span class="o">,</span>
          <span class="n">sentenceDetector</span><span class="o">,</span>
          <span class="n">tokenizer</span><span class="o">,</span>
          <span class="n">wordEmbeddings</span><span class="o">,</span>
          <span class="n">nerModel</span><span class="o">,</span>
          <span class="n">nerConverter</span><span class="o">,</span>
          <span class="n">sentenceChunkEmbeddings</span><span class="o">))</span>

 <span class="k">val</span> <span class="nv">sampleText</span> <span class="k">=</span> <span class="s">"Her Diabetes has become type 2 in the last year with her Diabetes."</span> <span class="o">+</span>
    <span class="s">" He complains of swelling in his right forearm."</span>

 <span class="k">val</span> <span class="nv">testDataset</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">""</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">emptyDataset</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">testDataset</span><span class="o">)</span>

 <span class="n">result</span>
    <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(sentence_chunk_embeddings) AS s"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"s.result"</span><span class="o">,</span> <span class="s">"slice(s.embeddings, 1, 5) AS averageEmbedding"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>

 <span class="o">+-----------------------------+-----------------------------------------------------------------+</span>
 <span class="o">|</span>                       <span class="n">result</span><span class="o">|</span>                                                 <span class="n">averageEmbedding</span><span class="o">|</span>
 <span class="o">+-----------------------------+-----------------------------------------------------------------+</span>
 <span class="o">|</span><span class="nc">Her</span> <span class="nc">Diabetes</span>                 <span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">31995273</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">04710883</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">28973156</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1294758</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12481072</span><span class="o">]</span>  <span class="o">|</span>
 <span class="o">|</span><span class="k">type</span> <span class="err">2</span>                       <span class="kt">|</span><span class="err">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">027161136</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.24613449</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.0949309</span><span class="o">,</span> <span class="mf">0.1825444</span><span class="o">,</span> <span class="o">-</span><span class="mf">0.2252143</span><span class="err">]</span>   <span class="o">|</span>
 <span class="o">|</span><span class="n">her</span> <span class="nc">Diabetes</span>                 <span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">31995273</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">04710883</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">28973156</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1294758</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12481072</span><span class="o">]</span>  <span class="o">|</span>
 <span class="o">|</span><span class="n">swelling</span> <span class="n">in</span> <span class="n">his</span> <span class="n">right</span> <span class="n">forearm</span><span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">45139068</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12400375</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0075617577</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">90806055</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12871636</span><span class="o">]|</span>
 <span class="o">+-----------------------------+-----------------------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="chunk2token">Chunk2Token</h2>

  <div class="h3-box model-content">

    <p>A feature transformer that converts the input array of strings (annotatorType CHUNK) into an
array of chunk-based tokens (annotatorType TOKEN).</p>

    <p>When the input is empty, an empty array is returned.</p>

    <p>This Annotator is specially convenient when using NGramGenerator annotations as inputs to WordEmbeddingsModels</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/Chunk2Token">Chunk2Token</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Define a pipeline for generating n-grams
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">ngrammer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NGramGenerator</span><span class="p">()</span> \
 <span class="p">.</span><span class="n">setN</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setEnableCumulative</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
 <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngrams"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setDelimiter</span><span class="p">(</span><span class="s">"_"</span><span class="p">)</span>

<span class="c1"># Stage to convert n-gram CHUNKS to TOKEN type
</span><span class="n">chunk2Token</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Chunk2Token</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ngrams"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngram_tokens"</span><span class="p">)</span>
<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="n">sentenceDetector</span><span class="p">,</span> <span class="n">token</span><span class="p">,</span> <span class="n">ngrammer</span><span class="p">,</span> <span class="n">chunk2Token</span><span class="p">]).</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ngram_tokens)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
    <span class="o">+----------------------------------------------------------------+</span>
    <span class="o">|</span><span class="n">col</span>                                                             <span class="o">|</span>
    <span class="o">+----------------------------------------------------------------+</span>
    <span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">A_63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>  <span class="o">|</span>
    <span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old_man</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
    <span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">man_presents</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>  <span class="o">|</span>
    <span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="n">presents_to</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
    <span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="n">to_the</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="p">},</span> <span class="p">[]}</span>        <span class="o">|</span>
    <span class="o">+----------------------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Define a pipeline for generating n-grams
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">ngrammer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NGramGenerator</span><span class="p">()</span> \
 <span class="p">.</span><span class="n">setN</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setEnableCumulative</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
 <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngrams"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setDelimiter</span><span class="p">(</span><span class="s">"_"</span><span class="p">)</span>

<span class="c1"># Stage to convert n-gram CHUNKS to TOKEN type
</span><span class="n">chunk2Token</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">Chunk2Token</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ngrams"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngram_tokens"</span><span class="p">)</span>
<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="n">sentenceDetector</span><span class="p">,</span> <span class="n">token</span><span class="p">,</span> <span class="n">ngrammer</span><span class="p">,</span> <span class="n">chunk2Token</span><span class="p">])</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Define a pipeline for generating n-grams
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">ngrammer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NGramGenerator</span><span class="p">()</span> \
 <span class="p">.</span><span class="n">setN</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setEnableCumulative</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
 <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngrams"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setDelimiter</span><span class="p">(</span><span class="s">"_"</span><span class="p">)</span>

<span class="c1"># Stage to convert n-gram CHUNKS to TOKEN type
</span><span class="n">chunk2Token</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">Chunk2Token</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ngrams"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngram_tokens"</span><span class="p">)</span>
<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="n">sentenceDetector</span><span class="p">,</span> <span class="n">token</span><span class="p">,</span> <span class="n">ngrammer</span><span class="p">,</span> <span class="n">chunk2Token</span><span class="p">])</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">a</span> <span class="n">pipeline</span> <span class="k">for</span> <span class="n">generating</span> <span class="n">n</span><span class="o">-</span><span class="n">grams</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ngrammer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NGramGenerator</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setEnableCumulative</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setDelimiter</span><span class="o">(</span><span class="s">"_"</span><span class="o">)</span>

<span class="c1">// Stage to convert n-gram CHUNKS to TOKEN type</span>
<span class="k">val</span> <span class="nv">chunk2Token</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">Chunk2Token</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngram_tokens"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document</span><span class="o">,</span> <span class="n">sentenceDetector</span><span class="o">,</span> <span class="n">token</span><span class="o">,</span> <span class="n">ngrammer</span><span class="o">,</span> <span class="n">chunk2Token</span><span class="o">)).</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(ngram_tokens)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                             <span class="o">|</span>
<span class="o">+----------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">15</span><span class="o">,</span> <span class="nc">A_63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">},</span> <span class="o">[]}</span>  <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">19</span><span class="o">,</span> <span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old_man</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">17</span><span class="o">,</span> <span class="mi">28</span><span class="o">,</span> <span class="n">man_presents</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="o">},</span> <span class="o">[]}</span>  <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">21</span><span class="o">,</span> <span class="mi">31</span><span class="o">,</span> <span class="n">presents_to</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="o">},</span> <span class="o">[]}</span>   <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">30</span><span class="o">,</span> <span class="mi">35</span><span class="o">,</span> <span class="n">to_the</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">},</span> <span class="o">[]}</span>        <span class="o">|</span>
<span class="o">+----------------------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">a</span> <span class="n">pipeline</span> <span class="k">for</span> <span class="n">generating</span> <span class="n">n</span><span class="o">-</span><span class="n">grams</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ngrammer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NGramGenerator</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setEnableCumulative</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setDelimiter</span><span class="o">(</span><span class="s">"_"</span><span class="o">)</span>

<span class="c1">// Stage to convert n-gram CHUNKS to TOKEN type</span>
<span class="k">val</span> <span class="nv">chunk2Token</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">Chunk2Token</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngram_tokens"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document</span><span class="o">,</span> <span class="n">sentenceDetector</span><span class="o">,</span> <span class="n">token</span><span class="o">,</span> <span class="n">ngrammer</span><span class="o">,</span> <span class="n">chunk2Token</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">a</span> <span class="n">pipeline</span> <span class="k">for</span> <span class="n">generating</span> <span class="n">n</span><span class="o">-</span><span class="n">grams</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ngrammer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NGramGenerator</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setEnableCumulative</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setDelimiter</span><span class="o">(</span><span class="s">"_"</span><span class="o">)</span>

<span class="c1">// Stage to convert n-gram CHUNKS to TOKEN type</span>
<span class="k">val</span> <span class="nv">chunk2Token</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">Chunk2Token</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngram_tokens"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document</span><span class="o">,</span> <span class="n">sentenceDetector</span><span class="o">,</span> <span class="n">token</span><span class="o">,</span> <span class="n">ngrammer</span><span class="o">,</span> <span class="n">chunk2Token</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="chunkconverter">ChunkConverter</h2>

  <div class="h3-box model-content">

    <p>Convert chunks from <a href="https://nlp.johnsnowlabs.com/docs/en/annotators#regexmatcher">RegexMatcher</a> to chunks with a entity in the metadata.</p>

    <p>This annotator is important when the user wants to merge entities identified by NER models together with rules-based matching used by the RegexMathcer annotator. In the following steps of the pipeline, all the identified entities can be treated in a unified field.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunk_converter/index.html#sparknlp_jsl.annotator.chunker.chunk_converter.ChunkConverter">ChunkConverter</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkConverter.html">ChunkConverter</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Creating the pipeline
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical_large"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span><span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\

<span class="n">regex_matcher</span> <span class="o">=</span> <span class="n">RegexMatcher</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStrategy</span><span class="p">(</span><span class="s">"MATCH_ALL"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex_matches"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setExternalRules</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">'file:/dbfs/regex_rules.txt'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">','</span><span class="p">)</span>

<span class="n">chunkConverter</span> <span class="o">=</span> <span class="n">ChunkConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"regex_matches"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex_chunk"</span><span class="p">)</span>

<span class="n">merger</span><span class="o">=</span> <span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"regex_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"merged_chunks"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMergeOverlapping</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkPrecedence</span><span class="p">(</span><span class="s">"field"</span><span class="p">)</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
                           <span class="n">documentAssembler</span><span class="p">,</span>
                           <span class="n">sentenceDetector</span><span class="p">,</span>
                           <span class="n">tokenizer</span><span class="p">,</span>
                           <span class="n">word_embeddings</span><span class="p">,</span>
                           <span class="n">ner_model</span><span class="p">,</span>
                           <span class="n">ner_converter</span><span class="p">,</span>
                           <span class="n">regex_matcher</span><span class="p">,</span>
                           <span class="n">chunkConverter</span><span class="p">,</span>
                           <span class="n">merger</span>
<span class="p">])</span>

<span class="n">empty_df</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">model</span><span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_df</span><span class="p">)</span>

<span class="n">lp_model</span> <span class="o">=</span> <span class="n">LightPipeline</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">lp_model</span><span class="p">.</span><span class="n">fullAnnotate</span><span class="p">(</span><span class="n">sample_text</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Displaying the results
</span>
<span class="n">chunk</span><span class="o">=</span> <span class="p">[]</span>
<span class="n">merge</span><span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s">"merged_chunks"</span><span class="p">]):</span>
  <span class="n">merge</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="s">"entity"</span><span class="p">])</span>
  <span class="n">chunk</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">result</span><span class="p">)</span>
<span class="n">df_merge</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">"chunk"</span><span class="p">:</span> <span class="n">chunk</span><span class="p">,</span>  <span class="s">"merged_entity"</span><span class="p">:</span> <span class="n">merge</span><span class="p">})</span>
<span class="n">df_merge</span>

<span class="o">|</span>                                          <span class="n">chunk</span> <span class="o">|</span>  <span class="n">merged_entity</span> <span class="o">|</span>
<span class="o">|-----------------------------------------------</span><span class="p">:</span><span class="o">|---------------</span><span class="p">:</span><span class="o">|</span>
<span class="o">|</span>                       <span class="n">POSTOPERATIVE</span> <span class="n">DIAGNOSIS</span><span class="p">:</span> <span class="o">|</span> <span class="n">SECTION_HEADER</span> <span class="o">|</span>
<span class="o">|</span>                       <span class="n">Cervical</span> <span class="n">lymphadenopathy</span> <span class="o">|</span>        <span class="n">PROBLEM</span> <span class="o">|</span>
<span class="o">|</span>                                     <span class="n">PROCEDURE</span><span class="p">:</span> <span class="o">|</span> <span class="n">SECTION_HEADER</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">Excisional</span> <span class="n">biopsy</span> <span class="n">of</span> <span class="n">right</span> <span class="n">cervical</span> <span class="n">lymph</span> <span class="n">node</span> <span class="o">|</span>           <span class="n">TEST</span> <span class="o">|</span>
<span class="o">|</span>                                    <span class="n">ANESTHESIA</span><span class="p">:</span> <span class="o">|</span> <span class="n">SECTION_HEADER</span> <span class="o">|</span>
<span class="o">|</span>                <span class="n">General</span> <span class="n">endotracheal</span> <span class="n">anesthesia</span> <span class="o">|</span>      <span class="n">TREATMENT</span> <span class="o">|</span>
<span class="o">|</span>                      <span class="n">Right</span> <span class="n">cervical</span> <span class="n">lymph</span> <span class="n">node</span> <span class="o">|</span>        <span class="n">PROBLEM</span> <span class="o">|</span>
<span class="o">|</span>                                           <span class="n">EBL</span><span class="p">:</span> <span class="o">|</span> <span class="n">SECTION_HEADER</span> <span class="o">|</span>
<span class="o">|</span>                                 <span class="n">COMPLICATIONS</span><span class="p">:</span> <span class="o">|</span> <span class="n">SECTION_HEADER</span> <span class="o">|</span>
<span class="o">|</span>                                      <span class="n">FINDINGS</span><span class="p">:</span> <span class="o">|</span> <span class="n">SECTION_HEADER</span> <span class="o">|</span>
<span class="o">|</span>                    <span class="n">Enlarged</span> <span class="n">level</span> <span class="mi">2</span> <span class="n">lymph</span> <span class="n">node</span> <span class="o">|</span>        <span class="n">PROBLEM</span> <span class="o">|</span>
<span class="o">|</span> <span class="p">...</span>                                            <span class="o">|</span>                <span class="o">|</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">sampleDataset</span> <span class="k">=</span> <span class="nv">ResourceHelper</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
 <span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="s">"My first sentence with the first rule. This is my second sentence with ceremonies rule."</span><span class="o">)</span>
<span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"id"</span><span class="o">,</span> <span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">regexMatcher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexMatcher</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setExternalRules</span><span class="o">(</span><span class="nc">ExternalResource</span><span class="o">(</span><span class="s">"src/test/resources/regex-matcher/rules.txt"</span><span class="o">,</span> <span class="nv">ReadAs</span><span class="o">.</span><span class="py">TEXT</span><span class="o">,</span> <span class="nc">Map</span><span class="o">(</span><span class="s">"delimiter"</span> <span class="o">-&gt;</span> <span class="s">","</span><span class="o">)))</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regex"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setStrategy</span><span class="o">(</span><span class="n">strategy</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"regex"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">sentence</span><span class="o">,</span> <span class="n">regexMatcher</span><span class="o">,</span><span class="n">chunkConverter</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">sampleDataset</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">sampleDataset</span><span class="o">)</span>
<span class="nv">results</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                                             <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">23</span>, <span class="err">31</span>, <span class="kt">the</span> <span class="kt">first</span>, <span class="o">[</span><span class="kt">identifier</span> <span class="kt">-&gt;</span> <span class="kt">NAME</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">NAME</span><span class="o">]</span>, <span class="o">[]]</span> <span class="o">|</span>
<span class="o">|[</span><span class="kt">chunk</span>, <span class="err">71</span>, <span class="err">80</span>, <span class="kt">ceremonies</span>, <span class="o">[</span><span class="kt">identifier</span> <span class="kt">-&gt;</span> <span class="kt">NAME</span>, <span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">1</span>, <span class="kt">chunk</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">entity</span> <span class="kt">-&gt;</span> <span class="kt">NAME</span><span class="o">]</span>, <span class="o">[]]|</span>
<span class="o">+------------------------------------------------------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="chunkentityresolver">ChunkEntityResolver</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Contains all the parameters and methods to train a ChunkEntityResolverModel.
It transform a dataset with two Input Annotations of types TOKEN and WORD_EMBEDDINGS, coming from e.g. ChunkTokenizer
and ChunkEmbeddings Annotators and returns the normalized entity for a particular trained ontology / curated dataset.
(e.g. ICD-10, RxNorm, SNOMED etc.)</p>

    <p>To use pretrained models please use ChunkEntityResolverModel
and see the <a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/ChunkEntityResolverApproach">ChunkEntityResolverApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Training a SNOMED model
# Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data
# and their labels.
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_healthcare_100d"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">chunkEmb</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">ChunkEmbeddings</span><span class="p">()</span> \
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk_embeddings"</span><span class="p">)</span>

<span class="n">snomedTrainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document</span><span class="p">,</span>
    <span class="n">chunk</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">chunkEmb</span>
<span class="p">])</span>

<span class="n">snomedTrainingModel</span> <span class="o">=</span> <span class="n">snomedTrainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">snomedData</span> <span class="o">=</span> <span class="n">snomedTrainingModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Then the Resolver can be trained with
</span><span class="n">snomedExtractor</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkEntityResolverApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"chunk_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"recognized"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setNeighbours</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAlternatives</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setNormalizedCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEnableWmd</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableTfidf</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableJaccard</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEnableSorensenDice</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableJaroWinkler</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableLevenshtein</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDistanceWeights</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setAllDistancesMetadata</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"MAX"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mf">1e32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">snomedExtractor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snomedData</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Training</span> <span class="n">a</span> <span class="nc">SNOMED</span> <span class="n">model</span>
<span class="c1">// Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data</span>
<span class="c1">// and their labels.</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_healthcare_100d"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkEmb</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">ChunkEmbeddings</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedTrainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">chunk</span><span class="o">,</span>
  <span class="n">token</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">chunkEmb</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">snomedTrainingModel</span> <span class="k">=</span> <span class="nv">snomedTrainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedData</span> <span class="k">=</span> <span class="nv">snomedTrainingModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Then the Resolver can be trained with</span>
<span class="k">val</span> <span class="nv">snomedExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">ChunkEntityResolverApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"chunk_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"recognized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNeighbours</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAlternatives</span><span class="o">(</span><span class="mi">25</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNormalizedCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEnableWmd</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableTfidf</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableJaccard</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEnableSorensenDice</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableJaroWinkler</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableLevenshtein</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceWeights</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setAllDistancesMetadata</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"MAX"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mi">1</span><span class="n">e32</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">snomedExtractor</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">snomedData</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Returns a normalized entity for a particular trained ontology / curated dataset
(e.g. ICD-10, RxNorm, SNOMED etc).</p>

    <p>For available pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/ChunkEntityResolverModel">ChunkEntityResolverModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Using pretrained models for SNOMED
# First the prior steps of the pipeline are defined.
# Output of types TOKEN and WORD_EMBEDDINGS are needed.
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>
<span class="n">icdo_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_bionlp"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icdo_ner"</span><span class="p">)</span>
<span class="n">icdo_chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"icdo_ner"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icdo_chunk"</span><span class="p">).</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Cancer"</span><span class="p">])</span>
<span class="n">icdo_chunk_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">ChunkEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"icdo_chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icdo_chunk_embeddings"</span><span class="p">)</span>
<span class="n">icdo_chunk_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"chunkresolve_icdo_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span><span class="s">"icdo_chunk_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tm_icdo_code"</span><span class="p">)</span>
<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
<span class="n">ner_chunk_tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">ChunkTokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_token"</span><span class="p">)</span>
<span class="n">ner_chunk_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">ChunkEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_embeddings"</span><span class="p">)</span>

<span class="c1"># Definition of the SNOMED Resolution
</span><span class="n">ner_snomed_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"chunkresolve_snomed_findings_clinical"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_token"</span><span class="p">,</span><span class="s">"ner_chunk_embeddings"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_result"</span><span class="p">)</span>
<span class="n">pipelineFull</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">docAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>

      <span class="n">clinical_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_chunk_embeddings</span><span class="p">,</span>
      <span class="n">ner_chunk_tokenizer</span><span class="p">,</span>
      <span class="n">ner_snomed_resolver</span><span class="p">,</span>

      <span class="n">icdo_ner</span><span class="p">,</span>
      <span class="n">icdo_chunk</span><span class="p">,</span>
      <span class="n">icdo_chunk_embeddings</span><span class="p">,</span>
      <span class="n">icdo_chunk_resolver</span>
<span class="p">])</span>
<span class="n">pipelineModelFull</span> <span class="o">=</span> <span class="n">pipelineFull</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipelineModelFull</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(snomed_result)"</span><span class="p">)</span>
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"col.metadata.target_text"</span><span class="p">,</span>
    <span class="s">"col.metadata.resolved_text"</span><span class="p">,</span>
    <span class="s">"col.metadata.confidence"</span><span class="p">,</span>
    <span class="s">"col.metadata.all_k_results"</span><span class="p">,</span>
    <span class="s">"col.metadata.all_k_resolutions"</span><span class="p">)</span>
  <span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="err">$</span><span class="s">"confidence"</span> <span class="o">&gt;</span> <span class="mf">0.2</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="o">+--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="o">|</span>         <span class="n">target_text</span><span class="o">|</span>       <span class="n">resolved_text</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>       <span class="n">all_k_results</span><span class="o">|</span>   <span class="n">all_k_resolutions</span><span class="o">|</span>
<span class="o">+--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="o">|</span><span class="n">hypercholesterolemia</span><span class="o">|</span><span class="n">Hypercholesterolemia</span><span class="o">|</span>    <span class="mf">0.2524</span><span class="o">|</span><span class="mi">13644009</span><span class="p">:::</span><span class="mf">267432.</span><span class="p">..</span><span class="o">|</span><span class="n">Hypercholesterole</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>                 <span class="n">CBC</span><span class="o">|</span>             <span class="n">Neocyte</span><span class="o">|</span>    <span class="mf">0.4980</span><span class="o">|</span><span class="mi">259680000</span><span class="p">:::</span><span class="mf">11573.</span><span class="p">..</span><span class="o">|</span><span class="n">Neocyte</span><span class="p">:::</span><span class="n">Blood</span> <span class="n">g</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>                <span class="n">CD38</span><span class="o">|</span>       <span class="n">Hypoviscosity</span><span class="o">|</span>    <span class="mf">0.2560</span><span class="o">|</span><span class="mi">47872005</span><span class="p">:::</span><span class="mf">370970.</span><span class="p">..</span><span class="o">|</span><span class="n">Hypoviscosity</span><span class="p">:::</span><span class="n">E</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>           <span class="n">platelets</span><span class="o">|</span> <span class="n">Increased</span> <span class="n">platelets</span><span class="o">|</span>    <span class="mf">0.5267</span><span class="o">|</span><span class="mi">6631009</span><span class="p">:::</span><span class="mf">2596800.</span><span class="p">..</span><span class="o">|</span><span class="n">Increased</span> <span class="n">platele</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>                <span class="n">CD38</span><span class="o">|</span>       <span class="n">Hypoviscosity</span><span class="o">|</span>    <span class="mf">0.2560</span><span class="o">|</span><span class="mi">47872005</span><span class="p">:::</span><span class="mf">370970.</span><span class="p">..</span><span class="o">|</span><span class="n">Hypoviscosity</span><span class="p">:::</span><span class="n">E</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------+--------------------+----------+--------------------+--------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Using</span> <span class="n">pretrained</span> <span class="n">models</span> <span class="k">for</span> <span class="nc">SNOMED</span>
<span class="c1">// First the prior steps of the pipeline are defined.</span>
<span class="c1">// Output of types TOKEN and WORD_EMBEDDINGS are needed.</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">icdo_ner</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_bionlp"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"icdo_ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">icdo_chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"icdo_ner"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"icdo_chunk"</span><span class="o">).</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"Cancer"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">icdo_chunk_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">ChunkEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"icdo_chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"icdo_chunk_embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">icdo_chunk_resolver</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">ChunkEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"chunkresolve_icdo_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span><span class="s">"icdo_chunk_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tm_icdo_code"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_chunk_tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">ChunkTokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_chunk_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">ChunkEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_embeddings"</span><span class="o">)</span>

<span class="c1">// Definition of the SNOMED Resolution</span>
<span class="k">val</span> <span class="nv">ner_snomed_resolver</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">ChunkEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"chunkresolve_snomed_findings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_token"</span><span class="o">,</span><span class="s">"ner_chunk_embeddings"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"snomed_result"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineFull</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">docAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">word_embeddings</span><span class="o">,</span>

    <span class="n">clinical_ner</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">ner_chunk_embeddings</span><span class="o">,</span>
    <span class="n">ner_chunk_tokenizer</span><span class="o">,</span>
    <span class="n">ner_snomed_resolver</span><span class="o">,</span>

    <span class="n">icdo_ner</span><span class="o">,</span>
    <span class="n">icdo_chunk</span><span class="o">,</span>
    <span class="n">icdo_chunk_embeddings</span><span class="o">,</span>
    <span class="n">icdo_chunk_resolver</span>
<span class="o">))</span>
<span class="k">val</span> <span class="nv">pipelineModelFull</span> <span class="k">=</span> <span class="nv">pipelineFull</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipelineModelFull</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(snomed_result)")</span>
<span class="c1">//   .selectExpr(</span>
<span class="c1">//     "col.metadata.target_text",</span>
<span class="c1">//     "col.metadata.resolved_text",</span>
<span class="c1">//     "col.metadata.confidence",</span>
<span class="c1">//     "col.metadata.all_k_results",</span>
<span class="c1">//     "col.metadata.all_k_resolutions")</span>
<span class="c1">//   .filter($"confidence" &gt; 0.2).show(5)</span>
<span class="c1">// +--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="c1">// |         target_text|       resolved_text|confidence|       all_k_results|   all_k_resolutions|</span>
<span class="c1">// +--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="c1">// |hypercholesterolemia|Hypercholesterolemia|    0.2524|13644009:::267432...|Hypercholesterole...|</span>
<span class="c1">// |                 CBC|             Neocyte|    0.4980|259680000:::11573...|Neocyte:::Blood g...|</span>
<span class="c1">// |                CD38|       Hypoviscosity|    0.2560|47872005:::370970...|Hypoviscosity:::E...|</span>
<span class="c1">// |           platelets| Increased platelets|    0.5267|6631009:::2596800...|Increased platele...|</span>
<span class="c1">// |                CD38|       Hypoviscosity|    0.2560|47872005:::370970...|Hypoviscosity:::E...|</span>
<span class="c1">// +--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="chunkfilterer">ChunkFilterer</h2>

  <div class="h3-box model-content">

    <p>Filters entities coming from CHUNK annotations. Filters can be set via a white list of terms or a regular expression.
White list criteria is enabled by default. To use regex, <code class="language-plaintext highlighter-rouge">criteria</code> has to be set to <code class="language-plaintext highlighter-rouge">regex</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT,CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunker_filterer/index.html#sparknlp_jsl.annotator.chunker.chunker_filterer.ChunkFilterer">ChunkFilterer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkFilterer">ChunkFilterer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Filtering POS tags
</span>
<span class="c1"># First pipeline stages to extract the POS tags are defined
</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Has a past history of gastroenteritis and stomach pain, however patient ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">chunker</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"pos"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"(&lt;NN&gt;)+"</span><span class="p">])</span>

<span class="c1"># Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.
</span><span class="n">chunkerFilter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"chunk"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"isin"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"gastroenteritis"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">docAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">posTagger</span><span class="p">,</span>
  <span class="n">chunker</span><span class="p">,</span>
  <span class="n">chunkerFilter</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(chunk)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                              <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="n">gastroenteritis</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span>                <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">42</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span> <span class="n">stomach</span> <span class="n">pain</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>                   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="n">patient</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">81</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="n">stomach</span> <span class="n">pain</span> <span class="n">now</span><span class="p">.</span><span class="n">We</span> <span class="n">don</span><span class="s">'t care, {sentence -&gt; 0, chunk -&gt; 4}, []}|
|{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []}              |
+---------------------------------------------------------------------------------+

result.selectExpr("explode(filtered)").show(truncate=False)
+-------------------------------------------------------------------+
|col                                                                |
+-------------------------------------------------------------------+
|{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []}  |
|{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []}|
+-------------------------------------------------------------------+
</span></code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Filtering POS tags
# First pipeline stages to extract the POS tags are defined
</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">chunker</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"pos"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"(&lt;NN&gt;)+"</span><span class="p">])</span>

<span class="c1"># Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.
</span><span class="n">chunkerFilter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"chunk"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"isin"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"gastroenteritis"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">docAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">posTagger</span><span class="p">,</span>
  <span class="n">chunker</span><span class="p">,</span>
  <span class="n">chunkerFilter</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Filtering POS tags
</span>
<span class="c1"># First pipeline stages to extract the POS tags are defined
</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">chunker</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"pos"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"(&lt;NN&gt;)+"</span><span class="p">])</span>

<span class="c1"># Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.
</span><span class="n">chunkerFilter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"chunk"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"isin"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"gastroenteritis"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">docAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">posTagger</span><span class="p">,</span>
  <span class="n">chunker</span><span class="p">,</span>
  <span class="n">chunkerFilter</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Filtering</span> <span class="nc">POS</span> <span class="n">tags</span>
<span class="c1">// First pipeline stages to extract the POS tags are defined</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Has a past history of gastroenteritis and stomach pain, however patient ..."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Chunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"pos"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"(&lt;NN&gt;)+"</span><span class="o">))</span>

<span class="c1">// Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.</span>
<span class="k">val</span> <span class="nv">chunkerFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">ChunkFilterer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"isin"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"gastroenteritis"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">docAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">posTagger</span><span class="o">,</span>
  <span class="n">chunker</span><span class="o">,</span>
  <span class="n">chunkerFilter</span><span class="o">))</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(chunk)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                              <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">11</span><span class="o">,</span> <span class="mi">17</span><span class="o">,</span> <span class="n">history</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">},</span> <span class="o">[]}</span>                        <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">22</span><span class="o">,</span> <span class="mi">36</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span>                <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">42</span><span class="o">,</span> <span class="mi">53</span><span class="o">,</span> <span class="n">stomach</span> <span class="n">pain</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="o">},</span> <span class="o">[]}</span>                   <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">64</span><span class="o">,</span> <span class="mi">70</span><span class="o">,</span> <span class="n">patient</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="o">},</span> <span class="o">[]}</span>                        <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">81</span><span class="o">,</span> <span class="mi">110</span><span class="o">,</span> <span class="n">stomach</span> <span class="n">pain</span> <span class="nv">now</span><span class="o">.</span><span class="py">We</span> <span class="n">don</span><span class="ss">'t</span> <span class="n">care</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">118</span><span class="o">,</span> <span class="mi">132</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="o">},</span> <span class="o">[]}</span>              <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------+</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(filtered)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">22</span><span class="o">,</span> <span class="mi">36</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span>  <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">118</span><span class="o">,</span> <span class="mi">132</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">+-------------------------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

</span><span class="nn">val</span> <span class="n">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Chunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"pos"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"(&lt;NN&gt;)+"</span><span class="o">))</span>

<span class="c1">// Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.</span>
<span class="k">val</span> <span class="nv">chunkerFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">ChunkFilterer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"isin"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"gastroenteritis"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">docAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">posTagger</span><span class="o">,</span>
  <span class="n">chunker</span><span class="o">,</span>
  <span class="n">chunkerFilter</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

</span><span class="nn">val</span> <span class="n">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Chunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"pos"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"(&lt;NN&gt;)+"</span><span class="o">))</span>

<span class="c1">// Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.</span>
<span class="k">val</span> <span class="nv">chunkerFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">ChunkFilterer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"isin"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"gastroenteritis"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">docAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">posTagger</span><span class="o">,</span>
  <span class="n">chunker</span><span class="o">,</span>
  <span class="n">chunkerFilter</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="chunkkeyphraseextraction">ChunkKeyPhraseExtraction</h2>

  <div class="h3-box model-content">

    <p>Chunk KeyPhrase Extraction uses Bert Sentence Embeddings to determine the most relevant key phrases describing a text. 
The input to the model consists of chunk annotations and sentence or document annotation. The model compares the chunks 
against the corresponding sentences/documents and selects the chunks which are most representative of the broader text 
context (i.e. the document or the sentence they belong to). The key phrases candidates (i.e. the input chunks) can be 
generated in various ways, e.g. by NGramGenerator, TextMatcher or NerConverter. The model operates either at sentence 
(selecting the most descriptive chunks from the sentence they belong to) or at document level. In the latter case, the 
key phrases are selected to represent all the input document annotations.</p>

    <p>This model is a subclass of [[BertSentenceEmbeddings]] and shares all parameters with it. It can load any pretrained
BertSentenceEmbeddings model. Available models can be found at the <a href="https://nlp.johnsnowlabs.com/models?task=Sentence+Embeddings">Models Hub</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunk_key_phrase_extraction/index.html#sparknlp_jsl.annotator.chunker.chunk_key_phrase_extraction.ChunkKeyPhraseExtraction">ChunkKeyPhraseExtraction</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkKeyPhraseExtraction">ChunkKeyPhraseExtraction</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span> \

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl_slim"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">key_phrase_extractor</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkKeyPhraseExtraction</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setTopN</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDocumentLevelProcessing</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDivergence</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_key_phrases"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">sparknlp</span><span class="p">.</span><span class="n">base</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span><span class="n">documenter</span><span class="p">,</span> <span class="n">sentencer</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">ner_tagger</span><span class="p">,</span> <span class="n">ner_converter</span><span class="p">,</span> <span class="n">key_phrase_extractor</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Her Diabetes has become type 2 in the last year with her Diabetes.He complains of swelling in his right forearm."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">results</span>\
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_chunk_key_phrases) AS key_phrase"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
        <span class="s">"key_phrase.result"</span><span class="p">,</span>
        <span class="s">"key_phrase.metadata.entity"</span><span class="p">,</span>
        <span class="s">"key_phrase.metadata.DocumentSimilarity"</span><span class="p">,</span>
        <span class="s">"key_phrase.metadata.MMRScore"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------+------------------+-------------------+</span>
<span class="o">|</span><span class="n">result</span>                       <span class="o">|</span><span class="n">DocumentSimilarity</span><span class="o">|</span><span class="n">MMRScore</span>           <span class="o">|</span>
<span class="o">+-----------------------------+------------------+-------------------+</span>
<span class="o">|</span><span class="n">gestational</span> <span class="n">diabetes</span> <span class="n">mellitus</span><span class="o">|</span><span class="mf">0.7391447825527298</span><span class="o">|</span><span class="mf">0.44348688715422274</span><span class="o">|</span>
<span class="o">|</span><span class="mi">28</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span>                  <span class="o">|</span><span class="mf">0.4366776288430703</span><span class="o">|</span><span class="mf">0.13577881610104517</span><span class="o">|</span>
<span class="o">|</span><span class="nb">type</span> <span class="n">two</span> <span class="n">diabetes</span> <span class="n">mellitus</span>   <span class="o">|</span><span class="mf">0.7323921930094919</span><span class="o">|</span><span class="mf">0.085800103824974</span>  <span class="o">|</span>
<span class="o">+-----------------------------+------------------+-------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">key_phrase_extractor</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkKeyPhraseExtraction</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setTopN</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDocumentLevelProcessing</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDivergence</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_key_phrases"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">sparknlp</span><span class="p">.</span><span class="n">base</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span><span class="n">documenter</span><span class="p">,</span> <span class="n">sentencer</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">ner_model</span><span class="p">,</span> <span class="n">ner_converter</span><span class="p">,</span> <span class="n">key_phrase_extractor</span><span class="p">])</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span> \

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">key_phrase_extractor</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkKeyPhraseExtraction</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setTopN</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDocumentLevelProcessing</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDivergence</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_key_phrases"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">sparknlp</span><span class="p">.</span><span class="n">base</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setStages</span><span class="p">([</span><span class="n">documenter</span><span class="p">,</span> <span class="n">sentencer</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">ner_model</span><span class="p">,</span> <span class="n">ner_converter</span><span class="p">,</span> <span class="n">key_phrase_extractor</span><span class="p">])</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">*

</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopWordsCleaner</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">StopWordsCleaner</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"clean_tokens"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nGrams</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NGramGenerator</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"clean_tokens"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">chunkKeyPhraseExtractor</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">ChunkKeyPhraseExtraction</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setTopN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDivergence</span><span class="o">(</span><span class="mf">0.7f</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"ngrams"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"key_phrases"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">stopWordsCleaner</span><span class="o">,</span>
    <span class="n">nGrams</span><span class="o">,</span>
    <span class="n">chunkKeyPhraseExtractor</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">sampleText</span> <span class="k">=</span> <span class="s">"Her Diabetes has become type 2 in the last year with her Diabetes."</span> <span class="o">+</span>
    <span class="s">" He complains of swelling in his right forearm."</span>

<span class="k">val</span> <span class="nv">testDataset</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">""</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">emptyDataset</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">testDataset</span><span class="o">)</span>

<span class="n">result</span>
    <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(key_phrases) AS key_phrase"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span>
        <span class="s">"key_phrase.result"</span><span class="o">,</span>
        <span class="s">"key_phrase.metadata.DocumentSimilarity"</span><span class="o">,</span>
        <span class="s">"key_phrase.metadata.MMRScore"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>

<span class="o">+--------------------------+-------------------+------------------+</span>
<span class="o">|</span><span class="n">result</span>                    <span class="o">|</span><span class="nc">DocumentSimilarity</span> <span class="o">|</span><span class="nc">MMRScore</span>          <span class="o">|</span>
<span class="o">+--------------------------+-------------------+------------------+</span>
<span class="o">|</span><span class="n">complains</span> <span class="n">swelling</span> <span class="n">forearm</span><span class="o">|</span><span class="mf">0.6325718954229369</span> <span class="o">|</span><span class="mf">0.1897715761677257</span><span class="o">|</span>
<span class="o">|</span><span class="k">type</span> <span class="err">2</span> <span class="kt">year</span>               <span class="kt">|</span><span class="err">0</span><span class="kt">.</span><span class="err">40181028931546364</span><span class="kt">|-</span><span class="err">0</span><span class="kt">.</span><span class="err">189501077108947</span><span class="kt">|</span>
<span class="kt">+--------------------------+-------------------+------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">*

</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopWordsCleaner</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">StopWordsCleaner</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"clean_tokens"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nGrams</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NGramGenerator</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"clean_tokens"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">chunkKeyPhraseExtractor</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">ChunkKeyPhraseExtraction</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setTopN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDivergence</span><span class="o">(</span><span class="mf">0.7f</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"ngrams"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"key_phrases"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">stopWordsCleaner</span><span class="o">,</span>
    <span class="n">nGrams</span><span class="o">,</span>
    <span class="n">chunkKeyPhraseExtractor</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">*

</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopWordsCleaner</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">StopWordsCleaner</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"clean_tokens"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nGrams</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NGramGenerator</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"clean_tokens"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">chunkKeyPhraseExtractor</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">ChunkKeyPhraseExtraction</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setTopN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDivergence</span><span class="o">(</span><span class="mf">0.7f</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"ngrams"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"key_phrases"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">stopWordsCleaner</span><span class="o">,</span>
    <span class="n">nGrams</span><span class="o">,</span>
    <span class="n">chunkKeyPhraseExtractor</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="chunkmapper">ChunkMapper</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>We can use ChunkMapper to map entities with their associated code/reference based on pre-defined dictionaries.</p>

    <p>This is the AnnotatorApproach of the ChunkMapper, which can be used to train ChunkMapper models by giving a custom mapping dictionary. To use pretriained models, check the documentation of the <a href="https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#chunkmappermodel">ChunkMapperModel</a> annotator.</p>

    <p>The annotator also allows using fuzzy matching, which can take into consideration parts of the tokens tha can map even when word order is different, char ngrams that can map even when thre are typos, and using fuzzy distance metric (Jaccard, Levenshtein, etc.).</p>

    <p>Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb">Healthcare Chunk Mapping</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">LABEL_DEPENDENCY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunkmapper/index.html#sparknlp_jsl.annotator.chunker.chunkmapper.ChunkMapperApproach">ChunkMapperApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/finance/chunk_classification/resolution/ChunkMapperApproach.html">ChunkMapperApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># First, create a dictionay in JSON format following this schema:
</span><span class="kn">import</span> <span class="nn">json</span>

<span class="n">data_set</span><span class="o">=</span> <span class="p">{</span>
  <span class="s">"mappings"</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s">"key"</span><span class="p">:</span> <span class="s">"metformin"</span><span class="p">,</span>
      <span class="s">"relations"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
          <span class="s">"key"</span><span class="p">:</span> <span class="s">"action"</span><span class="p">,</span>
          <span class="s">"values"</span> <span class="p">:</span> <span class="p">[</span><span class="s">"hypoglycemic"</span><span class="p">,</span> <span class="s">"Drugs Used In Diabetes"</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="p">{</span>
          <span class="s">"key"</span><span class="p">:</span> <span class="s">"treatment"</span><span class="p">,</span>
          <span class="s">"values"</span> <span class="p">:</span> <span class="p">[</span><span class="s">"diabetes"</span><span class="p">,</span> <span class="s">"t2dm"</span><span class="p">]</span>
        <span class="p">}]</span>
    <span class="p">}]</span>
<span class="p">}</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'sample_drug.json'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data_set</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>


<span class="c1"># Create a pipeline
</span>
<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1">#NER model to detect drug in the text
</span><span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology_small"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
	    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span>\
	    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setLabelCasing</span><span class="p">(</span><span class="s">"upper"</span><span class="p">)</span>
 
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"DRUG"</span><span class="p">])</span>

<span class="n">chunkerMapper</span> <span class="o">=</span> <span class="n">ChunkMapperApproach</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"mappings"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"sample_drug.json"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setRels</span><span class="p">([</span><span class="s">"action"</span><span class="p">])</span> <span class="c1">#or treatment
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">word_embeddings</span><span class="p">,</span>
        <span class="n">clinical_ner</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">chunkerMapper</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>


<span class="c1"># Train the model
</span>
<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s">"The patient was given 1 unit of metformin daily."</span><span class="p">]</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">text</span><span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>We can use ChunkMapper to map entities with their associated code/reference based on pre-defined dictionaries.</p>

    <p>This is the AnnotatorModel of the ChunkMapper, which can be used to access pretrained models with the <code class="language-plaintext highlighter-rouge">.pretrained()</code> or <code class="language-plaintext highlighter-rouge">.load()</code> methods. To train a new model, check the documentation of the <a href="https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#chunkmapperapproach">ChunkMapperApproach</a> annotator.</p>

    <p>The annotator also allows using fuzzy matching, which can take into consideration parts of the tokens tha can map even when word order is different, char ngrams that can map even when thre are typos, and using fuzzy distance metric (Jaccard, Levenshtein, etc.).</p>

    <p>Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb">Healthcare Chunk Mapping</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">LABEL_DEPENDENCY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunkmapper/index.html#sparknlp_jsl.annotator.chunker.chunkmapper.ChunkMapperModel">ChunkMapperModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/finance/chunk_classification/resolution/ChunkMapperModel.html">ChunkMapperModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Use `rxnorm_mapper` pretrained model to map entities with their corresponding RxNorm codes.
</span>
<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">chunkerMapper</span> <span class="o">=</span> <span class="n">ChunkMapperModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"rxnorm_mapper"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"rxnorm"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRels</span><span class="p">([</span><span class="s">"rxnorm_code"</span><span class="p">])</span>

<span class="n">mapper_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">chunkerMapper</span><span class="p">])</span>

<span class="n">empty_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">''</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>
<span class="n">mapper_model</span> <span class="o">=</span> <span class="n">mapper_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_df</span><span class="p">)</span>

<span class="n">mapper_lp</span> <span class="o">=</span> <span class="n">LightPipeline</span><span class="p">(</span><span class="n">mapper_model</span><span class="p">)</span>
<span class="n">mapper_lp</span><span class="p">.</span><span class="n">fullAnnotate</span><span class="p">(</span><span class="s">"metformin"</span><span class="p">)</span>

<span class="p">[{</span><span class="s">'ner_chunk'</span><span class="p">:</span> <span class="p">[</span><span class="n">Annotation</span><span class="p">(</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">metformin</span><span class="p">,</span> <span class="p">{})],</span>
  <span class="s">'rxnorm'</span><span class="p">:</span> <span class="p">[</span><span class="n">Annotation</span><span class="p">(</span><span class="n">labeled_dependency</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6809</span><span class="p">,</span> <span class="p">{</span><span class="s">'entity'</span><span class="p">:</span> <span class="s">'metformin'</span><span class="p">,</span> <span class="s">'relation'</span><span class="p">:</span> <span class="s">'rxnorm_code'</span><span class="p">,</span> <span class="s">'all_relations'</span><span class="p">:</span> <span class="s">''</span><span class="p">})]}]</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkerMapper</span> <span class="k">=</span> <span class="nv">ChunkMapperModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"rxnorm_mapper"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">ner_chunk</span><span class="err">"</span><span class="o">])\</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"rxnorm"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setRels</span><span class="o">([</span><span class="err">"</span><span class="kt">rxnorm_code</span><span class="err">"</span><span class="o">])</span>

<span class="n">mapper_pipeline</span> <span class="k">=</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">([</span><span class="kt">document_assembler</span>, <span class="kt">chunkerMapper</span><span class="o">])</span>

<span class="n">empty_df</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">([[</span><span class="kt">''</span><span class="o">]]).</span><span class="py">toDF</span><span class="o">(</span><span class="ss">'tex</span><span class="n">t</span><span class="o">')</span>
<span class="n">mapper_model</span> <span class="k">=</span> <span class="nv">mapper_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">empty_df</span><span class="o">)</span>

<span class="n">mapper_lp</span> <span class="k">=</span> <span class="nc">LightPipeline</span><span class="o">(</span><span class="n">mapper_model</span><span class="o">)</span>
<span class="nv">mapper_lp</span><span class="o">.</span><span class="py">fullAnnotate</span><span class="o">(</span><span class="s">"metformin"</span><span class="o">)</span>

<span class="o">[{</span><span class="kt">'ner_chunk':</span> <span class="o">[</span><span class="kt">Annotation</span><span class="o">(</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">8</span>, <span class="kt">metformin</span>, <span class="o">{})]</span>,
  <span class="kt">'rxnorm':</span> <span class="o">[</span><span class="kt">Annotation</span><span class="o">(</span><span class="kt">labeled_dependency</span>, <span class="err">0</span>, <span class="err">8</span>, <span class="err">6809</span>, <span class="o">{</span><span class="kt">'entity':</span> <span class="kt">'metformin'</span>, <span class="kt">'relation':</span> <span class="kt">'rxnorm_code'</span>, <span class="kt">'all_relations':</span> <span class="kt">''</span><span class="o">})]}]</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="chunkmapperfilterer">ChunkMapperFilterer</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p><strong>Input Annotator Types:</strong> ``</p>

    <p><strong>Output Annotator Type:</strong> ``</p>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p><code class="language-plaintext highlighter-rouge">ChunkMapperFilterer</code> is an annotator to be used after <code class="language-plaintext highlighter-rouge">ChunkMapper</code> that allows to filter chunks based on the results of the mapping, whether it was successful or failed.</p>

    <p>Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb">Healthcare Chunk Mapping</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, LABEL_DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunkmapper_filterer/index.html#sparknlp_jsl.annotator.chunker.chunkmapper_filterer.ChunkMapperFilterer">ChunkMapperFilterer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkMapperFilterer.html">ChunkMapperFilterer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology_greedy"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">chunkerMapper</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ChunkMapperModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"rxnorm_mapper"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"RxNorm_Mapper"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setRel</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">cfModel</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ChunkMapperFilterer</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">,</span> <span class="s">"RxNorm_Mapper"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunks_fail"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setReturnCriteria</span><span class="p">(</span><span class="s">"fail"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">chunk2doc</span> <span class="o">=</span> <span class="n">Chunk2Doc</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"chunks_fail"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"doc_chunk"</span><span class="p">)</span>

<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span>
        <span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"doc_chunk"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">resolver</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span>
        <span class="s">"sbiobertresolve_rxnorm_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunks_fail"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"resolver_code"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">resolverMerger</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ResolverMerger</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"resolver_code"</span><span class="p">,</span> <span class="s">"RxNorm_Mapper"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"RxNorm"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">mapper_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">word_embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">chunkerMapper</span><span class="p">,</span>
        <span class="n">chunkerMapper</span><span class="p">,</span>
        <span class="n">cfModel</span><span class="p">,</span>
        <span class="n">chunk2doc</span><span class="p">,</span>
        <span class="n">sbert_embedder</span><span class="p">,</span>
        <span class="n">resolver</span><span class="p">,</span>
        <span class="n">resolverMerger</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">mapper_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>


<span class="n">samples</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s">"The patient was given Adapin 10 MG, coumadn 5 mg"</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"The patient was given Avandia 4 mg, Tegretol, zitiga"</span><span class="p">],</span>
<span class="p">]</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">samples</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"chunk.result as chunk"</span><span class="p">,</span>
    <span class="s">"RxNorm_Mapper.result as RxNorm_Mapper"</span><span class="p">,</span>
    <span class="s">"chunks_fail.result as chunks_fail"</span><span class="p">,</span>
    <span class="s">"resolver_code.result as resolver_code"</span><span class="p">,</span>
    <span class="s">"RxNorm.result as RxNorm"</span><span class="p">,</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------+----------------------+--------------+-------------+------------------------+</span>
<span class="n">chunk</span>                           <span class="o">|</span><span class="n">RxNorm_Mapper</span>         <span class="o">|</span><span class="n">chunks_fail</span>   <span class="o">|</span><span class="n">resolver_code</span><span class="o">|</span><span class="n">RxNorm</span>                  <span class="o">|</span>
<span class="o">+--------------------------------+----------------------+--------------+-------------+------------------------+</span>
<span class="p">[</span><span class="n">Adapin</span> <span class="mi">10</span> <span class="n">MG</span><span class="p">,</span> <span class="n">coumadn</span> <span class="mi">5</span> <span class="n">mg</span><span class="p">]</span>    <span class="o">|</span><span class="p">[</span><span class="mi">1000049</span><span class="p">,</span> <span class="n">NONE</span><span class="p">]</span>       <span class="o">|</span><span class="p">[</span><span class="n">coumadn</span> <span class="mi">5</span> <span class="n">mg</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="mi">200883</span><span class="p">]</span>     <span class="o">|</span><span class="p">[</span><span class="mi">1000049</span><span class="p">,</span> <span class="mi">200883</span><span class="p">]</span>       <span class="o">|</span>
<span class="p">[</span><span class="n">Avandia</span> <span class="mi">4</span> <span class="n">mg</span><span class="p">,</span> <span class="n">Tegretol</span><span class="p">,</span> <span class="n">zitiga</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="mi">261242</span><span class="p">,</span> <span class="mi">203029</span><span class="p">,</span> <span class="n">NONE</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">zitiga</span><span class="p">]</span>      <span class="o">|</span><span class="p">[</span><span class="mi">220989</span><span class="p">]</span>     <span class="o">|</span><span class="p">[</span><span class="mi">261242</span><span class="p">,</span> <span class="mi">203029</span><span class="p">,</span> <span class="mi">220989</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------------+----------------------+--------------+-------------+------------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="chunkmerge">ChunkMerge</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Merges two chunk columns coming from two annotators(NER, ContextualParser or any other annotator producing
chunks). The merger of the two chunk columns is made by selecting one chunk from one of the columns according
to certain criteria.
The decision on which chunk to select is made according to the chunk indices in the source document.
(chunks with longer lengths and highest information will be kept from each source)
Labels can be changed by setReplaceDictResource.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/merge/chunk_merge/index.html#sparknlp_jsl.annotator.merge.chunk_merge.ChunkMergeApproach">ChunkMergeApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/merge/ChunkMergeApproach">ChunkMergeApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Define a pipeline with 2 different NER models with a ChunkMergeApproach at the end
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
 <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">),</span>
 <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
 <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">),</span>
  <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embs"</span><span class="p">),</span>
  <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"jsl_ner"</span><span class="p">),</span>
 <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"jsl_ner"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"jsl_ner_chunk"</span><span class="p">),</span>
  <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_bionlp"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bionlp_ner"</span><span class="p">),</span>
 <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"bionlp_ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bionlp_ner_chunk"</span><span class="p">),</span>
 <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"jsl_ner_chunk"</span><span class="p">,</span> <span class="s">"bionlp_ner_chunk"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"merged_chunk"</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(merged_chunk) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span><span class="s">"a.end"</span><span class="p">,</span><span class="s">"a.result as chunk"</span><span class="p">,</span><span class="s">"a.metadata.entity as entity"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+-----+---+-----------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">chunk</span>      <span class="o">|</span><span class="n">entity</span>   <span class="o">|</span>
<span class="o">+-----+---+-----------+---------+</span>
<span class="o">|</span><span class="mi">5</span>    <span class="o">|</span><span class="mi">15</span> <span class="o">|</span><span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">|</span><span class="n">Age</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">17</span>   <span class="o">|</span><span class="mi">19</span> <span class="o">|</span><span class="n">man</span>        <span class="o">|</span><span class="n">Gender</span>   <span class="o">|</span>
<span class="o">|</span><span class="mi">64</span>   <span class="o">|</span><span class="mi">72</span> <span class="o">|</span><span class="n">recurrent</span>  <span class="o">|</span><span class="n">Modifier</span> <span class="o">|</span>
<span class="o">|</span><span class="mi">98</span>   <span class="o">|</span><span class="mi">107</span><span class="o">|</span><span class="n">cellulitis</span> <span class="o">|</span><span class="n">Diagnosis</span><span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">pneumonias</span> <span class="o">|</span><span class="n">Diagnosis</span><span class="o">|</span>
<span class="o">+-----+---+-----------+---------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">bert_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">fin_ner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finner_deid'</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter</span> <span class="o">=</span>  <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ORG"</span><span class="p">:</span> <span class="s">"PARTY"</span><span class="p">})</span> <span class="c1"># Replace "ORG" entity as "PARTY"
</span>
<span class="n">ner_finner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_org_per_role_date"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"bert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_finner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter_finner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_finner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_finner_chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">'ROLE'</span><span class="p">])</span> <span class="c1"># Just use "ROLE" entity from this NER
</span>
<span class="n">chunk_merge</span> <span class="o">=</span>  <span class="n">finance</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_finner_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_merged_chunk"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">bert_embeddings</span><span class="p">,</span>
      <span class="n">fin_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_finner</span><span class="p">,</span>
      <span class="n">ner_converter_finner</span><span class="p">,</span>
      <span class="n">chunk_merge</span><span class="p">])</span>

<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">deid_merged_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">deid_merged_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span> \
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------+---------+</span>
<span class="o">|</span><span class="n">chunk</span>                <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+---------------------+---------+</span>
<span class="o">|</span><span class="n">Jeffrey</span> <span class="n">Preston</span> <span class="n">Bezos</span><span class="o">|</span><span class="n">PERSON</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">founder</span>              <span class="o">|</span><span class="n">ROLE</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">CEO</span>                  <span class="o">|</span><span class="n">ROLE</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">Amazon</span>               <span class="o">|</span><span class="n">PARTY</span>    <span class="o">|</span>
<span class="o">+---------------------+---------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"ENTIRE AGREEMENT.  This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter.

2THEMART.COM, INC.:                         I-ESCROW, INC.:

By:Dominic J. Magliarditi                By:Sanjay Bajaj Name: Dominic J. Magliarditi                Name: Sanjay Bajaj Title: President                            Title: VP Business Development Date: 6/21/99                               Date: 6/11/99 "</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">legal_ner</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ALIAS"</span><span class="p">:</span> <span class="s">"PARTY"</span><span class="p">})</span>

<span class="n">ner_signers</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_signers"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_signers"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter_signers</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_signers"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_signer_chunk"</span><span class="p">)</span>

<span class="n">chunk_merge</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_signer_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_merged_chunk"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">legal_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_signers</span><span class="p">,</span>
      <span class="n">ner_converter_signers</span><span class="p">,</span>
      <span class="n">chunk_merge</span><span class="p">])</span>

<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">deid_merged_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">deid_merged_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span> \
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------+--------------+</span>
<span class="o">|</span><span class="n">chunk</span>                  <span class="o">|</span><span class="n">ner_label</span>     <span class="o">|</span>
<span class="o">+-----------------------+--------------+</span>
<span class="o">|</span><span class="n">ENTIRE</span> <span class="n">AGREEMENT</span>       <span class="o">|</span><span class="n">DOC</span>           <span class="o">|</span>
<span class="o">|</span><span class="n">INC</span>                    <span class="o">|</span><span class="n">PARTY</span>         <span class="o">|</span>
<span class="o">|</span><span class="n">J</span><span class="p">.</span> <span class="n">Magliarditi</span>         <span class="o">|</span><span class="n">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">Bajaj</span>                  <span class="o">|</span><span class="n">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">Dominic</span> <span class="n">J</span><span class="p">.</span> <span class="n">Magliarditi</span> <span class="o">|</span><span class="n">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">Sanjay</span> <span class="n">Bajaj</span>           <span class="o">|</span><span class="n">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">President</span>              <span class="o">|</span><span class="n">SIGNING_TITLE</span> <span class="o">|</span>
<span class="o">|</span><span class="n">VP</span> <span class="n">Business</span> <span class="n">Development</span><span class="o">|</span><span class="n">SIGNING_TITLE</span> <span class="o">|</span>
<span class="o">+-----------------------+--------------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">*

// </span><span class="nn">Define</span> <span class="n">a</span> <span class="n">pipeline</span> <span class="k">with</span> <span class="mi">2</span> <span class="n">different</span> <span class="nc">NER</span> <span class="n">models</span> <span class="k">with</span> <span class="n">a</span> <span class="nc">ChunkMergeApproach</span> <span class="n">at</span> <span class="n">the</span> <span class="n">end</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">),</span>
  <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">),</span>
  <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">),</span>
  <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">).</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embs"</span><span class="o">),</span>
  <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embs"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"jsl_ner"</span><span class="o">),</span>
  <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"jsl_ner"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"jsl_ner_chunk"</span><span class="o">),</span>
  <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_bionlp"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embs"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bionlp_ner"</span><span class="o">),</span>
  <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"bionlp_ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bionlp_ner_chunk"</span><span class="o">),</span>
  <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">ChunkMergeApproach</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"jsl_ner_chunk"</span><span class="o">,</span> <span class="s">"bionlp_ner_chunk"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"merged_chunk"</span><span class="o">)</span>
<span class="o">))</span>

<span class="c1">// Show results</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(merged_chunk) as a"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"a.begin"</span><span class="o">,</span><span class="s">"a.end"</span><span class="o">,</span><span class="s">"a.result as chunk"</span><span class="o">,</span><span class="s">"a.metadata.entity as entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+-----+---+-----------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">chunk</span>      <span class="o">|</span><span class="n">entity</span>   <span class="o">|</span>
<span class="o">+-----+---+-----------+---------+</span>
<span class="o">|</span><span class="mi">5</span>    <span class="o">|</span><span class="mi">15</span> <span class="o">|</span><span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">|</span><span class="nc">Age</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">17</span>   <span class="o">|</span><span class="mi">19</span> <span class="o">|</span><span class="n">man</span>        <span class="o">|</span><span class="nc">Gender</span>   <span class="o">|</span>
<span class="o">|</span><span class="mi">64</span>   <span class="o">|</span><span class="mi">72</span> <span class="o">|</span><span class="n">recurrent</span>  <span class="o">|</span><span class="nc">Modifier</span> <span class="o">|</span>
<span class="o">|</span><span class="mi">98</span>   <span class="o">|</span><span class="mi">107</span><span class="o">|</span><span class="n">cellulitis</span> <span class="o">|</span><span class="nc">Diagnosis</span><span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">pneumonias</span> <span class="o">|</span><span class="nc">Diagnosis</span><span class="o">|</span>
<span class="o">+-----+---+-----------+---------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">*

</span><span class="nn">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon"</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">bert_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">fin_ner</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'finner_dei</span><span class="n">d</span><span class="o">',</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span>  <span class="nv">finance</span><span class="o">.</span><span class="py">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">({</span><span class="s">"ORG"</span><span class="k">:</span> <span class="err">"</span><span class="kt">PARTY</span><span class="err">"</span><span class="o">})</span> <span class="k">#</span> <span class="nc">Replace</span> <span class="s">"ORG"</span> <span class="n">entity</span> <span class="n">as</span> <span class="s">"PARTY"</span>

<span class="k">val</span> <span class="nv">ner_finner</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_org_per_role_date"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"bert_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_finner"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_finner</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_finner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_finner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">([</span><span class="kt">'ROLE'</span><span class="o">])</span> <span class="k">#</span> <span class="nc">Just</span> <span class="n">use</span> <span class="s">"ROLE"</span> <span class="n">entity</span> <span class="n">from</span> <span class="k">this</span> <span class="nc">NER</span>

<span class="k">val</span> <span class="nv">chunk_merge</span> <span class="k">=</span>  <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">ChunkMergeApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_finner_chunk"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_merged_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span> 
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">embeddings</span><span class="o">,</span>
      <span class="n">bert_embeddings</span><span class="o">,</span>
      <span class="n">fin_ner</span><span class="o">,</span>
      <span class="n">ner_converter</span><span class="o">,</span>
      <span class="n">ner_finner</span><span class="o">,</span>
      <span class="n">ner_converter_finner</span><span class="o">,</span>
      <span class="n">chunk_merge</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">*

</span><span class="nn">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"ENTIRE AGREEMENT.  This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter.

2THEMART.COM, INC.:                         I-ESCROW, INC.:

By:Dominic J. Magliarditi                By:Sanjay Bajaj Name: Dominic J. Magliarditi                Name: Sanjay Bajaj Title: President                            Title: VP Business Development Date: 6/21/99                               Date: 6/11/99 "</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">legal_ner</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">({</span><span class="s">"ALIAS"</span><span class="k">:</span> <span class="err">"</span><span class="kt">PARTY</span><span class="err">"</span><span class="o">})</span>

<span class="k">val</span> <span class="nv">ner_signers</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_signers"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_signers"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_signers</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_signers"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_signer_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk_merge</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">ChunkMergeApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_signer_chunk"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_merged_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span> 
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">embeddings</span><span class="o">,</span>
      <span class="n">legal_ner</span><span class="o">,</span>
      <span class="n">ner_converter</span><span class="o">,</span>
      <span class="n">ner_signers</span><span class="o">,</span>
      <span class="n">ner_converter_signers</span><span class="o">,</span>
      <span class="n">chunk_merge</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Merges entities coming from different CHUNK annotations</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/merge/chunk_merge/index.html#sparknlp_jsl.annotator.merge.chunk_merge.ChunkMergeModel">ChunkMergeModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/merge/ChunkMergeModel">ChunkMergeModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box">

  <h2 id="chunksentencesplitter">ChunkSentenceSplitter</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p><strong>Input Annotator Types:</strong> ``</p>

    <p><strong>Output Annotator Type:</strong> ``</p>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p><code class="language-plaintext highlighter-rouge">ChunkSentenceSplitter</code> annotator can split the documents into chunks according to separators given as <code class="language-plaintext highlighter-rouge">CHUNK</code> columns. It is useful when you need to perform different models or analysis in different sections of your document (for example, for different headers, clauses, items, etc.). The given separator chunk can be the output from, for example, <a href="https://nlp.johnsnowlabs.com/docs/en/annotators#regexmatcher">RegexMatcher</a> or <a href="https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#nermodel">NerModel</a>.</p>

    <p>For detailed usage of this annotator, visit <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/18.Chunk_Sentence_Splitter.ipynb">this notebook</a> from our <code class="language-plaintext highlighter-rouge">Spark NLP Workshop</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunk_sentence_splitter/index.html#sparknlp_jsl.annotator.chunker.chunk_sentence_splitter.ChunkSentenceSplitter">ChunkSentenceSplitter</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkSentenceSplitter.html">ChunkSentenceSplitter</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Defining the pipeline
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">MedicalBertForTokenClassifier</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span>
        <span class="s">"bert_token_classifier_ner_jsl_slim"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">NerConverter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Header"</span><span class="p">])</span>
<span class="p">)</span>

<span class="n">chunkSentenceSplitter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ChunkSentenceSplitter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"paragraphs"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setGroupBySentences</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">tokenClassifier</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">chunkSentenceSplitter</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">empty_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">pipeline_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_df</span><span class="p">)</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span>
        <span class="s">"""ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelioma.
        PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma.
        REVIEW OF SYSTEMS Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface.
    """</span>
    <span class="p">]</span>
<span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sentences</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">paragraphs</span> <span class="o">=</span> <span class="n">pipeline_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
 <span class="n">paragraphs</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(paragraphs) as result"</span><span class="p">).</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"result.result"</span><span class="p">,</span><span class="s">"result.metadata.entity"</span><span class="p">,</span> <span class="s">"result.metadata.splitter_chunk"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------+------+-------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span><span class="n">entity</span><span class="o">|</span>     <span class="n">splitter_chunk</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------+-------------------+</span>
<span class="o">|</span><span class="n">ADMISSION</span> <span class="n">DIAGNOSIS</span> <span class="n">Right</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="ow">and</span> <span class="n">suspected</span> <span class="n">malignant</span> <span class="n">mesothelio</span><span class="p">...</span><span class="o">|</span><span class="n">Header</span><span class="o">|</span><span class="n">ADMISSION</span> <span class="n">DIAGNOSIS</span><span class="o">|</span>
<span class="o">|</span><span class="n">PRINCIPAL</span> <span class="n">DIAGNOSIS</span> <span class="n">Right</span> <span class="n">pleural</span> <span class="n">effusion</span><span class="p">,</span> <span class="n">suspected</span> <span class="n">malignant</span> <span class="n">mesothelioma</span><span class="p">....</span><span class="o">|</span><span class="n">Header</span><span class="o">|</span><span class="n">PRINCIPAL</span> <span class="n">DIAGNOSIS</span><span class="o">|</span>
<span class="o">|</span><span class="n">REVIEW</span> <span class="n">OF</span> <span class="n">SYSTEMS</span> <span class="n">Right</span> <span class="n">pleural</span> <span class="n">effusion</span><span class="p">,</span> <span class="n">firm</span> <span class="n">nodules</span><span class="p">,</span> <span class="n">diffuse</span> <span class="n">scattered</span> <span class="n">thr</span><span class="p">...</span><span class="o">|</span><span class="n">Header</span><span class="o">|</span>  <span class="n">REVIEW</span> <span class="n">OF</span> <span class="n">SYSTEMS</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------+-------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">,</span><span class="n">text</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"doc"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">regexMatcher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexMatcher</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"doc"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunks"</span><span class="o">).</span><span class="py">setExternalRules</span><span class="o">(</span><span class="s">"src/test/resources/chunker/title_regex.txt"</span><span class="o">,</span><span class="s">","</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">chunkSentenceSplitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkSentenceSplitter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"chunks"</span><span class="o">,</span><span class="s">"doc"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"paragraphs"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span><span class="n">regexMatcher</span><span class="o">,</span><span class="n">chunkSentenceSplitter</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">select</span><span class="o">(</span><span class="s">"paragraphs"</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="contextualparser">ContextualParser</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Creates a model, that extracts entity from a document based on user defined rules.
Rule matching is based on a RegexMatcher defined in a JSON file. It is set through the parameter setJsonPath()
In this JSON file, regex is defined that you want to match along with the information that will output on metadata
field. Additionally, a dictionary can be provided with <code class="language-plaintext highlighter-rouge">setDictionary</code> to map extracted entities
to a unified representation. The first column of the dictionary file should be the representation with following
columns the possible matches.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/context/contextual_parser/index.html#sparknlp_jsl.annotator.context.contextual_parser.ContextualParserApproach">ContextualParserApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/context/ContextualParserApproach">ContextualParserApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># An example JSON file `regex_token.json` can look like this:
#
# {
#    "entity": "Stage",
#    "ruleScope": "sentence",
#    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",
#    "matchScope": "token"
#  }
#
# Which means to extract the stage code on a sentence level.
# An example pipeline could then be defined like this
# Pipeline could then be defined like this
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Define the parser (json file needs to be provided)
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... "</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">contextualParser</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ContextualParserApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setJsonPath</span><span class="p">(</span><span class="s">"/path/to/regex_token.json"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setContextMatch</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">contextualParser</span>
  <span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show Results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(entity)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                                                                      <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="n">pT1bN0M0</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">T5</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>         <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">148</span><span class="p">,</span> <span class="mi">156</span><span class="p">,</span> <span class="n">cT4bcN2M1</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">189</span><span class="p">,</span> <span class="mi">194</span><span class="p">,</span> <span class="n">T</span><span class="err">?</span><span class="n">N3M1</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">316</span><span class="p">,</span> <span class="mi">323</span><span class="p">,</span> <span class="n">pT1bN0M0</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># An example JSON file `regex_token.json` can look like this:
#
# {
#    "entity": "Stage",
#    "ruleScope": "sentence",
#    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",
#    "matchScope": "token"
#  }
#
# Which means to extract the stage code on a sentence level.
# An example pipeline could then be defined like this
# Pipeline could then be defined like this
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Define the parser (json file needs to be provided)
</span>
<span class="n">contextualParser</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ContextualParserApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setJsonPath</span><span class="p">(</span><span class="s">"/path/to/regex_token.json"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setContextMatch</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">contextualParser</span>
  <span class="p">])</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># An example JSON file `regex_token.json` can look like this:
#
# {
#    "entity": "Stage",
#    "ruleScope": "sentence",
#    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",
#    "matchScope": "token"
#  }
#
# Which means to extract the stage code on a sentence level.
# An example pipeline could then be defined like this
# Pipeline could then be defined like this
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Define the parser (json file needs to be provided)
</span>
<span class="n">contextualParser</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ContextualParserApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setJsonPath</span><span class="p">(</span><span class="s">"/path/to/regex_token.json"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setContextMatch</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">contextualParser</span>
  <span class="p">])</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">An</span> <span class="n">example</span> <span class="nc">JSON</span> <span class="n">file</span> <span class="n">`regex_token.json`</span> <span class="n">can</span> <span class="n">look</span> <span class="n">like</span> <span class="k">this:</span>
<span class="c1">//</span>
<span class="c1">// {</span>
<span class="c1">//    "entity": "Stage",</span>
<span class="c1">//    "ruleScope": "sentence",</span>
<span class="c1">//    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",</span>
<span class="c1">//    "matchScope": "token"</span>
<span class="c1">//  }</span>
<span class="c1">//</span>
<span class="c1">// Which means to extract the stage code on a sentence level.</span>
<span class="c1">// An example pipeline could then be defined like this</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Define the parser (json file needs to be provided)</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... "</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">contextualParser</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">ContextualParserApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setJsonPath</span><span class="o">(</span><span class="s">"/path/to/regex_token.json"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setContextMatch</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">contextualParser</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show Results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(entity)").show(5, truncate=false)</span>
<span class="c1">// +-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |col                                                                                                                      |</span>
<span class="c1">// +-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |{chunk, 32, 39, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []}   |</span>
<span class="c1">// |{chunk, 49, 50, T5, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []}         |</span>
<span class="c1">// |{chunk, 148, 156, cT4bcN2M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 1}, []}|</span>
<span class="c1">// |{chunk, 189, 194, T?N3M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 2}, []}   |</span>
<span class="c1">// |{chunk, 316, 323, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 3}, []} |</span>
<span class="c1">// +-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">An</span> <span class="n">example</span> <span class="nc">JSON</span> <span class="n">file</span> <span class="n">`regex_token.json`</span> <span class="n">can</span> <span class="n">look</span> <span class="n">like</span> <span class="k">this:</span>
<span class="c1">//</span>
<span class="c1">// {</span>
<span class="c1">//    "entity": "Stage",</span>
<span class="c1">//    "ruleScope": "sentence",</span>
<span class="c1">//    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",</span>
<span class="c1">//    "matchScope": "token"</span>
<span class="c1">//  }</span>
<span class="c1">//</span>
<span class="c1">// Which means to extract the stage code on a sentence level.</span>
<span class="c1">// An example pipeline could then be defined like this</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Define the parser (json file needs to be provided)</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... "</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">contextualParser</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">ContextualParserApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setJsonPath</span><span class="o">(</span><span class="s">"/path/to/regex_token.json"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setContextMatch</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">contextualParser</span>
  <span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">An</span> <span class="n">example</span> <span class="nc">JSON</span> <span class="n">file</span> <span class="n">`regex_token.json`</span> <span class="n">can</span> <span class="n">look</span> <span class="n">like</span> <span class="k">this:</span>
<span class="c1">//</span>
<span class="c1">// {</span>
<span class="c1">//    "entity": "Stage",</span>
<span class="c1">//    "ruleScope": "sentence",</span>
<span class="c1">//    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",</span>
<span class="c1">//    "matchScope": "token"</span>
<span class="c1">//  }</span>
<span class="c1">//</span>
<span class="c1">// Which means to extract the stage code on a sentence level.</span>
<span class="c1">// An example pipeline could then be defined like this</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Define the parser (json file needs to be provided)</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... "</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">contextualParser</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">ContextualParserApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setJsonPath</span><span class="o">(</span><span class="s">"/path/to/regex_token.json"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setContextMatch</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">contextualParser</span>
  <span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Extracts entity from a document based on user defined rules. Rule matching is based on a RegexMatcher defined in a
JSON file. In this file, regex is defined that you want to match along with the information that will output on
metadata field. To instantiate a model, see ContextualParserApproach and its accompanied example.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/context/contextual_parser/index.html#sparknlp_jsl.annotator.context.contextual_parser.ContextualParserModel">ContextualParserModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/context/ContextualParserModel">ContextualParserModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box">

  <h2 id="datenormalizer">DateNormalizer</h2>

  <div class="h3-box model-content">

    <p>This annotator transforms date mentions to a common standard format: YYYY/MM/DD. It is useful when using data from different sources, some times from different countries that has different formats to represent dates.</p>

    <p>For the relative dates (next year, past month, etc.), you can define an achor date to create the normalized date by setting the parameters <code class="language-plaintext highlighter-rouge">anchorDateYear</code>, <code class="language-plaintext highlighter-rouge">anchorDateMonth</code>, and <code class="language-plaintext highlighter-rouge">anchorDateDay</code>.</p>

    <p>The resultant chunk date will contain a metada indicating whether the normalization was successful or not (True / False).</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/normalizer/date_normalizer/index.html#sparknlp_jsl.annotator.normalizer.date_normalizer.DateNormalizer">DateNormalizer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/normalizer/DateNormalizer.html">DateNormalizer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span>

<span class="n">dates</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"08/02/2018"</span><span class="p">,</span>
    <span class="s">"11/2018"</span><span class="p">,</span>
    <span class="s">"11/01/2018"</span><span class="p">,</span>
    <span class="s">"12Mar2021"</span><span class="p">,</span>
    <span class="s">"Jan 30, 2018"</span><span class="p">,</span>
    <span class="s">"13.04.1999"</span><span class="p">,</span>
    <span class="s">"3April 2020"</span><span class="p">,</span>
    <span class="s">"next monday"</span><span class="p">,</span>
    <span class="s">"today"</span><span class="p">,</span>
    <span class="s">"next week"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dates</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"original_date"</span><span class="p">)</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"original_date"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">doc2chunk</span> <span class="o">=</span> <span class="n">Doc2Chunk</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date_chunk"</span><span class="p">)</span>

<span class="n">date_normalizer</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">DateNormalizer</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"date_chunk"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setAnchorDateYear</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setAnchorDateMonth</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setAnchorDateDay</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">doc2chunk</span><span class="p">,</span> <span class="n">date_normalizer</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"date.result as normalized_date"</span><span class="p">,</span>
    <span class="s">"original_date"</span><span class="p">,</span>
    <span class="s">"date.metadata[0].normalized as metadata"</span><span class="p">,</span>
<span class="p">).</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span><span class="n">normalized_date</span><span class="o">|</span><span class="n">original_date</span><span class="o">|</span><span class="n">metadata</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="p">]</span><span class="o">|</span>   <span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="n">DD</span><span class="p">]</span><span class="o">|</span>      <span class="mi">11</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="p">]</span><span class="o">|</span>   <span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2021</span><span class="o">/</span><span class="mi">03</span><span class="o">/</span><span class="mi">12</span><span class="p">]</span><span class="o">|</span>    <span class="mi">12</span><span class="n">Mar2021</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">30</span><span class="p">]</span><span class="o">|</span> <span class="n">Jan</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">1999</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">13</span><span class="p">]</span><span class="o">|</span>   <span class="mf">13.04</span><span class="p">.</span><span class="mi">1999</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2020</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">03</span><span class="p">]</span><span class="o">|</span>  <span class="mi">3</span><span class="n">April</span> <span class="mi">2020</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">03</span><span class="o">/</span><span class="mi">20</span><span class="p">]</span><span class="o">|</span>  <span class="nb">next</span> <span class="n">monday</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">03</span><span class="o">/</span><span class="mi">15</span><span class="p">]</span><span class="o">|</span>        <span class="n">today</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">03</span><span class="o">/</span><span class="mi">22</span><span class="p">]</span><span class="o">|</span>    <span class="nb">next</span> <span class="n">week</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"08/02/2018"</span><span class="o">),(</span><span class="s">"11/2018"</span><span class="o">),(</span><span class="s">"11/01/2018"</span><span class="o">),(</span><span class="s">"next monday"</span><span class="o">),(</span><span class="s">"today"</span><span class="o">),(</span><span class="s">"next week"</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"original_date"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"original_date"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunksDF</span> <span class="k">=</span> <span class="n">documentAssembler</span>
				  <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
				  <span class="o">.</span><span class="py">mapAnnotationsCol</span><span class="o">[</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">Annotation</span><span class="o">]](</span><span class="s">"document"</span><span class="o">,</span>
													  <span class="s">"chunk_date"</span><span class="o">,</span>
													   <span class="nc">CHUNK</span><span class="o">,</span>
												  <span class="o">(</span><span class="n">aa</span><span class="k">:</span><span class="kt">Seq</span><span class="o">[</span><span class="kt">Annotation</span><span class="o">])</span> <span class="k">=&gt;</span>
													<span class="nv">aa</span><span class="o">.</span><span class="py">map</span><span class="o">(</span> <span class="n">ann</span> <span class="k">=&gt;</span> <span class="nv">ann</span><span class="o">.</span><span class="py">copy</span><span class="o">(</span><span class="n">annotatorType</span> <span class="k">=</span> <span class="nc">CHUNK</span><span class="o">)))</span>
<span class="k">val</span> <span class="nv">dateNormalizerModel</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DateNormalizer</span><span class="o">()</span>
        <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"chunk_date"</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date"</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setAnchorDateDay</span><span class="o">(</span><span class="mi">15</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setAnchorDateMonth</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setAnchorDateYear</span><span class="o">(</span><span class="mi">2000</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">dateDf</span> <span class="k">=</span> <span class="nv">dateNormalizerModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">chunksDF</span><span class="o">)</span>

<span class="nv">dateDf</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"chunk_date.result"</span><span class="o">,</span><span class="s">"text"</span><span class="o">).</span><span class="py">show</span><span class="o">()</span>
<span class="o">+-------------+-------------+</span>
<span class="o">|</span>       <span class="n">result</span><span class="o">|</span><span class="n">original_date</span><span class="o">|</span>
<span class="o">+-------------+-------------+</span>
<span class="o">|</span> <span class="o">[</span><span class="err">08</span><span class="kt">/</span><span class="err">02</span><span class="kt">/</span><span class="err">2018</span><span class="o">]|</span>   <span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>
<span class="o">|</span>    <span class="o">[</span><span class="err">11</span><span class="kt">/</span><span class="err">2018</span><span class="o">]|</span>      <span class="mi">11</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>
<span class="o">|</span> <span class="o">[</span><span class="err">11</span><span class="kt">/</span><span class="err">01</span><span class="kt">/</span><span class="err">2018</span><span class="o">]|</span>   <span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>
<span class="o">|[</span><span class="kt">next</span> <span class="kt">monday</span><span class="o">]|</span>  <span class="n">next</span> <span class="n">monday</span><span class="o">|</span>
<span class="o">|</span>      <span class="o">[</span><span class="kt">today</span><span class="o">]|</span>        <span class="n">today</span><span class="o">|</span>
<span class="o">|</span>  <span class="o">[</span><span class="kt">next</span> <span class="kt">week</span><span class="o">]|</span>    <span class="n">next</span> <span class="n">week</span><span class="o">|</span>
<span class="o">+-------------+-------------+</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="deidentification">DeIdentification</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Contains all the methods for training a DeIdentificationModel model.
This module can obfuscate or mask the entities that contains personal information. These can be set with a file of
regex patterns with setRegexPatternsDictionary, where each line is a mapping of
entity to regex.</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DATE \d{4}
AID \d{6,7}
</code></pre></div>    </div>

    <p>Additionally, obfuscation strings can be defined with setObfuscateRefFile, where each line
is a mapping of string to entity. The format and seperator can be speficied with
setRefFileFormat and setRefSep.</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Dr. Gregory House#DOCTOR
01010101#MEDICALRECORD
</code></pre></div>    </div>

    <p>Ideally this annotator works in conjunction with Demographic Named EntityRecognizers that can be trained either using
<a href="/docs/en/annotators#textmatcher">TextMatchers</a>,
<a href="/docs/en/annotators#regexmatcher">RegexMatchers</a>,
<a href="/docs/en/annotators#datematcher">DateMatchers</a>,
<a href="/docs/en/annotators#nercrf">NerCRFs</a> or
<a href="/docs/en/annotators#nerdl">NerDLs</a></p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/deIdentification/index.html#sparknlp_jsl.annotator.deid.deIdentification.DeIdentification">DeIdentification</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/DeIdentification">DeIdentification</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

 <span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Ner entities
</span><span class="n">clinical_sensitive_entities</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_enriched"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_con"</span><span class="p">)</span>

<span class="c1"># Deidentification
</span><span class="n">deIdentification</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
    <span class="c1"># file with custom regex pattern for custom entities
</span>    <span class="p">.</span><span class="n">setRegexPatternsDictionary</span><span class="p">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="p">)</span> \
    <span class="c1"># file with custom obfuscator names for the entities
</span>    <span class="p">.</span><span class="n">setObfuscateRefFile</span><span class="p">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefFileFormat</span><span class="p">(</span><span class="s">"csv"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefSep</span><span class="p">(</span><span class="s">"#"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormats</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s">"MM/dd/yy"</span><span class="p">,</span><span class="s">"yyyy-MM-dd"</span><span class="p">))</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDays</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"file"</span><span class="p">)</span>

<span class="c1"># Pipeline
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09."</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">clinical_sensitive_entities</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">deIdentification</span>
<span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show Results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"dei.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                            <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="c1"># 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]|
</span><span class="o">+--------------------------------------------------------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

 <span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Ner entities
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_con"</span><span class="p">)</span>

<span class="c1"># Deidentification
</span><span class="n">deIdentification</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
    <span class="c1"># file with custom regex pattern for custom entities
</span>    <span class="p">.</span><span class="n">setRegexPatternsDictionary</span><span class="p">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="p">)</span> \
    <span class="c1"># file with custom obfuscator names for the entities
</span>    <span class="p">.</span><span class="n">setObfuscateRefFile</span><span class="p">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefFileFormat</span><span class="p">(</span><span class="s">"csv"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefSep</span><span class="p">(</span><span class="s">"#"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormats</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s">"MM/dd/yy"</span><span class="p">,</span><span class="s">"yyyy-MM-dd"</span><span class="p">))</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDays</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"file"</span><span class="p">)</span>

<span class="c1"># Pipeline
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">deIdentification</span>
<span class="p">])</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

 <span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Ner entities
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_con"</span><span class="p">)</span>

<span class="c1"># Deidentification
</span><span class="n">deIdentification</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
    <span class="c1"># file with custom regex pattern for custom entities
</span>    <span class="p">.</span><span class="n">setRegexPatternsDictionary</span><span class="p">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="p">)</span> \
    <span class="c1"># file with custom obfuscator names for the entities
</span>    <span class="p">.</span><span class="n">setObfuscateRefFile</span><span class="p">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefFileFormat</span><span class="p">(</span><span class="s">"csv"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefSep</span><span class="p">(</span><span class="s">"#"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormats</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s">"MM/dd/yy"</span><span class="p">,</span><span class="s">"yyyy-MM-dd"</span><span class="p">))</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDays</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"file"</span><span class="p">)</span>

<span class="c1"># Pipeline
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">deIdentification</span>
<span class="p">])</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span>
     <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Ner entities</span>
<span class="k">val</span> <span class="nv">clinical_sensitive_entities</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_enriched"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_con"</span><span class="o">)</span>

<span class="c1">// Deidentification</span>
<span class="k">val</span> <span class="nv">deIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">DeIdentification</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
     <span class="c1">// file with custom regex patterns for custom entities</span>
     <span class="o">.</span><span class="py">setRegexPatternsDictionary</span><span class="o">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="o">)</span>
     <span class="c1">// file with custom obfuscator names for the entities</span>
     <span class="o">.</span><span class="py">setObfuscateRefFile</span><span class="o">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefFileFormat</span><span class="o">(</span><span class="s">"csv"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefSep</span><span class="o">(</span><span class="s">"#"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateFormats</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"MM/dd/yy"</span><span class="o">,</span><span class="s">"yyyy-MM-dd"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateTag</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDays</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"file"</span><span class="o">)</span>

<span class="c1">// Pipeline</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">clinical_sensitive_entities</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">deIdentification</span>
<span class="o">))</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"dei.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>

<span class="c1">// Show Results</span>
<span class="c1">//</span>
<span class="c1">// result.select("dei.result").show(truncate = false)</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |result                                                                                            |</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]|</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span>
     <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Ner entities</span>
<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_con"</span><span class="o">)</span>

<span class="c1">// Deidentification</span>
<span class="k">val</span> <span class="nv">deIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">DeIdentification</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
     <span class="c1">// file with custom regex patterns for custom entities</span>
     <span class="o">.</span><span class="py">setRegexPatternsDictionary</span><span class="o">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="o">)</span>
     <span class="c1">// file with custom obfuscator names for the entities</span>
     <span class="o">.</span><span class="py">setObfuscateRefFile</span><span class="o">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefFileFormat</span><span class="o">(</span><span class="s">"csv"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefSep</span><span class="o">(</span><span class="s">"#"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateFormats</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"MM/dd/yy"</span><span class="o">,</span><span class="s">"yyyy-MM-dd"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateTag</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDays</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"file"</span><span class="o">)</span>

<span class="c1">// Pipeline</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">deIdentification</span>
<span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span>
     <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Ner entities</span>
<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_con"</span><span class="o">)</span>

<span class="c1">// Deidentification</span>
<span class="k">val</span> <span class="nv">deIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">DeIdentification</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
     <span class="c1">// file with custom regex patterns for custom entities</span>
     <span class="o">.</span><span class="py">setRegexPatternsDictionary</span><span class="o">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="o">)</span>
     <span class="c1">// file with custom obfuscator names for the entities</span>
     <span class="o">.</span><span class="py">setObfuscateRefFile</span><span class="o">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefFileFormat</span><span class="o">(</span><span class="s">"csv"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefSep</span><span class="o">(</span><span class="s">"#"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateFormats</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"MM/dd/yy"</span><span class="o">,</span><span class="s">"yyyy-MM-dd"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateTag</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDays</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"file"</span><span class="o">)</span>

<span class="c1">// Pipeline</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">deIdentification</span>
<span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Deidentifies Input Annotations of types DOCUMENT, TOKEN and CHUNK, by either masking or obfuscating the given CHUNKS.</p>

    <p>To create a configured DeIdentificationModel, please see the example of DeIdentification.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/deIdentification/index.html#sparknlp_jsl.annotator.deid.deIdentification.DeIdentificationModel">DeIdentificationModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/DeIdentificationModel">DeIdentificationModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">bert_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">fin_ner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finner_deid'</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter</span> <span class="o">=</span>  <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ORG"</span><span class="p">:</span> <span class="s">"PARTY"</span><span class="p">})</span> <span class="c1"># Replace "ORG" entity as "PARTY"
</span>
<span class="n">ner_finner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_org_per_role_date"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"bert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_finner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter_finner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_finner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_finner_chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">'ROLE'</span><span class="p">])</span> <span class="c1"># Just use "ROLE" entity from this NER
</span>
<span class="n">chunk_merge</span> <span class="o">=</span>  <span class="n">finance</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_finner_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_merged_chunk"</span><span class="p">)</span>

<span class="n">deidentification</span> <span class="o">=</span>  <span class="n">finance</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"deid_merged_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deidentified"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"mask"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Pipeline
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon"</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">bert_embeddings</span><span class="p">,</span>
      <span class="n">fin_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_finner</span><span class="p">,</span>
      <span class="n">ner_converter_finner</span><span class="p">,</span>
      <span class="n">chunk_merge</span><span class="p">,</span>
      <span class="n">deidentification</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">legal_ner</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ALIAS"</span><span class="p">:</span> <span class="s">"PARTY"</span><span class="p">})</span>

<span class="n">ner_signers</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_signers"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_signers"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter_signers</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_signers"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_signer_chunk"</span><span class="p">)</span>

<span class="n">chunk_merge</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_signer_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_merged_chunk"</span><span class="p">)</span>

<span class="n">deidentification</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"deid_merged_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deidentified"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"mask"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Pipeline
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"ENTIRE AGREEMENT.  This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter.

2THEMART.COM, INC.:                         I-ESCROW, INC.:

By:Dominic J. Magliarditi                By:Sanjay Bajaj Name: Dominic J. Magliarditi                Name: Sanjay Bajaj Title: President                            Title: VP Business Development Date: 6/21/99                               Date: 6/11/99 "</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">legal_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_signers</span><span class="p">,</span>
      <span class="n">ner_converter_signers</span><span class="p">,</span>
      <span class="n">chunk_merge</span><span class="p">,</span>
      <span class="n">deidentification</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">document</span><span class="err">"</span><span class="o">])</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">sentence</span><span class="err">"</span><span class="o">])</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">bert_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">fin_ner</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'finner_dei</span><span class="n">d</span><span class="o">',</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span>  <span class="nv">finance</span><span class="o">.</span><span class="py">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">({</span><span class="s">"ORG"</span><span class="k">:</span> <span class="err">"</span><span class="kt">PARTY</span><span class="err">"</span><span class="o">})</span> <span class="k">#</span> <span class="nc">Replace</span> <span class="s">"ORG"</span> <span class="n">entity</span> <span class="n">as</span> <span class="s">"PARTY"</span>

<span class="k">val</span> <span class="nv">ner_finner</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_org_per_role_date"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"bert_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_finner"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_finner</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_finner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_finner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">([</span><span class="kt">'ROLE'</span><span class="o">])</span> <span class="k">#</span> <span class="nc">Just</span> <span class="n">use</span> <span class="s">"ROLE"</span> <span class="n">entity</span> <span class="n">from</span> <span class="k">this</span> <span class="nc">NER</span>

<span class="k">val</span> <span class="nv">chunk_merge</span> <span class="k">=</span>  <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">ChunkMergeApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_finner_chunk"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_merged_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">deidentification</span> <span class="k">=</span>  <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">DeIdentification</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"deid_merged_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deidentified"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"mask"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setIgnoreRegex</span><span class="o">(</span><span class="nc">True</span><span class="o">)</span>

<span class="k">#</span> <span class="nc">Pipeline</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span> 
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">embeddings</span><span class="o">,</span>
      <span class="n">bert_embeddings</span><span class="o">,</span>
      <span class="n">fin_ner</span><span class="o">,</span>
      <span class="n">ner_converter</span><span class="o">,</span>
      <span class="n">ner_finner</span><span class="o">,</span>
      <span class="n">ner_converter_finner</span><span class="o">,</span>
      <span class="n">chunk_merge</span><span class="o">,</span>
      <span class="n">deidentification</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">document</span><span class="err">"</span><span class="o">])</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">sentence</span><span class="err">"</span><span class="o">])</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">legal_ner</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">({</span><span class="s">"ALIAS"</span><span class="k">:</span> <span class="err">"</span><span class="kt">PARTY</span><span class="err">"</span><span class="o">})</span>

<span class="k">val</span> <span class="nv">ner_signers</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_signers"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_signers"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_signers</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_signers"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_signer_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk_merge</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">ChunkMergeApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_signer_chunk"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_merged_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">deidentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">DeIdentification</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"deid_merged_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deidentified"</span><span class="o">)</span> <span class="o">\</span>
    <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"mask"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setIgnoreRegex</span><span class="o">(</span><span class="nc">True</span><span class="o">)</span>

<span class="k">#</span> <span class="nc">Pipeline</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"ENTIRE AGREEMENT.  This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter.

2THEMART.COM, INC.:                         I-ESCROW, INC.:

By:Dominic J. Magliarditi                By:Sanjay Bajaj Name: Dominic J. Magliarditi                Name: Sanjay Bajaj Title: President                            Title: VP Business Development Date: 6/21/99                               Date: 6/11/99 "</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span> 
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">embeddings</span><span class="o">,</span>
      <span class="n">legal_ner</span><span class="o">,</span>
      <span class="n">ner_converter</span><span class="o">,</span>
      <span class="n">ner_signers</span><span class="o">,</span>
      <span class="n">ner_converter_signers</span><span class="o">,</span>
      <span class="n">chunk_merge</span><span class="o">,</span>
      <span class="n">deidentification</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="doc2chunkinternal">Doc2ChunkInternal</h2>

  <div class="h3-box model-content">

    <p>Converts <code class="language-plaintext highlighter-rouge">DOCUMENT</code>, <code class="language-plaintext highlighter-rouge">TOKEN</code> typed annotations into <code class="language-plaintext highlighter-rouge">CHUNK</code> type with the contents of a <code class="language-plaintext highlighter-rouge">chunkCol</code>. Chunk text must be contained within input <code class="language-plaintext highlighter-rouge">DOCUMENT</code>. May be either <code class="language-plaintext highlighter-rouge">StringType</code> or <code class="language-plaintext highlighter-rouge">ArrayType[StringType]</code> (using <code class="language-plaintext highlighter-rouge">setIsArray</code>). Useful for annotators that require a CHUNK type input.</p>

    <p>For more extended examples on document pre-processing see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/doc2_chunk_internal/index.html#sparknlp_jsl.annotator.doc2_chunk_internal.Doc2ChunkInternal">Doc2ChunkInternal</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/annotator/Doc2ChunkInternal.html">Doc2ChunkInternal</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">Doc2ChunkInternal</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setIsArray</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="p">,</span>
            <span class="p">[</span><span class="s">"Spark NLP"</span><span class="p">,</span> <span class="s">"text processing library"</span><span class="p">,</span> <span class="s">"natural language processing"</span><span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"target"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">chunkAssembler</span><span class="p">]).</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"chunk.result"</span><span class="p">,</span> <span class="s">"chunk.annotatorType"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                           <span class="o">|</span><span class="n">annotatorType</span>        <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Spark</span> <span class="n">NLP</span><span class="p">,</span> <span class="n">text</span> <span class="n">processing</span> <span class="n">library</span><span class="p">,</span> <span class="n">natural</span> <span class="n">language</span> <span class="n">processing</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="documenthashcoder">DocumentHashCoder</h2>

  <div class="h3-box model-content">

    <p>This annotator can replace dates in a column of <code class="language-plaintext highlighter-rouge">DOCUMENT</code> type according with the hash code of any other column. It uses the hash of the specified column and creates a new document column containing the day shift information. In sequence, the <code class="language-plaintext highlighter-rouge">DeIdentification</code> annotator deidentifies the document with the shifted date information.</p>

    <p>If the specified column contains strings that can be parsed to integers, use those numbers to make the shift in the data accordingly.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/doccument_hashcoder/index.html#sparknlp_jsl.annotator.deid.doccument_hashcoder.DocumentHashCoder">DocumentHashCoder</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/DocumentHashCoder.html">DocumentHashCoder</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>


<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s">'patientID'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'A001'</span><span class="p">,</span> <span class="s">'A001'</span><span class="p">,</span> 
                    <span class="s">'A003'</span><span class="p">,</span> <span class="s">'A003'</span><span class="p">],</span>
     <span class="s">'text'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'Chris Brown was discharged on 10/02/2022'</span><span class="p">,</span> 
               <span class="s">'Mark White was discharged on 10/04/2022'</span><span class="p">,</span> 
               <span class="s">'John was discharged on 15/03/2022'</span><span class="p">,</span>
               <span class="s">'John Moore was discharged on 15/12/2022'</span>
              <span class="p">],</span>
     <span class="s">'dateshift'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'10'</span><span class="p">,</span> <span class="s">'10'</span><span class="p">,</span> 
                    <span class="s">'30'</span><span class="p">,</span> <span class="s">'30'</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">my_input_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">documentHasher</span> <span class="o">=</span> <span class="n">DocumentHashCoder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document2"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDateShiftColumn</span><span class="p">(</span><span class="s">"dateshift"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">de_identification</span> <span class="o">=</span> <span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"document2"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLanguage</span><span class="p">(</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">'faker'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseShifDays</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline_col</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">documentHasher</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">de_identification</span>
<span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">,</span> <span class="s">""</span><span class="p">,</span> <span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"patientID"</span><span class="p">,</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"dateshift"</span><span class="p">)</span>
<span class="n">pipeline_col_model</span> <span class="o">=</span> <span class="n">pipeline_col</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">pipeline_col_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">my_input_df</span><span class="p">)</span>
<span class="n">output</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span> <span class="s">'dateshift'</span><span class="p">,</span> <span class="s">'deid_text.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+----------------------------------------+---------+----------------------------------------------+</span>
<span class="n">text</span>                                    <span class="o">|</span><span class="n">dateshift</span><span class="o">|</span><span class="n">result</span>                                        <span class="o">|</span>
<span class="o">+----------------------------------------+---------+----------------------------------------------+</span>
<span class="n">Chris</span> <span class="n">Brown</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">10</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2022</span><span class="o">|</span><span class="mi">10</span>       <span class="o">|</span><span class="p">[</span><span class="n">Ellender</span> <span class="n">Manual</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">20</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span><span class="o">|</span>
<span class="n">Mark</span> <span class="n">White</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">10</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">2022</span> <span class="o">|</span><span class="mi">10</span>       <span class="o">|</span><span class="p">[</span><span class="n">Errol</span> <span class="n">Bang</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">20</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span>     <span class="o">|</span>
<span class="n">John</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">15</span><span class="o">/</span><span class="mi">03</span><span class="o">/</span><span class="mi">2022</span>       <span class="o">|</span><span class="mi">30</span>       <span class="o">|</span><span class="p">[</span><span class="n">Ariel</span> <span class="n">Null</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">14</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span>     <span class="o">|</span>
<span class="n">John</span> <span class="n">Moore</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">15</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="mi">2022</span> <span class="o">|</span><span class="mi">30</span>       <span class="o">|</span><span class="p">[</span><span class="n">Jean</span> <span class="n">Cotton</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">14</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">2023</span><span class="p">]</span>    <span class="o">|</span>
<span class="o">+----------------------------------------+---------+----------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="documentlogregclassifier">DocumentLogRegClassifier</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a model to classify documents with a Logarithmic Regression algorithm. Training data requires columns for
text and their label. The result is a trained DocumentLogRegClassifierModel.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/document_log_classifier/index.html#sparknlp_jsl.annotator.classification.document_log_classifier.DocumentLogRegClassifierApproach">DocumentLogRegClassifierApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/DocumentLogRegClassifierApproach">DocumentLogRegClassifierApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Define pipeline stages to prepare the data
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Normalizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span>

<span class="n">stopwords_cleaner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">StopWordsCleaner</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"normalized"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Stemmer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"cleanTokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"stem"</span><span class="p">)</span>

<span class="c1"># Define the document classifier and fit training data to it
</span><span class="n">logreg</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DocumentLogRegClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"stem"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">normalizer</span><span class="p">,</span>
  <span class="n">stopwords_cleaner</span><span class="p">,</span>
  <span class="n">stemmer</span><span class="p">,</span>
  <span class="n">logreg</span>
<span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Define pipeline stages to prepare the data
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Normalizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span>

<span class="n">stopwords_cleaner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">StopWordsCleaner</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"normalized"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Stemmer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"cleanTokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"stem"</span><span class="p">)</span>

<span class="c1"># Define the document classifier and fit training data to it
</span><span class="n">logreg</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">DocumentLogRegClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"stem"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">normalizer</span><span class="p">,</span>
  <span class="n">stopwords_cleaner</span><span class="p">,</span>
  <span class="n">stemmer</span><span class="p">,</span>
  <span class="n">logreg</span>
<span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Define pipeline stages to prepare the data
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Normalizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span>

<span class="n">stopwords_cleaner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">StopWordsCleaner</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"normalized"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Stemmer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"cleanTokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"stem"</span><span class="p">)</span>

<span class="c1"># Define the document classifier and fit training data to it
</span><span class="n">logreg</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DocumentLogRegClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"stem"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">normalizer</span><span class="p">,</span>
  <span class="n">stopwords_cleaner</span><span class="p">,</span>
  <span class="n">stemmer</span><span class="p">,</span>
  <span class="n">logreg</span>
<span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="n">to</span> <span class="n">prepare</span> <span class="n">the</span> <span class="n">data</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopwords_cleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">StopWordsCleaner</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stemmer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Stemmer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>

<span class="c1">// Define the document classifier and fit training data to it</span>
<span class="k">val</span> <span class="nv">logreg</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">DocumentLogRegClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">normalizer</span><span class="o">,</span>
  <span class="n">stopwords_cleaner</span><span class="o">,</span>
  <span class="n">stemmer</span><span class="o">,</span>
  <span class="n">logreg</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="n">to</span> <span class="n">prepare</span> <span class="n">the</span> <span class="n">data</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopwords_cleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">StopWordsCleaner</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stemmer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Stemmer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>

<span class="c1">// Define the document classifier and fit training data to it</span>
<span class="k">val</span> <span class="nv">logreg</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">DocumentLogRegClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">normalizer</span><span class="o">,</span>
  <span class="n">stopwords_cleaner</span><span class="o">,</span>
  <span class="n">stemmer</span><span class="o">,</span>
  <span class="n">logreg</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="n">to</span> <span class="n">prepare</span> <span class="n">the</span> <span class="n">data</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopwords_cleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">StopWordsCleaner</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stemmer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Stemmer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>

<span class="c1">// Define the document classifier and fit training data to it</span>
<span class="k">val</span> <span class="nv">logreg</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">DocumentLogRegClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">normalizer</span><span class="o">,</span>
  <span class="n">stopwords_cleaner</span><span class="o">,</span>
  <span class="n">stemmer</span><span class="o">,</span>
  <span class="n">logreg</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Classifies documents with a Logarithmic Regression algorithm.
Currently there are no pretrained models available.
Please see DocumentLogRegClassifierApproach to train your own model.</p>

    <p>Please check out the
<a href="https://nlp.johnsnowlabs.com/models">Models Hub</a> for available models in the future.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/document_log_classifier/index.html#sparknlp_jsl.annotator.classification.document_log_classifier.DocumentLogRegClassifierModel">DocumentLogRegClassifierModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/DocumentLogRegClassifierModel">DocumentLogRegClassifierModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box">

  <h2 id="drugnormalizer">DrugNormalizer</h2>

  <div class="h3-box model-content">

    <p>Annotator which normalizes raw text from clinical documents, e.g. scraped web pages or xml documents, from document type columns into Sentence.
Removes all dirty characters from text following one or more input regex patterns.
Can apply non wanted character removal which a specific policy.
Can apply lower case normalization.</p>

    <p>See <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/23.Drug_Normalizer.ipynb">Spark NLP Workshop</a> for more examples of usage.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/normalizer/drug_normalizer/index.html#sparknlp_jsl.annotator.normalizer.drug_normalizer.DrugNormalizer">DrugNormalizer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/DrugNormalizer">DrugNormalizer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
  <span class="p">[</span><span class="s">"Sodium Chloride/Potassium Chloride 13bag"</span><span class="p">],</span>
  <span class="p">[</span><span class="s">"interferon alfa-2b 10 million unit ( 1 ml ) injec"</span><span class="p">],</span>
  <span class="p">[</span><span class="s">"aspirin 10 meq/ 5 ml oral sol"</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">drugNormalizer</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DrugNormalizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document_normalized"</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="n">drugNormalizer</span><span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(document_normalized.result) as normalized_text"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------------------------------------+</span>
<span class="o">|</span><span class="n">normalized_text</span>                                     <span class="o">|</span>
<span class="o">+----------------------------------------------------+</span>
<span class="o">|</span><span class="n">Sodium</span> <span class="n">Chloride</span> <span class="o">/</span> <span class="n">Potassium</span> <span class="n">Chloride</span> <span class="mi">13</span> <span class="n">bag</span>         <span class="o">|</span>
<span class="o">|</span><span class="n">interferon</span> <span class="n">alfa</span> <span class="o">-</span> <span class="mi">2</span><span class="n">b</span> <span class="mi">10000000</span> <span class="n">unt</span> <span class="p">(</span> <span class="mi">1</span> <span class="n">ml</span> <span class="p">)</span> <span class="n">injection</span><span class="o">|</span>
<span class="o">|</span><span class="n">aspirin</span> <span class="mi">2</span> <span class="n">meq</span><span class="o">/</span><span class="n">ml</span> <span class="n">oral</span> <span class="n">solution</span>                      <span class="o">|</span>
<span class="o">+----------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">drugNormalizer</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">DrugNormalizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document_normalized"</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="n">drugNormalizer</span><span class="p">])</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">drugNormalizer</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DrugNormalizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document_normalized"</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="n">drugNormalizer</span><span class="p">])</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">"Sodium Chloride/Potassium Chloride 13bag"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"interferon alfa-2b 10 million unit ( 1 ml ) injec"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"aspirin 10 meq/ 5 ml oral sol"</span><span class="o">)</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">drugNormalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">DrugNormalizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document_normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document</span><span class="o">,</span> <span class="n">drugNormalizer</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(document_normalized.result) as normalized_text"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------+</span>
<span class="o">|</span><span class="n">normalized_text</span>                                     <span class="o">|</span>
<span class="o">+----------------------------------------------------+</span>
<span class="o">|</span><span class="nc">Sodium</span> <span class="nc">Chloride</span> <span class="o">/</span> <span class="nc">Potassium</span> <span class="nc">Chloride</span> <span class="mi">13</span> <span class="n">bag</span>         <span class="o">|</span>
<span class="o">|</span><span class="n">interferon</span> <span class="n">alfa</span> <span class="o">-</span> <span class="mi">2</span><span class="n">b</span> <span class="mi">10000000</span> <span class="nf">unt</span> <span class="o">(</span> <span class="mi">1</span> <span class="n">ml</span> <span class="o">)</span> <span class="n">injection</span><span class="o">|</span>
<span class="o">|</span><span class="n">aspirin</span> <span class="mi">2</span> <span class="n">meq</span><span class="o">/</span><span class="n">ml</span> <span class="n">oral</span> <span class="n">solution</span>                      <span class="o">|</span>
<span class="o">+----------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

</span><span class="nn">val</span> <span class="n">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">drugNormalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">DrugNormalizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document_normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document</span><span class="o">,</span> <span class="n">drugNormalizer</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 

</span><span class="nn">val</span> <span class="n">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">drugNormalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">DrugNormalizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document_normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document</span><span class="o">,</span> <span class="n">drugNormalizer</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="featuresassembler">FeaturesAssembler</h2>

  <div class="h3-box approach-content">

    <p>The FeaturesAssembler is used to collect features from different columns. It can collect features from single value
columns (anything which can be cast to a float, if casts fails then the value is set to 0), array columns or
SparkNLP annotations (if the annotation is an embedding, it takes the embedding, otherwise tries to cast the
<code class="language-plaintext highlighter-rouge">result</code> field). The output of the transformer is a <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code> annotation (the numeric vector is in the
<code class="language-plaintext highlighter-rouge">embeddings</code> field).</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">"feature_vector"</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/base/index.html#sparknlp_jsl.base.FeaturesAssembler">FeaturesAssembler</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/FeaturesAssembler">FeaturesAssembler</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="n">features_asm</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">GenericClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">features_asm</span><span class="p">,</span>
  <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="n">features_asm</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">GenericClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">features_asm</span><span class="p">,</span>
  <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="n">features_asm</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">GenericClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">features_asm</span><span class="p">,</span>
  <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="genericclassifier">GenericClassifier</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a TensorFlow model for generic classification of feature vectors. It takes FEATURE_VECTOR annotations from
<code class="language-plaintext highlighter-rouge">FeaturesAssembler</code> as input, classifies them and outputs CATEGORY annotations.
Please see the Parameters section for required training parameters.</p>

    <p>For a more extensive example please see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/8.Generic_Classifier.ipynb">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/generic_classifier/generic_classifier/index.html#sparknlp_jsl.annotator.generic_classifier.generic_classifier.GenericClassifierApproach">GenericClassifierApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/generic_classifier/GenericClassifierApproach">GenericClassifierApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">features_asm</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">GenericClassifierApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setlearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">features_asm</span><span class="p">,</span>
    <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">features_asm</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">GenericClassifierApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setlearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">features_asm</span><span class="p">,</span>
    <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">features_asm</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">GenericClassifierApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setlearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">features_asm</span><span class="p">,</span>
    <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Creates a generic single-label classifier which uses pre-generated Tensorflow graphs.
The model operates on FEATURE_VECTOR annotations which can be produced using FeatureAssembler.
Requires the FeaturesAssembler to create the input.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/generic_classifier/generic_classifier/index.html#sparknlp_jsl.annotator.generic_classifier.generic_classifier.GenericClassifierModel">GenericClassifierModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/generic_classifier/GenericClassifierModel">GenericClassifierModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box">

  <h2 id="iobtagger">IOBTagger</h2>

  <div class="h3-box model-content">

    <p>Merges token tags and NER labels from chunks in the specified format.
For example output columns as inputs from
<a href="/docs/en/annotators#nerconverter">NerConverter</a>
and <a href="/docs/en/annotators#tokenizer">Tokenizer</a> can be used to merge.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/iob_tagger/index.html#sparknlp_jsl.annotator.ner.iob_tagger.IOBTagger">IOBTagger</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/IOBTagger">IOBTagger</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Pipeline stages are defined where NER is done. NER is converted to chunks.
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">).</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embs"</span><span class="p">)</span>
<span class="n">nerModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">).</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1"># Define the IOB tagger, which needs tokens and chunks as input. Show results.
</span><span class="n">iobTagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">IOBTagger</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">docAssembler</span><span class="p">,</span> <span class="n">sentenceDetector</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">nerModel</span><span class="p">,</span> <span class="n">nerConverter</span><span class="p">,</span> <span class="n">iobTagger</span><span class="p">])</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_label) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span><span class="s">"a.end"</span><span class="p">,</span><span class="s">"a.result as chunk"</span><span class="p">,</span><span class="s">"a.metadata.word as word"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="s">"chunk!='O'"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----+---+-----------+-----------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">chunk</span>      <span class="o">|</span><span class="n">word</span>       <span class="o">|</span>
<span class="o">+-----+---+-----------+-----------+</span>
<span class="o">|</span><span class="mi">5</span>    <span class="o">|</span><span class="mi">15</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">Age</span>      <span class="o">|</span><span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">|</span>
<span class="o">|</span><span class="mi">17</span>   <span class="o">|</span><span class="mi">19</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">Gender</span>   <span class="o">|</span><span class="n">man</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">64</span>   <span class="o">|</span><span class="mi">72</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">Modifier</span> <span class="o">|</span><span class="n">recurrent</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">98</span>   <span class="o">|</span><span class="mi">107</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">Diagnosis</span><span class="o">|</span><span class="n">cellulitis</span> <span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">Diagnosis</span><span class="o">|</span><span class="n">pneumonias</span> <span class="o">|</span>
<span class="o">+-----+---+-----------+-----------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Pipeline stages are defined where NER is done. NER is converted to chunks.
</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">).</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embs"</span><span class="p">)</span>
<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">).</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1"># Define the IOB tagger, which needs tokens and chunks as input. Show results.
</span><span class="n">iobTagger</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">IOBTagger</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">docAssembler</span><span class="p">,</span> <span class="n">sentenceDetector</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">ner_model</span><span class="p">,</span> <span class="n">nerConverter</span><span class="p">,</span> <span class="n">iobTagger</span><span class="p">])</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Pipeline stages are defined where NER is done. NER is converted to chunks.
</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">).</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embs"</span><span class="p">)</span>
<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">).</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1"># Define the IOB tagger, which needs tokens and chunks as input. Show results.
</span><span class="n">iobTagger</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">IOBTagger</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">docAssembler</span><span class="p">,</span> <span class="n">sentenceDetector</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">ner_model</span><span class="p">,</span> <span class="n">nerConverter</span><span class="p">,</span> <span class="n">iobTagger</span><span class="p">])</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Pipeline</span> <span class="n">stages</span> <span class="n">are</span> <span class="n">defined</span> <span class="n">where</span> <span class="nc">NER</span> <span class="n">is</span> <span class="n">done</span><span class="o">.</span> <span class="nc">NER</span> <span class="n">is</span> <span class="n">converted</span> <span class="n">to</span> <span class="n">chunks</span><span class="o">.</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">).</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embs"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">).</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embs"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="c1">// Define the IOB tagger, which needs tokens and chunks as input. Show results.</span>
<span class="k">val</span> <span class="nv">iobTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">IOBTagger</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_label"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">docAssembler</span><span class="o">,</span> <span class="n">sentenceDetector</span><span class="o">,</span> <span class="n">tokenizer</span><span class="o">,</span> <span class="n">embeddings</span><span class="o">,</span> <span class="n">nerModel</span><span class="o">,</span> <span class="n">nerConverter</span><span class="o">,</span> <span class="n">iobTagger</span><span class="o">))</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(ner_label) as a"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"a.begin"</span><span class="o">,</span><span class="s">"a.end"</span><span class="o">,</span><span class="s">"a.result as chunk"</span><span class="o">,</span><span class="s">"a.metadata.word as word"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">where</span><span class="o">(</span><span class="s">"chunk!='O'"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>

<span class="o">+-----+---+-----------+-----------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">chunk</span>      <span class="o">|</span><span class="n">word</span>       <span class="o">|</span>
<span class="o">+-----+---+-----------+-----------+</span>
<span class="o">|</span><span class="mi">5</span>    <span class="o">|</span><span class="mi">15</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">Age</span>      <span class="o">|</span><span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">|</span>
<span class="o">|</span><span class="mi">17</span>   <span class="o">|</span><span class="mi">19</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">Gender</span>   <span class="o">|</span><span class="n">man</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">64</span>   <span class="o">|</span><span class="mi">72</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">Modifier</span> <span class="o">|</span><span class="n">recurrent</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">98</span>   <span class="o">|</span><span class="mi">107</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">Diagnosis</span><span class="o">|</span><span class="n">cellulitis</span> <span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">Diagnosis</span><span class="o">|</span><span class="n">pneumonias</span> <span class="o">|</span>
<span class="o">+-----+---+-----------+-----------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Pipeline</span> <span class="n">stages</span> <span class="n">are</span> <span class="n">defined</span> <span class="n">where</span> <span class="nc">NER</span> <span class="n">is</span> <span class="n">done</span><span class="o">.</span> <span class="nc">NER</span> <span class="n">is</span> <span class="n">converted</span> <span class="n">to</span> <span class="n">chunks</span><span class="o">.</span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">).</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embs"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">).</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embs"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="c1">// Define the IOB tagger, which needs tokens and chunks as input. Show results.</span>
<span class="k">val</span> <span class="nv">iobTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">IOBTagger</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_label"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">docAssembler</span><span class="o">,</span> <span class="n">sentenceDetector</span><span class="o">,</span> <span class="n">tokenizer</span><span class="o">,</span> <span class="n">embeddings</span><span class="o">,</span> <span class="n">ner_model</span><span class="o">,</span> <span class="n">nerConverter</span><span class="o">,</span> <span class="n">iobTagger</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Pipeline</span> <span class="n">stages</span> <span class="n">are</span> <span class="n">defined</span> <span class="n">where</span> <span class="nc">NER</span> <span class="n">is</span> <span class="n">done</span><span class="o">.</span> <span class="nc">NER</span> <span class="n">is</span> <span class="n">converted</span> <span class="n">to</span> <span class="n">chunks</span><span class="o">.</span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">).</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embs"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">).</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embs"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="c1">// Define the IOB tagger, which needs tokens and chunks as input. Show results.</span>
<span class="k">val</span> <span class="nv">iobTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">IOBTagger</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_label"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">docAssembler</span><span class="o">,</span> <span class="n">sentenceDetector</span><span class="o">,</span> <span class="n">tokenizer</span><span class="o">,</span> <span class="n">embeddings</span><span class="o">,</span> <span class="n">ner_model</span><span class="o">,</span> <span class="n">nerConverter</span><span class="o">,</span> <span class="n">iobTagger</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="nerchunker">NerChunker</h2>

  <div class="h3-box model-content">

    <p>Extracts phrases that fits into a known pattern using the NER tags. Useful for entity groups with neighboring tokens
when there is no pretrained NER model to address certain issues. A Regex needs to be provided to extract the tokens
between entities.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, NAMED_ENTITY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/ner_chunker/index.html#sparknlp_jsl.annotator.ner.ner_chunker.NerChunker">NerChunker</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/NerChunker">NerChunker</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Defining pipeline stages for NER
</span><span class="n">data</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"She has cystic cyst on her kidney."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">documentAssembler</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_radiology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setIncludeConfidence</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Define the NerChunker to combine to chunks
</span><span class="n">chunker</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerChunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;"</span><span class="p">])</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">ner</span><span class="p">,</span>
  <span class="n">chunker</span>
<span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results:
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(arrays_zip(ner.metadata , ner.result))"</span><span class="p">)</span>
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"col['0'].word as word"</span> <span class="p">,</span> <span class="s">"col['1'] as ner"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+-----------------+</span>
<span class="o">|</span><span class="n">word</span>  <span class="o">|</span><span class="n">ner</span>              <span class="o">|</span>
<span class="o">+------+-----------------+</span>
<span class="o">|</span><span class="n">She</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">has</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">cystic</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ImagingFindings</span><span class="o">|</span>
<span class="o">|</span><span class="n">cyst</span>  <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ImagingFindings</span><span class="o">|</span>
<span class="o">|</span><span class="n">on</span>    <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">her</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">kidney</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">BodyPart</span>       <span class="o">|</span>
<span class="o">|</span><span class="p">.</span>     <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">+------+-----------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner_chunk.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="n">result</span>                     <span class="o">|</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">cystic</span> <span class="n">cyst</span> <span class="n">on</span> <span class="n">her</span> <span class="n">kidney</span><span class="p">]</span><span class="o">|</span>
<span class="o">+---------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Defining pipeline stages for NER
</span>

<span class="n">documentAssembler</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="c1"># Define the NerChunker to combine to chunks
</span><span class="n">chunker</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerChunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;"</span><span class="p">])</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span>
  <span class="n">chunker</span>
<span class="p">])</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Defining pipeline stages for NER
</span>

<span class="n">documentAssembler</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="c1"># Define the NerChunker to combine to chunks
</span><span class="n">chunker</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerChunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;"</span><span class="p">])</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span>
  <span class="n">chunker</span>
<span class="p">])</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Defining</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="k">for</span> <span class="nc">NER</span>
<span class="k">val</span> <span class="nv">data</span><span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"She has cystic cyst on her kidney."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span><span class="k">=new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span><span class="k">=new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="nc">False</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span><span class="k">=new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="nc">False</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_radiology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setIncludeConfidence</span><span class="o">(</span><span class="nc">True</span><span class="o">)</span>

<span class="c1">// Define the NerChunker to combine to chunks</span>
<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerChunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"&lt;ImagingFindings&gt;.&lt;BodyPart&gt;"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span><span class="k">=new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner</span><span class="o">,</span>
  <span class="n">chunker</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results:</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(arrays_zip(ner.metadata , ner.result))")</span>
<span class="c1">//   .selectExpr("col['0'].word as word" , "col['1'] as ner").show(truncate=false)</span>
<span class="c1">// +------+-----------------+</span>
<span class="c1">// |word  |ner              |</span>
<span class="c1">// +------+-----------------+</span>
<span class="c1">// |She   |O                |</span>
<span class="c1">// |has   |O                |</span>
<span class="c1">// |cystic|B-ImagingFindings|</span>
<span class="c1">// |cyst  |I-ImagingFindings|</span>
<span class="c1">// |on    |O                |</span>
<span class="c1">// |her   |O                |</span>
<span class="c1">// |kidney|B-BodyPart       |</span>
<span class="c1">// |.     |O                |</span>
<span class="c1">// +------+-----------------+</span>
<span class="c1">// result.select("ner_chunk.result").show(truncate=false)</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">// |result                     |</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">// |[cystic cyst on her kidney]|</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Defining</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="k">for</span> <span class="nc">NER</span>
<span class="k">val</span> <span class="nv">documentAssembler</span><span class="k">=new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span><span class="k">=new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="nc">False</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span><span class="k">=new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="nc">False</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)\</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span> <span class="o">\</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="c1">// Define the NerChunker to combine to chunks</span>
<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerChunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"&lt;ImagingFindings&gt;.&lt;BodyPart&gt;"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span><span class="k">=new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">chunker</span>
<span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Defining</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="k">for</span> <span class="nc">NER</span>
<span class="k">val</span> <span class="nv">documentAssembler</span><span class="k">=new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span><span class="k">=new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="nc">False</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span><span class="k">=new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="nc">False</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)\</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))\</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="c1">// Define the NerChunker to combine to chunks</span>
<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerChunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"&lt;ImagingFindings&gt;.&lt;BodyPart&gt;"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span><span class="k">=new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">chunker</span>
<span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="nerconverterinternal">NerConverterInternal</h2>

  <div class="h3-box model-content">

    <p>Converts a IOB or IOB2 representation of NER to a user-friendly one,
by associating the tokens of recognized entities and their label.
Chunks with no associated entity (tagged “O”) are filtered.
See also <a href="https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)">Inside–outside–beginning (tagging)</a> for more information.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, NAMED_ENTITY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/ner_converter_internal/index.html#sparknlp_jsl.annotator.ner.ner_converter_internal.NerConverterInternal">NerConverterInternal</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/NerConverterInternal">NerConverterInternal</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> 

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">jsl_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"jsl_ner"</span><span class="p">)</span>

<span class="n">jsl_ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"jsl_ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"jsl_ner_chunk"</span><span class="p">)</span>

<span class="n">jsl_ner_converter_internal</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"jsl_ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"replaced_ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceDictResource</span><span class="p">(</span><span class="s">"replace_dict.csv"</span><span class="p">,</span><span class="s">"text"</span><span class="p">,</span> <span class="p">{</span><span class="s">"delimiter"</span><span class="p">:</span><span class="s">","</span><span class="p">})</span>
      
<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span> 
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">jsl_ner</span><span class="p">,</span>
    <span class="n">jsl_ner_converter</span><span class="p">,</span>
    <span class="n">jsl_ner_converter_internal</span>
    <span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
    <span class="c1">#.setCustomBounds(["\n\n"])
</span>
<span class="n">tokenizer</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">fin_ner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_deid"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ORG"</span><span class="p">:</span> <span class="s">"PARTY"</span><span class="p">})</span> <span class="c1"># Replace "ORG" entity as "PARTY"
</span>
<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">fin_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
    <span class="c1">#.setCustomBounds(["\n\n"])
</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">legal_ner</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ALIAS"</span><span class="p">:</span> <span class="s">"PARTY"</span><span class="p">})</span> <span class="c1"># "ALIAS" are secondary names of companies, so let's extract them also as PARTY
</span>
<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">legal_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 


<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">jsl_ner</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"jsl_ner"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">jsl_ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"jsl_ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"jsl_ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">jsl_ner_converter_internal</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerConverterInternal</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"jsl_ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"replaced_ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setReplaceDictResource</span><span class="o">(</span><span class="s">"replace_dict.csv"</span><span class="o">,</span><span class="s">"text"</span><span class="o">,</span> <span class="o">{</span><span class="s">"delimiter"</span><span class="k">:</span><span class="err">"</span><span class="o">,</span><span class="err">"</span><span class="o">})</span>


<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">word_embeddings</span><span class="o">,</span>
  <span class="n">jsl_ner</span><span class="o">,</span>
  <span class="n">jsl_ner_converter</span><span class="o">,</span>
  <span class="n">jsl_ner_converter_internal</span>

<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 


<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">RoBertaEmbeddings</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">fin_ner</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_deid"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerConverterInternal</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">({</span><span class="s">"ORG"</span><span class="k">:</span> <span class="err">"</span><span class="kt">PARTY</span><span class="err">"</span><span class="o">})</span> 


<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">fin_ner</span><span class="o">,</span>
  <span class="n">ner_converter</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 


<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">RoBertaEmbeddings</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">legal_ner</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerConverterInternal</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">({</span><span class="s">"ALIAS"</span><span class="k">:</span> <span class="err">"</span><span class="kt">PARTY</span><span class="err">"</span><span class="o">})</span>


<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">legal_ner</span><span class="o">,</span>
  <span class="n">ner_converter</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="nerdisambiguator">NerDisambiguator</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Links words of interest, such as names of persons, locations and companies, from an input text document to
a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs),
mentions, or surface forms.
The model needs extracted CHUNKS and SENTENCE_EMBEDDINGS type input from e.g.
<a href="/docs/en/annotators#sentenceembeddings">SentenceEmbeddings</a> and
<a href="/docs/en/annotators#nerconverter">NerConverter</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DISAMBIGUATION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/disambiguation/ner_disambiguator/index.html#sparknlp_jsl.annotator.disambiguation.ner_disambiguator.NerDisambiguator">NerDisambiguator</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/disambiguation/NerDisambiguator">NerDisambiguator</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Extracting Person identities
# First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.
# Extracting Person identities
# First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"The show also had a contestant named Donald Trump who later defeated Christina Aguilera ..."</span><span class="p">]])</span> \
  <span class="p">.</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceEmbeddings</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>
<span class="n">ner_model</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"PER"</span><span class="p">])</span>

<span class="c1"># Then the extracted entities can be disambiguated.
</span><span class="n">disambiguator</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerDisambiguator</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setS3KnowledgeBaseName</span><span class="p">(</span><span class="s">"i-per"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"disambiguation"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setNumFirstChars</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">word_embeddings</span><span class="p">,</span>
  <span class="n">sentence_embeddings</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span>
  <span class="n">ner_converter</span><span class="p">,</span>
  <span class="n">disambiguator</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(disambiguation)"</span><span class="p">)</span>
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"col.metadata.chunk as chunk"</span><span class="p">,</span> <span class="s">"col.result as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>             <span class="o">|</span><span class="n">result</span>                                                                                                                  <span class="o">|</span>
<span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">Donald</span> <span class="n">Trump</span>      <span class="o">|</span><span class="n">http</span><span class="p">:</span><span class="c1">#en.wikipedia.org/?curid=4848272, http:#en.wikipedia.org/?curid=31698421, http:#en.wikipedia.org/?curid=55907961   |
</span><span class="o">|</span><span class="n">Christina</span> <span class="n">Aguilera</span><span class="o">|</span><span class="n">http</span><span class="p">:</span><span class="c1">#en.wikipedia.org/?curid=144171, http:#en.wikipedia.org/?curid=6636454                                             |
</span><span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Extracting Person identities
# First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.
# Extracting Person identities
# First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceEmbeddings</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>
<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"PER"</span><span class="p">])</span>

<span class="c1"># Then the extracted entities can be disambiguated.
</span><span class="n">disambiguator</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerDisambiguator</span><span class="p">()</span> \
  <span class="c1">#.setS3KnowledgeBaseName("i-per") \
</span>  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"disambiguation"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setNumFirstChars</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">word_embeddings</span><span class="p">,</span>
  <span class="n">sentence_embeddings</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span>
  <span class="n">ner_converter</span><span class="p">,</span>
  <span class="n">disambiguator</span><span class="p">])</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Extracting Person identities
# First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.
# Extracting Person identities
# First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceEmbeddings</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>
<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"PER"</span><span class="p">])</span>

<span class="c1"># Then the extracted entities can be disambiguated.
</span><span class="n">disambiguator</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerDisambiguator</span><span class="p">()</span> \
  <span class="c1">#.setS3KnowledgeBaseName("i-per") \
</span>  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"disambiguation"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setNumFirstChars</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">word_embeddings</span><span class="p">,</span>
  <span class="n">sentence_embeddings</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span>
  <span class="n">ner_converter</span><span class="p">,</span>
  <span class="n">disambiguator</span><span class="p">])</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Extracting</span> <span class="nc">Person</span> <span class="n">identities</span>
<span class="c1">// First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The show also had a contestant named Donald Trump who later defeated Christina Aguilera ..."</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"PER"</span><span class="o">)</span>

<span class="c1">// Then the extracted entities can be disambiguated.</span>
<span class="k">val</span> <span class="nv">disambiguator</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerDisambiguator</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setS3KnowledgeBaseName</span><span class="o">(</span><span class="s">"i-per"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"sentence_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"disambiguation"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNumFirstChars</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">word_embeddings</span><span class="o">,</span>
  <span class="n">sentence_embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_converter</span><span class="o">,</span>
  <span class="n">disambiguator</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(disambiguation)")</span>
<span class="c1">//   .selectExpr("col.metadata.chunk as chunk", "col.result as result").show(5, false)</span>
<span class="c1">// +------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |chunk             |result                                                                                                                  |</span>
<span class="c1">// +------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |Donald Trump      |http://en.wikipedia.org/?curid=4848272, http://en.wikipedia.org/?curid=31698421, http://en.wikipedia.org/?curid=55907961|</span>
<span class="c1">// |Christina Aguilera|http://en.wikipedia.org/?curid=144171, http://en.wikipedia.org/?curid=6636454                                           |</span>
<span class="c1">// +------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Extracting</span> <span class="nc">Person</span> <span class="n">identities</span>
<span class="c1">// First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The show also had a contestant named Donald Trump who later defeated Christina Aguilera ..."</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)\</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span> <span class="o">\</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"PER"</span><span class="o">)</span>

<span class="c1">// Then the extracted entities can be disambiguated.</span>
<span class="k">val</span> <span class="nv">disambiguator</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerDisambiguator</span><span class="o">()</span>
  <span class="o">#.</span><span class="py">setS3KnowledgeBaseName</span><span class="o">(</span><span class="s">"i-per"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"sentence_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"disambiguation"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNumFirstChars</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">word_embeddings</span><span class="o">,</span>
  <span class="n">sentence_embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_converter</span><span class="o">,</span>
  <span class="n">disambiguator</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Extracting</span> <span class="nc">Person</span> <span class="n">identities</span>
<span class="c1">// First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The show also had a contestant named Donald Trump who later defeated Christina Aguilera ..."</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)\</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))\</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"PER"</span><span class="o">)</span>

<span class="c1">// Then the extracted entities can be disambiguated.</span>
<span class="k">val</span> <span class="nv">disambiguator</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerDisambiguator</span><span class="o">()</span>
  <span class="o">#.</span><span class="py">setS3KnowledgeBaseName</span><span class="o">(</span><span class="s">"i-per"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"sentence_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"disambiguation"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNumFirstChars</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">word_embeddings</span><span class="o">,</span>
  <span class="n">sentence_embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_converter</span><span class="o">,</span>
  <span class="n">disambiguator</span><span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Links words of interest, such as names of persons, locations and companies, from an input text document to
a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs),
mentions, or surface forms.
Instantiated / pretrained model of the NerDisambiguator.
Links words of interest, such as names of persons, locations and companies, from an input text document to
a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs),
mentions, or surface forms.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DISAMBIGUATION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/disambiguation/ner_disambiguator/index.html#sparknlp_jsl.annotator.disambiguation.ner_disambiguator.NerDisambiguatorModel">NerDisambiguatorModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/disambiguation/NerDisambiguatorModel">NerDisambiguatorModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box">

  <h2 id="nermodel">NerModel</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>This Named Entity recognition annotator allows to train generic NER model based on Neural Networks.</p>

    <p>The architecture of the neural network is a Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets.</p>

    <p>For instantiated/pretrained models, see NerDLModel.</p>

    <p>The training data should be a labeled Spark Dataset, in the format of <a href="/docs/en/training#conll-dataset">CoNLL</a>
2003 IOB with <code class="language-plaintext highlighter-rouge">Annotation</code> type columns. The data should have columns of type <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, WORD_EMBEDDINGS</code> and an
additional label column of annotator type <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code>.
Excluding the label, this can be done with for example</p>
    <ul>
      <li>a <a href="/docs/en/annotators#sentencedetector">SentenceDetector</a>,</li>
      <li>a <a href="/docs/en/annotators#tokenizer">Tokenizer</a> and</li>
      <li>a <a href="/docs/en/annotators#wordembeddings">WordEmbeddingsModel</a> with clinical embeddings
(any <a href="https://nlp.johnsnowlabs.com/models?task=Embeddings">clinical word embeddings</a> can be chosen).</li>
    </ul>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb">Spark NLP Workshop</a>
(sections starting with <code class="language-plaintext highlighter-rouge">Training a Clinical NER</code>)</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/medical_ner/index.html#sparknlp_jsl.annotator.ner.medical_ner.MedicalNerApproach">MedicalNerApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/MedicalNerApproach.html">MedicalNerApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">clinical_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'embeddings_clinical'</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerApproach</span><span class="p">()</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEvaluationLogExtended</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setEnableOutputLogs</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setIncludeConfidence</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">'ner_logs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="s">'medical_ner_graphs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEnableMemoryOptimizer</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
<span class="n">documentAssembler</span><span class="p">,</span>
<span class="n">sentence</span><span class="p">,</span>
<span class="n">tokenizer</span><span class="p">,</span>
<span class="n">clinical_embeddings</span><span class="p">,</span>
<span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">clinical_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'embeddings_clinical'</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerApproach</span><span class="p">()</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEvaluationLogExtended</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setEnableOutputLogs</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setIncludeConfidence</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">'ner_logs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="s">'medical_ner_graphs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEnableMemoryOptimizer</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
<span class="n">documentAssembler</span><span class="p">,</span>
<span class="n">sentence</span><span class="p">,</span>
<span class="n">tokenizer</span><span class="p">,</span>
<span class="n">clinical_embeddings</span><span class="p">,</span>
<span class="n">nerTagger</span>
<span class="p">])</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">clinical_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'embeddings_clinical'</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerApproach</span><span class="p">()</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEvaluationLogExtended</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setEnableOutputLogs</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setIncludeConfidence</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">'ner_logs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="s">'medical_ner_graphs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEnableMemoryOptimizer</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
<span class="n">documentAssembler</span><span class="p">,</span>
<span class="n">sentence</span><span class="p">,</span>
<span class="n">tokenizer</span><span class="p">,</span>
<span class="n">clinical_embeddings</span><span class="p">,</span>
<span class="n">nerTagger</span>
<span class="p">])</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">First</span> <span class="n">extract</span> <span class="n">the</span> <span class="n">prerequisites</span> <span class="k">for</span> <span class="n">the</span> <span class="nc">NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'embeddings_clinica</span><span class="n">l</span><span class="o">',</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerApproach</span><span class="o">()</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
<span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mf">0.003f</span><span class="o">)</span>
<span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">8</span><span class="o">)</span>
<span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEvaluationLogExtended</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEnableOutputLogs</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setIncludeConfidence</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">First</span> <span class="n">extract</span> <span class="n">the</span> <span class="n">prerequisites</span> <span class="k">for</span> <span class="n">the</span> <span class="nc">NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'embeddings_clinica</span><span class="n">l</span><span class="o">',</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerApproach</span><span class="o">()</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
<span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mf">0.003f</span><span class="o">)</span>
<span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">8</span><span class="o">)</span>
<span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEvaluationLogExtended</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEnableOutputLogs</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setIncludeConfidence</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">First</span> <span class="n">extract</span> <span class="n">the</span> <span class="n">prerequisites</span> <span class="k">for</span> <span class="n">the</span> <span class="nc">NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'embeddings_clinica</span><span class="n">l</span><span class="o">',</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerApproach</span><span class="o">()</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
<span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mf">0.003f</span><span class="o">)</span>
<span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">8</span><span class="o">)</span>
<span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEvaluationLogExtended</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEnableOutputLogs</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setIncludeConfidence</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>This Named Entity recognition annotator is a generic NER model based on Neural Networks.</p>

    <p>Pretrained models can be loaded with <code class="language-plaintext highlighter-rouge">pretrained</code> of the companion object:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>val nerModel = nlp.NerDLModel.pretrained()
  .setInputCols("sentence", "token", "embeddings")
  .setOutputCol("ner")
</code></pre></div>    </div>
    <p>The default model is <code class="language-plaintext highlighter-rouge">"ner_clinical"</code>, if no name is provided.</p>

    <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition">Models Hub</a>.
Additionally, pretrained pipelines are available for this module, see <a href="https://nlp.johnsnowlabs.com/docs/en/pipelines">Pipelines</a>.</p>

    <p>Note that some pretrained models require specific types of embeddings, depending on which they were trained on.
For example, the default model <code class="language-plaintext highlighter-rouge">"ner_dl"</code> requires the
<a href="/docs/en/annotators#wordembeddings">WordEmbeddings</a> <code class="language-plaintext highlighter-rouge">"ner_clinical"</code>.</p>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb">Spark NLP Workshop</a>
(sections starting with <code class="language-plaintext highlighter-rouge">Training a Clinical NER</code>)</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/medical_ner/index.html#sparknlp_jsl.annotator.ner.medical_ner.MedicalNerModel">MedicalNerModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/MedicalNerModel.html">MedicalNerModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> 

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>


<span class="n">jsl_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"jsl_ner"</span><span class="p">)</span>
    
<span class="n">jsl_ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"jsl_ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"jsl_ner_chunk"</span><span class="p">)</span>

<span class="n">jsl_ner_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span> 
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">jsl_ner</span><span class="p">,</span>
    <span class="n">jsl_ner_converter</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">jsl_ner_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
        
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_headers"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">sentenceDetector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">])</span>



<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
        
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_headers"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">sentenceDetector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">])</span>



<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">jsl_ner</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"jsl_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">jsl_ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"jsl_ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"jsl_ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">word_embeddings</span><span class="o">,</span>
  <span class="n">jsl_ner</span><span class="o">,</span>
  <span class="n">jsl_ner_converter</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 


<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertEmbeddings</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_headers"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_converter</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 


<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">RoBertaEmbeddings</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_headers"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>




<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_converter</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="renerchunksfilter">RENerChunksFilter</h2>

  <div class="h3-box model-content">

    <p>Filters and outputs combinations of relations between extracted entities, for further processing.
This annotator is especially useful to create inputs for the RelationExtractionDLModel.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/relation_ner_chunk_filter/index.html#sparknlp_jsl.annotator.re.relation_ner_chunk_filter.RENerChunksFilter">RENerChunksFilter</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RENerChunksFilter">RENerChunksFilter</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Define pipeline stages to extract entities
</span><span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">clinical_ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"jsl_ner_wip_greedy_clinical"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="c1"># Define the relation pairs and the filter
</span><span class="n">relationPairs</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s">"direction-external_body_part_or_region"</span><span class="p">,</span>
  <span class="s">"external_body_part_or_region-direction"</span><span class="p">,</span>
  <span class="s">"direction-internal_organ_or_component"</span><span class="p">,</span>
  <span class="s">"internal_organ_or_component-direction"</span>
<span class="p">]</span>

<span class="n">re_ner_chunk_filter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"internal_organ_or_component-direction"</span><span class="p">])</span>

<span class="n">trained_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documenter</span><span class="p">,</span>
  <span class="n">sentencer</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">words_embedder</span><span class="p">,</span>
  <span class="n">pos_tagger</span><span class="p">,</span>
  <span class="n">clinical_ner_tagger</span><span class="p">,</span>
  <span class="n">ner_chunker</span><span class="p">,</span>
  <span class="n">dependency_parser</span><span class="p">,</span>
  <span class="n">re_ner_chunk_filter</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trained_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(re_ner_chunks) as re_chunks"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"re_chunks.begin"</span><span class="p">,</span> <span class="s">"re_chunks.result"</span><span class="p">,</span> <span class="s">"re_chunks.metadata.entity"</span><span class="p">,</span> <span class="s">"re_chunks.metadata.paired_to"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----+-------------+---------------------------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">result</span>       <span class="o">|</span><span class="n">entity</span>                     <span class="o">|</span><span class="n">paired_to</span><span class="o">|</span>
<span class="o">+-----+-------------+---------------------------+---------+</span>
<span class="o">|</span><span class="mi">35</span>   <span class="o">|</span><span class="n">upper</span>        <span class="o">|</span><span class="n">Direction</span>                  <span class="o">|</span><span class="mi">41</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">41</span>   <span class="o">|</span><span class="n">brain</span> <span class="n">stem</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">35</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">35</span>   <span class="o">|</span><span class="n">upper</span>        <span class="o">|</span><span class="n">Direction</span>                  <span class="o">|</span><span class="mi">59</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">59</span>   <span class="o">|</span><span class="n">cerebellum</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">35</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">35</span>   <span class="o">|</span><span class="n">upper</span>        <span class="o">|</span><span class="n">Direction</span>                  <span class="o">|</span><span class="mi">81</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">81</span>   <span class="o">|</span><span class="n">basil</span> <span class="n">ganglia</span><span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">35</span>       <span class="o">|</span>
<span class="o">+-----+-------------+---------------------------+---------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Define pipeline stages to extract entities
</span><span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="c1"># Define the relation pairs and the filter
</span><span class="n">relationPairs</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s">"direction-external_body_part_or_region"</span><span class="p">,</span>
  <span class="s">"external_body_part_or_region-direction"</span><span class="p">,</span>
  <span class="s">"direction-internal_organ_or_component"</span><span class="p">,</span>
  <span class="s">"internal_organ_or_component-direction"</span>
<span class="p">]</span>

<span class="n">re_ner_chunk_filter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"internal_organ_or_component-direction"</span><span class="p">])</span>

<span class="n">trained_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documenter</span><span class="p">,</span>
  <span class="n">sentencer</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">words_embedder</span><span class="p">,</span>
  <span class="n">pos_tagger</span><span class="p">,</span>
  <span class="n">dependency_parser</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span>
  <span class="n">ner_chunker</span><span class="p">,</span>
  <span class="n">re_ner_chunk_filter</span>
<span class="p">])</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Define pipeline stages to extract entities
</span><span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embedding"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="c1"># Define the relation pairs and the filter
</span><span class="n">relationPairs</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s">"direction-external_body_part_or_region"</span><span class="p">,</span>
  <span class="s">"external_body_part_or_region-direction"</span><span class="p">,</span>
  <span class="s">"direction-internal_organ_or_component"</span><span class="p">,</span>
  <span class="s">"internal_organ_or_component-direction"</span>
<span class="p">]</span>

<span class="n">re_ner_chunk_filter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"internal_organ_or_component-direction"</span><span class="p">])</span>

<span class="n">trained_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documenter</span><span class="p">,</span>
  <span class="n">sentencer</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">words_embedder</span><span class="p">,</span>
  <span class="n">pos_tagger</span><span class="p">,</span>
  <span class="n">dependency_parser</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span>
  <span class="n">ner_chunker</span><span class="p">,</span>
  <span class="n">re_ner_chunk_filter</span>
<span class="p">])</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="n">to</span> <span class="n">extract</span> <span class="n">entities</span>
<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner_tagger</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"jsl_ner_wip_greedy_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_tags"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span>

<span class="c1">// Define the relation pairs and the filter</span>
<span class="k">val</span> <span class="nv">relationPairs</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"direction-external_body_part_or_region"</span><span class="o">,</span>
                      <span class="s">"external_body_part_or_region-direction"</span><span class="o">,</span>
                      <span class="s">"direction-internal_organ_or_component"</span><span class="o">,</span>
                      <span class="s">"internal_organ_or_component-direction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_ner_chunk_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">RENerChunksFilter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"internal_organ_or_component-direction"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">trained_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documenter</span><span class="o">,</span>
  <span class="n">sentencer</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">words_embedder</span><span class="o">,</span>
  <span class="n">pos_tagger</span><span class="o">,</span>
  <span class="n">clinical_ner_tagger</span><span class="o">,</span>
  <span class="n">ner_chunker</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">re_ner_chunk_filter</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trained_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(re_ner_chunks) as re_chunks")</span>
<span class="c1">//   .selectExpr("re_chunks.begin", "re_chunks.result", "re_chunks.metadata.entity", "re_chunks.metadata.paired_to")</span>
<span class="c1">//   .show(6, truncate=false)</span>
<span class="c1">// +-----+-------------+---------------------------+---------+</span>
<span class="c1">// |begin|result       |entity                     |paired_to|</span>
<span class="c1">// +-----+-------------+---------------------------+---------+</span>
<span class="c1">// |35   |upper        |Direction                  |41       |</span>
<span class="c1">// |41   |brain stem   |Internal_organ_or_component|35       |</span>
<span class="c1">// |35   |upper        |Direction                  |59       |</span>
<span class="c1">// |59   |cerebellum   |Internal_organ_or_component|35       |</span>
<span class="c1">// |35   |upper        |Direction                  |81       |</span>
<span class="c1">// |81   |basil ganglia|Internal_organ_or_component|35       |</span>
<span class="c1">// +-----+-------------+---------------------------+---------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="n">to</span> <span class="n">extract</span> <span class="n">entities</span>
<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span>

<span class="c1">// Define the relation pairs and the filter</span>
<span class="k">val</span> <span class="nv">relationPairs</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"direction-external_body_part_or_region"</span><span class="o">,</span>
                      <span class="s">"external_body_part_or_region-direction"</span><span class="o">,</span>
                      <span class="s">"direction-internal_organ_or_component"</span><span class="o">,</span>
                      <span class="s">"internal_organ_or_component-direction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_ner_chunk_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">RENerChunksFilter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"internal_organ_or_component-direction"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">trained_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documenter</span><span class="o">,</span>
  <span class="n">sentencer</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">words_embedder</span><span class="o">,</span>
  <span class="n">pos_tagger</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_chunker</span><span class="o">,</span>
  <span class="n">re_ner_chunk_filter</span>
<span class="o">))</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="n">to</span> <span class="n">extract</span> <span class="n">entities</span>
<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embedding"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span>

<span class="c1">// Define the relation pairs and the filter</span>
<span class="k">val</span> <span class="nv">relationPairs</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"direction-external_body_part_or_region"</span><span class="o">,</span>
                      <span class="s">"external_body_part_or_region-direction"</span><span class="o">,</span>
                      <span class="s">"direction-internal_organ_or_component"</span><span class="o">,</span>
                      <span class="s">"internal_organ_or_component-direction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_ner_chunk_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">RENerChunksFilter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"internal_organ_or_component-direction"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">trained_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documenter</span><span class="o">,</span>
  <span class="n">sentencer</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">words_embedder</span><span class="o">,</span>
  <span class="n">pos_tagger</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_chunker</span><span class="o">,</span>
  <span class="n">re_ner_chunk_filter</span>
<span class="o">))</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="reidentification">ReIdentification</h2>

  <div class="h3-box model-content">

    <p>Reidentifies obfuscated entities by DeIdentification. This annotator requires the outputs
from the deidentification as input. Input columns need to be the deidentified document and the deidentification
mappings set with DeIdentification.setMappingsColumn.
To see how the entities are deidentified, please refer to the example of that class.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT,CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/reIdentification/index.html#sparknlp_jsl.annotator.deid.reIdentification.ReIdentification">ReIdentification</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/ReIdentification">ReIdentification</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="c1"># Define the reidentification stage and transform the deidentified documents
</span><span class="n">reideintification</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ReIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"dei"</span><span class="p">,</span> <span class="s">"protectedEntities"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"reid"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"dei.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                            <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="c1"># 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]|
</span><span class="o">+--------------------------------------------------------------------------------------------------+</span>

<span class="n">reideintification</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(reid.result)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                                <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="c1"># 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.|
</span><span class="o">+-----------------------------------------------------------------------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="c1"># Define the reidentification stage and transform the deidentified documents
</span><span class="n">reideintification</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ReIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"aux"</span><span class="p">,</span> <span class="s">"deidentified"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"original"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="c1"># Define the reidentification stage and transform the deidentified documents
</span><span class="n">reideintification</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ReIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"aux"</span><span class="p">,</span> <span class="s">"deidentified"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"original"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">the</span> <span class="n">reidentification</span> <span class="n">stage</span> <span class="n">and</span> <span class="n">transform</span> <span class="n">the</span> <span class="n">deidentified</span> <span class="n">documents</span>
<span class="k">val</span> <span class="nv">reideintification</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">ReIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"dei"</span><span class="o">,</span> <span class="s">"protectedEntities"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"reid"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">result</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.select("dei.result").show(truncate = false)</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |result                                                                                            |</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]|</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">// reideintification.selectExpr("explode(reid.result)").show(false)</span>
<span class="c1">// +-----------------------------------------------------------------------------------+</span>
<span class="c1">// |col                                                                                |</span>
<span class="c1">// +-----------------------------------------------------------------------------------+</span>
<span class="c1">// |# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.|</span>
<span class="c1">// +-----------------------------------------------------------------------------------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">the</span> <span class="n">reidentification</span> <span class="n">stage</span> <span class="n">and</span> <span class="n">transform</span> <span class="n">the</span> <span class="n">deidentified</span> <span class="n">documents</span>
<span class="k">val</span> <span class="nv">reideintification</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">ReIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"aux"</span><span class="o">,</span> <span class="s">"deidentified"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"original"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">result</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Define</span> <span class="n">the</span> <span class="n">reidentification</span> <span class="n">stage</span> <span class="n">and</span> <span class="n">transform</span> <span class="n">the</span> <span class="n">deidentified</span> <span class="n">documents</span>
<span class="k">val</span> <span class="nv">reideintification</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">ReIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"aux"</span><span class="o">,</span> <span class="s">"deidentified"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"original"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">result</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="relationextraction">RelationExtraction</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a TensorFlow model for relation extraction. The Tensorflow graph in <code class="language-plaintext highlighter-rouge">.pb</code> format needs to be specified with
<code class="language-plaintext highlighter-rouge">setModelFile</code>. The result is a RelationExtractionModel.
To start training, see the parameters that need to be set in the Parameters section.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/relation_extraction/index.html#sparknlp_jsl.annotator.re.relation_extraction.RelationExtractionApproach">RelationExtractionApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionApproach">RelationExtractionApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span>
<span class="c1"># Defining pipeline stages to extract entities first
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"posTags"</span><span class="p">)</span>

<span class="n">nerTagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">MedicalNerModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_events_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"nerChunks"</span><span class="p">)</span>

<span class="n">depencyParser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"posTags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="c1"># Then define `RelationExtractionApproach` and training parameters
</span><span class="n">re</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"posTags"</span><span class="p">,</span> <span class="s">"train_ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations_t"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target_rel"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"path/to/graph_file.pb"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFromEntity</span><span class="p">(</span><span class="s">"from_begin"</span><span class="p">,</span> <span class="s">"from_end"</span><span class="p">,</span> <span class="s">"from_label"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setToEntity</span><span class="p">(</span><span class="s">"to_begin"</span><span class="p">,</span> <span class="s">"to_end"</span><span class="p">,</span> <span class="s">"to_label"</span><span class="p">)</span>

<span class="n">finisher</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Finisher</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"relations_t"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"relations"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setValueSplitSymbol</span><span class="p">(</span><span class="s">","</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setAnnotationSplitSymbol</span><span class="p">(</span><span class="s">","</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputAsArray</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Define complete pipeline and start training
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embedder</span><span class="p">,</span>
    <span class="n">posTagger</span><span class="p">,</span>
    <span class="n">nerTagger</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">depencyParser</span><span class="p">,</span>
    <span class="n">re</span><span class="p">,</span>
    <span class="n">finisher</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainData</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Defining</span> <span class="n">pipeline</span> <span class="n">stages</span> <span class="n">to</span> <span class="n">extract</span> <span class="n">entities</span> <span class="n">first</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embedder</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">PerceptronModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"posTags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_events_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_tags"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"nerChunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">depencyParser</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DependencyParserModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"posTags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="c1">// Then define `RelationExtractionApproach` and training parameters</span>
<span class="k">val</span> <span class="nv">re</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">RelationExtractionApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span> <span class="s">"posTags"</span><span class="o">,</span> <span class="s">"train_ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations_t"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target_rel"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">300</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">200</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.05f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFromEntity</span><span class="o">(</span><span class="s">"from_begin"</span><span class="o">,</span> <span class="s">"from_end"</span><span class="o">,</span> <span class="s">"from_label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setToEntity</span><span class="o">(</span><span class="s">"to_begin"</span><span class="o">,</span> <span class="s">"to_end"</span><span class="o">,</span> <span class="s">"to_label"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">finisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Finisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"relations_t"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"relations"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValueSplitSymbol</span><span class="o">(</span><span class="s">","</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAnnotationSplitSymbol</span><span class="o">(</span><span class="s">","</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsArray</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// Define complete pipeline and start training</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embedder</span><span class="o">,</span>
    <span class="n">posTagger</span><span class="o">,</span>
    <span class="n">nerTagger</span><span class="o">,</span>
    <span class="n">nerConverter</span><span class="o">,</span>
    <span class="n">depencyParser</span><span class="o">,</span>
    <span class="n">re</span><span class="o">,</span>
    <span class="n">finisher</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainData</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Extracts and classifies instances of relations between named entities. For this, relation pairs
need to be defined with <code class="language-plaintext highlighter-rouge">setRelationPairs</code>, to specify between which entities the extraction should be done.</p>

    <p>For pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Relation+Extraction">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/relation_extraction/index.html#sparknlp_jsl.annotator.re.relation_extraction.RelationExtractionModel">RelationExtractionModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionModel">RelationExtractionModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Relation Extraction between body parts
# Define pipeline stages to extract entities
</span><span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">clinical_ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"jsl_ner_wip_greedy_clinical"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="c1"># Define the relations that are to be extracted
</span><span class="n">relationPairs</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s">"direction-external_body_part_or_region"</span><span class="p">,</span>
  <span class="s">"external_body_part_or_region-direction"</span><span class="p">,</span>
  <span class="s">"direction-internal_organ_or_component"</span><span class="p">,</span>
  <span class="s">"internal_organ_or_component-direction"</span>
<span class="p">]</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"re_bodypart_directions"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">(</span><span class="n">relationPairs</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documenter</span><span class="p">,</span>
    <span class="n">sentencer</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">words_embedder</span><span class="p">,</span>
    <span class="n">pos_tagger</span><span class="p">,</span>
    <span class="n">clinical_ner_tagger</span><span class="p">,</span>
    <span class="n">ner_chunker</span><span class="p">,</span>
    <span class="n">dependency_parser</span><span class="p">,</span>
    <span class="n">re_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
#
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(relations) as relations"</span><span class="p">)</span>
 <span class="p">.</span><span class="n">select</span><span class="p">(</span>
   <span class="s">"relations.metadata.chunk1"</span><span class="p">,</span>
   <span class="s">"relations.metadata.entity1"</span><span class="p">,</span>
   <span class="s">"relations.metadata.chunk2"</span><span class="p">,</span>
   <span class="s">"relations.metadata.entity2"</span><span class="p">,</span>
   <span class="s">"relations.result"</span>
 <span class="p">)</span>
 <span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="s">"result != 0"</span><span class="p">)</span>
 <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(relations) as relations"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">select</span><span class="p">(</span>
     <span class="s">"relations.metadata.chunk1"</span><span class="p">,</span>
     <span class="s">"relations.metadata.entity1"</span><span class="p">,</span>
     <span class="s">"relations.metadata.chunk2"</span><span class="p">,</span>
     <span class="s">"relations.metadata.entity2"</span><span class="p">,</span>
     <span class="s">"relations.result"</span>
  <span class="p">).</span><span class="n">where</span><span class="p">(</span><span class="s">"result != 0"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
<span class="o">|</span><span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span>  <span class="o">|</span><span class="n">chunk2</span>       <span class="o">|</span><span class="n">entity2</span>                    <span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
<span class="o">|</span><span class="n">upper</span> <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">brain</span> <span class="n">stem</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">left</span>  <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">cerebellum</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">right</span> <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">basil</span> <span class="n">ganglia</span><span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Relation</span> <span class="nc">Extraction</span> <span class="n">between</span> <span class="n">body</span> <span class="n">parts</span>
<span class="c1">// Define pipeline stages to extract entities</span>
<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner_tagger</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"jsl_ner_wip_greedy_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_tags"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span>

<span class="c1">// Define the relations that are to be extracted</span>
<span class="k">val</span> <span class="nv">relationPairs</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"direction-external_body_part_or_region"</span><span class="o">,</span>
                      <span class="s">"external_body_part_or_region-direction"</span><span class="o">,</span>
                      <span class="s">"direction-internal_organ_or_component"</span><span class="o">,</span>
                      <span class="s">"internal_organ_or_component-direction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_model</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">RelationExtractionModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"re_bodypart_directions"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="n">relationPairs</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.9f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documenter</span><span class="o">,</span>
  <span class="n">sentencer</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">words_embedder</span><span class="o">,</span>
  <span class="n">pos_tagger</span><span class="o">,</span>
  <span class="n">clinical_ner_tagger</span><span class="o">,</span>
  <span class="n">ner_chunker</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">re_model</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(relations) as relations")</span>
<span class="c1">//  .select(</span>
<span class="c1">//    "relations.metadata.chunk1",</span>
<span class="c1">//    "relations.metadata.entity1",</span>
<span class="c1">//    "relations.metadata.chunk2",</span>
<span class="c1">//    "relations.metadata.entity2",</span>
<span class="c1">//    "relations.result"</span>
<span class="c1">//  )</span>
<span class="c1">//  .where("result != 0")</span>
<span class="c1">//  .show(truncate=false)</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">// |chunk1|entity1  |chunk2       |entity2                    |result|</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">// |upper |Direction|brain stem   |Internal_organ_or_component|1     |</span>
<span class="c1">// |left  |Direction|cerebellum   |Internal_organ_or_component|1     |</span>
<span class="c1">// |right |Direction|basil ganglia|Internal_organ_or_component|1     |</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="relationextractiondl">RelationExtractionDL</h2>

  <div class="h3-box model-content">

    <p>Extracts and classifies instances of relations between named entities.
In contrast with RelationExtractionModel, RelationExtractionDLModel is based on BERT.
For pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Relation+Extraction">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/relation_extraction_dl/index.html#sparknlp_jsl.annotator.re.relation_extraction_dl.RelationExtractionDLModel">RelationExtractionDLModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionDLModel">RelationExtractionDLModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Relation Extraction between body parts
# This is a continuation of the RENerChunksFilter example. See that class on how to extract the relation chunks.
# Define the extraction model
</span><span class="n">re_ner_chunk_filter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span> \
 <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
 <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"internal_organ_or_component-direction"</span><span class="p">])</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"redl_bodypart_direction_biobert"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunks"</span><span class="p">,</span> <span class="s">"sentences"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>

<span class="n">trained_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documenter</span><span class="p">,</span>
  <span class="n">sentencer</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">words_embedder</span><span class="p">,</span>
  <span class="n">pos_tagger</span><span class="p">,</span>
  <span class="n">clinical_ner_tagger</span><span class="p">,</span>
  <span class="n">ner_chunker</span><span class="p">,</span>
  <span class="n">dependency_parser</span><span class="p">,</span>
  <span class="n">re_ner_chunk_filter</span><span class="p">,</span>
  <span class="n">re_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trained_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(relations) as relations"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">select</span><span class="p">(</span>
   <span class="s">"relations.metadata.chunk1"</span><span class="p">,</span>
   <span class="s">"relations.metadata.entity1"</span><span class="p">,</span>
   <span class="s">"relations.metadata.chunk2"</span><span class="p">,</span>
   <span class="s">"relations.metadata.entity2"</span><span class="p">,</span>
   <span class="s">"relations.result"</span>
 <span class="p">)</span> \
 <span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="s">"result != 0"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
<span class="o">|</span><span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span>  <span class="o">|</span><span class="n">chunk2</span>       <span class="o">|</span><span class="n">entity2</span>                    <span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
<span class="o">|</span><span class="n">upper</span> <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">brain</span> <span class="n">stem</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">left</span>  <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">cerebellum</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">right</span> <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">basil</span> <span class="n">ganglia</span><span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span> <span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
        
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_org"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_org"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_org"</span><span class="p">)</span>

<span class="n">token_classifier</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DeBertaForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"deberta_v3_base_token_classifier_ontonotes"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span> 

<span class="n">ner_converter_date</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_date"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"DATE"</span><span class="p">])</span>

<span class="n">chunk_merger</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk_org"</span><span class="p">,</span> <span class="s">"ner_chunk_date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'ner_chunk'</span><span class="p">)</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finre_acquisitions_subsidiaries"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.3</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">token_classifier</span><span class="p">,</span>
        <span class="n">ner_converter_date</span><span class="p">,</span>
        <span class="n">chunk_merger</span><span class="p">,</span>
        <span class="n">re_model</span>
        <span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span> <span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
        
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
    
<span class="n">re_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legre_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">re_model</span>
        <span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Relation</span> <span class="nc">Extraction</span> <span class="n">between</span> <span class="n">body</span> <span class="n">parts</span>
<span class="c1">// This is a continuation of the [[RENerChunksFilter]] example. See that class on how to extract the relation chunks.</span>
<span class="c1">// Define the extraction model</span>
<span class="k">val</span> <span class="nv">re_ner_chunk_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">RENerChunksFilter</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"internal_organ_or_component-direction"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">re_model</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">RelationExtractionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"redl_bodypart_direction_biobert"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">,</span> <span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trained_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documenter</span><span class="o">,</span>
  <span class="n">sentencer</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">words_embedder</span><span class="o">,</span>
  <span class="n">pos_tagger</span><span class="o">,</span>
  <span class="n">clinical_ner_tagger</span><span class="o">,</span>
  <span class="n">ner_chunker</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">re_ner_chunk_filter</span><span class="o">,</span>
  <span class="n">re_model</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trained_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(relations) as relations")</span>
<span class="c1">//  .select(</span>
<span class="c1">//    "relations.metadata.chunk1",</span>
<span class="c1">//    "relations.metadata.entity1",</span>
<span class="c1">//    "relations.metadata.chunk2",</span>
<span class="c1">//    "relations.metadata.entity2",</span>
<span class="c1">//    "relations.result"</span>
<span class="c1">//  )</span>
<span class="c1">//  .where("result != 0")</span>
<span class="c1">//  .show(truncate=false)</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">// |chunk1|entity1  |chunk2       |entity2                    |result|</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">// |upper |Direction|brain stem   |Internal_organ_or_component|1     |</span>
<span class="c1">// |left  |Direction|cerebellum   |Internal_organ_or_component|1     |</span>
<span class="c1">// |right |Direction|basil ganglia|Internal_organ_or_component|1     |</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 


<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertEmbeddings</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_org"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_org"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_org"</span><span class="o">)</span>
   

<span class="k">val</span> <span class="nv">token_classifier</span>  <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DeBertaForTokenClassification</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"deberta_v3_base_token_classifier_ontonotes"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="nc">True</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMaxSentenceLength</span><span class="o">(</span><span class="mi">512</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter_date</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_date"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">chunk_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">ChunkMergeApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk_org"</span><span class="o">,</span> <span class="s">"ner_chunk_date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="ss">'ner_chun</span><span class="n">k</span><span class="o">')</span>


<span class="k">val</span> <span class="nv">re_model</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">RelationExtractionDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finre_acquisitions_subsidiaries"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.3</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
   
    
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_converter</span><span class="o">,</span>
  <span class="n">token_classifier</span><span class="o">,</span>
  <span class="n">ner_converter_date</span><span class="o">,</span>
  <span class="n">chunk_merger</span><span class="o">,</span>
  <span class="n">re_model</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 


<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">RoBertaEmbeddings</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setMaxSentenceLength</span><span class="o">(</span><span class="mi">512</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
   

<span class="k">val</span> <span class="nv">re_model</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">RelationExtractionDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legre_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.5</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
   
    
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_converter</span><span class="o">,</span>
  <span class="n">re_model</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="sentenceentityresolver">SentenceEntityResolver</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Contains all the parameters and methods to train a SentenceEntityResolverModel.
The model transforms a dataset with Input Annotation type SENTENCE_EMBEDDINGS, coming from e.g.
<a href="/docs/en/transformers#bertsentenceembeddings">BertSentenceEmbeddings</a>
and returns the normalized entity for a particular trained ontology / curated dataset.
(e.g. ICD-10, RxNorm, SNOMED etc.)</p>

    <p>To use pretrained models please use SentenceEntityResolverModel
and see the <a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/resolution/sentence_entity_resolver/index.html#sparknlp_jsl.annotator.resolution.sentence_entity_resolver.SentenceEntityResolverApproach">SentenceEntityResolverApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/SentenceEntityResolverApproach">SentenceEntityResolverApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box test-approach">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="c1"># Training a SNOMED resolution model using BERT sentence embeddings
# Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">bertEmbeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">snomedTrainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">bertEmbeddings</span>
<span class="p">])</span>
<span class="n">snomedTrainingModel</span> <span class="o">=</span> <span class="n">snomedTrainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">snomedData</span> <span class="o">=</span> <span class="n">snomedTrainingModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Then the Resolver can be trained with
</span><span class="n">bertExtractor</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setNeighbours</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"bert_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setNormalizedCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_code"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDIAN"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">snomedModel</span> <span class="o">=</span> <span class="n">bertExtractor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snomedData</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="c1"># Training a SNOMED resolution model using BERT sentence embeddings
# Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">bertEmbeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">snomedTrainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">bertEmbeddings</span>
<span class="p">])</span>
<span class="n">snomedTrainingModel</span> <span class="o">=</span> <span class="n">snomedTrainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">snomedData</span> <span class="o">=</span> <span class="n">snomedTrainingModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Then the Resolver can be trained with
</span><span class="n">bertExtractor</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">SentenceEntityResolverApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setNeighbours</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"bert_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setNormalizedCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_code"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDIAN"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">snomedModel</span> <span class="o">=</span> <span class="n">bertExtractor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snomedData</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="c1"># Training a SNOMED resolution model using BERT sentence embeddings
# Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">bertEmbeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">snomedTrainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">bertEmbeddings</span>
<span class="p">])</span>
<span class="n">snomedTrainingModel</span> <span class="o">=</span> <span class="n">snomedTrainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">snomedData</span> <span class="o">=</span> <span class="n">snomedTrainingModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Then the Resolver can be trained with
</span><span class="n">bertExtractor</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">SentenceEntityResolverApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setNeighbours</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"bert_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setNormalizedCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_code"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDIAN"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">snomedModel</span> <span class="o">=</span> <span class="n">bertExtractor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snomedData</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Training</span> <span class="n">a</span> <span class="nc">SNOMED</span> <span class="n">resolution</span> <span class="n">model</span> <span class="n">using</span> <span class="nc">BERT</span> <span class="n">sentence</span> <span class="n">embeddings</span>
<span class="c1">// Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">bertEmbeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedTrainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
   <span class="n">documentAssembler</span><span class="o">,</span>
   <span class="n">sentenceDetector</span><span class="o">,</span>
   <span class="n">bertEmbeddings</span>
 <span class="o">))</span>
 <span class="k">val</span> <span class="nv">snomedTrainingModel</span> <span class="k">=</span> <span class="nv">snomedTrainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedData</span> <span class="k">=</span> <span class="nv">snomedTrainingModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Then the Resolver can be trained with</span>
<span class="k">val</span> <span class="nv">bertExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">medical</span><span class="o">.</span><span class="py">SentenceEntityResolverApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setNeighbours</span><span class="o">(</span><span class="mi">25</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNormalizedCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"snomed_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDIAN"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedModel</span> <span class="k">=</span> <span class="nv">bertExtractor</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">snomedData</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Training</span> <span class="n">a</span> <span class="nc">SNOMED</span> <span class="n">resolution</span> <span class="n">model</span> <span class="n">using</span> <span class="nc">BERT</span> <span class="n">sentence</span> <span class="n">embeddings</span>
<span class="c1">// Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">bertEmbeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedTrainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
   <span class="n">documentAssembler</span><span class="o">,</span>
   <span class="n">sentenceDetector</span><span class="o">,</span>
   <span class="n">bertEmbeddings</span>
 <span class="o">))</span>
 <span class="k">val</span> <span class="nv">snomedTrainingModel</span> <span class="k">=</span> <span class="nv">snomedTrainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedData</span> <span class="k">=</span> <span class="nv">snomedTrainingModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Then the Resolver can be trained with</span>
<span class="k">val</span> <span class="nv">bertExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">finance</span><span class="o">.</span><span class="py">SentenceEntityResolverApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setNeighbours</span><span class="o">(</span><span class="mi">25</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNormalizedCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"snomed_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDIAN"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedModel</span> <span class="k">=</span> <span class="nv">bertExtractor</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">snomedData</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Training</span> <span class="n">a</span> <span class="nc">SNOMED</span> <span class="n">resolution</span> <span class="n">model</span> <span class="n">using</span> <span class="nc">BERT</span> <span class="n">sentence</span> <span class="n">embeddings</span>
<span class="c1">// Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">bertEmbeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedTrainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
   <span class="n">documentAssembler</span><span class="o">,</span>
   <span class="n">sentenceDetector</span><span class="o">,</span>
   <span class="n">bertEmbeddings</span>
 <span class="o">))</span>
 <span class="k">val</span> <span class="nv">snomedTrainingModel</span> <span class="k">=</span> <span class="nv">snomedTrainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedData</span> <span class="k">=</span> <span class="nv">snomedTrainingModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Then the Resolver can be trained with</span>
<span class="k">val</span> <span class="nv">bertExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">legal</span><span class="o">.</span><span class="py">SentenceEntityResolverApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setNeighbours</span><span class="o">(</span><span class="mi">25</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNormalizedCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"snomed_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDIAN"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedModel</span> <span class="k">=</span> <span class="nv">bertExtractor</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">snomedData</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>The model transforms a dataset with Input Annotation type SENTENCE_EMBEDDINGS, coming from e.g.
<a href="/docs/en/transformers#bertsentenceembeddings">BertSentenceEmbeddings</a>
and returns the normalized entity for a particular trained ontology / curated dataset.
(e.g. ICD-10, RxNorm, SNOMED etc.)</p>

    <p>To use pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/resolution/sentence_entity_resolver/index.html#sparknlp_jsl.annotator.resolution.sentence_entity_resolver.SentenceEntityResolverModel">SentenceEntityResolverModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/SentenceEntityResolverModel">SentenceEntityResolverModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Resolving CPT
# First define pipeline stages to extract entities
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"jsl_ner_wip_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Test"</span><span class="p">,</span><span class="s">"Procedure"</span><span class="p">])</span>
<span class="n">c2doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunk2Doc</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span>
<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>

<span class="c1"># Then the resolver is defined on the extracted entities and sentence embeddings
</span><span class="n">cpt_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_cpt_procedures_augmented"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sbert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cpt_code"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>
<span class="n">sbert_pipeline_cpt</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">c2doc</span><span class="p">,</span>
    <span class="n">sbert_embedder</span><span class="p">,</span>
    <span class="n">cpt_resolver</span><span class="p">])</span>

<span class="n">sbert_outputs</span> <span class="o">=</span> <span class="n">sbert_pipeline_cpt</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_ner</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># Show results
#
# sbert_outputs
#   .select("explode(arrays_zip(ner_chunk.result ,ner_chunk.metadata, cpt_code.result, cpt_code.metadata, ner_chunk.begin, ner_chunk.end)) as cpt_code")
#   .selectExpr(
#     "cpt_code['0'] as chunk",
#     "cpt_code['1'].entity as entity",
#     "cpt_code['2'] as code",
#     "cpt_code['3'].confidence as confidence",
#     "cpt_code['3'].all_k_resolutions as all_k_resolutions",
#     "cpt_code['3'].all_k_results as all_k_results"
#   ).show(5)
# +--------------------+---------+-----+----------+--------------------+--------------------+
# |               chunk|   entity| code|confidence|   all_k_resolutions|         all_k_codes|
# +--------------------+---------+-----+----------+--------------------+--------------------+
# |          heart cath|Procedure|93566|    0.1180|CCA - Cardiac cat...|93566:::62319:::9...|
# |selective coronar...|     Test|93460|    0.1000|Coronary angiogra...|93460:::93458:::9...|
# |common femoral an...|     Test|35884|    0.1808|Femoral artery by...|35884:::35883:::3...|
# |   StarClose closure|Procedure|33305|    0.1197|Heart closure:::H...|33305:::33300:::3...|
# |         stress test|     Test|93351|    0.2795|Cardiovascular st...|93351:::94621:::9...|
# +--------------------+---------+-----+----------+--------------------+--------------------+
#
</span></code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
        
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
        
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">chunk2doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunk2Doc</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span>

<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"tfhub_use"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>
    
<span class="n">resolver</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finel_edgar_company_name"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"resolution"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">sentenceDetector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">chunk2doc</span><span class="p">,</span>
        <span class="n">sentence_embeddings</span><span class="p">,</span>
        <span class="n">resolver</span>
<span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
        
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
        
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">chunk2doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunk2Doc</span><span class="p">()</span>\
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span>

<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"tfhub_use"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>
    
<span class="n">resolver</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legel_edgar_company_name"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"resolution"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">sentenceDetector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">chunk2doc</span><span class="p">,</span>
        <span class="n">sentence_embeddings</span><span class="p">,</span>
        <span class="n">resolver</span>
<span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
// </span><span class="nn">Resolving</span> <span class="nc">CPT</span>
<span class="c1">// First define pipeline stages to extract entities</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"jsl_ner_wip_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nf">array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"Test"</span><span class="o">,</span><span class="s">"Procedure"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">c2doc</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Chunk2Doc</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_doc"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sbert_embedder</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertSentenceEmbeddings</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk_doc"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sbert_embeddings"</span><span class="o">)</span>

<span class="c1">// Then the resolver is defined on the extracted entities and sentence embeddings</span>
<span class="k">val</span> <span class="nv">cpt_resolver</span> <span class="k">=</span> <span class="nv">medical</span><span class="o">.</span><span class="py">SentenceEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobertresolve_cpt_procedures_augmented"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"sbert_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cpt_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sbert_pipeline_cpt</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">word_embeddings</span><span class="o">,</span>
  <span class="n">clinical_ner</span><span class="o">,</span>
  <span class="n">ner_converter</span><span class="o">,</span>
  <span class="n">c2doc</span><span class="o">,</span>
  <span class="n">sbert_embedder</span><span class="o">,</span>
  <span class="n">cpt_resolver</span><span class="o">))</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// sbert_outputs</span>
<span class="c1">//   .select("explode(arrays_zip(ner_chunk.result ,ner_chunk.metadata, cpt_code.result, cpt_code.metadata, ner_chunk.begin, ner_chunk.end)) as cpt_code")</span>
<span class="c1">//   .selectExpr(</span>
<span class="c1">//     "cpt_code['0'] as chunk",</span>
<span class="c1">//     "cpt_code['1'].entity as entity",</span>
<span class="c1">//     "cpt_code['2'] as code",</span>
<span class="c1">//     "cpt_code['3'].confidence as confidence",</span>
<span class="c1">//     "cpt_code['3'].all_k_resolutions as all_k_resolutions",</span>
<span class="c1">//     "cpt_code['3'].all_k_results as all_k_results"</span>
<span class="c1">//   ).show(5)</span>
<span class="c1">// +--------------------+---------+-----+----------+--------------------+--------------------+</span>
<span class="c1">// |               chunk|   entity| code|confidence|   all_k_resolutions|         all_k_codes|</span>
<span class="c1">// +--------------------+---------+-----+----------+--------------------+--------------------+</span>
<span class="c1">// |          heart cath|Procedure|93566|    0.1180|CCA - Cardiac cat...|93566:::62319:::9...|</span>
<span class="c1">// |selective coronar...|     Test|93460|    0.1000|Coronary angiogra...|93460:::93458:::9...|</span>
<span class="c1">// |common femoral an...|     Test|35884|    0.1808|Femoral artery by...|35884:::35883:::3...|</span>
<span class="c1">// |   StarClose closure|Procedure|33305|    0.1197|Heart closure:::H...|33305:::33300:::3...|</span>
<span class="c1">// |         stress test|     Test|93351|    0.2795|Cardiovascular st...|93351:::94621:::9...|</span>
<span class="c1">// +--------------------+---------+-----+----------+--------------------+--------------------+</span>
<span class="c1">//</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 


<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertEmbeddings</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">NerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk2doc</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Chunk2Doc</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_doc"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">UniversalSentenceEncoder</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"tfhub_use"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk_doc"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">resolver</span> <span class="k">=</span> <span class="nv">finance</span><span class="o">.</span><span class="py">SentenceEntityResolverModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finel_edgar_company_name"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"sentence_embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"resolution"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_converter</span><span class="o">,</span>
  <span class="n">chunk2doc</span><span class="o">,</span>
  <span class="n">sentence_embeddings</span><span class="o">,</span>
  <span class="n">resolver</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">from</span> <span class="n">johnsnowlabs</span> <span class="k">import</span> <span class="err">* 
</span><span class="nn">val</span> <span class="n">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 


<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">BertEmbeddings</span>
   <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">NerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">NerConverter</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk2doc</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">Chunk2Doc</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_doc"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="nv">nlp</span><span class="o">.</span><span class="py">UniversalSentenceEncoder</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"tfhub_use"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk_doc"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">resolver</span> <span class="k">=</span> <span class="nv">legal</span><span class="o">.</span><span class="py">SentenceEntityResolverModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legel_edgar_company_name"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"sentence_embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"resolution"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_converter</span><span class="o">,</span>
  <span class="n">chunk2doc</span><span class="o">,</span>
  <span class="n">sentence_embeddings</span><span class="o">,</span>
  <span class="n">resolver</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="zeroshotnermodel">ZeroShotNerModel</h2>

  <div class="h3-box model-content">

    <p>This is a zero shot named entity recognition based on <code class="language-plaintext highlighter-rouge">RoBertaForQuestionAnswering</code>. Zero shot models excel at generalization, meaning that the model can accurately predict entities in very different data sets without the need to fine tune the model or train from scratch for each different domain.</p>

    <p>Even though a model trained to solve a specific problem can achieve better accuracy than a zero-shot model in this specific task, it probably won’t be be useful in a different task. That is where zero-shot models shows its usefulness by being able to achieve good results in many different scenarions.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/zero_shot_ner/index.html#sparknlp_jsl.annotator.ner.zero_shot_ner.ZeroShotNerModel">ZeroShotNerModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/finance/token_classification/ner/ZeroShotNerModel.html">ZeroShotNerModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">zero_shot_ner</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ZeroShotNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"zero_shot_ner_roberta"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setEntityDefinitions</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">"PROBLEM"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"What is the disease?"</span><span class="p">,</span>
                <span class="s">"What is his symptom?"</span><span class="p">,</span>
                <span class="s">"What is her disease?"</span><span class="p">,</span>
                <span class="s">"What is his disease?"</span><span class="p">,</span>
                <span class="s">"What is the problem?"</span><span class="p">,</span>
                <span class="s">"What does a patient suffer"</span><span class="p">,</span>
                <span class="s">"What was the reason that the patient is admitted to the clinic?"</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s">"DRUG"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"Which drug?"</span><span class="p">,</span>
                <span class="s">"Which is the drug?"</span><span class="p">,</span>
                <span class="s">"What is the drug?"</span><span class="p">,</span>
                <span class="s">"Which drug does he use?"</span><span class="p">,</span>
                <span class="s">"Which drug does she use?"</span><span class="p">,</span>
                <span class="s">"Which drug do I use?"</span><span class="p">,</span>
                <span class="s">"Which drug is prescribed for a symptom?"</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s">"ADMISSION_DATE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"When did patient admitted to a clinic?"</span><span class="p">],</span>
            <span class="s">"PATIENT_AGE"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"How old is the patient?"</span><span class="p">,</span>
                <span class="s">"What is the gae of the patient?"</span><span class="p">,</span>
            <span class="p">],</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"zero_shot_ner"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="p">)</span>  <span class="c1"># default 0.01
</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">sparknlp</span><span class="p">.</span><span class="n">annotators</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"zero_shot_ner"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">sentenceDetector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">zero_shot_ner</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">zero_shot_ner_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">text_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"The doctor pescribed Majezik for my severe headache."</span><span class="p">,</span>
    <span class="s">"The patient was admitted to the hospital for his colon cancer."</span><span class="p">,</span>
    <span class="s">"27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis."</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">text_list</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">zero_shot_ner_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span>
        <span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span>
            <span class="n">results</span><span class="p">.</span><span class="n">token</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
            <span class="n">results</span><span class="p">.</span><span class="n">zero_shot_ner</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
            <span class="n">results</span><span class="p">.</span><span class="n">zero_shot_ner</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span>
            <span class="n">results</span><span class="p">.</span><span class="n">zero_shot_ner</span><span class="p">.</span><span class="n">begin</span><span class="p">,</span>
            <span class="n">results</span><span class="p">.</span><span class="n">zero_shot_ner</span><span class="p">.</span><span class="n">end</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)</span>
<span class="p">).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"token"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['2']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['3']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['4']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['2']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span>
    <span class="mi">50</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="mi">100</span>
<span class="p">)</span>
<span class="o">+-------------+----------------+--------+-----+---+----------+</span>
        <span class="n">token</span><span class="o">|</span>       <span class="n">ner_label</span><span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+-------------+----------------+--------+-----+---+----------+</span>
          <span class="n">The</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>    <span class="mi">0</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
       <span class="n">doctor</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>    <span class="mi">4</span><span class="o">|</span>  <span class="mi">9</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
    <span class="n">pescribed</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">11</span><span class="o">|</span> <span class="mi">19</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
      <span class="n">Majezik</span><span class="o">|</span>          <span class="n">B</span><span class="o">-</span><span class="n">DRUG</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">21</span><span class="o">|</span> <span class="mi">27</span><span class="o">|</span> <span class="mf">0.6467137</span><span class="o">|</span>
          <span class="k">for</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">29</span><span class="o">|</span> <span class="mi">31</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
           <span class="n">my</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">33</span><span class="o">|</span> <span class="mi">34</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
       <span class="n">severe</span><span class="o">|</span>       <span class="n">B</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">36</span><span class="o">|</span> <span class="mi">41</span><span class="o">|</span><span class="mf">0.55263567</span><span class="o">|</span>
     <span class="n">headache</span><span class="o">|</span>       <span class="n">I</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">43</span><span class="o">|</span> <span class="mi">50</span><span class="o">|</span><span class="mf">0.55263567</span><span class="o">|</span>
            <span class="p">.</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">51</span><span class="o">|</span> <span class="mi">51</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
          <span class="n">The</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>    <span class="mi">0</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
      <span class="n">patient</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>    <span class="mi">4</span><span class="o">|</span> <span class="mi">10</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
          <span class="n">was</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">12</span><span class="o">|</span> <span class="mi">14</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
     <span class="n">admitted</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">16</span><span class="o">|</span> <span class="mi">23</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
           <span class="n">to</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">25</span><span class="o">|</span> <span class="mi">26</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
          <span class="n">the</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">28</span><span class="o">|</span> <span class="mi">30</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
     <span class="n">hospital</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">32</span><span class="o">|</span> <span class="mi">39</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
          <span class="k">for</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">41</span><span class="o">|</span> <span class="mi">43</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
          <span class="n">his</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">45</span><span class="o">|</span> <span class="mi">47</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
        <span class="n">colon</span><span class="o">|</span>       <span class="n">B</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">49</span><span class="o">|</span> <span class="mi">53</span><span class="o">|</span> <span class="mf">0.8898501</span><span class="o">|</span>
       <span class="n">cancer</span><span class="o">|</span>       <span class="n">I</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">55</span><span class="o">|</span> <span class="mi">60</span><span class="o">|</span> <span class="mf">0.8898501</span><span class="o">|</span>
            <span class="p">.</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">61</span><span class="o">|</span> <span class="mi">61</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
           <span class="mi">27</span><span class="o">|</span>   <span class="n">B</span><span class="o">-</span><span class="n">PATIENT_AGE</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>    <span class="mi">0</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span> <span class="mf">0.6943086</span><span class="o">|</span>
        <span class="n">years</span><span class="o">|</span>   <span class="n">I</span><span class="o">-</span><span class="n">PATIENT_AGE</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>    <span class="mi">3</span><span class="o">|</span>  <span class="mi">7</span><span class="o">|</span> <span class="mf">0.6943086</span><span class="o">|</span>
          <span class="n">old</span><span class="o">|</span>   <span class="n">I</span><span class="o">-</span><span class="n">PATIENT_AGE</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>    <span class="mi">9</span><span class="o">|</span> <span class="mi">11</span><span class="o">|</span> <span class="mf">0.6943086</span><span class="o">|</span>
      <span class="n">patient</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">13</span><span class="o">|</span> <span class="mi">19</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
          <span class="n">was</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">21</span><span class="o">|</span> <span class="mi">23</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
     <span class="n">admitted</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">25</span><span class="o">|</span> <span class="mi">32</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
           <span class="n">to</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">34</span><span class="o">|</span> <span class="mi">35</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
       <span class="n">clinic</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">37</span><span class="o">|</span> <span class="mi">42</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
           <span class="n">on</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">44</span><span class="o">|</span> <span class="mi">45</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
          <span class="n">Sep</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ADMISSION_DATE</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">47</span><span class="o">|</span> <span class="mi">49</span><span class="o">|</span><span class="mf">0.95646083</span><span class="o">|</span>
          <span class="mi">1</span><span class="n">st</span><span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ADMISSION_DATE</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">51</span><span class="o">|</span> <span class="mi">53</span><span class="o">|</span><span class="mf">0.95646083</span><span class="o">|</span>
           <span class="n">by</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">55</span><span class="o">|</span> <span class="mi">56</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
           <span class="n">Dr</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">58</span><span class="o">|</span> <span class="mi">59</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
            <span class="p">.</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">60</span><span class="o">|</span> <span class="mi">60</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
            <span class="n">X</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">62</span><span class="o">|</span> <span class="mi">62</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
          <span class="k">for</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">64</span><span class="o">|</span> <span class="mi">66</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
            <span class="n">a</span><span class="o">|</span>       <span class="n">B</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">68</span><span class="o">|</span> <span class="mi">68</span><span class="o">|</span><span class="mf">0.50026655</span><span class="o">|</span>
  <span class="n">right</span><span class="o">-</span><span class="n">sided</span><span class="o">|</span>       <span class="n">I</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">70</span><span class="o">|</span> <span class="mi">80</span><span class="o">|</span><span class="mf">0.50026655</span><span class="o">|</span>
      <span class="n">pleural</span><span class="o">|</span>       <span class="n">I</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">82</span><span class="o">|</span> <span class="mi">88</span><span class="o">|</span><span class="mf">0.50026655</span><span class="o">|</span>
     <span class="n">effusion</span><span class="o">|</span>       <span class="n">I</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">90</span><span class="o">|</span> <span class="mi">97</span><span class="o">|</span><span class="mf">0.50026655</span><span class="o">|</span>
          <span class="k">for</span><span class="o">|</span>       <span class="n">I</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>   <span class="mi">99</span><span class="o">|</span><span class="mi">101</span><span class="o">|</span><span class="mf">0.50026655</span><span class="o">|</span>
<span class="n">thoracentesis</span><span class="o">|</span>       <span class="n">I</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>  <span class="mi">103</span><span class="o">|</span><span class="mi">115</span><span class="o">|</span><span class="mf">0.50026655</span><span class="o">|</span>
            <span class="p">.</span><span class="o">|</span>               <span class="n">O</span><span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>  <span class="mi">116</span><span class="o">|</span><span class="mi">116</span><span class="o">|</span>      <span class="n">null</span><span class="o">|</span>
<span class="o">+-------------+----------------+--------+-----+---+----------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">document_assembler</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">zero_shot_ner</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">finance</span><span class="p">.</span><span class="n">ZeroShotNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span>
        <span class="s">"finner_roberta_zeroshot"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"zero_shot_ner"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setEntityDefinitions</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">"DATE"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"When was the company acquisition?"</span><span class="p">,</span>
                <span class="s">"When was the company purchase agreement?"</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s">"ORG"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which company was acquired?"</span><span class="p">],</span>
            <span class="s">"PRODUCT"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which product?"</span><span class="p">],</span>
            <span class="s">"PROFIT_INCREASE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"How much has the gross profit increased?"</span><span class="p">],</span>
            <span class="s">"REVENUES_DECLINED"</span><span class="p">:</span> <span class="p">[</span><span class="s">"How much has the revenues declined?"</span><span class="p">],</span>
            <span class="s">"OPERATING_LOSS_2020"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which was the operating loss in 2020"</span><span class="p">],</span>
            <span class="s">"OPERATING_LOSS_2019"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which was the operating loss in 2019"</span><span class="p">],</span>
        <span class="p">}</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"zero_shot_ner"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">zero_shot_ner</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>


<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio."</span><span class="p">,</span>
    <span class="s">"In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc."</span><span class="p">,</span>
    <span class="s">"While our gross profit margin increased to 81.4% in 2020 from 63.1% in 2019, our revenues declined approximately 27% in 2020 as compared to 2019."</span><span class="p">,</span>
    <span class="s">"We reported an operating loss of approximately $8,048,581 million in 2020 as compared to an operating loss of $7,738,193 in 2019."</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">p_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">p_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sample_text</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">res</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span>
        <span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span>
            <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
            <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">begin</span><span class="p">,</span>
            <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">end</span><span class="p">,</span>
            <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)</span>
<span class="p">).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['3']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)</span>
<span class="p">).</span><span class="nb">filter</span><span class="p">(</span>
    <span class="s">"ner_label!='O'"</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span>
    <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
<span class="o">+------------------+-------------------+</span>
<span class="o">|</span><span class="n">chunk</span>             <span class="o">|</span><span class="n">ner_label</span>          <span class="o">|</span>
<span class="o">+------------------+-------------------+</span>
<span class="o">|</span><span class="n">March</span> <span class="mi">2012</span>        <span class="o">|</span><span class="n">DATE</span>               <span class="o">|</span>
<span class="o">|</span><span class="n">Vertro</span>            <span class="o">|</span><span class="n">ORG</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">ALOT</span>              <span class="o">|</span><span class="n">PRODUCT</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">February</span> <span class="mi">2017</span>     <span class="o">|</span><span class="n">DATE</span>               <span class="o">|</span>
<span class="o">|</span><span class="n">NetSeer</span>           <span class="o">|</span><span class="n">ORG</span>                <span class="o">|</span>
<span class="o">|</span><span class="mf">81.4</span><span class="o">%</span>             <span class="o">|</span><span class="n">PROFIT_INCREASE</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">27</span><span class="o">%</span>               <span class="o">|</span><span class="n">REVENUES_DECLINED</span>  <span class="o">|</span>
<span class="o">|</span><span class="err">$</span><span class="mi">8</span><span class="p">,</span><span class="mi">048</span><span class="p">,</span><span class="mi">581</span> <span class="n">million</span><span class="o">|</span><span class="n">OPERATING_LOSS_2020</span><span class="o">|</span>
<span class="o">|</span><span class="err">$</span><span class="mi">7</span><span class="p">,</span><span class="mi">738</span><span class="p">,</span><span class="mi">193</span>        <span class="o">|</span><span class="n">OPERATING_LOSS_2019</span><span class="o">|</span>
<span class="o">|</span><span class="mi">2019</span>              <span class="o">|</span><span class="n">DATE</span>               <span class="o">|</span>
<span class="o">+------------------+-------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">zero_shot_ner</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">legal</span><span class="p">.</span><span class="n">ZeroShotNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_roberta_zeroshot"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"zero_shot_ner"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setEntityDefinitions</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">"DATE"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"When was the company acquisition?"</span><span class="p">,</span>
                <span class="s">"When was the company purchase agreement?"</span><span class="p">,</span>
                <span class="s">"When was the agreement?"</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s">"ORG"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which company?"</span><span class="p">],</span>
            <span class="s">"STATE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which state?"</span><span class="p">],</span>
            <span class="s">"AGREEMENT"</span><span class="p">:</span> <span class="p">[</span><span class="s">"What kind of agreement?"</span><span class="p">],</span>
            <span class="s">"LICENSE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"What kind of license?"</span><span class="p">],</span>
            <span class="s">"LICENSE_RECIPIENT"</span><span class="p">:</span> <span class="p">[</span><span class="s">"To whom the license is granted?"</span><span class="p">],</span>
        <span class="p">}</span>
    <span class="p">)</span>
<span class="p">)</span>


<span class="n">nerconverter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"zero_shot_ner"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">sentence</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">zero_shot_ner</span><span class="p">,</span>
        <span class="n">nerconverter</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span><span class="p">,</span> <span class="n">StringType</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio."</span><span class="p">,</span>
    <span class="s">"In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc."</span><span class="p">,</span>
    <span class="s">"This INTELLECTUAL PROPERTY AGREEMENT, dated as of December 31, 2018 (the 'Effective Date') is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ('Seller') and AFI Licensing LLC, a Delaware company (the 'Licensee')"</span><span class="p">,</span>
    <span class="s">"The Company hereby grants to Seller a perpetual, non- exclusive, royalty-free license"</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">p_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">p_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sample_text</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">res</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span>
        <span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span>
            <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
            <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">begin</span><span class="p">,</span>
            <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">end</span><span class="p">,</span>
            <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)</span>
<span class="p">).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['3']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)</span>
<span class="p">).</span><span class="nb">filter</span><span class="p">(</span>
    <span class="s">"ner_label!='O'"</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span>
    <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
<span class="o">+-------------------------------------+-----------------+</span>
<span class="o">|</span><span class="n">chunk</span>                                <span class="o">|</span><span class="n">ner_label</span>        <span class="o">|</span>
<span class="o">+-------------------------------------+-----------------+</span>
<span class="o">|</span><span class="n">March</span> <span class="mi">2012</span>                           <span class="o">|</span><span class="n">DATE</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">Vertro</span><span class="p">,</span> <span class="n">Inc</span>                          <span class="o">|</span><span class="n">ORG</span>              <span class="o">|</span>
<span class="o">|</span><span class="n">February</span> <span class="mi">2017</span>                        <span class="o">|</span><span class="n">DATE</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">asset</span> <span class="n">purchase</span> <span class="n">agreement</span>             <span class="o">|</span><span class="n">AGREEMENT</span>        <span class="o">|</span>
<span class="o">|</span><span class="n">NetSeer</span>                              <span class="o">|</span><span class="n">ORG</span>              <span class="o">|</span>
<span class="o">|</span><span class="n">INTELLECTUAL</span> <span class="n">PROPERTY</span>                <span class="o">|</span><span class="n">AGREEMENT</span>        <span class="o">|</span>
<span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2018</span>                    <span class="o">|</span><span class="n">DATE</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">Armstrong</span> <span class="n">Flooring</span>                   <span class="o">|</span><span class="n">LICENSE_RECIPIENT</span><span class="o">|</span>
<span class="o">|</span><span class="n">Delaware</span>                             <span class="o">|</span><span class="n">STATE</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">AFI</span> <span class="n">Licensing</span> <span class="n">LLC</span><span class="p">,</span> <span class="n">a</span> <span class="n">Delaware</span> <span class="n">company</span><span class="o">|</span><span class="n">LICENSE_RECIPIENT</span><span class="o">|</span>
<span class="o">|</span><span class="n">Seller</span>                               <span class="o">|</span><span class="n">LICENSE_RECIPIENT</span><span class="o">|</span>
<span class="o">|</span><span class="n">perpetual</span>                            <span class="o">|</span><span class="n">LICENSE</span>          <span class="o">|</span>
<span class="o">|</span><span class="n">non</span><span class="o">-</span> <span class="n">exclusive</span>                       <span class="o">|</span><span class="n">LICENSE</span>          <span class="o">|</span>
<span class="o">|</span><span class="n">royalty</span><span class="o">-</span><span class="n">free</span>                         <span class="o">|</span><span class="n">LICENSE</span>          <span class="o">|</span>
<span class="o">+-------------------------------------+-----------------+</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">zeroShotNer</span> <span class="k">=</span> <span class="nc">ZeroShotNerModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setEntityDefinitions</span><span class="o">(</span>
    <span class="nc">Map</span><span class="o">(</span>
      <span class="s">"NAME"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"What is his name?"</span><span class="o">,</span> <span class="s">"What is her name?"</span><span class="o">),</span>
      <span class="s">"CITY"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"Which city?"</span><span class="o">)))</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.01f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"zero_shot_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">zeroShotNer</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="s">""</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">(</span><span class="s">"Clara often travels between New York and Paris."</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">))</span>

<span class="n">results</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"explode(zero_shot_ner) AS entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">select</span><span class="o">(</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.result"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.word"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.sentence"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.begin"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.end"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.confidence"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.question"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>

<span class="o">+------+-----+--------+-----+---+----------+------------------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span><span class="n">word</span> <span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span><span class="n">question</span>          <span class="o">|</span>
<span class="o">+------+-----+--------+-----+---+----------+------------------+</span>
<span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">CITY</span><span class="o">|</span><span class="nc">Paris</span><span class="o">|</span><span class="mi">0</span>       <span class="o">|</span><span class="mi">41</span>   <span class="o">|</span><span class="mi">45</span> <span class="o">|</span><span class="mf">0.78655756</span><span class="o">|</span><span class="nc">Which</span> <span class="n">is</span> <span class="n">the</span> <span class="n">city</span><span class="o">?|</span>
<span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">CITY</span><span class="o">|</span><span class="nc">New</span>  <span class="o">|</span><span class="mi">0</span>       <span class="o">|</span><span class="mi">28</span>   <span class="o">|</span><span class="mi">30</span> <span class="o">|</span><span class="mf">0.29346612</span><span class="o">|</span><span class="nc">Which</span> <span class="n">city</span><span class="o">?</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">CITY</span><span class="o">|</span><span class="nc">York</span> <span class="o">|</span><span class="mi">0</span>       <span class="o">|</span><span class="mi">32</span>   <span class="o">|</span><span class="mi">35</span> <span class="o">|</span><span class="mf">0.29346612</span><span class="o">|</span><span class="nc">Which</span> <span class="n">city</span><span class="o">?</span>       <span class="o">|</span>
<span class="o">+------+-----+--------+-----+---+----------+------------------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">zeroShotNer</span> <span class="k">=</span> <span class="nc">ZeroShotNerModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setEntityDefinitions</span><span class="o">(</span>
    <span class="nc">Map</span><span class="o">(</span>
      <span class="s">"NAME"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"What is his name?"</span><span class="o">,</span> <span class="s">"What is her name?"</span><span class="o">),</span>
      <span class="s">"CITY"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"Which city?"</span><span class="o">)))</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.01f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"zero_shot_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">zeroShotNer</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="s">""</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span>
  <span class="nc">Seq</span><span class="o">(</span><span class="s">"Clara often travels between New York and Paris."</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">))</span>

<span class="n">results</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"explode(zero_shot_ner) AS entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">select</span><span class="o">(</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.result"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.word"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.sentence"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.begin"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.end"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.confidence"</span><span class="o">),</span>
    <span class="nf">col</span><span class="o">(</span><span class="s">"entity.metadata.question"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>

<span class="o">+------+-----+--------+-----+---+----------+------------------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span><span class="n">word</span> <span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span><span class="n">question</span>          <span class="o">|</span>
<span class="o">+------+-----+--------+-----+---+----------+------------------+</span>
<span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">CITY</span><span class="o">|</span><span class="nc">Paris</span><span class="o">|</span><span class="mi">0</span>       <span class="o">|</span><span class="mi">41</span>   <span class="o">|</span><span class="mi">45</span> <span class="o">|</span><span class="mf">0.78655756</span><span class="o">|</span><span class="nc">Which</span> <span class="n">is</span> <span class="n">the</span> <span class="n">city</span><span class="o">?|</span>
<span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">CITY</span><span class="o">|</span><span class="nc">New</span>  <span class="o">|</span><span class="mi">0</span>       <span class="o">|</span><span class="mi">28</span>   <span class="o">|</span><span class="mi">30</span> <span class="o">|</span><span class="mf">0.29346612</span><span class="o">|</span><span class="nc">Which</span> <span class="n">city</span><span class="o">?</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">CITY</span><span class="o">|</span><span class="nc">York</span> <span class="o">|</span><span class="mi">0</span>       <span class="o">|</span><span class="mi">32</span>   <span class="o">|</span><span class="mi">35</span> <span class="o">|</span><span class="mf">0.29346612</span><span class="o">|</span><span class="nc">Which</span> <span class="n">city</span><span class="o">?</span>       <span class="o">|</span>
<span class="o">+------+-----+--------+-----+---+----------+------------------+</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

<div class="tabs-box">

  <h2 id="zeroshotrelationextractionmodel">ZeroShotRelationExtractionModel</h2>

  <div class="h3-box model-content">

    <p><code class="language-plaintext highlighter-rouge">ZeroShotRelationExtractionModel</code> implements zero-shot binary relations extraction by utilizing <code class="language-plaintext highlighter-rouge">BERT</code> transformer models trained on the NLI (Natural Language Inference) task.</p>

    <p>The model inputs consists of documents/sentences and paired NER chunks, usually obtained by <code class="language-plaintext highlighter-rouge">RENerChunksFilter</code>. The definitions of relations which are extracted is given by a dictionary structures, specifying a set of statements regarding the relationship of named entities.</p>

    <p>These statements are automatically appended to each document in the dataset and the NLI model is used to determine whether a particular relationship between entities.</p>

    <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Zero-Shot-Classification Models Hub">NLP Models Hub</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/zero_shot_relation_extraction/index.html#sparknlp_jsl.annotator.re.zero_shot_relation_extraction.ZeroShotRelationExtractionModel">ZeroShotRelationExtractionModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/finance/graph/relation_extraction/ZeroShotRelationExtractionModel.html">ZeroShotRelationExtractionModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <p><button data-type="python" class="tab-li tab-li-second active">Python</button><button data-type="scala" class="tab-li tab-li-second">Scala</button></p>
</div>

        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-python active">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button><button data-type="finance" class="tab-li-inner">Finance</button><button data-type="legal" class="tab-li-inner">Legal</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">documenter</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span>
        <span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">WordEmbeddingsModel</span><span class="p">()</span>
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">ner_clinical</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">ner_clinical_converter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">NerConverter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_clinical"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_clinical_chunks"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"PROBLEM"</span><span class="p">,</span> <span class="s">"TEST"</span><span class="p">])</span>
<span class="p">)</span>  <span class="c1"># PROBLEM-TEST-TREATMENT
</span>
<span class="n">ner_posology</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">ner_posology_converter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">NerConverter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_posology"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_posology_chunks"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"DRUG"</span><span class="p">])</span>
<span class="p">)</span>  <span class="c1"># DRUG-FREQUENCY-DOSAGE-DURATION-FORM-ROUTE-STRENGTH
</span>
<span class="n">chunk_merger</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ChunkMergeApproach</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_clinical_chunks"</span><span class="p">,</span> <span class="s">"ner_posology_chunks"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"merged_ner_chunks"</span><span class="p">)</span>
<span class="p">)</span>


<span class="c1">## ZERO-SHOT RE Starting...
</span>
<span class="n">pos_tagger</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">PerceptronModel</span><span class="p">()</span>
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">DependencyParserModel</span><span class="p">()</span>
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">re_ner_chunk_filter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">RENerChunksFilter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"problem-test"</span><span class="p">,</span> <span class="s">"problem-drug"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setDocLevelRelations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"merged_ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ZeroShotRelationExtractionModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span>
        <span class="s">"re_zeroshot_biobert"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunks"</span><span class="p">,</span> <span class="s">"sentences"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setRelationalCategories</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">"ADE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{DRUG} causes {PROBLEM}."</span><span class="p">],</span>
            <span class="s">"IMPROVE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{DRUG} improves {PROBLEM}."</span><span class="p">,</span> <span class="s">"{DRUG} cures {PROBLEM}."</span><span class="p">],</span>
            <span class="s">"REVEAL"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{TEST} reveals {PROBLEM}."</span><span class="p">],</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setMultiLabel</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">sparknlp</span><span class="p">.</span><span class="n">base</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">documenter</span><span class="p">,</span>
        <span class="n">sentencer</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">words_embedder</span><span class="p">,</span>
        <span class="n">ner_clinical</span><span class="p">,</span>
        <span class="n">ner_clinical_converter</span><span class="p">,</span>
        <span class="n">ner_posology</span><span class="p">,</span>
        <span class="n">ner_posology_converter</span><span class="p">,</span>
        <span class="n">chunk_merger</span><span class="p">,</span>
        <span class="n">pos_tagger</span><span class="p">,</span>
        <span class="n">dependency_parser</span><span class="p">,</span>
        <span class="n">re_ner_chunk_filter</span><span class="p">,</span>
        <span class="n">re_model</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer."</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">results</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">results</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span>
        <span class="s">"cols"</span>
    <span class="p">)</span>
<span class="p">).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['hypothesis']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"hypothesis"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['nli_prediction']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"nli_prediction"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span>
    <span class="n">truncate</span><span class="o">=</span><span class="mi">70</span>
<span class="p">)</span>
<span class="o">+--------+-------------+-----------+-----------+-------+-------------+-----------+--------+-------+------------------------------+--------------+--------+----------+</span>
<span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>     <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>  <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span>                    <span class="n">hypothesis</span><span class="o">|</span><span class="n">nli_prediction</span><span class="o">|</span><span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------+-------+-------------+-----------+--------+-------+------------------------------+--------------+--------+----------+</span>
       <span class="mi">0</span><span class="o">|</span>            <span class="mi">0</span><span class="o">|</span>         <span class="mi">10</span><span class="o">|</span><span class="n">Paracetamol</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>           <span class="mi">38</span><span class="o">|</span>         <span class="mi">45</span><span class="o">|</span><span class="n">sickness</span><span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span><span class="n">Paracetamol</span> <span class="n">improves</span> <span class="n">sickness</span><span class="p">.</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span> <span class="n">IMPROVE</span><span class="o">|</span><span class="mf">0.98819494</span><span class="o">|</span>
       <span class="mi">0</span><span class="o">|</span>            <span class="mi">0</span><span class="o">|</span>         <span class="mi">10</span><span class="o">|</span><span class="n">Paracetamol</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>           <span class="mi">26</span><span class="o">|</span>         <span class="mi">33</span><span class="o">|</span><span class="n">headache</span><span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span><span class="n">Paracetamol</span> <span class="n">improves</span> <span class="n">headache</span><span class="p">.</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span> <span class="n">IMPROVE</span><span class="o">|</span> <span class="mf">0.9929625</span><span class="o">|</span>
       <span class="mi">1</span><span class="o">|</span>           <span class="mi">48</span><span class="o">|</span>         <span class="mi">58</span><span class="o">|</span><span class="n">An</span> <span class="n">MRI</span> <span class="n">test</span><span class="o">|</span>   <span class="n">TEST</span><span class="o">|</span>           <span class="mi">80</span><span class="o">|</span>         <span class="mi">85</span><span class="o">|</span>  <span class="n">cancer</span><span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span>   <span class="n">An</span> <span class="n">MRI</span> <span class="n">test</span> <span class="n">reveals</span> <span class="n">cancer</span><span class="p">.</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>  <span class="n">REVEAL</span><span class="o">|</span> <span class="mf">0.9760039</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------+-------+-------------+-----------+--------+-------+------------------------------+--------------+--------+----------+</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-finance">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">document_assembler</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span> <span class="s">"xx"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_financial_small"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">finance</span><span class="p">.</span><span class="n">ZeroShotRelationExtractionModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span>
        <span class="s">"finre_zero_shot"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setMultiLabel</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">re_model</span><span class="p">.</span><span class="n">setRelationalCategories</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s">"profit_decline_by"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"{PROFIT_DECLINE} decreased by {AMOUNT} from"</span><span class="p">,</span>
            <span class="s">"{PROFIT_DECLINE} decreased by {AMOUNT} to"</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s">"profit_decline_by_per"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"{PROFIT_DECLINE} decreased by a {PERCENTAGE} from"</span><span class="p">,</span>
            <span class="s">"{PROFIT_DECLINE} decreased by a {PERCENTAGE} to"</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s">"profit_decline_from"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"{PROFIT_DECLINE} decreased from {AMOUNT}"</span><span class="p">,</span>
            <span class="s">"{PROFIT_DECLINE} decreased from {AMOUNT} for the year"</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s">"profit_decline_from_per"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"{PROFIT_DECLINE} decreased from {PERCENTAGE} to"</span><span class="p">,</span>
            <span class="s">"{PROFIT_DECLINE} decreased from {PERCENTAGE} to a total of"</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s">"profit_decline_to"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{PROFIT_DECLINE} to {AMOUNT}"</span><span class="p">],</span>
        <span class="s">"profit_increase_from"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{PROFIT_INCREASE} from {AMOUNT}"</span><span class="p">],</span>
        <span class="s">"profit_increase_to"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{PROFIT_INCREASE} to {AMOUNT}"</span><span class="p">],</span>
        <span class="s">"expense_decrease_by"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{EXPENSE_DECREASE} decreased by {AMOUNT}"</span><span class="p">],</span>
        <span class="s">"expense_decrease_by_per"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{EXPENSE_DECREASE} decreased by a {PERCENTAGE}"</span><span class="p">],</span>
        <span class="s">"expense_decrease_from"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{EXPENSE_DECREASE} decreased from {AMOUNT}"</span><span class="p">],</span>
        <span class="s">"expense_decrease_to"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"{EXPENSE_DECREASE} for a total of {AMOUNT} for the fiscal year"</span>
        <span class="p">],</span>
        <span class="s">"has_date"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"{AMOUNT} for the fiscal year ended {FISCAL_YEAR}"</span><span class="p">,</span>
            <span class="s">"{PERCENTAGE} for the fiscal year ended {FISCAL_YEAR}"</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">re_model</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">light_model</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">LightPipeline</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"""License fees revenue decreased 40 %, or $ 0.5 million to $ 0.7 million for the year ended December 31, 2020 compared to $ 1.2 million for the year ended December 31, 2019. Services revenue increased 4 %, or $ 1.1 million, to $ 25.6 million for the year ended December 31, 2020 from $ 24.5 million for the year ended December 31, 2019. Costs of revenue, excluding depreciation and amortization increased by $ 0.1 million, or 2 %, to $ 8.8 million for the year ended December 31, 2020 from $ 8.7 million for the year ended December 31, 2019.  Also, a decrease in travel costs of $ 0.4 million due to travel restrictions caused by the global pandemic. As a percentage of revenue, cost of revenue, excluding depreciation and amortization was 34 % for each of the years ended December 31, 2020 and 2019. Sales and marketing expenses decreased 20 %, or $ 1.5 million, to $ 6.0 million for the year ended December 31, 2020 from $ 7.5 million for the year ended December 31, 2019"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(relations) as relation"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">relation</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                             <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">8462</span><span class="p">,</span> <span class="mi">8693</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">227</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mf">25.6</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.8744761</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">332</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">238</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">316</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mf">25.6</span> <span class="n">million</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span>                                          <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">4643</span><span class="p">,</span> <span class="mi">4873</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">31</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mi">40</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.7889031</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">PERCENTAGE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">169</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">32</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">153</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mi">40</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                                                            <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">13507</span><span class="p">,</span> <span class="mi">13748</span><span class="p">,</span> <span class="n">expense_decrease_from</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">799</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">expense_decrease_from</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="n">Sales</span> <span class="ow">and</span> <span class="n">marketing</span> <span class="n">expenses</span> <span class="n">decreased</span> <span class="k">from</span> <span class="mf">7.5</span> <span class="n">million</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.9770538</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">EXPENSE_DECREASE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="mf">7.5</span> <span class="n">million</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">933</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">826</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">923</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="n">Sales</span> <span class="ow">and</span> <span class="n">marketing</span> <span class="n">expenses</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">5354</span><span class="p">,</span> <span class="mi">5593</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">59</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mf">0.7</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.6718765</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">106</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">69</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">90</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mf">0.7</span> <span class="n">million</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                                               <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">6490</span><span class="p">,</span> <span class="mi">6697</span><span class="p">,</span> <span class="n">profit_increase_to</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">172</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">profit_increase_to</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="n">Services</span> <span class="n">revenue</span> <span class="n">to</span> <span class="mf">25.6</span> <span class="n">million</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.9674029</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">PROFIT_INCREASE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="mf">25.6</span> <span class="n">million</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">238</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">187</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">227</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="n">Services</span> <span class="n">revenue</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span>                                           <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">4412</span><span class="p">,</span> <span class="mi">4642</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">31</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mi">40</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.778003</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">PERCENTAGE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">106</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">32</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">90</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mi">40</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                                                              <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">13989</span><span class="p">,</span> <span class="mi">14221</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">838</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mi">20</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.8545547</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">PERCENTAGE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">914</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">839</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">898</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mi">20</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="p">},</span> <span class="p">[]}</span>                                                        <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">11157</span><span class="p">,</span> <span class="mi">11314</span><span class="p">,</span> <span class="n">expense_decrease_by</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">561</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">expense_decrease_by</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="n">travel</span> <span class="n">costs</span> <span class="n">decreased</span> <span class="n">by</span> <span class="mf">0.4</span> <span class="n">million</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.9946776</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">EXPENSE_DECREASE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="mf">0.4</span> <span class="n">million</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">589</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">572</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">579</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="n">travel</span> <span class="n">costs</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span>                                      <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">5114</span><span class="p">,</span> <span class="mi">5353</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">42</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mf">0.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.77566886</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">169</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">52</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">153</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mf">0.5</span> <span class="n">million</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                                             <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">6281</span><span class="p">,</span> <span class="mi">6489</span><span class="p">,</span> <span class="n">profit_increase_from</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">172</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">profit_increase_from</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="n">Services</span> <span class="n">revenue</span> <span class="k">from</span> <span class="mf">1.1</span> <span class="n">million</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.96610945</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">PROFIT_INCREASE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="mf">1.1</span> <span class="n">million</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">219</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">187</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">209</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="n">Services</span> <span class="n">revenue</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span>                                      <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">9199</span><span class="p">,</span> <span class="mi">9471</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">408</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mf">0.1</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.9083246</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">537</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">418</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">521</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mf">0.1</span> <span class="n">million</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>                                            <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">14455</span><span class="p">,</span> <span class="mi">14696</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">849</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mf">1.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.75281376</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">914</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">859</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">898</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mf">1.5</span> <span class="n">million</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="p">},</span> <span class="p">[]}</span>                                         <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">14697</span><span class="p">,</span> <span class="mi">14938</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">849</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mf">1.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.8073463</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">970</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">859</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">954</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mf">1.5</span> <span class="n">million</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="p">},</span> <span class="p">[]}</span>                                          <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">4874</span><span class="p">,</span> <span class="mi">5113</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">42</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mf">0.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.71575713</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">106</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">52</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">90</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mf">0.5</span> <span class="n">million</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                                              <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">6908</span><span class="p">,</span> <span class="mi">7115</span><span class="p">,</span> <span class="n">profit_increase_to</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">172</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">profit_increase_to</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="n">Services</span> <span class="n">revenue</span> <span class="n">to</span> <span class="mf">24.5</span> <span class="n">million</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.85972106</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">PROFIT_INCREASE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="mf">24.5</span> <span class="n">million</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">295</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">187</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">284</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="n">Services</span> <span class="n">revenue</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span>                                          <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">5594</span><span class="p">,</span> <span class="mi">5833</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">59</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mf">0.7</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.7484568</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">AMOUNT</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">169</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">69</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">153</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mf">0.7</span> <span class="n">million</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                                              <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">7326</span><span class="p">,</span> <span class="mi">7546</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">199</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mi">4</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.8412763</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">PERCENTAGE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">275</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">199</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">259</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span>                                                            <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">9472</span><span class="p">,</span> <span class="mi">9734</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">424</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.8046481</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">PERCENTAGE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">481</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">424</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">465</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>                                                            <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">9735</span><span class="p">,</span> <span class="mi">9997</span><span class="p">,</span> <span class="n">has_date</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">424</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">has_date</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.8485106</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">PERCENTAGE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">537</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">424</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">521</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">FISCAL_YEAR</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>                                                            <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">category</span><span class="p">,</span> <span class="mi">691</span><span class="p">,</span> <span class="mi">916</span><span class="p">,</span> <span class="n">profit_decline_by_per</span><span class="p">,</span> <span class="p">{</span><span class="n">entity1_begin</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">relation</span> <span class="o">-&gt;</span> <span class="n">profit_decline_by_per</span><span class="p">,</span> <span class="n">hypothesis</span> <span class="o">-&gt;</span> <span class="n">License</span> <span class="n">fees</span> <span class="n">revenue</span> <span class="n">decreased</span> <span class="n">by</span> <span class="n">a</span> <span class="mi">40</span> <span class="n">to</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.9948003</span><span class="p">,</span> <span class="n">nli_prediction</span> <span class="o">-&gt;</span> <span class="n">entail</span><span class="p">,</span> <span class="n">entity1</span> <span class="o">-&gt;</span> <span class="n">PROFIT_DECLINE</span><span class="p">,</span> <span class="n">syntactic_distance</span> <span class="o">-&gt;</span> <span class="n">undefined</span><span class="p">,</span> <span class="n">chunk2</span> <span class="o">-&gt;</span> <span class="mi">40</span><span class="p">,</span> <span class="n">entity2_end</span> <span class="o">-&gt;</span> <span class="mi">32</span><span class="p">,</span> <span class="n">entity1_end</span> <span class="o">-&gt;</span> <span class="mi">19</span><span class="p">,</span> <span class="n">entity2_begin</span> <span class="o">-&gt;</span> <span class="mi">31</span><span class="p">,</span> <span class="n">entity2</span> <span class="o">-&gt;</span> <span class="n">PERCENTAGE</span><span class="p">,</span> <span class="n">chunk1</span> <span class="o">-&gt;</span> <span class="n">License</span> <span class="n">fees</span> <span class="n">revenue</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                                      <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="n">only</span> <span class="n">showing</span> <span class="n">top</span> <span class="mi">20</span> <span class="n">rows</span>
</code></pre></div>            </div>

          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-legal">

            <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">document_assembler</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>


<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">legal</span><span class="p">.</span><span class="n">BertForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span>
        <span class="s">"legner_obligations"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">legal</span><span class="p">.</span><span class="n">ZeroShotRelationExtractionModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span>
        <span class="s">"legre_zero_shot"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span>
    <span class="p">)</span>
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span>
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">re_model</span><span class="p">.</span><span class="n">setRelationalCategories</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s">"should_provide"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"{OBLIGATION_SUBJECT} will provide {OBLIGATION}"</span><span class="p">,</span>
            <span class="s">"{OBLIGATION_SUBJECT} should provide {OBLIGATION}"</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s">"commits_with"</span><span class="p">:</span> <span class="p">[</span>
            <span class="s">"{OBLIGATION_SUBJECT} to {OBLIGATION_INDIRECT_OBJECT}"</span><span class="p">,</span>
            <span class="s">"{OBLIGATION_SUBJECT} with {OBLIGATION_INDIRECT_OBJECT}"</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="s">"commits_to"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{OBLIGATION_SUBJECT} commits to {OBLIGATION}"</span><span class="p">],</span>
        <span class="s">"agree_to"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{OBLIGATION_SUBJECT} agrees to {OBLIGATION}"</span><span class="p">],</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">tokenClassifier</span><span class="p">,</span> <span class="n">ner_converter</span><span class="p">,</span> <span class="n">re_model</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>
<span class="n">light_model</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">LightPipeline</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="k">def</span> <span class="nf">get_relations_df</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">"relations"</span><span class="p">):</span>
    <span class="n">rel_pairs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">rel</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">col</span><span class="p">]:</span>
            <span class="n">rel_pairs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">rel</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                    <span class="n">rel</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="s">"entity1"</span><span class="p">],</span>
                    <span class="n">rel</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="s">"entity1_begin"</span><span class="p">],</span>
                    <span class="n">rel</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="s">"entity1_end"</span><span class="p">],</span>
                    <span class="n">rel</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="s">"chunk1"</span><span class="p">],</span>
                    <span class="n">rel</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="s">"entity2"</span><span class="p">],</span>
                    <span class="n">rel</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="s">"entity2_begin"</span><span class="p">],</span>
                    <span class="n">rel</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="s">"entity2_end"</span><span class="p">],</span>
                    <span class="n">rel</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="s">"chunk2"</span><span class="p">],</span>
                    <span class="n">rel</span><span class="p">.</span><span class="n">metadata</span><span class="p">[</span><span class="s">"confidence"</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="p">)</span>
    <span class="n">rel_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">rel_pairs</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="p">[</span>
            <span class="s">"relation"</span><span class="p">,</span>
            <span class="s">"entity1"</span><span class="p">,</span>
            <span class="s">"entity1_begin"</span><span class="p">,</span>
            <span class="s">"entity1_end"</span><span class="p">,</span>
            <span class="s">"chunk1"</span><span class="p">,</span>
            <span class="s">"entity2"</span><span class="p">,</span>
            <span class="s">"entity2_begin"</span><span class="p">,</span>
            <span class="s">"entity2_end"</span><span class="p">,</span>
            <span class="s">"chunk2"</span><span class="p">,</span>
            <span class="s">"confidence"</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">rel_df</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"""This INTELLECTUAL PROPERTY AGREEMENT (this "Agreement"), dated as of December 31, 2018 (the "Effective Date") is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ("Seller") and AFI Licensing LLC, a Delaware limited liability company ("Licensing" and together with Seller, "Arizona") and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation ("Buyer") and Armstrong Hardwood Flooring Company, a Tennessee corporation (the "Company" and together with Buyer the "Buyer Entities") (each of Arizona on the one hand and the Buyer Entities on the other hand, a "Party" and collectively, the "Parties")."""</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">light_model</span><span class="p">.</span><span class="n">fullAnnotate</span><span class="p">(</span><span class="n">sample_text</span><span class="p">)</span>
<span class="n">rel_df</span> <span class="o">=</span> <span class="n">get_relations_df</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="n">rel_df</span><span class="p">[</span><span class="n">rel_df</span><span class="p">[</span><span class="s">"relation"</span><span class="p">]</span> <span class="o">!=</span> <span class="s">"no_rel"</span><span class="p">]</span>
<span class="o">|</span>             <span class="n">relation</span> <span class="o">|</span> <span class="n">entity1</span> <span class="o">|</span> <span class="n">entity1_begin</span> <span class="o">|</span> <span class="n">entity1_end</span> <span class="o">|</span>                              <span class="n">chunk1</span> <span class="o">|</span> <span class="n">entity2</span> <span class="o">|</span> <span class="n">entity2_begin</span> <span class="o">|</span> <span class="n">entity2_end</span> <span class="o">|</span>                  <span class="n">chunk2</span> <span class="o">|</span> <span class="n">confidence</span> <span class="o">|</span>
<span class="o">|---------------------</span><span class="p">:</span><span class="o">|--------</span><span class="p">:</span><span class="o">|--------------</span><span class="p">:</span><span class="o">|------------</span><span class="p">:</span><span class="o">|------------------------------------</span><span class="p">:</span><span class="o">|--------</span><span class="p">:</span><span class="o">|--------------</span><span class="p">:</span><span class="o">|------------</span><span class="p">:</span><span class="o">|------------------------</span><span class="p">:</span><span class="o">|-----------</span><span class="p">:</span><span class="o">|</span>
<span class="o">|</span>             <span class="n">dated_as</span> <span class="o">|</span>     <span class="n">DOC</span> <span class="o">|</span>             <span class="mi">5</span> <span class="o">|</span>          <span class="mi">35</span> <span class="o">|</span>     <span class="n">INTELLECTUAL</span> <span class="n">PROPERTY</span> <span class="n">AGREEMENT</span> <span class="o">|</span> <span class="n">EFFDATE</span> <span class="o">|</span>            <span class="mi">69</span> <span class="o">|</span>          <span class="mi">85</span> <span class="o">|</span>       <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2018</span> <span class="o">|</span> <span class="mf">0.98433626</span> <span class="o">|</span>
<span class="o">|</span>            <span class="n">signed_by</span> <span class="o">|</span>     <span class="n">DOC</span> <span class="o">|</span>             <span class="mi">5</span> <span class="o">|</span>          <span class="mi">35</span> <span class="o">|</span>     <span class="n">INTELLECTUAL</span> <span class="n">PROPERTY</span> <span class="n">AGREEMENT</span> <span class="o">|</span>   <span class="n">PARTY</span> <span class="o">|</span>           <span class="mi">141</span> <span class="o">|</span>         <span class="mi">163</span> <span class="o">|</span> <span class="n">Armstrong</span> <span class="n">Flooring</span><span class="p">,</span> <span class="n">Inc</span> <span class="o">|</span> <span class="mf">0.60404813</span> <span class="o">|</span>
<span class="o">|</span>            <span class="n">has_alias</span> <span class="o">|</span>   <span class="n">PARTY</span> <span class="o">|</span>           <span class="mi">141</span> <span class="o">|</span>         <span class="mi">163</span> <span class="o">|</span>             <span class="n">Armstrong</span> <span class="n">Flooring</span><span class="p">,</span> <span class="n">Inc</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">192</span> <span class="o">|</span>         <span class="mi">197</span> <span class="o">|</span>                  <span class="n">Seller</span> <span class="o">|</span> <span class="mf">0.96357507</span> <span class="o">|</span>
<span class="o">|</span>            <span class="n">has_alias</span> <span class="o">|</span>   <span class="n">PARTY</span> <span class="o">|</span>           <span class="mi">205</span> <span class="o">|</span>         <span class="mi">221</span> <span class="o">|</span>                   <span class="n">AFI</span> <span class="n">Licensing</span> <span class="n">LLC</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">263</span> <span class="o">|</span>         <span class="mi">271</span> <span class="o">|</span>               <span class="n">Licensing</span> <span class="o">|</span>  <span class="mf">0.9546678</span> <span class="o">|</span>
<span class="o">|</span>            <span class="n">has_alias</span> <span class="o">|</span>   <span class="n">PARTY</span> <span class="o">|</span>           <span class="mi">315</span> <span class="o">|</span>         <span class="mi">330</span> <span class="o">|</span>                    <span class="n">AHF</span> <span class="n">Holding</span><span class="p">,</span> <span class="n">Inc</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">611</span> <span class="o">|</span>         <span class="mi">615</span> <span class="o">|</span>                   <span class="n">Party</span> <span class="o">|</span>  <span class="mf">0.5387175</span> <span class="o">|</span>
<span class="o">|</span>            <span class="n">has_alias</span> <span class="o">|</span>   <span class="n">PARTY</span> <span class="o">|</span>           <span class="mi">315</span> <span class="o">|</span>         <span class="mi">330</span> <span class="o">|</span>                    <span class="n">AHF</span> <span class="n">Holding</span><span class="p">,</span> <span class="n">Inc</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">641</span> <span class="o">|</span>         <span class="mi">647</span> <span class="o">|</span>                 <span class="n">Parties</span> <span class="o">|</span>  <span class="mf">0.5387175</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">has_collective_alias</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">399</span> <span class="o">|</span>         <span class="mi">403</span> <span class="o">|</span>                               <span class="n">Buyer</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">611</span> <span class="o">|</span>         <span class="mi">615</span> <span class="o">|</span>                   <span class="n">Party</span> <span class="o">|</span>  <span class="mf">0.5539445</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">has_collective_alias</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">399</span> <span class="o">|</span>         <span class="mi">403</span> <span class="o">|</span>                               <span class="n">Buyer</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">641</span> <span class="o">|</span>         <span class="mi">647</span> <span class="o">|</span>                 <span class="n">Parties</span> <span class="o">|</span>  <span class="mf">0.5539445</span> <span class="o">|</span>
<span class="o">|</span>            <span class="n">has_alias</span> <span class="o">|</span>   <span class="n">PARTY</span> <span class="o">|</span>           <span class="mi">411</span> <span class="o">|</span>         <span class="mi">445</span> <span class="o">|</span> <span class="n">Armstrong</span> <span class="n">Hardwood</span> <span class="n">Flooring</span> <span class="n">Company</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">478</span> <span class="o">|</span>         <span class="mi">484</span> <span class="o">|</span>                 <span class="n">Company</span> <span class="o">|</span> <span class="mf">0.92106056</span> <span class="o">|</span>
<span class="o">|</span>            <span class="n">has_alias</span> <span class="o">|</span>   <span class="n">PARTY</span> <span class="o">|</span>           <span class="mi">411</span> <span class="o">|</span>         <span class="mi">445</span> <span class="o">|</span> <span class="n">Armstrong</span> <span class="n">Hardwood</span> <span class="n">Flooring</span> <span class="n">Company</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">611</span> <span class="o">|</span>         <span class="mi">615</span> <span class="o">|</span>                   <span class="n">Party</span> <span class="o">|</span> <span class="mf">0.58123946</span> <span class="o">|</span>
<span class="o">|</span>            <span class="n">has_alias</span> <span class="o">|</span>   <span class="n">PARTY</span> <span class="o">|</span>           <span class="mi">411</span> <span class="o">|</span>         <span class="mi">445</span> <span class="o">|</span> <span class="n">Armstrong</span> <span class="n">Hardwood</span> <span class="n">Flooring</span> <span class="n">Company</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">641</span> <span class="o">|</span>         <span class="mi">647</span> <span class="o">|</span>                 <span class="n">Parties</span> <span class="o">|</span> <span class="mf">0.58123946</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">has_collective_alias</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">505</span> <span class="o">|</span>         <span class="mi">509</span> <span class="o">|</span>                               <span class="n">Buyer</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">516</span> <span class="o">|</span>         <span class="mi">529</span> <span class="o">|</span>          <span class="n">Buyer</span> <span class="n">Entities</span> <span class="o">|</span> <span class="mf">0.63492435</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">has_collective_alias</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">505</span> <span class="o">|</span>         <span class="mi">509</span> <span class="o">|</span>                               <span class="n">Buyer</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">611</span> <span class="o">|</span>         <span class="mi">615</span> <span class="o">|</span>                   <span class="n">Party</span> <span class="o">|</span>  <span class="mf">0.6483803</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">has_collective_alias</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">505</span> <span class="o">|</span>         <span class="mi">509</span> <span class="o">|</span>                               <span class="n">Buyer</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">641</span> <span class="o">|</span>         <span class="mi">647</span> <span class="o">|</span>                 <span class="n">Parties</span> <span class="o">|</span>  <span class="mf">0.6483803</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">has_collective_alias</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">516</span> <span class="o">|</span>         <span class="mi">529</span> <span class="o">|</span>                      <span class="n">Buyer</span> <span class="n">Entities</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">611</span> <span class="o">|</span>         <span class="mi">615</span> <span class="o">|</span>                   <span class="n">Party</span> <span class="o">|</span>  <span class="mf">0.6970743</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">has_collective_alias</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">516</span> <span class="o">|</span>         <span class="mi">529</span> <span class="o">|</span>                      <span class="n">Buyer</span> <span class="n">Entities</span> <span class="o">|</span>   <span class="n">ALIAS</span> <span class="o">|</span>           <span class="mi">641</span> <span class="o">|</span>         <span class="mi">647</span> <span class="o">|</span>                 <span class="n">Parties</span> <span class="o">|</span>  <span class="mf">0.6970743</span> <span class="o">|</span>
</code></pre></div>            </div>

          </div>

        </div>
        <div class="tabs-box-medic-inner tabs-wrapper highlighter-rouge language-scala">

          <div class="top_tab_li toptab-second">
            <p><button data-type="medical" class="tab-li-inner">Medical</button></p>
          </div>

          <div class="tabs-box-medic-inner-second highlighter-rouge language-medical">

            <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nc">PerceptronModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"posTags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="nc">MedicalNerModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"nerTags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"nerTags"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"nerChunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependencyParser</span> <span class="k">=</span> <span class="nc">DependencyParserModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"posTags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reNerFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RENerChunksFilter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"problem-test"</span><span class="o">,</span><span class="s">"problem-treatment"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDocLevelRelations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"nerChunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"RENerChunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re</span> <span class="k">=</span> <span class="nc">ZeroShotRelationExtractionModel</span>
  <span class="o">.</span><span class="py">load</span><span class="o">(</span><span class="s">"/tmp/spark_sbert_zero_shot"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationalCategories</span><span class="o">(</span>
    <span class="nc">Map</span><span class="o">(</span>
      <span class="s">"CURE"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{TREATMENT} cures {PROBLEM}."</span><span class="o">),</span>
      <span class="s">"IMPROVE"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{TREATMENT} improves {PROBLEM}."</span><span class="o">,</span> <span class="s">"{TREATMENT} cures {PROBLEM}."</span><span class="o">),</span>
      <span class="s">"REVEAL"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{TEST} reveals {PROBLEM}."</span><span class="o">)</span>
      <span class="o">))</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.9f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMultiLabel</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"RENerChunks"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations)

val pipeline = new Pipeline()
  .setStages(Array(
    documentAssembler,
    sentencer,
    tokenizer,
    embeddings,
    posTagger,
    nerTagger,
    nerConverter,
    dependencyParser,
    reNerFilter,
    re))

val model = pipeline.fit(Seq("").toDS.toDF("</span><span class="n">text</span><span class="s">"))
val results = model.transform(
  Seq("</span><span class="nc">Paracetamol</span> <span class="n">can</span> <span class="n">alleviate</span> <span class="n">headache</span> <span class="n">or</span> <span class="n">sickness</span><span class="o">.</span> <span class="nc">An</span> <span class="nc">MRI</span> <span class="n">test</span> <span class="n">can</span> <span class="n">be</span> <span class="n">used</span> <span class="n">to</span> <span class="n">find</span> <span class="n">cancer</span><span class="o">.</span><span class="s">").toDS.toDF("</span><span class="n">text</span><span class="s">"))

results
  .selectExpr("</span><span class="nc">EXPLODE</span><span class="o">(</span><span class="n">relations</span><span class="o">)</span> <span class="n">as</span> <span class="n">relation</span><span class="s">")
  .selectExpr("</span><span class="nv">relation</span><span class="o">.</span><span class="py">result</span><span class="s">", "</span><span class="nv">relation</span><span class="o">.</span><span class="py">metadata</span><span class="o">.</span><span class="py">confidence</span><span class="err">"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>

<span class="o">+-------+----------+</span>
<span class="o">|</span><span class="n">result</span> <span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+-------+----------+</span>
<span class="o">|</span><span class="nc">REVEAL</span> <span class="o">|</span><span class="mf">0.9760039</span> <span class="o">|</span>
<span class="o">|</span><span class="nc">IMPROVE</span><span class="o">|</span><span class="mf">0.98819494</span><span class="o">|</span>
<span class="o">|</span><span class="nc">IMPROVE</span><span class="o">|</span><span class="mf">0.9929625</span> <span class="o">|</span>
<span class="o">+-------+----------+</span>
</code></pre></div>            </div>

          </div>

        </div>

      </div>

</details>

  </div>

</div>

</div><div class="d-print-none"><footer class="article__footer"><span class="footer_date">Last updated
      <time itemprop="dateModified" datetime="2020-08-10T00:00:00+00:00">Aug 10, 2020</time>
    </span><!-- start custom article footer snippet -->

<!-- end custom article footer snippet --></footer>

<script>

/* 
jQuery(document).ready(function(){  
    $( ".scala-button" ).click(function() {
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-scala" ).show();
        $(this).closest( ".tabs-box" ).find( ".language-python, .nlu-block" ).hide();
    });

    $( ".python-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-un-active').addClass( "code-selector-active" ); 

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');


        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-python" ).show();
        $(this).closest( ".tabs-box" ).find( ".nlu-block, .language-scala" ).hide();
    });

    $( ".nlu-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets        
        $(this).closest( ".tabs-box" ).find( ".language-python, .language-scala" ).hide();
        $(this).closest( ".tabs-box" ).find( ".nlu-block" ).show();
    });
}); */

/* function togglePython1() {

    //set current button to active class and remove unactive class
    $( ".python-button" ).addClass( "code-selector-active" );


    //toggle language snippets
    $( ".tabs-box .language-python" ).show();
    $( ".tabs-box .nlu-block" ).hide();
    $( ".tabs-box .language-scala" ).hide();
}

function defer(method) { //wait until jquery ready
    if (window.jQuery) {
        method();
    } else {
        setTimeout(function() { defer(method); }, 15);
    }
}

defer(function () { // load inital language
    togglePython1();
}); */


if((document.querySelectorAll('.model-wrap').length !== 0) || (document.querySelectorAll('.tabs-new').length !== 0)) {

    let tabLi = document.querySelectorAll('.tabs-new .tab-li');

    if((document.querySelectorAll('.model-wrap').length !== 0)) {
        tabLi = document.querySelectorAll('.model-wrap .tab-li');
    } 
    
    let tabLiTopF = document.querySelectorAll('.top_tab_li'),
        pythonInner = document.querySelectorAll('.python-inner');

    tabLiTopF.forEach(e => {        
        e.nextElementSibling.classList.add('active');
    });
    pythonInner.forEach(e => {
        e.firstElementChild.classList.remove('language-python');
    });

    tabLi.forEach(element => {
        element.addEventListener('click', function(e) {
            e.preventDefault();
            let tabAttribute = element.getAttribute('data-type'),
                tabLiInner = element.parentNode.querySelectorAll('.tab-li'),
                tabBoxInner = element.parentNode.parentNode.parentNode.querySelectorAll('.highlighter-rouge');
            
            //remove active class from NLU
            tabBoxInner.forEach(item => {
                item.classList.remove('active');
                if(item.classList.contains('nlu-block')) {
                    item.classList.remove('language-python');
                }  
                
            });
            tabLiInner.forEach(el => {
                el.classList.remove('active');
                el.classList.remove('code-selector-active');
            });
            element.classList.add('active');
    
            //add active class
            switch (tabAttribute) {
                case "python":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('language-python')) {
                            item.classList.add('active');
                        }                    
                    });
                    break;
                case "scala":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('language-scala')) {
                            item.classList.add('active');
                        }                    
                    });
                  break;
                  case "nlu":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('nlu-block')) {
                            item.classList.add('active');
                        }                    
                    });
                  break;
                default:              
              }
        });
    });
}

//Second tabs
if(document.querySelectorAll('.tab-li-second').length !== 0) {
    let tabLi = document.querySelectorAll('.tab-li-second');

    tabLi.forEach(element => {
        element.addEventListener('click', function(e) {
            e.preventDefault();
            let tabAttribute = element.getAttribute('data-type'),
                tabLiInner = element.parentNode.querySelectorAll('.tab-li-second'),
                tabBoxInner = element.parentNode.parentNode.parentNode.querySelectorAll('.tabs-box-medic-inner');
            

            //remove active class
            tabBoxInner.forEach(item => {
                item.classList.remove('active');
            });
            tabLiInner.forEach(el => {
                el.classList.remove('active');
            });
            element.classList.add('active');
    
            //add active class
            switch (tabAttribute) {
                case "python":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('language-python')) {
                            item.classList.add('active');
                        }                    
                    });
                    break;
                case "scala":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('language-scala')) {
                            item.classList.add('active');
                        }                    
                    });
                  break;
                default:              
              }
        });
    });
}

//Third tabs
if(document.querySelectorAll('.tab-li-inner').length !== 0) {

    let tabLiSecond = document.querySelectorAll('.tab-li-inner'),
        tabLiTop = document.querySelectorAll('.toptab-second'),
        tabLi = document.querySelectorAll('.toptab-second p');


    tabLiTop.forEach(e => {        
        e.nextElementSibling.classList.add('active');
    });

    tabLi.forEach(e => {        
        e.firstChild.classList.add('active');
    });


    tabLiSecond.forEach(element => {
        element.addEventListener('click', function(e) {
            e.preventDefault();
            let tabAttributeSecond = element.getAttribute('data-type'),
                tabLiInnerSecond = element.parentNode.querySelectorAll('.tab-li-inner'),
                tabBoxInnerSecond = element.parentNode.parentNode.parentNode.querySelectorAll('.tabs-box-medic-inner-second');
            
            //remove active class
            tabBoxInnerSecond.forEach(item => {
                item.classList.remove('active');
            });
            tabLiInnerSecond.forEach(el => {
                el.classList.remove('active');
            });
            element.classList.add('active');
    
            //add active class
            switch (tabAttributeSecond) {
                case "medical":
                    tabBoxInnerSecond.forEach(item => {
                        if(item.classList.contains('language-medical')) {
                            item.classList.add('active');
                        }                    
                    });
                    break;
                case "finance":
                    tabBoxInnerSecond.forEach(item => {
                        if(item.classList.contains('language-finance')) {
                            item.classList.add('active');
                        }                    
                    });
                  break;
                case "legal":
                tabBoxInnerSecond.forEach(item => {
                    if(item.classList.contains('language-legal')) {
                        item.classList.add('active');
                    }                    
                });
                break;
                default:              
              }
        });
    });
}

//Forth tabs
if(document.querySelectorAll('.tab-jsl').length !== 0) {
    let tabLiForth = document.querySelectorAll('.tab-jsl');

    tabLiForth.forEach(element => {
        element.addEventListener('click', function(e) {
            e.preventDefault();
            let tabAttribute = element.getAttribute('data-type'),
                tabLiInner = element.parentNode.querySelectorAll('.tab-jsl'),
                tabBoxInner = element.parentNode.parentNode.parentNode.querySelectorAll('.python-inner');
            

            //remove active class
            tabBoxInner.forEach(item => {
                item.classList.remove('active');
            });
            tabLiInner.forEach(el => {
                el.classList.remove('active');
            });
            element.classList.add('active');
    
            //add active class
            switch (tabAttribute) {
                case "spark-nlp-jsl":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('python-johnsnowlabs')) {
                            item.classList.add('active');
                        }                    
                    });
                    break;
                case "johnsnowlabs":
                    tabBoxInner.forEach(item => {
                        if(item.classList.contains('python-spark-nlp-jsl')) {
                            item.classList.add('active');
                        }                    
                    });
                  break;
                default:              
              }
        });
    });
}

</script>


<style>
  /* Remove Scrollbar from Code Segments */
.article__content .highlighter-rouge > .highlight > pre > code, .article__content figure.highlight > pre > code  {
    overflow: auto;
}



button.code-selector-active {
 background-color: white;
 color: #08c;
 font-weight: bold;
 border-width: 1px;
 padding-left: 12px;
 padding-right: 12px;
 width: 90px;
 padding-top: 6px;
 margin-right: 2px;

 border-bottom: none;

 position: relative;
 z-index: 2;
}

button.code-selector-un-active {
    background-color: white;
    padding-left: 12px;
    padding-right: 12px;
    width: 90px;
    margin-right: 2px;
    padding-top: 8px;
    position: relative;
    border-bottom: none;

   }

hr.code-selector-underlie {
    border-top: 1px solid;
    background-color: black;
    width: fill;
    height: 1px;
    margin-top: -3px;
    position: relative;

}

</style><div class="article__section-navigator clearfix"><div class="previous nav_link"><span>PREVIOUS</span><a href="/docs/en/licensed_install">Installation</a></div><div class="next nav_link"><span>NEXT</span><a href="/docs/en/licensed_training">Training</a></div></div></div>

</div>
</div>

<script>/*! jQuery v1.12.3 | (c) jQuery Foundation | jquery.org/license */
!function(a,b){"object"==typeof module&&"object"==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error("jQuery requires a window with a document");return b(a)}:b(a)}("undefined"!=typeof window?window:this,function(a,b){var c=[],d=a.document,e=c.slice,f=c.concat,g=c.push,h=c.indexOf,i={},j=i.toString,k=i.hasOwnProperty,l={},m="1.12.3",n=function(a,b){return new n.fn.init(a,b)},o=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,p=/^-ms-/,q=/-([\da-z])/gi,r=function(a,b){return b.toUpperCase()};n.fn=n.prototype={jquery:m,constructor:n,selector:"",length:0,toArray:function(){return e.call(this)},get:function(a){return null!=a?0>a?this[a+this.length]:this[a]:e.call(this)},pushStack:function(a){var b=n.merge(this.constructor(),a);return b.prevObject=this,b.context=this.context,b},each:function(a){return n.each(this,a)},map:function(a){return this.pushStack(n.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushStack(e.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},eq:function(a){var b=this.length,c=+a+(0>a?b:0);return this.pushStack(c>=0&&b>c?[this[c]]:[])},end:function(){return this.prevObject||this.constructor()},push:g,sort:c.sort,splice:c.splice},n.extend=n.fn.extend=function(){var a,b,c,d,e,f,g=arguments[0]||{},h=1,i=arguments.length,j=!1;for("boolean"==typeof g&&(j=g,g=arguments[h]||{},h++),"object"==typeof g||n.isFunction(g)||(g={}),h===i&&(g=this,h--);i>h;h++)if(null!=(e=arguments[h]))for(d in e)a=g[d],c=e[d],g!==c&&(j&&c&&(n.isPlainObject(c)||(b=n.isArray(c)))?(b?(b=!1,f=a&&n.isArray(a)?a:[]):f=a&&n.isPlainObject(a)?a:{},g[d]=n.extend(j,f,c)):void 0!==c&&(g[d]=c));return g},n.extend({expando:"jQuery"+(m+Math.random()).replace(/\D/g,""),isReady:!0,error:function(a){throw new Error(a)},noop:function(){},isFunction:function(a){return"function"===n.type(a)},isArray:Array.isArray||function(a){return"array"===n.type(a)},isWindow:function(a){return null!=a&&a==a.window},isNumeric:function(a){var b=a&&a.toString();return!n.isArray(a)&&b-parseFloat(b)+1>=0},isEmptyObject:function(a){var b;for(b in a)return!1;return!0},isPlainObject:function(a){var b;if(!a||"object"!==n.type(a)||a.nodeType||n.isWindow(a))return!1;try{if(a.constructor&&!k.call(a,"constructor")&&!k.call(a.constructor.prototype,"isPrototypeOf"))return!1}catch(c){return!1}if(!l.ownFirst)for(b in a)return k.call(a,b);for(b in a);return void 0===b||k.call(a,b)},type:function(a){return null==a?a+"":"object"==typeof a||"function"==typeof a?i[j.call(a)]||"object":typeof a},globalEval:function(b){b&&n.trim(b)&&(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.replace(p,"ms-").replace(q,r)},nodeName:function(a,b){return a.nodeName&&a.nodeName.toLowerCase()===b.toLowerCase()},each:function(a,b){var c,d=0;if(s(a)){for(c=a.length;c>d;d++)if(b.call(a[d],d,a[d])===!1)break}else for(d in a)if(b.call(a[d],d,a[d])===!1)break;return a},trim:function(a){return null==a?"":(a+"").replace(o,"")},makeArray:function(a,b){var c=b||[];return null!=a&&(s(Object(a))?n.merge(c,"string"==typeof a?[a]:a):g.call(c,a)),c},inArray:function(a,b,c){var d;if(b){if(h)return h.call(b,a,c);for(d=b.length,c=c?0>c?Math.max(0,d+c):c:0;d>c;c++)if(c in b&&b[c]===a)return c}return-1},merge:function(a,b){var c=+b.length,d=0,e=a.length;while(c>d)a[e++]=b[d++];if(c!==c)while(void 0!==b[d])a[e++]=b[d++];return a.length=e,a},grep:function(a,b,c){for(var d,e=[],f=0,g=a.length,h=!c;g>f;f++)d=!b(a[f],f),d!==h&&e.push(a[f]);return e},map:function(a,b,c){var d,e,g=0,h=[];if(s(a))for(d=a.length;d>g;g++)e=b(a[g],g,c),null!=e&&h.push(e);else for(g in a)e=b(a[g],g,c),null!=e&&h.push(e);return f.apply([],h)},guid:1,proxy:function(a,b){var c,d,f;return"string"==typeof b&&(f=a[b],b=a,a=f),n.isFunction(a)?(c=e.call(arguments,2),d=function(){return a.apply(b||this,c.concat(e.call(arguments)))},d.guid=a.guid=a.guid||n.guid++,d):void 0},now:function(){return+new Date},support:l}),"function"==typeof Symbol&&(n.fn[Symbol.iterator]=c[Symbol.iterator]),n.each("Boolean Number String Function Array Date RegExp Object Error Symbol".split(" "),function(a,b){i["[object "+b+"]"]=b.toLowerCase()});function s(a){var b=!!a&&"length"in a&&a.length,c=n.type(a);return"function"===c||n.isWindow(a)?!1:"array"===c||0===b||"number"==typeof b&&b>0&&b-1 in a}var t=function(a){var b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u="sizzle"+1*new Date,v=a.document,w=0,x=0,y=ga(),z=ga(),A=ga(),B=function(a,b){return a===b&&(l=!0),0},C=1<<31,D={}.hasOwnProperty,E=[],F=E.pop,G=E.push,H=E.push,I=E.slice,J=function(a,b){for(var c=0,d=a.length;d>c;c++)if(a[c]===b)return c;return-1},K="checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|ismap|loop|multiple|open|readonly|required|scoped",L="[\\x20\\t\\r\\n\\f]",M="(?:\\\\.|[\\w-]|[^\\x00-\\xa0])+",N="\\["+L+"*("+M+")(?:"+L+"*([*^$|!~]?=)"+L+"*(?:'((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\"|("+M+"))|)"+L+"*\\]",O=":("+M+")(?:\\((('((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\")|((?:\\\\.|[^\\\\()[\\]]|"+N+")*)|.*)\\)|)",P=new RegExp(L+"+","g"),Q=new RegExp("^"+L+"+|((?:^|[^\\\\])(?:\\\\.)*)"+L+"+$","g"),R=new RegExp("^"+L+"*,"+L+"*"),S=new RegExp("^"+L+"*([>+~]|"+L+")"+L+"*"),T=new RegExp("="+L+"*([^\\]'\"]*?)"+L+"*\\]","g"),U=new RegExp(O),V=new RegExp("^"+M+"$"),W={ID:new RegExp("^#("+M+")"),CLASS:new RegExp("^\\.("+M+")"),TAG:new RegExp("^("+M+"|[*])"),ATTR:new RegExp("^"+N),PSEUDO:new RegExp("^"+O),CHILD:new RegExp("^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\("+L+"*(even|odd|(([+-]|)(\\d*)n|)"+L+"*(?:([+-]|)"+L+"*(\\d+)|))"+L+"*\\)|)","i"),bool:new RegExp("^(?:"+K+")$","i"),needsContext:new RegExp("^"+L+"*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\("+L+"*((?:-\\d)?\\d*)"+L+"*\\)|)(?=[^-]|$)","i")},X=/^(?:input|select|textarea|button)$/i,Y=/^h\d$/i,Z=/^[^{]+\{\s*\[native \w/,$=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,_=/[+~]/,aa=/'|\\/g,ba=new RegExp("\\\\([\\da-f]{1,6}"+L+"?|("+L+")|.)","ig"),ca=function(a,b,c){var d="0x"+b-65536;return d!==d||c?b:0>d?String.fromCharCode(d+65536):String.fromCharCode(d>>10|55296,1023&d|56320)},da=function(){m()};try{H.apply(E=I.call(v.childNodes),v.childNodes),E[v.childNodes.length].nodeType}catch(ea){H={apply:E.length?function(a,b){G.apply(a,I.call(b))}:function(a,b){var c=a.length,d=0;while(a[c++]=b[d++]);a.length=c-1}}}function fa(a,b,d,e){var f,h,j,k,l,o,r,s,w=b&&b.ownerDocument,x=b?b.nodeType:9;if(d=d||[],"string"!=typeof a||!a||1!==x&&9!==x&&11!==x)return d;if(!e&&((b?b.ownerDocument||b:v)!==n&&m(b),b=b||n,p)){if(11!==x&&(o=$.exec(a)))if(f=o[1]){if(9===x){if(!(j=b.getElementById(f)))return d;if(j.id===f)return d.push(j),d}else if(w&&(j=w.getElementById(f))&&t(b,j)&&j.id===f)return d.push(j),d}else{if(o[2])return H.apply(d,b.getElementsByTagName(a)),d;if((f=o[3])&&c.getElementsByClassName&&b.getElementsByClassName)return H.apply(d,b.getElementsByClassName(f)),d}if(c.qsa&&!A[a+" "]&&(!q||!q.test(a))){if(1!==x)w=b,s=a;else if("object"!==b.nodeName.toLowerCase()){(k=b.getAttribute("id"))?k=k.replace(aa,"\\$&"):b.setAttribute("id",k=u),r=g(a),h=r.length,l=V.test(k)?"#"+k:"[id='"+k+"']";while(h--)r[h]=l+" "+qa(r[h]);s=r.join(","),w=_.test(a)&&oa(b.parentNode)||b}if(s)try{return H.apply(d,w.querySelectorAll(s)),d}catch(y){}finally{k===u&&b.removeAttribute("id")}}}return i(a.replace(Q,"$1"),b,d,e)}function ga(){var a=[];function b(c,e){return a.push(c+" ")>d.cacheLength&&delete b[a.shift()],b[c+" "]=e}return b}function ha(a){return a[u]=!0,a}function ia(a){var b=n.createElement("div");try{return!!a(b)}catch(c){return!1}finally{b.parentNode&&b.parentNode.removeChild(b),b=null}}function ja(a,b){var c=a.split("|"),e=c.length;while(e--)d.attrHandle[c[e]]=b}function ka(a,b){var c=b&&a,d=c&&1===a.nodeType&&1===b.nodeType&&(~b.sourceIndex||C)-(~a.sourceIndex||C);if(d)return d;if(c)while(c=c.nextSibling)if(c===b)return-1;return a?1:-1}function la(a){return function(b){var c=b.nodeName.toLowerCase();return"input"===c&&b.type===a}}function ma(a){return function(b){var c=b.nodeName.toLowerCase();return("input"===c||"button"===c)&&b.type===a}}function na(a){return ha(function(b){return b=+b,ha(function(c,d){var e,f=a([],c.length,b),g=f.length;while(g--)c[e=f[g]]&&(c[e]=!(d[e]=c[e]))})})}function oa(a){return a&&"undefined"!=typeof a.getElementsByTagName&&a}c=fa.support={},f=fa.isXML=function(a){var b=a&&(a.ownerDocument||a).documentElement;return b?"HTML"!==b.nodeName:!1},m=fa.setDocument=function(a){var b,e,g=a?a.ownerDocument||a:v;return g!==n&&9===g.nodeType&&g.documentElement?(n=g,o=n.documentElement,p=!f(n),(e=n.defaultView)&&e.top!==e&&(e.addEventListener?e.addEventListener("unload",da,!1):e.attachEvent&&e.attachEvent("onunload",da)),c.attributes=ia(function(a){return a.className="i",!a.getAttribute("className")}),c.getElementsByTagName=ia(function(a){return a.appendChild(n.createComment("")),!a.getElementsByTagName("*").length}),c.getElementsByClassName=Z.test(n.getElementsByClassName),c.getById=ia(function(a){return o.appendChild(a).id=u,!n.getElementsByName||!n.getElementsByName(u).length}),c.getById?(d.find.ID=function(a,b){if("undefined"!=typeof b.getElementById&&p){var c=b.getElementById(a);return c?[c]:[]}},d.filter.ID=function(a){var b=a.replace(ba,ca);return function(a){return a.getAttribute("id")===b}}):(delete d.find.ID,d.filter.ID=function(a){var b=a.replace(ba,ca);return function(a){var c="undefined"!=typeof a.getAttributeNode&&a.getAttributeNode("id");return c&&c.value===b}}),d.find.TAG=c.getElementsByTagName?function(a,b){return"undefined"!=typeof b.getElementsByTagName?b.getElementsByTagName(a):c.qsa?b.querySelectorAll(a):void 0}:function(a,b){var c,d=[],e=0,f=b.getElementsByTagName(a);if("*"===a){while(c=f[e++])1===c.nodeType&&d.push(c);return d}return f},d.find.CLASS=c.getElementsByClassName&&function(a,b){return"undefined"!=typeof b.getElementsByClassName&&p?b.getElementsByClassName(a):void 0},r=[],q=[],(c.qsa=Z.test(n.querySelectorAll))&&(ia(function(a){o.appendChild(a).innerHTML="<a id='"+u+"'></a><select id='"+u+"-\r\\' msallowcapture=''><option selected=''></option></select>",a.querySelectorAll("[msallowcapture^='']").length&&q.push("[*^$]="+L+"*(?:''|\"\")"),a.querySelectorAll("[selected]").length||q.push("\\["+L+"*(?:value|"+K+")"),a.querySelectorAll("[id~="+u+"-]").length||q.push("~="),a.querySelectorAll(":checked").length||q.push(":checked"),a.querySelectorAll("a#"+u+"+*").length||q.push(".#.+[+~]")}),ia(function(a){var b=n.createElement("input");b.setAttribute("type","hidden"),a.appendChild(b).setAttribute("name","D"),a.querySelectorAll("[name=d]").length&&q.push("name"+L+"*[*^$|!~]?="),a.querySelectorAll(":enabled").length||q.push(":enabled",":disabled"),a.querySelectorAll("*,:x"),q.push(",.*:")})),(c.matchesSelector=Z.test(s=o.matches||o.webkitMatchesSelector||o.mozMatchesSelector||o.oMatchesSelector||o.msMatchesSelector))&&ia(function(a){c.disconnectedMatch=s.call(a,"div"),s.call(a,"[s!='']:x"),r.push("!=",O)}),q=q.length&&new RegExp(q.join("|")),r=r.length&&new RegExp(r.join("|")),b=Z.test(o.compareDocumentPosition),t=b||Z.test(o.contains)?function(a,b){var c=9===a.nodeType?a.documentElement:a,d=b&&b.parentNode;return a===d||!(!d||1!==d.nodeType||!(c.contains?c.contains(d):a.compareDocumentPosition&&16&a.compareDocumentPosition(d)))}:function(a,b){if(b)while(b=b.parentNode)if(b===a)return!0;return!1},B=b?function(a,b){if(a===b)return l=!0,0;var d=!a.compareDocumentPosition-!b.compareDocumentPosition;return d?d:(d=(a.ownerDocument||a)===(b.ownerDocument||b)?a.compareDocumentPosition(b):1,1&d||!c.sortDetached&&b.compareDocumentPosition(a)===d?a===n||a.ownerDocument===v&&t(v,a)?-1:b===n||b.ownerDocument===v&&t(v,b)?1:k?J(k,a)-J(k,b):0:4&d?-1:1)}:function(a,b){if(a===b)return l=!0,0;var c,d=0,e=a.parentNode,f=b.parentNode,g=[a],h=[b];if(!e||!f)return a===n?-1:b===n?1:e?-1:f?1:k?J(k,a)-J(k,b):0;if(e===f)return ka(a,b);c=a;while(c=c.parentNode)g.unshift(c);c=b;while(c=c.parentNode)h.unshift(c);while(g[d]===h[d])d++;return d?ka(g[d],h[d]):g[d]===v?-1:h[d]===v?1:0},n):n},fa.matches=function(a,b){return fa(a,null,null,b)},fa.matchesSelector=function(a,b){if((a.ownerDocument||a)!==n&&m(a),b=b.replace(T,"='$1']"),c.matchesSelector&&p&&!A[b+" "]&&(!r||!r.test(b))&&(!q||!q.test(b)))try{var d=s.call(a,b);if(d||c.disconnectedMatch||a.document&&11!==a.document.nodeType)return d}catch(e){}return fa(b,n,null,[a]).length>0},fa.contains=function(a,b){return(a.ownerDocument||a)!==n&&m(a),t(a,b)},fa.attr=function(a,b){(a.ownerDocument||a)!==n&&m(a);var e=d.attrHandle[b.toLowerCase()],f=e&&D.call(d.attrHandle,b.toLowerCase())?e(a,b,!p):void 0;return void 0!==f?f:c.attributes||!p?a.getAttribute(b):(f=a.getAttributeNode(b))&&f.specified?f.value:null},fa.error=function(a){throw new Error("Syntax error, unrecognized expression: "+a)},fa.uniqueSort=function(a){var b,d=[],e=0,f=0;if(l=!c.detectDuplicates,k=!c.sortStable&&a.slice(0),a.sort(B),l){while(b=a[f++])b===a[f]&&(e=d.push(f));while(e--)a.splice(d[e],1)}return k=null,a},e=fa.getText=function(a){var b,c="",d=0,f=a.nodeType;if(f){if(1===f||9===f||11===f){if("string"==typeof a.textContent)return a.textContent;for(a=a.firstChild;a;a=a.nextSibling)c+=e(a)}else if(3===f||4===f)return a.nodeValue}else while(b=a[d++])c+=e(b);return c},d=fa.selectors={cacheLength:50,createPseudo:ha,match:W,attrHandle:{},find:{},relative:{">":{dir:"parentNode",first:!0}," ":{dir:"parentNode"},"+":{dir:"previousSibling",first:!0},"~":{dir:"previousSibling"}},preFilter:{ATTR:function(a){return a[1]=a[1].replace(ba,ca),a[3]=(a[3]||a[4]||a[5]||"").replace(ba,ca),"~="===a[2]&&(a[3]=" "+a[3]+" "),a.slice(0,4)},CHILD:function(a){return a[1]=a[1].toLowerCase(),"nth"===a[1].slice(0,3)?(a[3]||fa.error(a[0]),a[4]=+(a[4]?a[5]+(a[6]||1):2*("even"===a[3]||"odd"===a[3])),a[5]=+(a[7]+a[8]||"odd"===a[3])):a[3]&&fa.error(a[0]),a},PSEUDO:function(a){var b,c=!a[6]&&a[2];return W.CHILD.test(a[0])?null:(a[3]?a[2]=a[4]||a[5]||"":c&&U.test(c)&&(b=g(c,!0))&&(b=c.indexOf(")",c.length-b)-c.length)&&(a[0]=a[0].slice(0,b),a[2]=c.slice(0,b)),a.slice(0,3))}},filter:{TAG:function(a){var b=a.replace(ba,ca).toLowerCase();return"*"===a?function(){return!0}:function(a){return a.nodeName&&a.nodeName.toLowerCase()===b}},CLASS:function(a){var b=y[a+" "];return b||(b=new RegExp("(^|"+L+")"+a+"("+L+"|$)"))&&y(a,function(a){return b.test("string"==typeof a.className&&a.className||"undefined"!=typeof a.getAttribute&&a.getAttribute("class")||"")})},ATTR:function(a,b,c){return function(d){var e=fa.attr(d,a);return null==e?"!="===b:b?(e+="","="===b?e===c:"!="===b?e!==c:"^="===b?c&&0===e.indexOf(c):"*="===b?c&&e.indexOf(c)>-1:"$="===b?c&&e.slice(-c.length)===c:"~="===b?(" "+e.replace(P," ")+" ").indexOf(c)>-1:"|="===b?e===c||e.slice(0,c.length+1)===c+"-":!1):!0}},CHILD:function(a,b,c,d,e){var f="nth"!==a.slice(0,3),g="last"!==a.slice(-4),h="of-type"===b;return 1===d&&0===e?function(a){return!!a.parentNode}:function(b,c,i){var j,k,l,m,n,o,p=f!==g?"nextSibling":"previousSibling",q=b.parentNode,r=h&&b.nodeName.toLowerCase(),s=!i&&!h,t=!1;if(q){if(f){while(p){m=b;while(m=m[p])if(h?m.nodeName.toLowerCase()===r:1===m.nodeType)return!1;o=p="only"===a&&!o&&"nextSibling"}return!0}if(o=[g?q.firstChild:q.lastChild],g&&s){m=q,l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),j=k[a]||[],n=j[0]===w&&j[1],t=n&&j[2],m=n&&q.childNodes[n];while(m=++n&&m&&m[p]||(t=n=0)||o.pop())if(1===m.nodeType&&++t&&m===b){k[a]=[w,n,t];break}}else if(s&&(m=b,l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),j=k[a]||[],n=j[0]===w&&j[1],t=n),t===!1)while(m=++n&&m&&m[p]||(t=n=0)||o.pop())if((h?m.nodeName.toLowerCase()===r:1===m.nodeType)&&++t&&(s&&(l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),k[a]=[w,t]),m===b))break;return t-=e,t===d||t%d===0&&t/d>=0}}},PSEUDO:function(a,b){var c,e=d.pseudos[a]||d.setFilters[a.toLowerCase()]||fa.error("unsupported pseudo: "+a);return e[u]?e(b):e.length>1?(c=[a,a,"",b],d.setFilters.hasOwnProperty(a.toLowerCase())?ha(function(a,c){var d,f=e(a,b),g=f.length;while(g--)d=J(a,f[g]),a[d]=!(c[d]=f[g])}):function(a){return e(a,0,c)}):e}},pseudos:{not:ha(function(a){var b=[],c=[],d=h(a.replace(Q,"$1"));return d[u]?ha(function(a,b,c,e){var f,g=d(a,null,e,[]),h=a.length;while(h--)(f=g[h])&&(a[h]=!(b[h]=f))}):function(a,e,f){return b[0]=a,d(b,null,f,c),b[0]=null,!c.pop()}}),has:ha(function(a){return function(b){return fa(a,b).length>0}}),contains:ha(function(a){return a=a.replace(ba,ca),function(b){return(b.textContent||b.innerText||e(b)).indexOf(a)>-1}}),lang:ha(function(a){return V.test(a||"")||fa.error("unsupported lang: "+a),a=a.replace(ba,ca).toLowerCase(),function(b){var c;do if(c=p?b.lang:b.getAttribute("xml:lang")||b.getAttribute("lang"))return c=c.toLowerCase(),c===a||0===c.indexOf(a+"-");while((b=b.parentNode)&&1===b.nodeType);return!1}}),target:function(b){var c=a.location&&a.location.hash;return c&&c.slice(1)===b.id},root:function(a){return a===o},focus:function(a){return a===n.activeElement&&(!n.hasFocus||n.hasFocus())&&!!(a.type||a.href||~a.tabIndex)},enabled:function(a){return a.disabled===!1},disabled:function(a){return a.disabled===!0},checked:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&!!a.checked||"option"===b&&!!a.selected},selected:function(a){return a.parentNode&&a.parentNode.selectedIndex,a.selected===!0},empty:function(a){for(a=a.firstChild;a;a=a.nextSibling)if(a.nodeType<6)return!1;return!0},parent:function(a){return!d.pseudos.empty(a)},header:function(a){return Y.test(a.nodeName)},input:function(a){return X.test(a.nodeName)},button:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&"button"===a.type||"button"===b},text:function(a){var b;return"input"===a.nodeName.toLowerCase()&&"text"===a.type&&(null==(b=a.getAttribute("type"))||"text"===b.toLowerCase())},first:na(function(){return[0]}),last:na(function(a,b){return[b-1]}),eq:na(function(a,b,c){return[0>c?c+b:c]}),even:na(function(a,b){for(var c=0;b>c;c+=2)a.push(c);return a}),odd:na(function(a,b){for(var c=1;b>c;c+=2)a.push(c);return a}),lt:na(function(a,b,c){for(var d=0>c?c+b:c;--d>=0;)a.push(d);return a}),gt:na(function(a,b,c){for(var d=0>c?c+b:c;++d<b;)a.push(d);return a})}},d.pseudos.nth=d.pseudos.eq;for(b in{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})d.pseudos[b]=la(b);for(b in{submit:!0,reset:!0})d.pseudos[b]=ma(b);function pa(){}pa.prototype=d.filters=d.pseudos,d.setFilters=new pa,g=fa.tokenize=function(a,b){var c,e,f,g,h,i,j,k=z[a+" "];if(k)return b?0:k.slice(0);h=a,i=[],j=d.preFilter;while(h){c&&!(e=R.exec(h))||(e&&(h=h.slice(e[0].length)||h),i.push(f=[])),c=!1,(e=S.exec(h))&&(c=e.shift(),f.push({value:c,type:e[0].replace(Q," ")}),h=h.slice(c.length));for(g in d.filter)!(e=W[g].exec(h))||j[g]&&!(e=j[g](e))||(c=e.shift(),f.push({value:c,type:g,matches:e}),h=h.slice(c.length));if(!c)break}return b?h.length:h?fa.error(a):z(a,i).slice(0)};function qa(a){for(var b=0,c=a.length,d="";c>b;b++)d+=a[b].value;return d}function ra(a,b,c){var d=b.dir,e=c&&"parentNode"===d,f=x++;return b.first?function(b,c,f){while(b=b[d])if(1===b.nodeType||e)return a(b,c,f)}:function(b,c,g){var h,i,j,k=[w,f];if(g){while(b=b[d])if((1===b.nodeType||e)&&a(b,c,g))return!0}else while(b=b[d])if(1===b.nodeType||e){if(j=b[u]||(b[u]={}),i=j[b.uniqueID]||(j[b.uniqueID]={}),(h=i[d])&&h[0]===w&&h[1]===f)return k[2]=h[2];if(i[d]=k,k[2]=a(b,c,g))return!0}}}function sa(a){return a.length>1?function(b,c,d){var e=a.length;while(e--)if(!a[e](b,c,d))return!1;return!0}:a[0]}function ta(a,b,c){for(var d=0,e=b.length;e>d;d++)fa(a,b[d],c);return c}function ua(a,b,c,d,e){for(var f,g=[],h=0,i=a.length,j=null!=b;i>h;h++)(f=a[h])&&(c&&!c(f,d,e)||(g.push(f),j&&b.push(h)));return g}function va(a,b,c,d,e,f){return d&&!d[u]&&(d=va(d)),e&&!e[u]&&(e=va(e,f)),ha(function(f,g,h,i){var j,k,l,m=[],n=[],o=g.length,p=f||ta(b||"*",h.nodeType?[h]:h,[]),q=!a||!f&&b?p:ua(p,m,a,h,i),r=c?e||(f?a:o||d)?[]:g:q;if(c&&c(q,r,h,i),d){j=ua(r,n),d(j,[],h,i),k=j.length;while(k--)(l=j[k])&&(r[n[k]]=!(q[n[k]]=l))}if(f){if(e||a){if(e){j=[],k=r.length;while(k--)(l=r[k])&&j.push(q[k]=l);e(null,r=[],j,i)}k=r.length;while(k--)(l=r[k])&&(j=e?J(f,l):m[k])>-1&&(f[j]=!(g[j]=l))}}else r=ua(r===g?r.splice(o,r.length):r),e?e(null,g,r,i):H.apply(g,r)})}function wa(a){for(var b,c,e,f=a.length,g=d.relative[a[0].type],h=g||d.relative[" "],i=g?1:0,k=ra(function(a){return a===b},h,!0),l=ra(function(a){return J(b,a)>-1},h,!0),m=[function(a,c,d){var e=!g&&(d||c!==j)||((b=c).nodeType?k(a,c,d):l(a,c,d));return b=null,e}];f>i;i++)if(c=d.relative[a[i].type])m=[ra(sa(m),c)];else{if(c=d.filter[a[i].type].apply(null,a[i].matches),c[u]){for(e=++i;f>e;e++)if(d.relative[a[e].type])break;return va(i>1&&sa(m),i>1&&qa(a.slice(0,i-1).concat({value:" "===a[i-2].type?"*":""})).replace(Q,"$1"),c,e>i&&wa(a.slice(i,e)),f>e&&wa(a=a.slice(e)),f>e&&qa(a))}m.push(c)}return sa(m)}function xa(a,b){var c=b.length>0,e=a.length>0,f=function(f,g,h,i,k){var l,o,q,r=0,s="0",t=f&&[],u=[],v=j,x=f||e&&d.find.TAG("*",k),y=w+=null==v?1:Math.random()||.1,z=x.length;for(k&&(j=g===n||g||k);s!==z&&null!=(l=x[s]);s++){if(e&&l){o=0,g||l.ownerDocument===n||(m(l),h=!p);while(q=a[o++])if(q(l,g||n,h)){i.push(l);break}k&&(w=y)}c&&((l=!q&&l)&&r--,f&&t.push(l))}if(r+=s,c&&s!==r){o=0;while(q=b[o++])q(t,u,g,h);if(f){if(r>0)while(s--)t[s]||u[s]||(u[s]=F.call(i));u=ua(u)}H.apply(i,u),k&&!f&&u.length>0&&r+b.length>1&&fa.uniqueSort(i)}return k&&(w=y,j=v),t};return c?ha(f):f}return h=fa.compile=function(a,b){var c,d=[],e=[],f=A[a+" "];if(!f){b||(b=g(a)),c=b.length;while(c--)f=wa(b[c]),f[u]?d.push(f):e.push(f);f=A(a,xa(e,d)),f.selector=a}return f},i=fa.select=function(a,b,e,f){var i,j,k,l,m,n="function"==typeof a&&a,o=!f&&g(a=n.selector||a);if(e=e||[],1===o.length){if(j=o[0]=o[0].slice(0),j.length>2&&"ID"===(k=j[0]).type&&c.getById&&9===b.nodeType&&p&&d.relative[j[1].type]){if(b=(d.find.ID(k.matches[0].replace(ba,ca),b)||[])[0],!b)return e;n&&(b=b.parentNode),a=a.slice(j.shift().value.length)}i=W.needsContext.test(a)?0:j.length;while(i--){if(k=j[i],d.relative[l=k.type])break;if((m=d.find[l])&&(f=m(k.matches[0].replace(ba,ca),_.test(j[0].type)&&oa(b.parentNode)||b))){if(j.splice(i,1),a=f.length&&qa(j),!a)return H.apply(e,f),e;break}}}return(n||h(a,o))(f,b,!p,e,!b||_.test(a)&&oa(b.parentNode)||b),e},c.sortStable=u.split("").sort(B).join("")===u,c.detectDuplicates=!!l,m(),c.sortDetached=ia(function(a){return 1&a.compareDocumentPosition(n.createElement("div"))}),ia(function(a){return a.innerHTML="<a href='#'></a>","#"===a.firstChild.getAttribute("href")})||ja("type|href|height|width",function(a,b,c){return c?void 0:a.getAttribute(b,"type"===b.toLowerCase()?1:2)}),c.attributes&&ia(function(a){return a.innerHTML="<input/>",a.firstChild.setAttribute("value",""),""===a.firstChild.getAttribute("value")})||ja("value",function(a,b,c){return c||"input"!==a.nodeName.toLowerCase()?void 0:a.defaultValue}),ia(function(a){return null==a.getAttribute("disabled")})||ja(K,function(a,b,c){var d;return c?void 0:a[b]===!0?b.toLowerCase():(d=a.getAttributeNode(b))&&d.specified?d.value:null}),fa}(a);n.find=t,n.expr=t.selectors,n.expr[":"]=n.expr.pseudos,n.uniqueSort=n.unique=t.uniqueSort,n.text=t.getText,n.isXMLDoc=t.isXML,n.contains=t.contains;var u=function(a,b,c){var d=[],e=void 0!==c;while((a=a[b])&&9!==a.nodeType)if(1===a.nodeType){if(e&&n(a).is(c))break;d.push(a)}return d},v=function(a,b){for(var c=[];a;a=a.nextSibling)1===a.nodeType&&a!==b&&c.push(a);return c},w=n.expr.match.needsContext,x=/^<([\w-]+)\s*\/?>(?:<\/\1>|)$/,y=/^.[^:#\[\.,]*$/;function z(a,b,c){if(n.isFunction(b))return n.grep(a,function(a,d){return!!b.call(a,d,a)!==c});if(b.nodeType)return n.grep(a,function(a){return a===b!==c});if("string"==typeof b){if(y.test(b))return n.filter(b,a,c);b=n.filter(b,a)}return n.grep(a,function(a){return n.inArray(a,b)>-1!==c})}n.filter=function(a,b,c){var d=b[0];return c&&(a=":not("+a+")"),1===b.length&&1===d.nodeType?n.find.matchesSelector(d,a)?[d]:[]:n.find.matches(a,n.grep(b,function(a){return 1===a.nodeType}))},n.fn.extend({find:function(a){var b,c=[],d=this,e=d.length;if("string"!=typeof a)return this.pushStack(n(a).filter(function(){for(b=0;e>b;b++)if(n.contains(d[b],this))return!0}));for(b=0;e>b;b++)n.find(a,d[b],c);return c=this.pushStack(e>1?n.unique(c):c),c.selector=this.selector?this.selector+" "+a:a,c},filter:function(a){return this.pushStack(z(this,a||[],!1))},not:function(a){return this.pushStack(z(this,a||[],!0))},is:function(a){return!!z(this,"string"==typeof a&&w.test(a)?n(a):a||[],!1).length}});var A,B=/^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]*))$/,C=n.fn.init=function(a,b,c){var e,f;if(!a)return this;if(c=c||A,"string"==typeof a){if(e="<"===a.charAt(0)&&">"===a.charAt(a.length-1)&&a.length>=3?[null,a,null]:B.exec(a),!e||!e[1]&&b)return!b||b.jquery?(b||c).find(a):this.constructor(b).find(a);if(e[1]){if(b=b instanceof n?b[0]:b,n.merge(this,n.parseHTML(e[1],b&&b.nodeType?b.ownerDocument||b:d,!0)),x.test(e[1])&&n.isPlainObject(b))for(e in b)n.isFunction(this[e])?this[e](b[e]):this.attr(e,b[e]);return this}if(f=d.getElementById(e[2]),f&&f.parentNode){if(f.id!==e[2])return A.find(a);this.length=1,this[0]=f}return this.context=d,this.selector=a,this}return a.nodeType?(this.context=this[0]=a,this.length=1,this):n.isFunction(a)?"undefined"!=typeof c.ready?c.ready(a):a(n):(void 0!==a.selector&&(this.selector=a.selector,this.context=a.context),n.makeArray(a,this))};C.prototype=n.fn,A=n(d);var D=/^(?:parents|prev(?:Until|All))/,E={children:!0,contents:!0,next:!0,prev:!0};n.fn.extend({has:function(a){var b,c=n(a,this),d=c.length;return this.filter(function(){for(b=0;d>b;b++)if(n.contains(this,c[b]))return!0})},closest:function(a,b){for(var c,d=0,e=this.length,f=[],g=w.test(a)||"string"!=typeof a?n(a,b||this.context):0;e>d;d++)for(c=this[d];c&&c!==b;c=c.parentNode)if(c.nodeType<11&&(g?g.index(c)>-1:1===c.nodeType&&n.find.matchesSelector(c,a))){f.push(c);break}return this.pushStack(f.length>1?n.uniqueSort(f):f)},index:function(a){return a?"string"==typeof a?n.inArray(this[0],n(a)):n.inArray(a.jquery?a[0]:a,this):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(a,b){return this.pushStack(n.uniqueSort(n.merge(this.get(),n(a,b))))},addBack:function(a){return this.add(null==a?this.prevObject:this.prevObject.filter(a))}});function F(a,b){do a=a[b];while(a&&1!==a.nodeType);return a}n.each({parent:function(a){var b=a.parentNode;return b&&11!==b.nodeType?b:null},parents:function(a){return u(a,"parentNode")},parentsUntil:function(a,b,c){return u(a,"parentNode",c)},next:function(a){return F(a,"nextSibling")},prev:function(a){return F(a,"previousSibling")},nextAll:function(a){return u(a,"nextSibling")},prevAll:function(a){return u(a,"previousSibling")},nextUntil:function(a,b,c){return u(a,"nextSibling",c)},prevUntil:function(a,b,c){return u(a,"previousSibling",c)},siblings:function(a){return v((a.parentNode||{}).firstChild,a)},children:function(a){return v(a.firstChild)},contents:function(a){return n.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:n.merge([],a.childNodes)}},function(a,b){n.fn[a]=function(c,d){var e=n.map(this,b,c);return"Until"!==a.slice(-5)&&(d=c),d&&"string"==typeof d&&(e=n.filter(d,e)),this.length>1&&(E[a]||(e=n.uniqueSort(e)),D.test(a)&&(e=e.reverse())),this.pushStack(e)}});var G=/\S+/g;function H(a){var b={};return n.each(a.match(G)||[],function(a,c){b[c]=!0}),b}n.Callbacks=function(a){a="string"==typeof a?H(a):n.extend({},a);var b,c,d,e,f=[],g=[],h=-1,i=function(){for(e=a.once,d=b=!0;g.length;h=-1){c=g.shift();while(++h<f.length)f[h].apply(c[0],c[1])===!1&&a.stopOnFalse&&(h=f.length,c=!1)}a.memory||(c=!1),b=!1,e&&(f=c?[]:"")},j={add:function(){return f&&(c&&!b&&(h=f.length-1,g.push(c)),function d(b){n.each(b,function(b,c){n.isFunction(c)?a.unique&&j.has(c)||f.push(c):c&&c.length&&"string"!==n.type(c)&&d(c)})}(arguments),c&&!b&&i()),this},remove:function(){return n.each(arguments,function(a,b){var c;while((c=n.inArray(b,f,c))>-1)f.splice(c,1),h>=c&&h--}),this},has:function(a){return a?n.inArray(a,f)>-1:f.length>0},empty:function(){return f&&(f=[]),this},disable:function(){return e=g=[],f=c="",this},disabled:function(){return!f},lock:function(){return e=!0,c||j.disable(),this},locked:function(){return!!e},fireWith:function(a,c){return e||(c=c||[],c=[a,c.slice?c.slice():c],g.push(c),b||i()),this},fire:function(){return j.fireWith(this,arguments),this},fired:function(){return!!d}};return j},n.extend({Deferred:function(a){var b=[["resolve","done",n.Callbacks("once memory"),"resolved"],["reject","fail",n.Callbacks("once memory"),"rejected"],["notify","progress",n.Callbacks("memory")]],c="pending",d={state:function(){return c},always:function(){return e.done(arguments).fail(arguments),this},then:function(){var a=arguments;return n.Deferred(function(c){n.each(b,function(b,f){var g=n.isFunction(a[b])&&a[b];e[f[1]](function(){var a=g&&g.apply(this,arguments);a&&n.isFunction(a.promise)?a.promise().progress(c.notify).done(c.resolve).fail(c.reject):c[f[0]+"With"](this===d?c.promise():this,g?[a]:arguments)})}),a=null}).promise()},promise:function(a){return null!=a?n.extend(a,d):d}},e={};return d.pipe=d.then,n.each(b,function(a,f){var g=f[2],h=f[3];d[f[1]]=g.add,h&&g.add(function(){c=h},b[1^a][2].disable,b[2][2].lock),e[f[0]]=function(){return e[f[0]+"With"](this===e?d:this,arguments),this},e[f[0]+"With"]=g.fireWith}),d.promise(e),a&&a.call(e,e),e},when:function(a){var b=0,c=e.call(arguments),d=c.length,f=1!==d||a&&n.isFunction(a.promise)?d:0,g=1===f?a:n.Deferred(),h=function(a,b,c){return function(d){b[a]=this,c[a]=arguments.length>1?e.call(arguments):d,c===i?g.notifyWith(b,c):--f||g.resolveWith(b,c)}},i,j,k;if(d>1)for(i=new Array(d),j=new Array(d),k=new Array(d);d>b;b++)c[b]&&n.isFunction(c[b].promise)?c[b].promise().progress(h(b,j,i)).done(h(b,k,c)).fail(g.reject):--f;return f||g.resolveWith(k,c),g.promise()}});var I;n.fn.ready=function(a){return n.ready.promise().done(a),this},n.extend({isReady:!1,readyWait:1,holdReady:function(a){a?n.readyWait++:n.ready(!0)},ready:function(a){(a===!0?--n.readyWait:n.isReady)||(n.isReady=!0,a!==!0&&--n.readyWait>0||(I.resolveWith(d,[n]),n.fn.triggerHandler&&(n(d).triggerHandler("ready"),n(d).off("ready"))))}});function J(){d.addEventListener?(d.removeEventListener("DOMContentLoaded",K),a.removeEventListener("load",K)):(d.detachEvent("onreadystatechange",K),a.detachEvent("onload",K))}function K(){(d.addEventListener||"load"===a.event.type||"complete"===d.readyState)&&(J(),n.ready())}n.ready.promise=function(b){if(!I)if(I=n.Deferred(),"complete"===d.readyState||"loading"!==d.readyState&&!d.documentElement.doScroll)a.setTimeout(n.ready);else if(d.addEventListener)d.addEventListener("DOMContentLoaded",K),a.addEventListener("load",K);else{d.attachEvent("onreadystatechange",K),a.attachEvent("onload",K);var c=!1;try{c=null==a.frameElement&&d.documentElement}catch(e){}c&&c.doScroll&&!function f(){if(!n.isReady){try{c.doScroll("left")}catch(b){return a.setTimeout(f,50)}J(),n.ready()}}()}return I.promise(b)},n.ready.promise();var L;for(L in n(l))break;l.ownFirst="0"===L,l.inlineBlockNeedsLayout=!1,n(function(){var a,b,c,e;c=d.getElementsByTagName("body")[0],c&&c.style&&(b=d.createElement("div"),e=d.createElement("div"),e.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(e).appendChild(b),"undefined"!=typeof b.style.zoom&&(b.style.cssText="display:inline;margin:0;border:0;padding:1px;width:1px;zoom:1",l.inlineBlockNeedsLayout=a=3===b.offsetWidth,a&&(c.style.zoom=1)),c.removeChild(e))}),function(){var a=d.createElement("div");l.deleteExpando=!0;try{delete a.test}catch(b){l.deleteExpando=!1}a=null}();var M=function(a){var b=n.noData[(a.nodeName+" ").toLowerCase()],c=+a.nodeType||1;return 1!==c&&9!==c?!1:!b||b!==!0&&a.getAttribute("classid")===b},N=/^(?:\{[\w\W]*\}|\[[\w\W]*\])$/,O=/([A-Z])/g;function P(a,b,c){if(void 0===c&&1===a.nodeType){var d="data-"+b.replace(O,"-$1").toLowerCase();if(c=a.getAttribute(d),"string"==typeof c){try{c="true"===c?!0:"false"===c?!1:"null"===c?null:+c+""===c?+c:N.test(c)?n.parseJSON(c):c}catch(e){}n.data(a,b,c)}else c=void 0;
}return c}function Q(a){var b;for(b in a)if(("data"!==b||!n.isEmptyObject(a[b]))&&"toJSON"!==b)return!1;return!0}function R(a,b,d,e){if(M(a)){var f,g,h=n.expando,i=a.nodeType,j=i?n.cache:a,k=i?a[h]:a[h]&&h;if(k&&j[k]&&(e||j[k].data)||void 0!==d||"string"!=typeof b)return k||(k=i?a[h]=c.pop()||n.guid++:h),j[k]||(j[k]=i?{}:{toJSON:n.noop}),"object"!=typeof b&&"function"!=typeof b||(e?j[k]=n.extend(j[k],b):j[k].data=n.extend(j[k].data,b)),g=j[k],e||(g.data||(g.data={}),g=g.data),void 0!==d&&(g[n.camelCase(b)]=d),"string"==typeof b?(f=g[b],null==f&&(f=g[n.camelCase(b)])):f=g,f}}function S(a,b,c){if(M(a)){var d,e,f=a.nodeType,g=f?n.cache:a,h=f?a[n.expando]:n.expando;if(g[h]){if(b&&(d=c?g[h]:g[h].data)){n.isArray(b)?b=b.concat(n.map(b,n.camelCase)):b in d?b=[b]:(b=n.camelCase(b),b=b in d?[b]:b.split(" ")),e=b.length;while(e--)delete d[b[e]];if(c?!Q(d):!n.isEmptyObject(d))return}(c||(delete g[h].data,Q(g[h])))&&(f?n.cleanData([a],!0):l.deleteExpando||g!=g.window?delete g[h]:g[h]=void 0)}}}n.extend({cache:{},noData:{"applet ":!0,"embed ":!0,"object ":"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000"},hasData:function(a){return a=a.nodeType?n.cache[a[n.expando]]:a[n.expando],!!a&&!Q(a)},data:function(a,b,c){return R(a,b,c)},removeData:function(a,b){return S(a,b)},_data:function(a,b,c){return R(a,b,c,!0)},_removeData:function(a,b){return S(a,b,!0)}}),n.fn.extend({data:function(a,b){var c,d,e,f=this[0],g=f&&f.attributes;if(void 0===a){if(this.length&&(e=n.data(f),1===f.nodeType&&!n._data(f,"parsedAttrs"))){c=g.length;while(c--)g[c]&&(d=g[c].name,0===d.indexOf("data-")&&(d=n.camelCase(d.slice(5)),P(f,d,e[d])));n._data(f,"parsedAttrs",!0)}return e}return"object"==typeof a?this.each(function(){n.data(this,a)}):arguments.length>1?this.each(function(){n.data(this,a,b)}):f?P(f,a,n.data(f,a)):void 0},removeData:function(a){return this.each(function(){n.removeData(this,a)})}}),n.extend({queue:function(a,b,c){var d;return a?(b=(b||"fx")+"queue",d=n._data(a,b),c&&(!d||n.isArray(c)?d=n._data(a,b,n.makeArray(c)):d.push(c)),d||[]):void 0},dequeue:function(a,b){b=b||"fx";var c=n.queue(a,b),d=c.length,e=c.shift(),f=n._queueHooks(a,b),g=function(){n.dequeue(a,b)};"inprogress"===e&&(e=c.shift(),d--),e&&("fx"===b&&c.unshift("inprogress"),delete f.stop,e.call(a,g,f)),!d&&f&&f.empty.fire()},_queueHooks:function(a,b){var c=b+"queueHooks";return n._data(a,c)||n._data(a,c,{empty:n.Callbacks("once memory").add(function(){n._removeData(a,b+"queue"),n._removeData(a,c)})})}}),n.fn.extend({queue:function(a,b){var c=2;return"string"!=typeof a&&(b=a,a="fx",c--),arguments.length<c?n.queue(this[0],a):void 0===b?this:this.each(function(){var c=n.queue(this,a,b);n._queueHooks(this,a),"fx"===a&&"inprogress"!==c[0]&&n.dequeue(this,a)})},dequeue:function(a){return this.each(function(){n.dequeue(this,a)})},clearQueue:function(a){return this.queue(a||"fx",[])},promise:function(a,b){var c,d=1,e=n.Deferred(),f=this,g=this.length,h=function(){--d||e.resolveWith(f,[f])};"string"!=typeof a&&(b=a,a=void 0),a=a||"fx";while(g--)c=n._data(f[g],a+"queueHooks"),c&&c.empty&&(d++,c.empty.add(h));return h(),e.promise(b)}}),function(){var a;l.shrinkWrapBlocks=function(){if(null!=a)return a;a=!1;var b,c,e;return c=d.getElementsByTagName("body")[0],c&&c.style?(b=d.createElement("div"),e=d.createElement("div"),e.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(e).appendChild(b),"undefined"!=typeof b.style.zoom&&(b.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:1px;width:1px;zoom:1",b.appendChild(d.createElement("div")).style.width="5px",a=3!==b.offsetWidth),c.removeChild(e),a):void 0}}();var T=/[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/.source,U=new RegExp("^(?:([+-])=|)("+T+")([a-z%]*)$","i"),V=["Top","Right","Bottom","Left"],W=function(a,b){return a=b||a,"none"===n.css(a,"display")||!n.contains(a.ownerDocument,a)};function X(a,b,c,d){var e,f=1,g=20,h=d?function(){return d.cur()}:function(){return n.css(a,b,"")},i=h(),j=c&&c[3]||(n.cssNumber[b]?"":"px"),k=(n.cssNumber[b]||"px"!==j&&+i)&&U.exec(n.css(a,b));if(k&&k[3]!==j){j=j||k[3],c=c||[],k=+i||1;do f=f||".5",k/=f,n.style(a,b,k+j);while(f!==(f=h()/i)&&1!==f&&--g)}return c&&(k=+k||+i||0,e=c[1]?k+(c[1]+1)*c[2]:+c[2],d&&(d.unit=j,d.start=k,d.end=e)),e}var Y=function(a,b,c,d,e,f,g){var h=0,i=a.length,j=null==c;if("object"===n.type(c)){e=!0;for(h in c)Y(a,b,h,c[h],!0,f,g)}else if(void 0!==d&&(e=!0,n.isFunction(d)||(g=!0),j&&(g?(b.call(a,d),b=null):(j=b,b=function(a,b,c){return j.call(n(a),c)})),b))for(;i>h;h++)b(a[h],c,g?d:d.call(a[h],h,b(a[h],c)));return e?a:j?b.call(a):i?b(a[0],c):f},Z=/^(?:checkbox|radio)$/i,$=/<([\w:-]+)/,_=/^$|\/(?:java|ecma)script/i,aa=/^\s+/,ba="abbr|article|aside|audio|bdi|canvas|data|datalist|details|dialog|figcaption|figure|footer|header|hgroup|main|mark|meter|nav|output|picture|progress|section|summary|template|time|video";function ca(a){var b=ba.split("|"),c=a.createDocumentFragment();if(c.createElement)while(b.length)c.createElement(b.pop());return c}!function(){var a=d.createElement("div"),b=d.createDocumentFragment(),c=d.createElement("input");a.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",l.leadingWhitespace=3===a.firstChild.nodeType,l.tbody=!a.getElementsByTagName("tbody").length,l.htmlSerialize=!!a.getElementsByTagName("link").length,l.html5Clone="<:nav></:nav>"!==d.createElement("nav").cloneNode(!0).outerHTML,c.type="checkbox",c.checked=!0,b.appendChild(c),l.appendChecked=c.checked,a.innerHTML="<textarea>x</textarea>",l.noCloneChecked=!!a.cloneNode(!0).lastChild.defaultValue,b.appendChild(a),c=d.createElement("input"),c.setAttribute("type","radio"),c.setAttribute("checked","checked"),c.setAttribute("name","t"),a.appendChild(c),l.checkClone=a.cloneNode(!0).cloneNode(!0).lastChild.checked,l.noCloneEvent=!!a.addEventListener,a[n.expando]=1,l.attributes=!a.getAttribute(n.expando)}();var da={option:[1,"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],area:[1,"<map>","</map>"],param:[1,"<object>","</object>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],_default:l.htmlSerialize?[0,"",""]:[1,"X<div>","</div>"]};da.optgroup=da.option,da.tbody=da.tfoot=da.colgroup=da.caption=da.thead,da.th=da.td;function ea(a,b){var c,d,e=0,f="undefined"!=typeof a.getElementsByTagName?a.getElementsByTagName(b||"*"):"undefined"!=typeof a.querySelectorAll?a.querySelectorAll(b||"*"):void 0;if(!f)for(f=[],c=a.childNodes||a;null!=(d=c[e]);e++)!b||n.nodeName(d,b)?f.push(d):n.merge(f,ea(d,b));return void 0===b||b&&n.nodeName(a,b)?n.merge([a],f):f}function fa(a,b){for(var c,d=0;null!=(c=a[d]);d++)n._data(c,"globalEval",!b||n._data(b[d],"globalEval"))}var ga=/<|&#?\w+;/,ha=/<tbody/i;function ia(a){Z.test(a.type)&&(a.defaultChecked=a.checked)}function ja(a,b,c,d,e){for(var f,g,h,i,j,k,m,o=a.length,p=ca(b),q=[],r=0;o>r;r++)if(g=a[r],g||0===g)if("object"===n.type(g))n.merge(q,g.nodeType?[g]:g);else if(ga.test(g)){i=i||p.appendChild(b.createElement("div")),j=($.exec(g)||["",""])[1].toLowerCase(),m=da[j]||da._default,i.innerHTML=m[1]+n.htmlPrefilter(g)+m[2],f=m[0];while(f--)i=i.lastChild;if(!l.leadingWhitespace&&aa.test(g)&&q.push(b.createTextNode(aa.exec(g)[0])),!l.tbody){g="table"!==j||ha.test(g)?"<table>"!==m[1]||ha.test(g)?0:i:i.firstChild,f=g&&g.childNodes.length;while(f--)n.nodeName(k=g.childNodes[f],"tbody")&&!k.childNodes.length&&g.removeChild(k)}n.merge(q,i.childNodes),i.textContent="";while(i.firstChild)i.removeChild(i.firstChild);i=p.lastChild}else q.push(b.createTextNode(g));i&&p.removeChild(i),l.appendChecked||n.grep(ea(q,"input"),ia),r=0;while(g=q[r++])if(d&&n.inArray(g,d)>-1)e&&e.push(g);else if(h=n.contains(g.ownerDocument,g),i=ea(p.appendChild(g),"script"),h&&fa(i),c){f=0;while(g=i[f++])_.test(g.type||"")&&c.push(g)}return i=null,p}!function(){var b,c,e=d.createElement("div");for(b in{submit:!0,change:!0,focusin:!0})c="on"+b,(l[b]=c in a)||(e.setAttribute(c,"t"),l[b]=e.attributes[c].expando===!1);e=null}();var ka=/^(?:input|select|textarea)$/i,la=/^key/,ma=/^(?:mouse|pointer|contextmenu|drag|drop)|click/,na=/^(?:focusinfocus|focusoutblur)$/,oa=/^([^.]*)(?:\.(.+)|)/;function pa(){return!0}function qa(){return!1}function ra(){try{return d.activeElement}catch(a){}}function sa(a,b,c,d,e,f){var g,h;if("object"==typeof b){"string"!=typeof c&&(d=d||c,c=void 0);for(h in b)sa(a,h,c,d,b[h],f);return a}if(null==d&&null==e?(e=c,d=c=void 0):null==e&&("string"==typeof c?(e=d,d=void 0):(e=d,d=c,c=void 0)),e===!1)e=qa;else if(!e)return a;return 1===f&&(g=e,e=function(a){return n().off(a),g.apply(this,arguments)},e.guid=g.guid||(g.guid=n.guid++)),a.each(function(){n.event.add(this,b,e,d,c)})}n.event={global:{},add:function(a,b,c,d,e){var f,g,h,i,j,k,l,m,o,p,q,r=n._data(a);if(r){c.handler&&(i=c,c=i.handler,e=i.selector),c.guid||(c.guid=n.guid++),(g=r.events)||(g=r.events={}),(k=r.handle)||(k=r.handle=function(a){return"undefined"==typeof n||a&&n.event.triggered===a.type?void 0:n.event.dispatch.apply(k.elem,arguments)},k.elem=a),b=(b||"").match(G)||[""],h=b.length;while(h--)f=oa.exec(b[h])||[],o=q=f[1],p=(f[2]||"").split(".").sort(),o&&(j=n.event.special[o]||{},o=(e?j.delegateType:j.bindType)||o,j=n.event.special[o]||{},l=n.extend({type:o,origType:q,data:d,handler:c,guid:c.guid,selector:e,needsContext:e&&n.expr.match.needsContext.test(e),namespace:p.join(".")},i),(m=g[o])||(m=g[o]=[],m.delegateCount=0,j.setup&&j.setup.call(a,d,p,k)!==!1||(a.addEventListener?a.addEventListener(o,k,!1):a.attachEvent&&a.attachEvent("on"+o,k))),j.add&&(j.add.call(a,l),l.handler.guid||(l.handler.guid=c.guid)),e?m.splice(m.delegateCount++,0,l):m.push(l),n.event.global[o]=!0);a=null}},remove:function(a,b,c,d,e){var f,g,h,i,j,k,l,m,o,p,q,r=n.hasData(a)&&n._data(a);if(r&&(k=r.events)){b=(b||"").match(G)||[""],j=b.length;while(j--)if(h=oa.exec(b[j])||[],o=q=h[1],p=(h[2]||"").split(".").sort(),o){l=n.event.special[o]||{},o=(d?l.delegateType:l.bindType)||o,m=k[o]||[],h=h[2]&&new RegExp("(^|\\.)"+p.join("\\.(?:.*\\.|)")+"(\\.|$)"),i=f=m.length;while(f--)g=m[f],!e&&q!==g.origType||c&&c.guid!==g.guid||h&&!h.test(g.namespace)||d&&d!==g.selector&&("**"!==d||!g.selector)||(m.splice(f,1),g.selector&&m.delegateCount--,l.remove&&l.remove.call(a,g));i&&!m.length&&(l.teardown&&l.teardown.call(a,p,r.handle)!==!1||n.removeEvent(a,o,r.handle),delete k[o])}else for(o in k)n.event.remove(a,o+b[j],c,d,!0);n.isEmptyObject(k)&&(delete r.handle,n._removeData(a,"events"))}},trigger:function(b,c,e,f){var g,h,i,j,l,m,o,p=[e||d],q=k.call(b,"type")?b.type:b,r=k.call(b,"namespace")?b.namespace.split("."):[];if(i=m=e=e||d,3!==e.nodeType&&8!==e.nodeType&&!na.test(q+n.event.triggered)&&(q.indexOf(".")>-1&&(r=q.split("."),q=r.shift(),r.sort()),h=q.indexOf(":")<0&&"on"+q,b=b[n.expando]?b:new n.Event(q,"object"==typeof b&&b),b.isTrigger=f?2:3,b.namespace=r.join("."),b.rnamespace=b.namespace?new RegExp("(^|\\.)"+r.join("\\.(?:.*\\.|)")+"(\\.|$)"):null,b.result=void 0,b.target||(b.target=e),c=null==c?[b]:n.makeArray(c,[b]),l=n.event.special[q]||{},f||!l.trigger||l.trigger.apply(e,c)!==!1)){if(!f&&!l.noBubble&&!n.isWindow(e)){for(j=l.delegateType||q,na.test(j+q)||(i=i.parentNode);i;i=i.parentNode)p.push(i),m=i;m===(e.ownerDocument||d)&&p.push(m.defaultView||m.parentWindow||a)}o=0;while((i=p[o++])&&!b.isPropagationStopped())b.type=o>1?j:l.bindType||q,g=(n._data(i,"events")||{})[b.type]&&n._data(i,"handle"),g&&g.apply(i,c),g=h&&i[h],g&&g.apply&&M(i)&&(b.result=g.apply(i,c),b.result===!1&&b.preventDefault());if(b.type=q,!f&&!b.isDefaultPrevented()&&(!l._default||l._default.apply(p.pop(),c)===!1)&&M(e)&&h&&e[q]&&!n.isWindow(e)){m=e[h],m&&(e[h]=null),n.event.triggered=q;try{e[q]()}catch(s){}n.event.triggered=void 0,m&&(e[h]=m)}return b.result}},dispatch:function(a){a=n.event.fix(a);var b,c,d,f,g,h=[],i=e.call(arguments),j=(n._data(this,"events")||{})[a.type]||[],k=n.event.special[a.type]||{};if(i[0]=a,a.delegateTarget=this,!k.preDispatch||k.preDispatch.call(this,a)!==!1){h=n.event.handlers.call(this,a,j),b=0;while((f=h[b++])&&!a.isPropagationStopped()){a.currentTarget=f.elem,c=0;while((g=f.handlers[c++])&&!a.isImmediatePropagationStopped())a.rnamespace&&!a.rnamespace.test(g.namespace)||(a.handleObj=g,a.data=g.data,d=((n.event.special[g.origType]||{}).handle||g.handler).apply(f.elem,i),void 0!==d&&(a.result=d)===!1&&(a.preventDefault(),a.stopPropagation()))}return k.postDispatch&&k.postDispatch.call(this,a),a.result}},handlers:function(a,b){var c,d,e,f,g=[],h=b.delegateCount,i=a.target;if(h&&i.nodeType&&("click"!==a.type||isNaN(a.button)||a.button<1))for(;i!=this;i=i.parentNode||this)if(1===i.nodeType&&(i.disabled!==!0||"click"!==a.type)){for(d=[],c=0;h>c;c++)f=b[c],e=f.selector+" ",void 0===d[e]&&(d[e]=f.needsContext?n(e,this).index(i)>-1:n.find(e,this,null,[i]).length),d[e]&&d.push(f);d.length&&g.push({elem:i,handlers:d})}return h<b.length&&g.push({elem:this,handlers:b.slice(h)}),g},fix:function(a){if(a[n.expando])return a;var b,c,e,f=a.type,g=a,h=this.fixHooks[f];h||(this.fixHooks[f]=h=ma.test(f)?this.mouseHooks:la.test(f)?this.keyHooks:{}),e=h.props?this.props.concat(h.props):this.props,a=new n.Event(g),b=e.length;while(b--)c=e[b],a[c]=g[c];return a.target||(a.target=g.srcElement||d),3===a.target.nodeType&&(a.target=a.target.parentNode),a.metaKey=!!a.metaKey,h.filter?h.filter(a,g):a},props:"altKey bubbles cancelable ctrlKey currentTarget detail eventPhase metaKey relatedTarget shiftKey target timeStamp view which".split(" "),fixHooks:{},keyHooks:{props:"char charCode key keyCode".split(" "),filter:function(a,b){return null==a.which&&(a.which=null!=b.charCode?b.charCode:b.keyCode),a}},mouseHooks:{props:"button buttons clientX clientY fromElement offsetX offsetY pageX pageY screenX screenY toElement".split(" "),filter:function(a,b){var c,e,f,g=b.button,h=b.fromElement;return null==a.pageX&&null!=b.clientX&&(e=a.target.ownerDocument||d,f=e.documentElement,c=e.body,a.pageX=b.clientX+(f&&f.scrollLeft||c&&c.scrollLeft||0)-(f&&f.clientLeft||c&&c.clientLeft||0),a.pageY=b.clientY+(f&&f.scrollTop||c&&c.scrollTop||0)-(f&&f.clientTop||c&&c.clientTop||0)),!a.relatedTarget&&h&&(a.relatedTarget=h===a.target?b.toElement:h),a.which||void 0===g||(a.which=1&g?1:2&g?3:4&g?2:0),a}},special:{load:{noBubble:!0},focus:{trigger:function(){if(this!==ra()&&this.focus)try{return this.focus(),!1}catch(a){}},delegateType:"focusin"},blur:{trigger:function(){return this===ra()&&this.blur?(this.blur(),!1):void 0},delegateType:"focusout"},click:{trigger:function(){return n.nodeName(this,"input")&&"checkbox"===this.type&&this.click?(this.click(),!1):void 0},_default:function(a){return n.nodeName(a.target,"a")}},beforeunload:{postDispatch:function(a){void 0!==a.result&&a.originalEvent&&(a.originalEvent.returnValue=a.result)}}},simulate:function(a,b,c){var d=n.extend(new n.Event,c,{type:a,isSimulated:!0});n.event.trigger(d,null,b),d.isDefaultPrevented()&&c.preventDefault()}},n.removeEvent=d.removeEventListener?function(a,b,c){a.removeEventListener&&a.removeEventListener(b,c)}:function(a,b,c){var d="on"+b;a.detachEvent&&("undefined"==typeof a[d]&&(a[d]=null),a.detachEvent(d,c))},n.Event=function(a,b){return this instanceof n.Event?(a&&a.type?(this.originalEvent=a,this.type=a.type,this.isDefaultPrevented=a.defaultPrevented||void 0===a.defaultPrevented&&a.returnValue===!1?pa:qa):this.type=a,b&&n.extend(this,b),this.timeStamp=a&&a.timeStamp||n.now(),void(this[n.expando]=!0)):new n.Event(a,b)},n.Event.prototype={constructor:n.Event,isDefaultPrevented:qa,isPropagationStopped:qa,isImmediatePropagationStopped:qa,preventDefault:function(){var a=this.originalEvent;this.isDefaultPrevented=pa,a&&(a.preventDefault?a.preventDefault():a.returnValue=!1)},stopPropagation:function(){var a=this.originalEvent;this.isPropagationStopped=pa,a&&!this.isSimulated&&(a.stopPropagation&&a.stopPropagation(),a.cancelBubble=!0)},stopImmediatePropagation:function(){var a=this.originalEvent;this.isImmediatePropagationStopped=pa,a&&a.stopImmediatePropagation&&a.stopImmediatePropagation(),this.stopPropagation()}},n.each({mouseenter:"mouseover",mouseleave:"mouseout",pointerenter:"pointerover",pointerleave:"pointerout"},function(a,b){n.event.special[a]={delegateType:b,bindType:b,handle:function(a){var c,d=this,e=a.relatedTarget,f=a.handleObj;return e&&(e===d||n.contains(d,e))||(a.type=f.origType,c=f.handler.apply(this,arguments),a.type=b),c}}}),l.submit||(n.event.special.submit={setup:function(){return n.nodeName(this,"form")?!1:void n.event.add(this,"click._submit keypress._submit",function(a){var b=a.target,c=n.nodeName(b,"input")||n.nodeName(b,"button")?n.prop(b,"form"):void 0;c&&!n._data(c,"submit")&&(n.event.add(c,"submit._submit",function(a){a._submitBubble=!0}),n._data(c,"submit",!0))})},postDispatch:function(a){a._submitBubble&&(delete a._submitBubble,this.parentNode&&!a.isTrigger&&n.event.simulate("submit",this.parentNode,a))},teardown:function(){return n.nodeName(this,"form")?!1:void n.event.remove(this,"._submit")}}),l.change||(n.event.special.change={setup:function(){return ka.test(this.nodeName)?("checkbox"!==this.type&&"radio"!==this.type||(n.event.add(this,"propertychange._change",function(a){"checked"===a.originalEvent.propertyName&&(this._justChanged=!0)}),n.event.add(this,"click._change",function(a){this._justChanged&&!a.isTrigger&&(this._justChanged=!1),n.event.simulate("change",this,a)})),!1):void n.event.add(this,"beforeactivate._change",function(a){var b=a.target;ka.test(b.nodeName)&&!n._data(b,"change")&&(n.event.add(b,"change._change",function(a){!this.parentNode||a.isSimulated||a.isTrigger||n.event.simulate("change",this.parentNode,a)}),n._data(b,"change",!0))})},handle:function(a){var b=a.target;return this!==b||a.isSimulated||a.isTrigger||"radio"!==b.type&&"checkbox"!==b.type?a.handleObj.handler.apply(this,arguments):void 0},teardown:function(){return n.event.remove(this,"._change"),!ka.test(this.nodeName)}}),l.focusin||n.each({focus:"focusin",blur:"focusout"},function(a,b){var c=function(a){n.event.simulate(b,a.target,n.event.fix(a))};n.event.special[b]={setup:function(){var d=this.ownerDocument||this,e=n._data(d,b);e||d.addEventListener(a,c,!0),n._data(d,b,(e||0)+1)},teardown:function(){var d=this.ownerDocument||this,e=n._data(d,b)-1;e?n._data(d,b,e):(d.removeEventListener(a,c,!0),n._removeData(d,b))}}}),n.fn.extend({on:function(a,b,c,d){return sa(this,a,b,c,d)},one:function(a,b,c,d){return sa(this,a,b,c,d,1)},off:function(a,b,c){var d,e;if(a&&a.preventDefault&&a.handleObj)return d=a.handleObj,n(a.delegateTarget).off(d.namespace?d.origType+"."+d.namespace:d.origType,d.selector,d.handler),this;if("object"==typeof a){for(e in a)this.off(e,b,a[e]);return this}return b!==!1&&"function"!=typeof b||(c=b,b=void 0),c===!1&&(c=qa),this.each(function(){n.event.remove(this,a,c,b)})},trigger:function(a,b){return this.each(function(){n.event.trigger(a,b,this)})},triggerHandler:function(a,b){var c=this[0];return c?n.event.trigger(a,b,c,!0):void 0}});var ta=/ jQuery\d+="(?:null|\d+)"/g,ua=new RegExp("<(?:"+ba+")[\\s/>]","i"),va=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:-]+)[^>]*)\/>/gi,wa=/<script|<style|<link/i,xa=/checked\s*(?:[^=]|=\s*.checked.)/i,ya=/^true\/(.*)/,za=/^\s*<!(?:\[CDATA\[|--)|(?:\]\]|--)>\s*$/g,Aa=ca(d),Ba=Aa.appendChild(d.createElement("div"));function Ca(a,b){return n.nodeName(a,"table")&&n.nodeName(11!==b.nodeType?b:b.firstChild,"tr")?a.getElementsByTagName("tbody")[0]||a.appendChild(a.ownerDocument.createElement("tbody")):a}function Da(a){return a.type=(null!==n.find.attr(a,"type"))+"/"+a.type,a}function Ea(a){var b=ya.exec(a.type);return b?a.type=b[1]:a.removeAttribute("type"),a}function Fa(a,b){if(1===b.nodeType&&n.hasData(a)){var c,d,e,f=n._data(a),g=n._data(b,f),h=f.events;if(h){delete g.handle,g.events={};for(c in h)for(d=0,e=h[c].length;e>d;d++)n.event.add(b,c,h[c][d])}g.data&&(g.data=n.extend({},g.data))}}function Ga(a,b){var c,d,e;if(1===b.nodeType){if(c=b.nodeName.toLowerCase(),!l.noCloneEvent&&b[n.expando]){e=n._data(b);for(d in e.events)n.removeEvent(b,d,e.handle);b.removeAttribute(n.expando)}"script"===c&&b.text!==a.text?(Da(b).text=a.text,Ea(b)):"object"===c?(b.parentNode&&(b.outerHTML=a.outerHTML),l.html5Clone&&a.innerHTML&&!n.trim(b.innerHTML)&&(b.innerHTML=a.innerHTML)):"input"===c&&Z.test(a.type)?(b.defaultChecked=b.checked=a.checked,b.value!==a.value&&(b.value=a.value)):"option"===c?b.defaultSelected=b.selected=a.defaultSelected:"input"!==c&&"textarea"!==c||(b.defaultValue=a.defaultValue)}}function Ha(a,b,c,d){b=f.apply([],b);var e,g,h,i,j,k,m=0,o=a.length,p=o-1,q=b[0],r=n.isFunction(q);if(r||o>1&&"string"==typeof q&&!l.checkClone&&xa.test(q))return a.each(function(e){var f=a.eq(e);r&&(b[0]=q.call(this,e,f.html())),Ha(f,b,c,d)});if(o&&(k=ja(b,a[0].ownerDocument,!1,a,d),e=k.firstChild,1===k.childNodes.length&&(k=e),e||d)){for(i=n.map(ea(k,"script"),Da),h=i.length;o>m;m++)g=k,m!==p&&(g=n.clone(g,!0,!0),h&&n.merge(i,ea(g,"script"))),c.call(a[m],g,m);if(h)for(j=i[i.length-1].ownerDocument,n.map(i,Ea),m=0;h>m;m++)g=i[m],_.test(g.type||"")&&!n._data(g,"globalEval")&&n.contains(j,g)&&(g.src?n._evalUrl&&n._evalUrl(g.src):n.globalEval((g.text||g.textContent||g.innerHTML||"").replace(za,"")));k=e=null}return a}function Ia(a,b,c){for(var d,e=b?n.filter(b,a):a,f=0;null!=(d=e[f]);f++)c||1!==d.nodeType||n.cleanData(ea(d)),d.parentNode&&(c&&n.contains(d.ownerDocument,d)&&fa(ea(d,"script")),d.parentNode.removeChild(d));return a}n.extend({htmlPrefilter:function(a){return a.replace(va,"<$1></$2>")},clone:function(a,b,c){var d,e,f,g,h,i=n.contains(a.ownerDocument,a);if(l.html5Clone||n.isXMLDoc(a)||!ua.test("<"+a.nodeName+">")?f=a.cloneNode(!0):(Ba.innerHTML=a.outerHTML,Ba.removeChild(f=Ba.firstChild)),!(l.noCloneEvent&&l.noCloneChecked||1!==a.nodeType&&11!==a.nodeType||n.isXMLDoc(a)))for(d=ea(f),h=ea(a),g=0;null!=(e=h[g]);++g)d[g]&&Ga(e,d[g]);if(b)if(c)for(h=h||ea(a),d=d||ea(f),g=0;null!=(e=h[g]);g++)Fa(e,d[g]);else Fa(a,f);return d=ea(f,"script"),d.length>0&&fa(d,!i&&ea(a,"script")),d=h=e=null,f},cleanData:function(a,b){for(var d,e,f,g,h=0,i=n.expando,j=n.cache,k=l.attributes,m=n.event.special;null!=(d=a[h]);h++)if((b||M(d))&&(f=d[i],g=f&&j[f])){if(g.events)for(e in g.events)m[e]?n.event.remove(d,e):n.removeEvent(d,e,g.handle);j[f]&&(delete j[f],k||"undefined"==typeof d.removeAttribute?d[i]=void 0:d.removeAttribute(i),c.push(f))}}}),n.fn.extend({domManip:Ha,detach:function(a){return Ia(this,a,!0)},remove:function(a){return Ia(this,a)},text:function(a){return Y(this,function(a){return void 0===a?n.text(this):this.empty().append((this[0]&&this[0].ownerDocument||d).createTextNode(a))},null,a,arguments.length)},append:function(){return Ha(this,arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=Ca(this,a);b.appendChild(a)}})},prepend:function(){return Ha(this,arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=Ca(this,a);b.insertBefore(a,b.firstChild)}})},before:function(){return Ha(this,arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this)})},after:function(){return Ha(this,arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this.nextSibling)})},empty:function(){for(var a,b=0;null!=(a=this[b]);b++){1===a.nodeType&&n.cleanData(ea(a,!1));while(a.firstChild)a.removeChild(a.firstChild);a.options&&n.nodeName(a,"select")&&(a.options.length=0)}return this},clone:function(a,b){return a=null==a?!1:a,b=null==b?a:b,this.map(function(){return n.clone(this,a,b)})},html:function(a){return Y(this,function(a){var b=this[0]||{},c=0,d=this.length;if(void 0===a)return 1===b.nodeType?b.innerHTML.replace(ta,""):void 0;if("string"==typeof a&&!wa.test(a)&&(l.htmlSerialize||!ua.test(a))&&(l.leadingWhitespace||!aa.test(a))&&!da[($.exec(a)||["",""])[1].toLowerCase()]){a=n.htmlPrefilter(a);try{for(;d>c;c++)b=this[c]||{},1===b.nodeType&&(n.cleanData(ea(b,!1)),b.innerHTML=a);b=0}catch(e){}}b&&this.empty().append(a)},null,a,arguments.length)},replaceWith:function(){var a=[];return Ha(this,arguments,function(b){var c=this.parentNode;n.inArray(this,a)<0&&(n.cleanData(ea(this)),c&&c.replaceChild(b,this))},a)}}),n.each({appendTo:"append",prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){n.fn[a]=function(a){for(var c,d=0,e=[],f=n(a),h=f.length-1;h>=d;d++)c=d===h?this:this.clone(!0),n(f[d])[b](c),g.apply(e,c.get());return this.pushStack(e)}});var Ja,Ka={HTML:"block",BODY:"block"};function La(a,b){var c=n(b.createElement(a)).appendTo(b.body),d=n.css(c[0],"display");return c.detach(),d}function Ma(a){var b=d,c=Ka[a];return c||(c=La(a,b),"none"!==c&&c||(Ja=(Ja||n("<iframe frameborder='0' width='0' height='0'/>")).appendTo(b.documentElement),b=(Ja[0].contentWindow||Ja[0].contentDocument).document,b.write(),b.close(),c=La(a,b),Ja.detach()),Ka[a]=c),c}var Na=/^margin/,Oa=new RegExp("^("+T+")(?!px)[a-z%]+$","i"),Pa=function(a,b,c,d){var e,f,g={};for(f in b)g[f]=a.style[f],a.style[f]=b[f];e=c.apply(a,d||[]);for(f in b)a.style[f]=g[f];return e},Qa=d.documentElement;!function(){var b,c,e,f,g,h,i=d.createElement("div"),j=d.createElement("div");if(j.style){j.style.cssText="float:left;opacity:.5",l.opacity="0.5"===j.style.opacity,l.cssFloat=!!j.style.cssFloat,j.style.backgroundClip="content-box",j.cloneNode(!0).style.backgroundClip="",l.clearCloneStyle="content-box"===j.style.backgroundClip,i=d.createElement("div"),i.style.cssText="border:0;width:8px;height:0;top:0;left:-9999px;padding:0;margin-top:1px;position:absolute",j.innerHTML="",i.appendChild(j),l.boxSizing=""===j.style.boxSizing||""===j.style.MozBoxSizing||""===j.style.WebkitBoxSizing,n.extend(l,{reliableHiddenOffsets:function(){return null==b&&k(),f},boxSizingReliable:function(){return null==b&&k(),e},pixelMarginRight:function(){return null==b&&k(),c},pixelPosition:function(){return null==b&&k(),b},reliableMarginRight:function(){return null==b&&k(),g},reliableMarginLeft:function(){return null==b&&k(),h}});function k(){var k,l,m=d.documentElement;m.appendChild(i),j.style.cssText="-webkit-box-sizing:border-box;box-sizing:border-box;position:relative;display:block;margin:auto;border:1px;padding:1px;top:1%;width:50%",b=e=h=!1,c=g=!0,a.getComputedStyle&&(l=a.getComputedStyle(j),b="1%"!==(l||{}).top,h="2px"===(l||{}).marginLeft,e="4px"===(l||{width:"4px"}).width,j.style.marginRight="50%",c="4px"===(l||{marginRight:"4px"}).marginRight,k=j.appendChild(d.createElement("div")),k.style.cssText=j.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:0",k.style.marginRight=k.style.width="0",j.style.width="1px",g=!parseFloat((a.getComputedStyle(k)||{}).marginRight),j.removeChild(k)),j.style.display="none",f=0===j.getClientRects().length,f&&(j.style.display="",j.innerHTML="<table><tr><td></td><td>t</td></tr></table>",k=j.getElementsByTagName("td"),k[0].style.cssText="margin:0;border:0;padding:0;display:none",f=0===k[0].offsetHeight,f&&(k[0].style.display="",k[1].style.display="none",f=0===k[0].offsetHeight)),m.removeChild(i)}}}();var Ra,Sa,Ta=/^(top|right|bottom|left)$/;a.getComputedStyle?(Ra=function(b){var c=b.ownerDocument.defaultView;return c&&c.opener||(c=a),c.getComputedStyle(b)},Sa=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ra(a),g=c?c.getPropertyValue(b)||c[b]:void 0,""!==g&&void 0!==g||n.contains(a.ownerDocument,a)||(g=n.style(a,b)),c&&!l.pixelMarginRight()&&Oa.test(g)&&Na.test(b)&&(d=h.width,e=h.minWidth,f=h.maxWidth,h.minWidth=h.maxWidth=h.width=g,g=c.width,h.width=d,h.minWidth=e,h.maxWidth=f),void 0===g?g:g+""}):Qa.currentStyle&&(Ra=function(a){return a.currentStyle},Sa=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ra(a),g=c?c[b]:void 0,null==g&&h&&h[b]&&(g=h[b]),Oa.test(g)&&!Ta.test(b)&&(d=h.left,e=a.runtimeStyle,f=e&&e.left,f&&(e.left=a.currentStyle.left),h.left="fontSize"===b?"1em":g,g=h.pixelLeft+"px",h.left=d,f&&(e.left=f)),void 0===g?g:g+""||"auto"});function Ua(a,b){return{get:function(){return a()?void delete this.get:(this.get=b).apply(this,arguments)}}}var Va=/alpha\([^)]*\)/i,Wa=/opacity\s*=\s*([^)]*)/i,Xa=/^(none|table(?!-c[ea]).+)/,Ya=new RegExp("^("+T+")(.*)$","i"),Za={position:"absolute",visibility:"hidden",display:"block"},$a={letterSpacing:"0",fontWeight:"400"},_a=["Webkit","O","Moz","ms"],ab=d.createElement("div").style;function bb(a){if(a in ab)return a;var b=a.charAt(0).toUpperCase()+a.slice(1),c=_a.length;while(c--)if(a=_a[c]+b,a in ab)return a}function cb(a,b){for(var c,d,e,f=[],g=0,h=a.length;h>g;g++)d=a[g],d.style&&(f[g]=n._data(d,"olddisplay"),c=d.style.display,b?(f[g]||"none"!==c||(d.style.display=""),""===d.style.display&&W(d)&&(f[g]=n._data(d,"olddisplay",Ma(d.nodeName)))):(e=W(d),(c&&"none"!==c||!e)&&n._data(d,"olddisplay",e?c:n.css(d,"display"))));for(g=0;h>g;g++)d=a[g],d.style&&(b&&"none"!==d.style.display&&""!==d.style.display||(d.style.display=b?f[g]||"":"none"));return a}function db(a,b,c){var d=Ya.exec(b);return d?Math.max(0,d[1]-(c||0))+(d[2]||"px"):b}function eb(a,b,c,d,e){for(var f=c===(d?"border":"content")?4:"width"===b?1:0,g=0;4>f;f+=2)"margin"===c&&(g+=n.css(a,c+V[f],!0,e)),d?("content"===c&&(g-=n.css(a,"padding"+V[f],!0,e)),"margin"!==c&&(g-=n.css(a,"border"+V[f]+"Width",!0,e))):(g+=n.css(a,"padding"+V[f],!0,e),"padding"!==c&&(g+=n.css(a,"border"+V[f]+"Width",!0,e)));return g}function fb(b,c,e){var f=!0,g="width"===c?b.offsetWidth:b.offsetHeight,h=Ra(b),i=l.boxSizing&&"border-box"===n.css(b,"boxSizing",!1,h);if(d.msFullscreenElement&&a.top!==a&&b.getClientRects().length&&(g=Math.round(100*b.getBoundingClientRect()[c])),0>=g||null==g){if(g=Sa(b,c,h),(0>g||null==g)&&(g=b.style[c]),Oa.test(g))return g;f=i&&(l.boxSizingReliable()||g===b.style[c]),g=parseFloat(g)||0}return g+eb(b,c,e||(i?"border":"content"),f,h)+"px"}n.extend({cssHooks:{opacity:{get:function(a,b){if(b){var c=Sa(a,"opacity");return""===c?"1":c}}}},cssNumber:{animationIterationCount:!0,columnCount:!0,fillOpacity:!0,flexGrow:!0,flexShrink:!0,fontWeight:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{"float":l.cssFloat?"cssFloat":"styleFloat"},style:function(a,b,c,d){if(a&&3!==a.nodeType&&8!==a.nodeType&&a.style){var e,f,g,h=n.camelCase(b),i=a.style;if(b=n.cssProps[h]||(n.cssProps[h]=bb(h)||h),g=n.cssHooks[b]||n.cssHooks[h],void 0===c)return g&&"get"in g&&void 0!==(e=g.get(a,!1,d))?e:i[b];if(f=typeof c,"string"===f&&(e=U.exec(c))&&e[1]&&(c=X(a,b,e),f="number"),null!=c&&c===c&&("number"===f&&(c+=e&&e[3]||(n.cssNumber[h]?"":"px")),l.clearCloneStyle||""!==c||0!==b.indexOf("background")||(i[b]="inherit"),!(g&&"set"in g&&void 0===(c=g.set(a,c,d)))))try{i[b]=c}catch(j){}}},css:function(a,b,c,d){var e,f,g,h=n.camelCase(b);return b=n.cssProps[h]||(n.cssProps[h]=bb(h)||h),g=n.cssHooks[b]||n.cssHooks[h],g&&"get"in g&&(f=g.get(a,!0,c)),void 0===f&&(f=Sa(a,b,d)),"normal"===f&&b in $a&&(f=$a[b]),""===c||c?(e=parseFloat(f),c===!0||isFinite(e)?e||0:f):f}}),n.each(["height","width"],function(a,b){n.cssHooks[b]={get:function(a,c,d){return c?Xa.test(n.css(a,"display"))&&0===a.offsetWidth?Pa(a,Za,function(){return fb(a,b,d)}):fb(a,b,d):void 0},set:function(a,c,d){var e=d&&Ra(a);return db(a,c,d?eb(a,b,d,l.boxSizing&&"border-box"===n.css(a,"boxSizing",!1,e),e):0)}}}),l.opacity||(n.cssHooks.opacity={get:function(a,b){return Wa.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?.01*parseFloat(RegExp.$1)+"":b?"1":""},set:function(a,b){var c=a.style,d=a.currentStyle,e=n.isNumeric(b)?"alpha(opacity="+100*b+")":"",f=d&&d.filter||c.filter||"";c.zoom=1,(b>=1||""===b)&&""===n.trim(f.replace(Va,""))&&c.removeAttribute&&(c.removeAttribute("filter"),""===b||d&&!d.filter)||(c.filter=Va.test(f)?f.replace(Va,e):f+" "+e)}}),n.cssHooks.marginRight=Ua(l.reliableMarginRight,function(a,b){return b?Pa(a,{display:"inline-block"},Sa,[a,"marginRight"]):void 0}),n.cssHooks.marginLeft=Ua(l.reliableMarginLeft,function(a,b){
return b?(parseFloat(Sa(a,"marginLeft"))||(n.contains(a.ownerDocument,a)?a.getBoundingClientRect().left-Pa(a,{marginLeft:0},function(){return a.getBoundingClientRect().left}):0))+"px":void 0}),n.each({margin:"",padding:"",border:"Width"},function(a,b){n.cssHooks[a+b]={expand:function(c){for(var d=0,e={},f="string"==typeof c?c.split(" "):[c];4>d;d++)e[a+V[d]+b]=f[d]||f[d-2]||f[0];return e}},Na.test(a)||(n.cssHooks[a+b].set=db)}),n.fn.extend({css:function(a,b){return Y(this,function(a,b,c){var d,e,f={},g=0;if(n.isArray(b)){for(d=Ra(a),e=b.length;e>g;g++)f[b[g]]=n.css(a,b[g],!1,d);return f}return void 0!==c?n.style(a,b,c):n.css(a,b)},a,b,arguments.length>1)},show:function(){return cb(this,!0)},hide:function(){return cb(this)},toggle:function(a){return"boolean"==typeof a?a?this.show():this.hide():this.each(function(){W(this)?n(this).show():n(this).hide()})}});function gb(a,b,c,d,e){return new gb.prototype.init(a,b,c,d,e)}n.Tween=gb,gb.prototype={constructor:gb,init:function(a,b,c,d,e,f){this.elem=a,this.prop=c,this.easing=e||n.easing._default,this.options=b,this.start=this.now=this.cur(),this.end=d,this.unit=f||(n.cssNumber[c]?"":"px")},cur:function(){var a=gb.propHooks[this.prop];return a&&a.get?a.get(this):gb.propHooks._default.get(this)},run:function(a){var b,c=gb.propHooks[this.prop];return this.options.duration?this.pos=b=n.easing[this.easing](a,this.options.duration*a,0,1,this.options.duration):this.pos=b=a,this.now=(this.end-this.start)*b+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),c&&c.set?c.set(this):gb.propHooks._default.set(this),this}},gb.prototype.init.prototype=gb.prototype,gb.propHooks={_default:{get:function(a){var b;return 1!==a.elem.nodeType||null!=a.elem[a.prop]&&null==a.elem.style[a.prop]?a.elem[a.prop]:(b=n.css(a.elem,a.prop,""),b&&"auto"!==b?b:0)},set:function(a){n.fx.step[a.prop]?n.fx.step[a.prop](a):1!==a.elem.nodeType||null==a.elem.style[n.cssProps[a.prop]]&&!n.cssHooks[a.prop]?a.elem[a.prop]=a.now:n.style(a.elem,a.prop,a.now+a.unit)}}},gb.propHooks.scrollTop=gb.propHooks.scrollLeft={set:function(a){a.elem.nodeType&&a.elem.parentNode&&(a.elem[a.prop]=a.now)}},n.easing={linear:function(a){return a},swing:function(a){return.5-Math.cos(a*Math.PI)/2},_default:"swing"},n.fx=gb.prototype.init,n.fx.step={};var hb,ib,jb=/^(?:toggle|show|hide)$/,kb=/queueHooks$/;function lb(){return a.setTimeout(function(){hb=void 0}),hb=n.now()}function mb(a,b){var c,d={height:a},e=0;for(b=b?1:0;4>e;e+=2-b)c=V[e],d["margin"+c]=d["padding"+c]=a;return b&&(d.opacity=d.width=a),d}function nb(a,b,c){for(var d,e=(qb.tweeners[b]||[]).concat(qb.tweeners["*"]),f=0,g=e.length;g>f;f++)if(d=e[f].call(c,b,a))return d}function ob(a,b,c){var d,e,f,g,h,i,j,k,m=this,o={},p=a.style,q=a.nodeType&&W(a),r=n._data(a,"fxshow");c.queue||(h=n._queueHooks(a,"fx"),null==h.unqueued&&(h.unqueued=0,i=h.empty.fire,h.empty.fire=function(){h.unqueued||i()}),h.unqueued++,m.always(function(){m.always(function(){h.unqueued--,n.queue(a,"fx").length||h.empty.fire()})})),1===a.nodeType&&("height"in b||"width"in b)&&(c.overflow=[p.overflow,p.overflowX,p.overflowY],j=n.css(a,"display"),k="none"===j?n._data(a,"olddisplay")||Ma(a.nodeName):j,"inline"===k&&"none"===n.css(a,"float")&&(l.inlineBlockNeedsLayout&&"inline"!==Ma(a.nodeName)?p.zoom=1:p.display="inline-block")),c.overflow&&(p.overflow="hidden",l.shrinkWrapBlocks()||m.always(function(){p.overflow=c.overflow[0],p.overflowX=c.overflow[1],p.overflowY=c.overflow[2]}));for(d in b)if(e=b[d],jb.exec(e)){if(delete b[d],f=f||"toggle"===e,e===(q?"hide":"show")){if("show"!==e||!r||void 0===r[d])continue;q=!0}o[d]=r&&r[d]||n.style(a,d)}else j=void 0;if(n.isEmptyObject(o))"inline"===("none"===j?Ma(a.nodeName):j)&&(p.display=j);else{r?"hidden"in r&&(q=r.hidden):r=n._data(a,"fxshow",{}),f&&(r.hidden=!q),q?n(a).show():m.done(function(){n(a).hide()}),m.done(function(){var b;n._removeData(a,"fxshow");for(b in o)n.style(a,b,o[b])});for(d in o)g=nb(q?r[d]:0,d,m),d in r||(r[d]=g.start,q&&(g.end=g.start,g.start="width"===d||"height"===d?1:0))}}function pb(a,b){var c,d,e,f,g;for(c in a)if(d=n.camelCase(c),e=b[d],f=a[c],n.isArray(f)&&(e=f[1],f=a[c]=f[0]),c!==d&&(a[d]=f,delete a[c]),g=n.cssHooks[d],g&&"expand"in g){f=g.expand(f),delete a[d];for(c in f)c in a||(a[c]=f[c],b[c]=e)}else b[d]=e}function qb(a,b,c){var d,e,f=0,g=qb.prefilters.length,h=n.Deferred().always(function(){delete i.elem}),i=function(){if(e)return!1;for(var b=hb||lb(),c=Math.max(0,j.startTime+j.duration-b),d=c/j.duration||0,f=1-d,g=0,i=j.tweens.length;i>g;g++)j.tweens[g].run(f);return h.notifyWith(a,[j,f,c]),1>f&&i?c:(h.resolveWith(a,[j]),!1)},j=h.promise({elem:a,props:n.extend({},b),opts:n.extend(!0,{specialEasing:{},easing:n.easing._default},c),originalProperties:b,originalOptions:c,startTime:hb||lb(),duration:c.duration,tweens:[],createTween:function(b,c){var d=n.Tween(a,j.opts,b,c,j.opts.specialEasing[b]||j.opts.easing);return j.tweens.push(d),d},stop:function(b){var c=0,d=b?j.tweens.length:0;if(e)return this;for(e=!0;d>c;c++)j.tweens[c].run(1);return b?(h.notifyWith(a,[j,1,0]),h.resolveWith(a,[j,b])):h.rejectWith(a,[j,b]),this}}),k=j.props;for(pb(k,j.opts.specialEasing);g>f;f++)if(d=qb.prefilters[f].call(j,a,k,j.opts))return n.isFunction(d.stop)&&(n._queueHooks(j.elem,j.opts.queue).stop=n.proxy(d.stop,d)),d;return n.map(k,nb,j),n.isFunction(j.opts.start)&&j.opts.start.call(a,j),n.fx.timer(n.extend(i,{elem:a,anim:j,queue:j.opts.queue})),j.progress(j.opts.progress).done(j.opts.done,j.opts.complete).fail(j.opts.fail).always(j.opts.always)}n.Animation=n.extend(qb,{tweeners:{"*":[function(a,b){var c=this.createTween(a,b);return X(c.elem,a,U.exec(b),c),c}]},tweener:function(a,b){n.isFunction(a)?(b=a,a=["*"]):a=a.match(G);for(var c,d=0,e=a.length;e>d;d++)c=a[d],qb.tweeners[c]=qb.tweeners[c]||[],qb.tweeners[c].unshift(b)},prefilters:[ob],prefilter:function(a,b){b?qb.prefilters.unshift(a):qb.prefilters.push(a)}}),n.speed=function(a,b,c){var d=a&&"object"==typeof a?n.extend({},a):{complete:c||!c&&b||n.isFunction(a)&&a,duration:a,easing:c&&b||b&&!n.isFunction(b)&&b};return d.duration=n.fx.off?0:"number"==typeof d.duration?d.duration:d.duration in n.fx.speeds?n.fx.speeds[d.duration]:n.fx.speeds._default,null!=d.queue&&d.queue!==!0||(d.queue="fx"),d.old=d.complete,d.complete=function(){n.isFunction(d.old)&&d.old.call(this),d.queue&&n.dequeue(this,d.queue)},d},n.fn.extend({fadeTo:function(a,b,c,d){return this.filter(W).css("opacity",0).show().end().animate({opacity:b},a,c,d)},animate:function(a,b,c,d){var e=n.isEmptyObject(a),f=n.speed(b,c,d),g=function(){var b=qb(this,n.extend({},a),f);(e||n._data(this,"finish"))&&b.stop(!0)};return g.finish=g,e||f.queue===!1?this.each(g):this.queue(f.queue,g)},stop:function(a,b,c){var d=function(a){var b=a.stop;delete a.stop,b(c)};return"string"!=typeof a&&(c=b,b=a,a=void 0),b&&a!==!1&&this.queue(a||"fx",[]),this.each(function(){var b=!0,e=null!=a&&a+"queueHooks",f=n.timers,g=n._data(this);if(e)g[e]&&g[e].stop&&d(g[e]);else for(e in g)g[e]&&g[e].stop&&kb.test(e)&&d(g[e]);for(e=f.length;e--;)f[e].elem!==this||null!=a&&f[e].queue!==a||(f[e].anim.stop(c),b=!1,f.splice(e,1));!b&&c||n.dequeue(this,a)})},finish:function(a){return a!==!1&&(a=a||"fx"),this.each(function(){var b,c=n._data(this),d=c[a+"queue"],e=c[a+"queueHooks"],f=n.timers,g=d?d.length:0;for(c.finish=!0,n.queue(this,a,[]),e&&e.stop&&e.stop.call(this,!0),b=f.length;b--;)f[b].elem===this&&f[b].queue===a&&(f[b].anim.stop(!0),f.splice(b,1));for(b=0;g>b;b++)d[b]&&d[b].finish&&d[b].finish.call(this);delete c.finish})}}),n.each(["toggle","show","hide"],function(a,b){var c=n.fn[b];n.fn[b]=function(a,d,e){return null==a||"boolean"==typeof a?c.apply(this,arguments):this.animate(mb(b,!0),a,d,e)}}),n.each({slideDown:mb("show"),slideUp:mb("hide"),slideToggle:mb("toggle"),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){n.fn[a]=function(a,c,d){return this.animate(b,a,c,d)}}),n.timers=[],n.fx.tick=function(){var a,b=n.timers,c=0;for(hb=n.now();c<b.length;c++)a=b[c],a()||b[c]!==a||b.splice(c--,1);b.length||n.fx.stop(),hb=void 0},n.fx.timer=function(a){n.timers.push(a),a()?n.fx.start():n.timers.pop()},n.fx.interval=13,n.fx.start=function(){ib||(ib=a.setInterval(n.fx.tick,n.fx.interval))},n.fx.stop=function(){a.clearInterval(ib),ib=null},n.fx.speeds={slow:600,fast:200,_default:400},n.fn.delay=function(b,c){return b=n.fx?n.fx.speeds[b]||b:b,c=c||"fx",this.queue(c,function(c,d){var e=a.setTimeout(c,b);d.stop=function(){a.clearTimeout(e)}})},function(){var a,b=d.createElement("input"),c=d.createElement("div"),e=d.createElement("select"),f=e.appendChild(d.createElement("option"));c=d.createElement("div"),c.setAttribute("className","t"),c.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",a=c.getElementsByTagName("a")[0],b.setAttribute("type","checkbox"),c.appendChild(b),a=c.getElementsByTagName("a")[0],a.style.cssText="top:1px",l.getSetAttribute="t"!==c.className,l.style=/top/.test(a.getAttribute("style")),l.hrefNormalized="/a"===a.getAttribute("href"),l.checkOn=!!b.value,l.optSelected=f.selected,l.enctype=!!d.createElement("form").enctype,e.disabled=!0,l.optDisabled=!f.disabled,b=d.createElement("input"),b.setAttribute("value",""),l.input=""===b.getAttribute("value"),b.value="t",b.setAttribute("type","radio"),l.radioValue="t"===b.value}();var rb=/\r/g,sb=/[\x20\t\r\n\f]+/g;n.fn.extend({val:function(a){var b,c,d,e=this[0];{if(arguments.length)return d=n.isFunction(a),this.each(function(c){var e;1===this.nodeType&&(e=d?a.call(this,c,n(this).val()):a,null==e?e="":"number"==typeof e?e+="":n.isArray(e)&&(e=n.map(e,function(a){return null==a?"":a+""})),b=n.valHooks[this.type]||n.valHooks[this.nodeName.toLowerCase()],b&&"set"in b&&void 0!==b.set(this,e,"value")||(this.value=e))});if(e)return b=n.valHooks[e.type]||n.valHooks[e.nodeName.toLowerCase()],b&&"get"in b&&void 0!==(c=b.get(e,"value"))?c:(c=e.value,"string"==typeof c?c.replace(rb,""):null==c?"":c)}}}),n.extend({valHooks:{option:{get:function(a){var b=n.find.attr(a,"value");return null!=b?b:n.trim(n.text(a)).replace(sb," ")}},select:{get:function(a){for(var b,c,d=a.options,e=a.selectedIndex,f="select-one"===a.type||0>e,g=f?null:[],h=f?e+1:d.length,i=0>e?h:f?e:0;h>i;i++)if(c=d[i],(c.selected||i===e)&&(l.optDisabled?!c.disabled:null===c.getAttribute("disabled"))&&(!c.parentNode.disabled||!n.nodeName(c.parentNode,"optgroup"))){if(b=n(c).val(),f)return b;g.push(b)}return g},set:function(a,b){var c,d,e=a.options,f=n.makeArray(b),g=e.length;while(g--)if(d=e[g],n.inArray(n.valHooks.option.get(d),f)>-1)try{d.selected=c=!0}catch(h){d.scrollHeight}else d.selected=!1;return c||(a.selectedIndex=-1),e}}}}),n.each(["radio","checkbox"],function(){n.valHooks[this]={set:function(a,b){return n.isArray(b)?a.checked=n.inArray(n(a).val(),b)>-1:void 0}},l.checkOn||(n.valHooks[this].get=function(a){return null===a.getAttribute("value")?"on":a.value})});var tb,ub,vb=n.expr.attrHandle,wb=/^(?:checked|selected)$/i,xb=l.getSetAttribute,yb=l.input;n.fn.extend({attr:function(a,b){return Y(this,n.attr,a,b,arguments.length>1)},removeAttr:function(a){return this.each(function(){n.removeAttr(this,a)})}}),n.extend({attr:function(a,b,c){var d,e,f=a.nodeType;if(3!==f&&8!==f&&2!==f)return"undefined"==typeof a.getAttribute?n.prop(a,b,c):(1===f&&n.isXMLDoc(a)||(b=b.toLowerCase(),e=n.attrHooks[b]||(n.expr.match.bool.test(b)?ub:tb)),void 0!==c?null===c?void n.removeAttr(a,b):e&&"set"in e&&void 0!==(d=e.set(a,c,b))?d:(a.setAttribute(b,c+""),c):e&&"get"in e&&null!==(d=e.get(a,b))?d:(d=n.find.attr(a,b),null==d?void 0:d))},attrHooks:{type:{set:function(a,b){if(!l.radioValue&&"radio"===b&&n.nodeName(a,"input")){var c=a.value;return a.setAttribute("type",b),c&&(a.value=c),b}}}},removeAttr:function(a,b){var c,d,e=0,f=b&&b.match(G);if(f&&1===a.nodeType)while(c=f[e++])d=n.propFix[c]||c,n.expr.match.bool.test(c)?yb&&xb||!wb.test(c)?a[d]=!1:a[n.camelCase("default-"+c)]=a[d]=!1:n.attr(a,c,""),a.removeAttribute(xb?c:d)}}),ub={set:function(a,b,c){return b===!1?n.removeAttr(a,c):yb&&xb||!wb.test(c)?a.setAttribute(!xb&&n.propFix[c]||c,c):a[n.camelCase("default-"+c)]=a[c]=!0,c}},n.each(n.expr.match.bool.source.match(/\w+/g),function(a,b){var c=vb[b]||n.find.attr;yb&&xb||!wb.test(b)?vb[b]=function(a,b,d){var e,f;return d||(f=vb[b],vb[b]=e,e=null!=c(a,b,d)?b.toLowerCase():null,vb[b]=f),e}:vb[b]=function(a,b,c){return c?void 0:a[n.camelCase("default-"+b)]?b.toLowerCase():null}}),yb&&xb||(n.attrHooks.value={set:function(a,b,c){return n.nodeName(a,"input")?void(a.defaultValue=b):tb&&tb.set(a,b,c)}}),xb||(tb={set:function(a,b,c){var d=a.getAttributeNode(c);return d||a.setAttributeNode(d=a.ownerDocument.createAttribute(c)),d.value=b+="","value"===c||b===a.getAttribute(c)?b:void 0}},vb.id=vb.name=vb.coords=function(a,b,c){var d;return c?void 0:(d=a.getAttributeNode(b))&&""!==d.value?d.value:null},n.valHooks.button={get:function(a,b){var c=a.getAttributeNode(b);return c&&c.specified?c.value:void 0},set:tb.set},n.attrHooks.contenteditable={set:function(a,b,c){tb.set(a,""===b?!1:b,c)}},n.each(["width","height"],function(a,b){n.attrHooks[b]={set:function(a,c){return""===c?(a.setAttribute(b,"auto"),c):void 0}}})),l.style||(n.attrHooks.style={get:function(a){return a.style.cssText||void 0},set:function(a,b){return a.style.cssText=b+""}});var zb=/^(?:input|select|textarea|button|object)$/i,Ab=/^(?:a|area)$/i;n.fn.extend({prop:function(a,b){return Y(this,n.prop,a,b,arguments.length>1)},removeProp:function(a){return a=n.propFix[a]||a,this.each(function(){try{this[a]=void 0,delete this[a]}catch(b){}})}}),n.extend({prop:function(a,b,c){var d,e,f=a.nodeType;if(3!==f&&8!==f&&2!==f)return 1===f&&n.isXMLDoc(a)||(b=n.propFix[b]||b,e=n.propHooks[b]),void 0!==c?e&&"set"in e&&void 0!==(d=e.set(a,c,b))?d:a[b]=c:e&&"get"in e&&null!==(d=e.get(a,b))?d:a[b]},propHooks:{tabIndex:{get:function(a){var b=n.find.attr(a,"tabindex");return b?parseInt(b,10):zb.test(a.nodeName)||Ab.test(a.nodeName)&&a.href?0:-1}}},propFix:{"for":"htmlFor","class":"className"}}),l.hrefNormalized||n.each(["href","src"],function(a,b){n.propHooks[b]={get:function(a){return a.getAttribute(b,4)}}}),l.optSelected||(n.propHooks.selected={get:function(a){var b=a.parentNode;return b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex),null},set:function(a){var b=a.parentNode;b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex)}}),n.each(["tabIndex","readOnly","maxLength","cellSpacing","cellPadding","rowSpan","colSpan","useMap","frameBorder","contentEditable"],function(){n.propFix[this.toLowerCase()]=this}),l.enctype||(n.propFix.enctype="encoding");var Bb=/[\t\r\n\f]/g;function Cb(a){return n.attr(a,"class")||""}n.fn.extend({addClass:function(a){var b,c,d,e,f,g,h,i=0;if(n.isFunction(a))return this.each(function(b){n(this).addClass(a.call(this,b,Cb(this)))});if("string"==typeof a&&a){b=a.match(G)||[];while(c=this[i++])if(e=Cb(c),d=1===c.nodeType&&(" "+e+" ").replace(Bb," ")){g=0;while(f=b[g++])d.indexOf(" "+f+" ")<0&&(d+=f+" ");h=n.trim(d),e!==h&&n.attr(c,"class",h)}}return this},removeClass:function(a){var b,c,d,e,f,g,h,i=0;if(n.isFunction(a))return this.each(function(b){n(this).removeClass(a.call(this,b,Cb(this)))});if(!arguments.length)return this.attr("class","");if("string"==typeof a&&a){b=a.match(G)||[];while(c=this[i++])if(e=Cb(c),d=1===c.nodeType&&(" "+e+" ").replace(Bb," ")){g=0;while(f=b[g++])while(d.indexOf(" "+f+" ")>-1)d=d.replace(" "+f+" "," ");h=n.trim(d),e!==h&&n.attr(c,"class",h)}}return this},toggleClass:function(a,b){var c=typeof a;return"boolean"==typeof b&&"string"===c?b?this.addClass(a):this.removeClass(a):n.isFunction(a)?this.each(function(c){n(this).toggleClass(a.call(this,c,Cb(this),b),b)}):this.each(function(){var b,d,e,f;if("string"===c){d=0,e=n(this),f=a.match(G)||[];while(b=f[d++])e.hasClass(b)?e.removeClass(b):e.addClass(b)}else void 0!==a&&"boolean"!==c||(b=Cb(this),b&&n._data(this,"__className__",b),n.attr(this,"class",b||a===!1?"":n._data(this,"__className__")||""))})},hasClass:function(a){var b,c,d=0;b=" "+a+" ";while(c=this[d++])if(1===c.nodeType&&(" "+Cb(c)+" ").replace(Bb," ").indexOf(b)>-1)return!0;return!1}}),n.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu".split(" "),function(a,b){n.fn[b]=function(a,c){return arguments.length>0?this.on(b,null,a,c):this.trigger(b)}}),n.fn.extend({hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)}});var Db=a.location,Eb=n.now(),Fb=/\?/,Gb=/(,)|(\[|{)|(}|])|"(?:[^"\\\r\n]|\\["\\\/bfnrt]|\\u[\da-fA-F]{4})*"\s*:?|true|false|null|-?(?!0\d)\d+(?:\.\d+|)(?:[eE][+-]?\d+|)/g;n.parseJSON=function(b){if(a.JSON&&a.JSON.parse)return a.JSON.parse(b+"");var c,d=null,e=n.trim(b+"");return e&&!n.trim(e.replace(Gb,function(a,b,e,f){return c&&b&&(d=0),0===d?a:(c=e||b,d+=!f-!e,"")}))?Function("return "+e)():n.error("Invalid JSON: "+b)},n.parseXML=function(b){var c,d;if(!b||"string"!=typeof b)return null;try{a.DOMParser?(d=new a.DOMParser,c=d.parseFromString(b,"text/xml")):(c=new a.ActiveXObject("Microsoft.XMLDOM"),c.async="false",c.loadXML(b))}catch(e){c=void 0}return c&&c.documentElement&&!c.getElementsByTagName("parsererror").length||n.error("Invalid XML: "+b),c};var Hb=/#.*$/,Ib=/([?&])_=[^&]*/,Jb=/^(.*?):[ \t]*([^\r\n]*)\r?$/gm,Kb=/^(?:about|app|app-storage|.+-extension|file|res|widget):$/,Lb=/^(?:GET|HEAD)$/,Mb=/^\/\//,Nb=/^([\w.+-]+:)(?:\/\/(?:[^\/?#]*@|)([^\/?#:]*)(?::(\d+)|)|)/,Ob={},Pb={},Qb="*/".concat("*"),Rb=Db.href,Sb=Nb.exec(Rb.toLowerCase())||[];function Tb(a){return function(b,c){"string"!=typeof b&&(c=b,b="*");var d,e=0,f=b.toLowerCase().match(G)||[];if(n.isFunction(c))while(d=f[e++])"+"===d.charAt(0)?(d=d.slice(1)||"*",(a[d]=a[d]||[]).unshift(c)):(a[d]=a[d]||[]).push(c)}}function Ub(a,b,c,d){var e={},f=a===Pb;function g(h){var i;return e[h]=!0,n.each(a[h]||[],function(a,h){var j=h(b,c,d);return"string"!=typeof j||f||e[j]?f?!(i=j):void 0:(b.dataTypes.unshift(j),g(j),!1)}),i}return g(b.dataTypes[0])||!e["*"]&&g("*")}function Vb(a,b){var c,d,e=n.ajaxSettings.flatOptions||{};for(d in b)void 0!==b[d]&&((e[d]?a:c||(c={}))[d]=b[d]);return c&&n.extend(!0,a,c),a}function Wb(a,b,c){var d,e,f,g,h=a.contents,i=a.dataTypes;while("*"===i[0])i.shift(),void 0===e&&(e=a.mimeType||b.getResponseHeader("Content-Type"));if(e)for(g in h)if(h[g]&&h[g].test(e)){i.unshift(g);break}if(i[0]in c)f=i[0];else{for(g in c){if(!i[0]||a.converters[g+" "+i[0]]){f=g;break}d||(d=g)}f=f||d}return f?(f!==i[0]&&i.unshift(f),c[f]):void 0}function Xb(a,b,c,d){var e,f,g,h,i,j={},k=a.dataTypes.slice();if(k[1])for(g in a.converters)j[g.toLowerCase()]=a.converters[g];f=k.shift();while(f)if(a.responseFields[f]&&(c[a.responseFields[f]]=b),!i&&d&&a.dataFilter&&(b=a.dataFilter(b,a.dataType)),i=f,f=k.shift())if("*"===f)f=i;else if("*"!==i&&i!==f){if(g=j[i+" "+f]||j["* "+f],!g)for(e in j)if(h=e.split(" "),h[1]===f&&(g=j[i+" "+h[0]]||j["* "+h[0]])){g===!0?g=j[e]:j[e]!==!0&&(f=h[0],k.unshift(h[1]));break}if(g!==!0)if(g&&a["throws"])b=g(b);else try{b=g(b)}catch(l){return{state:"parsererror",error:g?l:"No conversion from "+i+" to "+f}}}return{state:"success",data:b}}n.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:Rb,type:"GET",isLocal:Kb.test(Sb[1]),global:!0,processData:!0,async:!0,contentType:"application/x-www-form-urlencoded; charset=UTF-8",accepts:{"*":Qb,text:"text/plain",html:"text/html",xml:"application/xml, text/xml",json:"application/json, text/javascript"},contents:{xml:/\bxml\b/,html:/\bhtml/,json:/\bjson\b/},responseFields:{xml:"responseXML",text:"responseText",json:"responseJSON"},converters:{"* text":String,"text html":!0,"text json":n.parseJSON,"text xml":n.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(a,b){return b?Vb(Vb(a,n.ajaxSettings),b):Vb(n.ajaxSettings,a)},ajaxPrefilter:Tb(Ob),ajaxTransport:Tb(Pb),ajax:function(b,c){"object"==typeof b&&(c=b,b=void 0),c=c||{};var d,e,f,g,h,i,j,k,l=n.ajaxSetup({},c),m=l.context||l,o=l.context&&(m.nodeType||m.jquery)?n(m):n.event,p=n.Deferred(),q=n.Callbacks("once memory"),r=l.statusCode||{},s={},t={},u=0,v="canceled",w={readyState:0,getResponseHeader:function(a){var b;if(2===u){if(!k){k={};while(b=Jb.exec(g))k[b[1].toLowerCase()]=b[2]}b=k[a.toLowerCase()]}return null==b?null:b},getAllResponseHeaders:function(){return 2===u?g:null},setRequestHeader:function(a,b){var c=a.toLowerCase();return u||(a=t[c]=t[c]||a,s[a]=b),this},overrideMimeType:function(a){return u||(l.mimeType=a),this},statusCode:function(a){var b;if(a)if(2>u)for(b in a)r[b]=[r[b],a[b]];else w.always(a[w.status]);return this},abort:function(a){var b=a||v;return j&&j.abort(b),y(0,b),this}};if(p.promise(w).complete=q.add,w.success=w.done,w.error=w.fail,l.url=((b||l.url||Rb)+"").replace(Hb,"").replace(Mb,Sb[1]+"//"),l.type=c.method||c.type||l.method||l.type,l.dataTypes=n.trim(l.dataType||"*").toLowerCase().match(G)||[""],null==l.crossDomain&&(d=Nb.exec(l.url.toLowerCase()),l.crossDomain=!(!d||d[1]===Sb[1]&&d[2]===Sb[2]&&(d[3]||("http:"===d[1]?"80":"443"))===(Sb[3]||("http:"===Sb[1]?"80":"443")))),l.data&&l.processData&&"string"!=typeof l.data&&(l.data=n.param(l.data,l.traditional)),Ub(Ob,l,c,w),2===u)return w;i=n.event&&l.global,i&&0===n.active++&&n.event.trigger("ajaxStart"),l.type=l.type.toUpperCase(),l.hasContent=!Lb.test(l.type),f=l.url,l.hasContent||(l.data&&(f=l.url+=(Fb.test(f)?"&":"?")+l.data,delete l.data),l.cache===!1&&(l.url=Ib.test(f)?f.replace(Ib,"$1_="+Eb++):f+(Fb.test(f)?"&":"?")+"_="+Eb++)),l.ifModified&&(n.lastModified[f]&&w.setRequestHeader("If-Modified-Since",n.lastModified[f]),n.etag[f]&&w.setRequestHeader("If-None-Match",n.etag[f])),(l.data&&l.hasContent&&l.contentType!==!1||c.contentType)&&w.setRequestHeader("Content-Type",l.contentType),w.setRequestHeader("Accept",l.dataTypes[0]&&l.accepts[l.dataTypes[0]]?l.accepts[l.dataTypes[0]]+("*"!==l.dataTypes[0]?", "+Qb+"; q=0.01":""):l.accepts["*"]);for(e in l.headers)w.setRequestHeader(e,l.headers[e]);if(l.beforeSend&&(l.beforeSend.call(m,w,l)===!1||2===u))return w.abort();v="abort";for(e in{success:1,error:1,complete:1})w[e](l[e]);if(j=Ub(Pb,l,c,w)){if(w.readyState=1,i&&o.trigger("ajaxSend",[w,l]),2===u)return w;l.async&&l.timeout>0&&(h=a.setTimeout(function(){w.abort("timeout")},l.timeout));try{u=1,j.send(s,y)}catch(x){if(!(2>u))throw x;y(-1,x)}}else y(-1,"No Transport");function y(b,c,d,e){var k,s,t,v,x,y=c;2!==u&&(u=2,h&&a.clearTimeout(h),j=void 0,g=e||"",w.readyState=b>0?4:0,k=b>=200&&300>b||304===b,d&&(v=Wb(l,w,d)),v=Xb(l,v,w,k),k?(l.ifModified&&(x=w.getResponseHeader("Last-Modified"),x&&(n.lastModified[f]=x),x=w.getResponseHeader("etag"),x&&(n.etag[f]=x)),204===b||"HEAD"===l.type?y="nocontent":304===b?y="notmodified":(y=v.state,s=v.data,t=v.error,k=!t)):(t=y,!b&&y||(y="error",0>b&&(b=0))),w.status=b,w.statusText=(c||y)+"",k?p.resolveWith(m,[s,y,w]):p.rejectWith(m,[w,y,t]),w.statusCode(r),r=void 0,i&&o.trigger(k?"ajaxSuccess":"ajaxError",[w,l,k?s:t]),q.fireWith(m,[w,y]),i&&(o.trigger("ajaxComplete",[w,l]),--n.active||n.event.trigger("ajaxStop")))}return w},getJSON:function(a,b,c){return n.get(a,b,c,"json")},getScript:function(a,b){return n.get(a,void 0,b,"script")}}),n.each(["get","post"],function(a,b){n[b]=function(a,c,d,e){return n.isFunction(c)&&(e=e||d,d=c,c=void 0),n.ajax(n.extend({url:a,type:b,dataType:e,data:c,success:d},n.isPlainObject(a)&&a))}}),n._evalUrl=function(a){return n.ajax({url:a,type:"GET",dataType:"script",cache:!0,async:!1,global:!1,"throws":!0})},n.fn.extend({wrapAll:function(a){if(n.isFunction(a))return this.each(function(b){n(this).wrapAll(a.call(this,b))});if(this[0]){var b=n(a,this[0].ownerDocument).eq(0).clone(!0);this[0].parentNode&&b.insertBefore(this[0]),b.map(function(){var a=this;while(a.firstChild&&1===a.firstChild.nodeType)a=a.firstChild;return a}).append(this)}return this},wrapInner:function(a){return n.isFunction(a)?this.each(function(b){n(this).wrapInner(a.call(this,b))}):this.each(function(){var b=n(this),c=b.contents();c.length?c.wrapAll(a):b.append(a)})},wrap:function(a){var b=n.isFunction(a);return this.each(function(c){n(this).wrapAll(b?a.call(this,c):a)})},unwrap:function(){return this.parent().each(function(){n.nodeName(this,"body")||n(this).replaceWith(this.childNodes)}).end()}});function Yb(a){return a.style&&a.style.display||n.css(a,"display")}function Zb(a){while(a&&1===a.nodeType){if("none"===Yb(a)||"hidden"===a.type)return!0;a=a.parentNode}return!1}n.expr.filters.hidden=function(a){return l.reliableHiddenOffsets()?a.offsetWidth<=0&&a.offsetHeight<=0&&!a.getClientRects().length:Zb(a)},n.expr.filters.visible=function(a){return!n.expr.filters.hidden(a)};var $b=/%20/g,_b=/\[\]$/,ac=/\r?\n/g,bc=/^(?:submit|button|image|reset|file)$/i,cc=/^(?:input|select|textarea|keygen)/i;function dc(a,b,c,d){var e;if(n.isArray(b))n.each(b,function(b,e){c||_b.test(a)?d(a,e):dc(a+"["+("object"==typeof e&&null!=e?b:"")+"]",e,c,d)});else if(c||"object"!==n.type(b))d(a,b);else for(e in b)dc(a+"["+e+"]",b[e],c,d)}n.param=function(a,b){var c,d=[],e=function(a,b){b=n.isFunction(b)?b():null==b?"":b,d[d.length]=encodeURIComponent(a)+"="+encodeURIComponent(b)};if(void 0===b&&(b=n.ajaxSettings&&n.ajaxSettings.traditional),n.isArray(a)||a.jquery&&!n.isPlainObject(a))n.each(a,function(){e(this.name,this.value)});else for(c in a)dc(c,a[c],b,e);return d.join("&").replace($b,"+")},n.fn.extend({serialize:function(){return n.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var a=n.prop(this,"elements");return a?n.makeArray(a):this}).filter(function(){var a=this.type;return this.name&&!n(this).is(":disabled")&&cc.test(this.nodeName)&&!bc.test(a)&&(this.checked||!Z.test(a))}).map(function(a,b){var c=n(this).val();return null==c?null:n.isArray(c)?n.map(c,function(a){return{name:b.name,value:a.replace(ac,"\r\n")}}):{name:b.name,value:c.replace(ac,"\r\n")}}).get()}}),n.ajaxSettings.xhr=void 0!==a.ActiveXObject?function(){return this.isLocal?ic():d.documentMode>8?hc():/^(get|post|head|put|delete|options)$/i.test(this.type)&&hc()||ic()}:hc;var ec=0,fc={},gc=n.ajaxSettings.xhr();a.attachEvent&&a.attachEvent("onunload",function(){for(var a in fc)fc[a](void 0,!0)}),l.cors=!!gc&&"withCredentials"in gc,gc=l.ajax=!!gc,gc&&n.ajaxTransport(function(b){if(!b.crossDomain||l.cors){var c;return{send:function(d,e){var f,g=b.xhr(),h=++ec;if(g.open(b.type,b.url,b.async,b.username,b.password),b.xhrFields)for(f in b.xhrFields)g[f]=b.xhrFields[f];b.mimeType&&g.overrideMimeType&&g.overrideMimeType(b.mimeType),b.crossDomain||d["X-Requested-With"]||(d["X-Requested-With"]="XMLHttpRequest");for(f in d)void 0!==d[f]&&g.setRequestHeader(f,d[f]+"");g.send(b.hasContent&&b.data||null),c=function(a,d){var f,i,j;if(c&&(d||4===g.readyState))if(delete fc[h],c=void 0,g.onreadystatechange=n.noop,d)4!==g.readyState&&g.abort();else{j={},f=g.status,"string"==typeof g.responseText&&(j.text=g.responseText);try{i=g.statusText}catch(k){i=""}f||!b.isLocal||b.crossDomain?1223===f&&(f=204):f=j.text?200:404}j&&e(f,i,j,g.getAllResponseHeaders())},b.async?4===g.readyState?a.setTimeout(c):g.onreadystatechange=fc[h]=c:c()},abort:function(){c&&c(void 0,!0)}}}});function hc(){try{return new a.XMLHttpRequest}catch(b){}}function ic(){try{return new a.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}}n.ajaxSetup({accepts:{script:"text/javascript, application/javascript, application/ecmascript, application/x-ecmascript"},contents:{script:/\b(?:java|ecma)script\b/},converters:{"text script":function(a){return n.globalEval(a),a}}}),n.ajaxPrefilter("script",function(a){void 0===a.cache&&(a.cache=!1),a.crossDomain&&(a.type="GET",a.global=!1)}),n.ajaxTransport("script",function(a){if(a.crossDomain){var b,c=d.head||n("head")[0]||d.documentElement;return{send:function(e,f){b=d.createElement("script"),b.async=!0,a.scriptCharset&&(b.charset=a.scriptCharset),b.src=a.url,b.onload=b.onreadystatechange=function(a,c){(c||!b.readyState||/loaded|complete/.test(b.readyState))&&(b.onload=b.onreadystatechange=null,b.parentNode&&b.parentNode.removeChild(b),b=null,c||f(200,"success"))},c.insertBefore(b,c.firstChild)},abort:function(){b&&b.onload(void 0,!0)}}}});var jc=[],kc=/(=)\?(?=&|$)|\?\?/;n.ajaxSetup({jsonp:"callback",jsonpCallback:function(){var a=jc.pop()||n.expando+"_"+Eb++;return this[a]=!0,a}}),n.ajaxPrefilter("json jsonp",function(b,c,d){var e,f,g,h=b.jsonp!==!1&&(kc.test(b.url)?"url":"string"==typeof b.data&&0===(b.contentType||"").indexOf("application/x-www-form-urlencoded")&&kc.test(b.data)&&"data");return h||"jsonp"===b.dataTypes[0]?(e=b.jsonpCallback=n.isFunction(b.jsonpCallback)?b.jsonpCallback():b.jsonpCallback,h?b[h]=b[h].replace(kc,"$1"+e):b.jsonp!==!1&&(b.url+=(Fb.test(b.url)?"&":"?")+b.jsonp+"="+e),b.converters["script json"]=function(){return g||n.error(e+" was not called"),g[0]},b.dataTypes[0]="json",f=a[e],a[e]=function(){g=arguments},d.always(function(){void 0===f?n(a).removeProp(e):a[e]=f,b[e]&&(b.jsonpCallback=c.jsonpCallback,jc.push(e)),g&&n.isFunction(f)&&f(g[0]),g=f=void 0}),"script"):void 0}),n.parseHTML=function(a,b,c){if(!a||"string"!=typeof a)return null;"boolean"==typeof b&&(c=b,b=!1),b=b||d;var e=x.exec(a),f=!c&&[];return e?[b.createElement(e[1])]:(e=ja([a],b,f),f&&f.length&&n(f).remove(),n.merge([],e.childNodes))};var lc=n.fn.load;n.fn.load=function(a,b,c){if("string"!=typeof a&&lc)return lc.apply(this,arguments);var d,e,f,g=this,h=a.indexOf(" ");return h>-1&&(d=n.trim(a.slice(h,a.length)),a=a.slice(0,h)),n.isFunction(b)?(c=b,b=void 0):b&&"object"==typeof b&&(e="POST"),g.length>0&&n.ajax({url:a,type:e||"GET",dataType:"html",data:b}).done(function(a){f=arguments,g.html(d?n("<div>").append(n.parseHTML(a)).find(d):a)}).always(c&&function(a,b){g.each(function(){c.apply(this,f||[a.responseText,b,a])})}),this},n.each(["ajaxStart","ajaxStop","ajaxComplete","ajaxError","ajaxSuccess","ajaxSend"],function(a,b){n.fn[b]=function(a){return this.on(b,a)}}),n.expr.filters.animated=function(a){return n.grep(n.timers,function(b){return a===b.elem}).length};function mc(a){return n.isWindow(a)?a:9===a.nodeType?a.defaultView||a.parentWindow:!1}n.offset={setOffset:function(a,b,c){var d,e,f,g,h,i,j,k=n.css(a,"position"),l=n(a),m={};"static"===k&&(a.style.position="relative"),h=l.offset(),f=n.css(a,"top"),i=n.css(a,"left"),j=("absolute"===k||"fixed"===k)&&n.inArray("auto",[f,i])>-1,j?(d=l.position(),g=d.top,e=d.left):(g=parseFloat(f)||0,e=parseFloat(i)||0),n.isFunction(b)&&(b=b.call(a,c,n.extend({},h))),null!=b.top&&(m.top=b.top-h.top+g),null!=b.left&&(m.left=b.left-h.left+e),"using"in b?b.using.call(a,m):l.css(m)}},n.fn.extend({offset:function(a){if(arguments.length)return void 0===a?this:this.each(function(b){n.offset.setOffset(this,a,b)});var b,c,d={top:0,left:0},e=this[0],f=e&&e.ownerDocument;if(f)return b=f.documentElement,n.contains(b,e)?("undefined"!=typeof e.getBoundingClientRect&&(d=e.getBoundingClientRect()),c=mc(f),{top:d.top+(c.pageYOffset||b.scrollTop)-(b.clientTop||0),left:d.left+(c.pageXOffset||b.scrollLeft)-(b.clientLeft||0)}):d},position:function(){if(this[0]){var a,b,c={top:0,left:0},d=this[0];return"fixed"===n.css(d,"position")?b=d.getBoundingClientRect():(a=this.offsetParent(),b=this.offset(),n.nodeName(a[0],"html")||(c=a.offset()),c.top+=n.css(a[0],"borderTopWidth",!0),c.left+=n.css(a[0],"borderLeftWidth",!0)),{top:b.top-c.top-n.css(d,"marginTop",!0),left:b.left-c.left-n.css(d,"marginLeft",!0)}}},offsetParent:function(){return this.map(function(){var a=this.offsetParent;while(a&&!n.nodeName(a,"html")&&"static"===n.css(a,"position"))a=a.offsetParent;return a||Qa})}}),n.each({scrollLeft:"pageXOffset",scrollTop:"pageYOffset"},function(a,b){var c=/Y/.test(b);n.fn[a]=function(d){return Y(this,function(a,d,e){var f=mc(a);return void 0===e?f?b in f?f[b]:f.document.documentElement[d]:a[d]:void(f?f.scrollTo(c?n(f).scrollLeft():e,c?e:n(f).scrollTop()):a[d]=e)},a,d,arguments.length,null)}}),n.each(["top","left"],function(a,b){n.cssHooks[b]=Ua(l.pixelPosition,function(a,c){return c?(c=Sa(a,b),Oa.test(c)?n(a).position()[b]+"px":c):void 0;
})}),n.each({Height:"height",Width:"width"},function(a,b){n.each({padding:"inner"+a,content:b,"":"outer"+a},function(c,d){n.fn[d]=function(d,e){var f=arguments.length&&(c||"boolean"!=typeof d),g=c||(d===!0||e===!0?"margin":"border");return Y(this,function(b,c,d){var e;return n.isWindow(b)?b.document.documentElement["client"+a]:9===b.nodeType?(e=b.documentElement,Math.max(b.body["scroll"+a],e["scroll"+a],b.body["offset"+a],e["offset"+a],e["client"+a])):void 0===d?n.css(b,c,g):n.style(b,c,d,g)},b,f?d:void 0,f,null)}})}),n.fn.extend({bind:function(a,b,c){return this.on(a,null,b,c)},unbind:function(a,b){return this.off(a,null,b)},delegate:function(a,b,c,d){return this.on(b,a,c,d)},undelegate:function(a,b,c){return 1===arguments.length?this.off(a,"**"):this.off(b,a||"**",c)}}),n.fn.size=function(){return this.length},n.fn.andSelf=n.fn.addBack,"function"==typeof define&&define.amd&&define("jquery",[],function(){return n});var nc=a.jQuery,oc=a.$;return n.noConflict=function(b){return a.$===n&&(a.$=oc),b&&a.jQuery===n&&(a.jQuery=nc),n},b||(a.jQuery=a.$=n),n});
/**
 * Owl Carousel v2.3.4
 * Copyright 2013-2018 David Deutsch
 * Licensed under: SEE LICENSE IN https://github.com/OwlCarousel2/OwlCarousel2/blob/master/LICENSE
 */
!function(a,b,c,d){function e(b,c){this.settings=null,this.options=a.extend({},e.Defaults,c),this.$element=a(b),this._handlers={},this._plugins={},this._supress={},this._current=null,this._speed=null,this._coordinates=[],this._breakpoint=null,this._width=null,this._items=[],this._clones=[],this._mergers=[],this._widths=[],this._invalidated={},this._pipe=[],this._drag={time:null,target:null,pointer:null,stage:{start:null,current:null},direction:null},this._states={current:{},tags:{initializing:["busy"],animating:["busy"],dragging:["interacting"]}},a.each(["onResize","onThrottledResize"],a.proxy(function(b,c){this._handlers[c]=a.proxy(this[c],this)},this)),a.each(e.Plugins,a.proxy(function(a,b){this._plugins[a.charAt(0).toLowerCase()+a.slice(1)]=new b(this)},this)),a.each(e.Workers,a.proxy(function(b,c){this._pipe.push({filter:c.filter,run:a.proxy(c.run,this)})},this)),this.setup(),this.initialize()}e.Defaults={items:3,loop:!1,center:!1,rewind:!1,checkVisibility:!0,mouseDrag:!0,touchDrag:!0,pullDrag:!0,freeDrag:!1,margin:0,stagePadding:0,merge:!1,mergeFit:!0,autoWidth:!1,startPosition:0,rtl:!1,smartSpeed:250,fluidSpeed:!1,dragEndSpeed:!1,responsive:{},responsiveRefreshRate:200,responsiveBaseElement:b,fallbackEasing:"swing",slideTransition:"",info:!1,nestedItemSelector:!1,itemElement:"div",stageElement:"div",refreshClass:"owl-refresh",loadedClass:"owl-loaded",loadingClass:"owl-loading",rtlClass:"owl-rtl",responsiveClass:"owl-responsive",dragClass:"owl-drag",itemClass:"owl-item",stageClass:"owl-stage",stageOuterClass:"owl-stage-outer",grabClass:"owl-grab"},e.Width={Default:"default",Inner:"inner",Outer:"outer"},e.Type={Event:"event",State:"state"},e.Plugins={},e.Workers=[{filter:["width","settings"],run:function(){this._width=this.$element.width()}},{filter:["width","items","settings"],run:function(a){a.current=this._items&&this._items[this.relative(this._current)]}},{filter:["items","settings"],run:function(){this.$stage.children(".cloned").remove()}},{filter:["width","items","settings"],run:function(a){var b=this.settings.margin||"",c=!this.settings.autoWidth,d=this.settings.rtl,e={width:"auto","margin-left":d?b:"","margin-right":d?"":b};!c&&this.$stage.children().css(e),a.css=e}},{filter:["width","items","settings"],run:function(a){var b=(this.width()/this.settings.items).toFixed(3)-this.settings.margin,c=null,d=this._items.length,e=!this.settings.autoWidth,f=[];for(a.items={merge:!1,width:b};d--;)c=this._mergers[d],c=this.settings.mergeFit&&Math.min(c,this.settings.items)||c,a.items.merge=c>1||a.items.merge,f[d]=e?b*c:this._items[d].width();this._widths=f}},{filter:["items","settings"],run:function(){var b=[],c=this._items,d=this.settings,e=Math.max(2*d.items,4),f=2*Math.ceil(c.length/2),g=d.loop&&c.length?d.rewind?e:Math.max(e,f):0,h="",i="";for(g/=2;g>0;)b.push(this.normalize(b.length/2,!0)),h+=c[b[b.length-1]][0].outerHTML,b.push(this.normalize(c.length-1-(b.length-1)/2,!0)),i=c[b[b.length-1]][0].outerHTML+i,g-=1;this._clones=b,a(h).addClass("cloned").appendTo(this.$stage),a(i).addClass("cloned").prependTo(this.$stage)}},{filter:["width","items","settings"],run:function(){for(var a=this.settings.rtl?1:-1,b=this._clones.length+this._items.length,c=-1,d=0,e=0,f=[];++c<b;)d=f[c-1]||0,e=this._widths[this.relative(c)]+this.settings.margin,f.push(d+e*a);this._coordinates=f}},{filter:["width","items","settings"],run:function(){var a=this.settings.stagePadding,b=this._coordinates,c={width:Math.ceil(Math.abs(b[b.length-1]))+2*a,"padding-left":a||"","padding-right":a||""};this.$stage.css(c)}},{filter:["width","items","settings"],run:function(a){var b=this._coordinates.length,c=!this.settings.autoWidth,d=this.$stage.children();if(c&&a.items.merge)for(;b--;)a.css.width=this._widths[this.relative(b)],d.eq(b).css(a.css);else c&&(a.css.width=a.items.width,d.css(a.css))}},{filter:["items"],run:function(){this._coordinates.length<1&&this.$stage.removeAttr("style")}},{filter:["width","items","settings"],run:function(a){a.current=a.current?this.$stage.children().index(a.current):0,a.current=Math.max(this.minimum(),Math.min(this.maximum(),a.current)),this.reset(a.current)}},{filter:["position"],run:function(){this.animate(this.coordinates(this._current))}},{filter:["width","position","items","settings"],run:function(){var a,b,c,d,e=this.settings.rtl?1:-1,f=2*this.settings.stagePadding,g=this.coordinates(this.current())+f,h=g+this.width()*e,i=[];for(c=0,d=this._coordinates.length;c<d;c++)a=this._coordinates[c-1]||0,b=Math.abs(this._coordinates[c])+f*e,(this.op(a,"<=",g)&&this.op(a,">",h)||this.op(b,"<",g)&&this.op(b,">",h))&&i.push(c);this.$stage.children(".active").removeClass("active"),this.$stage.children(":eq("+i.join("), :eq(")+")").addClass("active"),this.$stage.children(".center").removeClass("center"),this.settings.center&&this.$stage.children().eq(this.current()).addClass("center")}}],e.prototype.initializeStage=function(){this.$stage=this.$element.find("."+this.settings.stageClass),this.$stage.length||(this.$element.addClass(this.options.loadingClass),this.$stage=a("<"+this.settings.stageElement+">",{class:this.settings.stageClass}).wrap(a("<div/>",{class:this.settings.stageOuterClass})),this.$element.append(this.$stage.parent()))},e.prototype.initializeItems=function(){var b=this.$element.find(".owl-item");if(b.length)return this._items=b.get().map(function(b){return a(b)}),this._mergers=this._items.map(function(){return 1}),void this.refresh();this.replace(this.$element.children().not(this.$stage.parent())),this.isVisible()?this.refresh():this.invalidate("width"),this.$element.removeClass(this.options.loadingClass).addClass(this.options.loadedClass)},e.prototype.initialize=function(){if(this.enter("initializing"),this.trigger("initialize"),this.$element.toggleClass(this.settings.rtlClass,this.settings.rtl),this.settings.autoWidth&&!this.is("pre-loading")){var a,b,c;a=this.$element.find("img"),b=this.settings.nestedItemSelector?"."+this.settings.nestedItemSelector:d,c=this.$element.children(b).width(),a.length&&c<=0&&this.preloadAutoWidthImages(a)}this.initializeStage(),this.initializeItems(),this.registerEventHandlers(),this.leave("initializing"),this.trigger("initialized")},e.prototype.isVisible=function(){return!this.settings.checkVisibility||this.$element.is(":visible")},e.prototype.setup=function(){var b=this.viewport(),c=this.options.responsive,d=-1,e=null;c?(a.each(c,function(a){a<=b&&a>d&&(d=Number(a))}),e=a.extend({},this.options,c[d]),"function"==typeof e.stagePadding&&(e.stagePadding=e.stagePadding()),delete e.responsive,e.responsiveClass&&this.$element.attr("class",this.$element.attr("class").replace(new RegExp("("+this.options.responsiveClass+"-)\\S+\\s","g"),"$1"+d))):e=a.extend({},this.options),this.trigger("change",{property:{name:"settings",value:e}}),this._breakpoint=d,this.settings=e,this.invalidate("settings"),this.trigger("changed",{property:{name:"settings",value:this.settings}})},e.prototype.optionsLogic=function(){this.settings.autoWidth&&(this.settings.stagePadding=!1,this.settings.merge=!1)},e.prototype.prepare=function(b){var c=this.trigger("prepare",{content:b});return c.data||(c.data=a("<"+this.settings.itemElement+"/>").addClass(this.options.itemClass).append(b)),this.trigger("prepared",{content:c.data}),c.data},e.prototype.update=function(){for(var b=0,c=this._pipe.length,d=a.proxy(function(a){return this[a]},this._invalidated),e={};b<c;)(this._invalidated.all||a.grep(this._pipe[b].filter,d).length>0)&&this._pipe[b].run(e),b++;this._invalidated={},!this.is("valid")&&this.enter("valid")},e.prototype.width=function(a){switch(a=a||e.Width.Default){case e.Width.Inner:case e.Width.Outer:return this._width;default:return this._width-2*this.settings.stagePadding+this.settings.margin}},e.prototype.refresh=function(){this.enter("refreshing"),this.trigger("refresh"),this.setup(),this.optionsLogic(),this.$element.addClass(this.options.refreshClass),this.update(),this.$element.removeClass(this.options.refreshClass),this.leave("refreshing"),this.trigger("refreshed")},e.prototype.onThrottledResize=function(){b.clearTimeout(this.resizeTimer),this.resizeTimer=b.setTimeout(this._handlers.onResize,this.settings.responsiveRefreshRate)},e.prototype.onResize=function(){return!!this._items.length&&(this._width!==this.$element.width()&&(!!this.isVisible()&&(this.enter("resizing"),this.trigger("resize").isDefaultPrevented()?(this.leave("resizing"),!1):(this.invalidate("width"),this.refresh(),this.leave("resizing"),void this.trigger("resized")))))},e.prototype.registerEventHandlers=function(){a.support.transition&&this.$stage.on(a.support.transition.end+".owl.core",a.proxy(this.onTransitionEnd,this)),!1!==this.settings.responsive&&this.on(b,"resize",this._handlers.onThrottledResize),this.settings.mouseDrag&&(this.$element.addClass(this.options.dragClass),this.$stage.on("mousedown.owl.core",a.proxy(this.onDragStart,this)),this.$stage.on("dragstart.owl.core selectstart.owl.core",function(){return!1})),this.settings.touchDrag&&(this.$stage.on("touchstart.owl.core",a.proxy(this.onDragStart,this)),this.$stage.on("touchcancel.owl.core",a.proxy(this.onDragEnd,this)))},e.prototype.onDragStart=function(b){var d=null;3!==b.which&&(a.support.transform?(d=this.$stage.css("transform").replace(/.*\(|\)| /g,"").split(","),d={x:d[16===d.length?12:4],y:d[16===d.length?13:5]}):(d=this.$stage.position(),d={x:this.settings.rtl?d.left+this.$stage.width()-this.width()+this.settings.margin:d.left,y:d.top}),this.is("animating")&&(a.support.transform?this.animate(d.x):this.$stage.stop(),this.invalidate("position")),this.$element.toggleClass(this.options.grabClass,"mousedown"===b.type),this.speed(0),this._drag.time=(new Date).getTime(),this._drag.target=a(b.target),this._drag.stage.start=d,this._drag.stage.current=d,this._drag.pointer=this.pointer(b),a(c).on("mouseup.owl.core touchend.owl.core",a.proxy(this.onDragEnd,this)),a(c).one("mousemove.owl.core touchmove.owl.core",a.proxy(function(b){var d=this.difference(this._drag.pointer,this.pointer(b));a(c).on("mousemove.owl.core touchmove.owl.core",a.proxy(this.onDragMove,this)),Math.abs(d.x)<Math.abs(d.y)&&this.is("valid")||(b.preventDefault(),this.enter("dragging"),this.trigger("drag"))},this)))},e.prototype.onDragMove=function(a){var b=null,c=null,d=null,e=this.difference(this._drag.pointer,this.pointer(a)),f=this.difference(this._drag.stage.start,e);this.is("dragging")&&(a.preventDefault(),this.settings.loop?(b=this.coordinates(this.minimum()),c=this.coordinates(this.maximum()+1)-b,f.x=((f.x-b)%c+c)%c+b):(b=this.settings.rtl?this.coordinates(this.maximum()):this.coordinates(this.minimum()),c=this.settings.rtl?this.coordinates(this.minimum()):this.coordinates(this.maximum()),d=this.settings.pullDrag?-1*e.x/5:0,f.x=Math.max(Math.min(f.x,b+d),c+d)),this._drag.stage.current=f,this.animate(f.x))},e.prototype.onDragEnd=function(b){var d=this.difference(this._drag.pointer,this.pointer(b)),e=this._drag.stage.current,f=d.x>0^this.settings.rtl?"left":"right";a(c).off(".owl.core"),this.$element.removeClass(this.options.grabClass),(0!==d.x&&this.is("dragging")||!this.is("valid"))&&(this.speed(this.settings.dragEndSpeed||this.settings.smartSpeed),this.current(this.closest(e.x,0!==d.x?f:this._drag.direction)),this.invalidate("position"),this.update(),this._drag.direction=f,(Math.abs(d.x)>3||(new Date).getTime()-this._drag.time>300)&&this._drag.target.one("click.owl.core",function(){return!1})),this.is("dragging")&&(this.leave("dragging"),this.trigger("dragged"))},e.prototype.closest=function(b,c){var e=-1,f=30,g=this.width(),h=this.coordinates();return this.settings.freeDrag||a.each(h,a.proxy(function(a,i){return"left"===c&&b>i-f&&b<i+f?e=a:"right"===c&&b>i-g-f&&b<i-g+f?e=a+1:this.op(b,"<",i)&&this.op(b,">",h[a+1]!==d?h[a+1]:i-g)&&(e="left"===c?a+1:a),-1===e},this)),this.settings.loop||(this.op(b,">",h[this.minimum()])?e=b=this.minimum():this.op(b,"<",h[this.maximum()])&&(e=b=this.maximum())),e},e.prototype.animate=function(b){var c=this.speed()>0;this.is("animating")&&this.onTransitionEnd(),c&&(this.enter("animating"),this.trigger("translate")),a.support.transform3d&&a.support.transition?this.$stage.css({transform:"translate3d("+b+"px,0px,0px)",transition:this.speed()/1e3+"s"+(this.settings.slideTransition?" "+this.settings.slideTransition:"")}):c?this.$stage.animate({left:b+"px"},this.speed(),this.settings.fallbackEasing,a.proxy(this.onTransitionEnd,this)):this.$stage.css({left:b+"px"})},e.prototype.is=function(a){return this._states.current[a]&&this._states.current[a]>0},e.prototype.current=function(a){if(a===d)return this._current;if(0===this._items.length)return d;if(a=this.normalize(a),this._current!==a){var b=this.trigger("change",{property:{name:"position",value:a}});b.data!==d&&(a=this.normalize(b.data)),this._current=a,this.invalidate("position"),this.trigger("changed",{property:{name:"position",value:this._current}})}return this._current},e.prototype.invalidate=function(b){return"string"===a.type(b)&&(this._invalidated[b]=!0,this.is("valid")&&this.leave("valid")),a.map(this._invalidated,function(a,b){return b})},e.prototype.reset=function(a){(a=this.normalize(a))!==d&&(this._speed=0,this._current=a,this.suppress(["translate","translated"]),this.animate(this.coordinates(a)),this.release(["translate","translated"]))},e.prototype.normalize=function(a,b){var c=this._items.length,e=b?0:this._clones.length;return!this.isNumeric(a)||c<1?a=d:(a<0||a>=c+e)&&(a=((a-e/2)%c+c)%c+e/2),a},e.prototype.relative=function(a){return a-=this._clones.length/2,this.normalize(a,!0)},e.prototype.maximum=function(a){var b,c,d,e=this.settings,f=this._coordinates.length;if(e.loop)f=this._clones.length/2+this._items.length-1;else if(e.autoWidth||e.merge){if(b=this._items.length)for(c=this._items[--b].width(),d=this.$element.width();b--&&!((c+=this._items[b].width()+this.settings.margin)>d););f=b+1}else f=e.center?this._items.length-1:this._items.length-e.items;return a&&(f-=this._clones.length/2),Math.max(f,0)},e.prototype.minimum=function(a){return a?0:this._clones.length/2},e.prototype.items=function(a){return a===d?this._items.slice():(a=this.normalize(a,!0),this._items[a])},e.prototype.mergers=function(a){return a===d?this._mergers.slice():(a=this.normalize(a,!0),this._mergers[a])},e.prototype.clones=function(b){var c=this._clones.length/2,e=c+this._items.length,f=function(a){return a%2==0?e+a/2:c-(a+1)/2};return b===d?a.map(this._clones,function(a,b){return f(b)}):a.map(this._clones,function(a,c){return a===b?f(c):null})},e.prototype.speed=function(a){return a!==d&&(this._speed=a),this._speed},e.prototype.coordinates=function(b){var c,e=1,f=b-1;return b===d?a.map(this._coordinates,a.proxy(function(a,b){return this.coordinates(b)},this)):(this.settings.center?(this.settings.rtl&&(e=-1,f=b+1),c=this._coordinates[b],c+=(this.width()-c+(this._coordinates[f]||0))/2*e):c=this._coordinates[f]||0,c=Math.ceil(c))},e.prototype.duration=function(a,b,c){return 0===c?0:Math.min(Math.max(Math.abs(b-a),1),6)*Math.abs(c||this.settings.smartSpeed)},e.prototype.to=function(a,b){var c=this.current(),d=null,e=a-this.relative(c),f=(e>0)-(e<0),g=this._items.length,h=this.minimum(),i=this.maximum();this.settings.loop?(!this.settings.rewind&&Math.abs(e)>g/2&&(e+=-1*f*g),a=c+e,(d=((a-h)%g+g)%g+h)!==a&&d-e<=i&&d-e>0&&(c=d-e,a=d,this.reset(c))):this.settings.rewind?(i+=1,a=(a%i+i)%i):a=Math.max(h,Math.min(i,a)),this.speed(this.duration(c,a,b)),this.current(a),this.isVisible()&&this.update()},e.prototype.next=function(a){a=a||!1,this.to(this.relative(this.current())+1,a)},e.prototype.prev=function(a){a=a||!1,this.to(this.relative(this.current())-1,a)},e.prototype.onTransitionEnd=function(a){if(a!==d&&(a.stopPropagation(),(a.target||a.srcElement||a.originalTarget)!==this.$stage.get(0)))return!1;this.leave("animating"),this.trigger("translated")},e.prototype.viewport=function(){var d;return this.options.responsiveBaseElement!==b?d=a(this.options.responsiveBaseElement).width():b.innerWidth?d=b.innerWidth:c.documentElement&&c.documentElement.clientWidth?d=c.documentElement.clientWidth:console.warn("Can not detect viewport width."),d},e.prototype.replace=function(b){this.$stage.empty(),this._items=[],b&&(b=b instanceof jQuery?b:a(b)),this.settings.nestedItemSelector&&(b=b.find("."+this.settings.nestedItemSelector)),b.filter(function(){return 1===this.nodeType}).each(a.proxy(function(a,b){b=this.prepare(b),this.$stage.append(b),this._items.push(b),this._mergers.push(1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)},this)),this.reset(this.isNumeric(this.settings.startPosition)?this.settings.startPosition:0),this.invalidate("items")},e.prototype.add=function(b,c){var e=this.relative(this._current);c=c===d?this._items.length:this.normalize(c,!0),b=b instanceof jQuery?b:a(b),this.trigger("add",{content:b,position:c}),b=this.prepare(b),0===this._items.length||c===this._items.length?(0===this._items.length&&this.$stage.append(b),0!==this._items.length&&this._items[c-1].after(b),this._items.push(b),this._mergers.push(1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)):(this._items[c].before(b),this._items.splice(c,0,b),this._mergers.splice(c,0,1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)),this._items[e]&&this.reset(this._items[e].index()),this.invalidate("items"),this.trigger("added",{content:b,position:c})},e.prototype.remove=function(a){(a=this.normalize(a,!0))!==d&&(this.trigger("remove",{content:this._items[a],position:a}),this._items[a].remove(),this._items.splice(a,1),this._mergers.splice(a,1),this.invalidate("items"),this.trigger("removed",{content:null,position:a}))},e.prototype.preloadAutoWidthImages=function(b){b.each(a.proxy(function(b,c){this.enter("pre-loading"),c=a(c),a(new Image).one("load",a.proxy(function(a){c.attr("src",a.target.src),c.css("opacity",1),this.leave("pre-loading"),!this.is("pre-loading")&&!this.is("initializing")&&this.refresh()},this)).attr("src",c.attr("src")||c.attr("data-src")||c.attr("data-src-retina"))},this))},e.prototype.destroy=function(){this.$element.off(".owl.core"),this.$stage.off(".owl.core"),a(c).off(".owl.core"),!1!==this.settings.responsive&&(b.clearTimeout(this.resizeTimer),this.off(b,"resize",this._handlers.onThrottledResize));for(var d in this._plugins)this._plugins[d].destroy();this.$stage.children(".cloned").remove(),this.$stage.unwrap(),this.$stage.children().contents().unwrap(),this.$stage.children().unwrap(),this.$stage.remove(),this.$element.removeClass(this.options.refreshClass).removeClass(this.options.loadingClass).removeClass(this.options.loadedClass).removeClass(this.options.rtlClass).removeClass(this.options.dragClass).removeClass(this.options.grabClass).attr("class",this.$element.attr("class").replace(new RegExp(this.options.responsiveClass+"-\\S+\\s","g"),"")).removeData("owl.carousel")},e.prototype.op=function(a,b,c){var d=this.settings.rtl;switch(b){case"<":return d?a>c:a<c;case">":return d?a<c:a>c;case">=":return d?a<=c:a>=c;case"<=":return d?a>=c:a<=c}},e.prototype.on=function(a,b,c,d){a.addEventListener?a.addEventListener(b,c,d):a.attachEvent&&a.attachEvent("on"+b,c)},e.prototype.off=function(a,b,c,d){a.removeEventListener?a.removeEventListener(b,c,d):a.detachEvent&&a.detachEvent("on"+b,c)},e.prototype.trigger=function(b,c,d,f,g){var h={item:{count:this._items.length,index:this.current()}},i=a.camelCase(a.grep(["on",b,d],function(a){return a}).join("-").toLowerCase()),j=a.Event([b,"owl",d||"carousel"].join(".").toLowerCase(),a.extend({relatedTarget:this},h,c));return this._supress[b]||(a.each(this._plugins,function(a,b){b.onTrigger&&b.onTrigger(j)}),this.register({type:e.Type.Event,name:b}),this.$element.trigger(j),this.settings&&"function"==typeof this.settings[i]&&this.settings[i].call(this,j)),j},e.prototype.enter=function(b){a.each([b].concat(this._states.tags[b]||[]),a.proxy(function(a,b){this._states.current[b]===d&&(this._states.current[b]=0),this._states.current[b]++},this))},e.prototype.leave=function(b){a.each([b].concat(this._states.tags[b]||[]),a.proxy(function(a,b){this._states.current[b]--},this))},e.prototype.register=function(b){if(b.type===e.Type.Event){if(a.event.special[b.name]||(a.event.special[b.name]={}),!a.event.special[b.name].owl){var c=a.event.special[b.name]._default;a.event.special[b.name]._default=function(a){return!c||!c.apply||a.namespace&&-1!==a.namespace.indexOf("owl")?a.namespace&&a.namespace.indexOf("owl")>-1:c.apply(this,arguments)},a.event.special[b.name].owl=!0}}else b.type===e.Type.State&&(this._states.tags[b.name]?this._states.tags[b.name]=this._states.tags[b.name].concat(b.tags):this._states.tags[b.name]=b.tags,this._states.tags[b.name]=a.grep(this._states.tags[b.name],a.proxy(function(c,d){return a.inArray(c,this._states.tags[b.name])===d},this)))},e.prototype.suppress=function(b){a.each(b,a.proxy(function(a,b){this._supress[b]=!0},this))},e.prototype.release=function(b){a.each(b,a.proxy(function(a,b){delete this._supress[b]},this))},e.prototype.pointer=function(a){var c={x:null,y:null};return a=a.originalEvent||a||b.event,a=a.touches&&a.touches.length?a.touches[0]:a.changedTouches&&a.changedTouches.length?a.changedTouches[0]:a,a.pageX?(c.x=a.pageX,c.y=a.pageY):(c.x=a.clientX,c.y=a.clientY),c},e.prototype.isNumeric=function(a){return!isNaN(parseFloat(a))},e.prototype.difference=function(a,b){return{x:a.x-b.x,y:a.y-b.y}},a.fn.owlCarousel=function(b){var c=Array.prototype.slice.call(arguments,1);return this.each(function(){var d=a(this),f=d.data("owl.carousel");f||(f=new e(this,"object"==typeof b&&b),d.data("owl.carousel",f),a.each(["next","prev","to","destroy","refresh","replace","add","remove"],function(b,c){f.register({type:e.Type.Event,name:c}),f.$element.on(c+".owl.carousel.core",a.proxy(function(a){a.namespace&&a.relatedTarget!==this&&(this.suppress([c]),f[c].apply(this,[].slice.call(arguments,1)),this.release([c]))},f))})),"string"==typeof b&&"_"!==b.charAt(0)&&f[b].apply(f,c)})},a.fn.owlCarousel.Constructor=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._interval=null,this._visible=null,this._handlers={"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoRefresh&&this.watch()},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers)};e.Defaults={autoRefresh:!0,autoRefreshInterval:500},e.prototype.watch=function(){this._interval||(this._visible=this._core.isVisible(),this._interval=b.setInterval(a.proxy(this.refresh,this),this._core.settings.autoRefreshInterval))},e.prototype.refresh=function(){this._core.isVisible()!==this._visible&&(this._visible=!this._visible,this._core.$element.toggleClass("owl-hidden",!this._visible),this._visible&&this._core.invalidate("width")&&this._core.refresh())},e.prototype.destroy=function(){var a,c;b.clearInterval(this._interval);for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(c in Object.getOwnPropertyNames(this))"function"!=typeof this[c]&&(this[c]=null)},a.fn.owlCarousel.Constructor.Plugins.AutoRefresh=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._loaded=[],this._handlers={"initialized.owl.carousel change.owl.carousel resized.owl.carousel":a.proxy(function(b){if(b.namespace&&this._core.settings&&this._core.settings.lazyLoad&&(b.property&&"position"==b.property.name||"initialized"==b.type)){var c=this._core.settings,e=c.center&&Math.ceil(c.items/2)||c.items,f=c.center&&-1*e||0,g=(b.property&&b.property.value!==d?b.property.value:this._core.current())+f,h=this._core.clones().length,i=a.proxy(function(a,b){this.load(b)},this);for(c.lazyLoadEager>0&&(e+=c.lazyLoadEager,c.loop&&(g-=c.lazyLoadEager,e++));f++<e;)this.load(h/2+this._core.relative(g)),h&&a.each(this._core.clones(this._core.relative(g)),i),g++}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers)};e.Defaults={lazyLoad:!1,lazyLoadEager:0},e.prototype.load=function(c){var d=this._core.$stage.children().eq(c),e=d&&d.find(".owl-lazy");!e||a.inArray(d.get(0),this._loaded)>-1||(e.each(a.proxy(function(c,d){var e,f=a(d),g=b.devicePixelRatio>1&&f.attr("data-src-retina")||f.attr("data-src")||f.attr("data-srcset");this._core.trigger("load",{element:f,url:g},"lazy"),f.is("img")?f.one("load.owl.lazy",a.proxy(function(){f.css("opacity",1),this._core.trigger("loaded",{element:f,url:g},"lazy")},this)).attr("src",g):f.is("source")?f.one("load.owl.lazy",a.proxy(function(){this._core.trigger("loaded",{element:f,url:g},"lazy")},this)).attr("srcset",g):(e=new Image,e.onload=a.proxy(function(){f.css({"background-image":'url("'+g+'")',opacity:"1"}),this._core.trigger("loaded",{element:f,url:g},"lazy")},this),e.src=g)},this)),this._loaded.push(d.get(0)))},e.prototype.destroy=function(){var a,b;for(a in this.handlers)this._core.$element.off(a,this.handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Lazy=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(c){this._core=c,this._previousHeight=null,this._handlers={"initialized.owl.carousel refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&this.update()},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&"position"===a.property.name&&this.update()},this),"loaded.owl.lazy":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&a.element.closest("."+this._core.settings.itemClass).index()===this._core.current()&&this.update()},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers),this._intervalId=null;var d=this;a(b).on("load",function(){d._core.settings.autoHeight&&d.update()}),a(b).resize(function(){d._core.settings.autoHeight&&(null!=d._intervalId&&clearTimeout(d._intervalId),d._intervalId=setTimeout(function(){d.update()},250))})};e.Defaults={autoHeight:!1,autoHeightClass:"owl-height"},e.prototype.update=function(){var b=this._core._current,c=b+this._core.settings.items,d=this._core.settings.lazyLoad,e=this._core.$stage.children().toArray().slice(b,c),f=[],g=0;a.each(e,function(b,c){f.push(a(c).height())}),g=Math.max.apply(null,f),g<=1&&d&&this._previousHeight&&(g=this._previousHeight),this._previousHeight=g,this._core.$stage.parent().height(g).addClass(this._core.settings.autoHeightClass)},e.prototype.destroy=function(){var a,b;for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.AutoHeight=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._videos={},this._playing=null,this._handlers={"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.register({type:"state",name:"playing",tags:["interacting"]})},this),"resize.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.video&&this.isInFullScreen()&&a.preventDefault()},this),"refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.is("resizing")&&this._core.$stage.find(".cloned .owl-video-frame").remove()},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&"position"===a.property.name&&this._playing&&this.stop()},this),"prepared.owl.carousel":a.proxy(function(b){if(b.namespace){var c=a(b.content).find(".owl-video");c.length&&(c.css("display","none"),this.fetch(c,a(b.content)))}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers),this._core.$element.on("click.owl.video",".owl-video-play-icon",a.proxy(function(a){this.play(a)},this))};e.Defaults={video:!1,videoHeight:!1,videoWidth:!1},e.prototype.fetch=function(a,b){var c=function(){return a.attr("data-vimeo-id")?"vimeo":a.attr("data-vzaar-id")?"vzaar":"youtube"}(),d=a.attr("data-vimeo-id")||a.attr("data-youtube-id")||a.attr("data-vzaar-id"),e=a.attr("data-width")||this._core.settings.videoWidth,f=a.attr("data-height")||this._core.settings.videoHeight,g=a.attr("href");if(!g)throw new Error("Missing video URL.");if(d=g.match(/(http:|https:|)\/\/(player.|www.|app.)?(vimeo\.com|youtu(be\.com|\.be|be\.googleapis\.com|be\-nocookie\.com)|vzaar\.com)\/(video\/|videos\/|embed\/|channels\/.+\/|groups\/.+\/|watch\?v=|v\/)?([A-Za-z0-9._%-]*)(\&\S+)?/),d[3].indexOf("youtu")>-1)c="youtube";else if(d[3].indexOf("vimeo")>-1)c="vimeo";else{if(!(d[3].indexOf("vzaar")>-1))throw new Error("Video URL not supported.");c="vzaar"}d=d[6],this._videos[g]={type:c,id:d,width:e,height:f},b.attr("data-video",g),this.thumbnail(a,this._videos[g])},e.prototype.thumbnail=function(b,c){var d,e,f,g=c.width&&c.height?"width:"+c.width+"px;height:"+c.height+"px;":"",h=b.find("img"),i="src",j="",k=this._core.settings,l=function(c){e='<div class="owl-video-play-icon"></div>',d=k.lazyLoad?a("<div/>",{class:"owl-video-tn "+j,srcType:c}):a("<div/>",{class:"owl-video-tn",style:"opacity:1;background-image:url("+c+")"}),b.after(d),b.after(e)};if(b.wrap(a("<div/>",{class:"owl-video-wrapper",style:g})),this._core.settings.lazyLoad&&(i="data-src",j="owl-lazy"),h.length)return l(h.attr(i)),h.remove(),!1;"youtube"===c.type?(f="//img.youtube.com/vi/"+c.id+"/hqdefault.jpg",l(f)):"vimeo"===c.type?a.ajax({type:"GET",url:"//vimeo.com/api/v2/video/"+c.id+".json",jsonp:"callback",dataType:"jsonp",success:function(a){f=a[0].thumbnail_large,l(f)}}):"vzaar"===c.type&&a.ajax({type:"GET",url:"//vzaar.com/api/videos/"+c.id+".json",jsonp:"callback",dataType:"jsonp",success:function(a){f=a.framegrab_url,l(f)}})},e.prototype.stop=function(){this._core.trigger("stop",null,"video"),this._playing.find(".owl-video-frame").remove(),this._playing.removeClass("owl-video-playing"),this._playing=null,this._core.leave("playing"),this._core.trigger("stopped",null,"video")},e.prototype.play=function(b){var c,d=a(b.target),e=d.closest("."+this._core.settings.itemClass),f=this._videos[e.attr("data-video")],g=f.width||"100%",h=f.height||this._core.$stage.height();this._playing||(this._core.enter("playing"),this._core.trigger("play",null,"video"),e=this._core.items(this._core.relative(e.index())),this._core.reset(e.index()),c=a('<iframe frameborder="0" allowfullscreen mozallowfullscreen webkitAllowFullScreen ></iframe>'),c.attr("height",h),c.attr("width",g),"youtube"===f.type?c.attr("src","//www.youtube.com/embed/"+f.id+"?autoplay=1&rel=0&v="+f.id):"vimeo"===f.type?c.attr("src","//player.vimeo.com/video/"+f.id+"?autoplay=1"):"vzaar"===f.type&&c.attr("src","//view.vzaar.com/"+f.id+"/player?autoplay=true"),a(c).wrap('<div class="owl-video-frame" />').insertAfter(e.find(".owl-video")),this._playing=e.addClass("owl-video-playing"))},e.prototype.isInFullScreen=function(){var b=c.fullscreenElement||c.mozFullScreenElement||c.webkitFullscreenElement;return b&&a(b).parent().hasClass("owl-video-frame")},e.prototype.destroy=function(){var a,b;this._core.$element.off("click.owl.video");for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Video=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this.core=b,this.core.options=a.extend({},e.Defaults,this.core.options),this.swapping=!0,this.previous=d,this.next=d,this.handlers={"change.owl.carousel":a.proxy(function(a){a.namespace&&"position"==a.property.name&&(this.previous=this.core.current(),this.next=a.property.value)},this),"drag.owl.carousel dragged.owl.carousel translated.owl.carousel":a.proxy(function(a){a.namespace&&(this.swapping="translated"==a.type)},this),"translate.owl.carousel":a.proxy(function(a){a.namespace&&this.swapping&&(this.core.options.animateOut||this.core.options.animateIn)&&this.swap()},this)},this.core.$element.on(this.handlers)};e.Defaults={animateOut:!1,
animateIn:!1},e.prototype.swap=function(){if(1===this.core.settings.items&&a.support.animation&&a.support.transition){this.core.speed(0);var b,c=a.proxy(this.clear,this),d=this.core.$stage.children().eq(this.previous),e=this.core.$stage.children().eq(this.next),f=this.core.settings.animateIn,g=this.core.settings.animateOut;this.core.current()!==this.previous&&(g&&(b=this.core.coordinates(this.previous)-this.core.coordinates(this.next),d.one(a.support.animation.end,c).css({left:b+"px"}).addClass("animated owl-animated-out").addClass(g)),f&&e.one(a.support.animation.end,c).addClass("animated owl-animated-in").addClass(f))}},e.prototype.clear=function(b){a(b.target).css({left:""}).removeClass("animated owl-animated-out owl-animated-in").removeClass(this.core.settings.animateIn).removeClass(this.core.settings.animateOut),this.core.onTransitionEnd()},e.prototype.destroy=function(){var a,b;for(a in this.handlers)this.core.$element.off(a,this.handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Animate=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._call=null,this._time=0,this._timeout=0,this._paused=!0,this._handlers={"changed.owl.carousel":a.proxy(function(a){a.namespace&&"settings"===a.property.name?this._core.settings.autoplay?this.play():this.stop():a.namespace&&"position"===a.property.name&&this._paused&&(this._time=0)},this),"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoplay&&this.play()},this),"play.owl.autoplay":a.proxy(function(a,b,c){a.namespace&&this.play(b,c)},this),"stop.owl.autoplay":a.proxy(function(a){a.namespace&&this.stop()},this),"mouseover.owl.autoplay":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.pause()},this),"mouseleave.owl.autoplay":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.play()},this),"touchstart.owl.core":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.pause()},this),"touchend.owl.core":a.proxy(function(){this._core.settings.autoplayHoverPause&&this.play()},this)},this._core.$element.on(this._handlers),this._core.options=a.extend({},e.Defaults,this._core.options)};e.Defaults={autoplay:!1,autoplayTimeout:5e3,autoplayHoverPause:!1,autoplaySpeed:!1},e.prototype._next=function(d){this._call=b.setTimeout(a.proxy(this._next,this,d),this._timeout*(Math.round(this.read()/this._timeout)+1)-this.read()),this._core.is("interacting")||c.hidden||this._core.next(d||this._core.settings.autoplaySpeed)},e.prototype.read=function(){return(new Date).getTime()-this._time},e.prototype.play=function(c,d){var e;this._core.is("rotating")||this._core.enter("rotating"),c=c||this._core.settings.autoplayTimeout,e=Math.min(this._time%(this._timeout||c),c),this._paused?(this._time=this.read(),this._paused=!1):b.clearTimeout(this._call),this._time+=this.read()%c-e,this._timeout=c,this._call=b.setTimeout(a.proxy(this._next,this,d),c-e)},e.prototype.stop=function(){this._core.is("rotating")&&(this._time=0,this._paused=!0,b.clearTimeout(this._call),this._core.leave("rotating"))},e.prototype.pause=function(){this._core.is("rotating")&&!this._paused&&(this._time=this.read(),this._paused=!0,b.clearTimeout(this._call))},e.prototype.destroy=function(){var a,b;this.stop();for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.autoplay=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){"use strict";var e=function(b){this._core=b,this._initialized=!1,this._pages=[],this._controls={},this._templates=[],this.$element=this._core.$element,this._overrides={next:this._core.next,prev:this._core.prev,to:this._core.to},this._handlers={"prepared.owl.carousel":a.proxy(function(b){b.namespace&&this._core.settings.dotsData&&this._templates.push('<div class="'+this._core.settings.dotClass+'">'+a(b.content).find("[data-dot]").addBack("[data-dot]").attr("data-dot")+"</div>")},this),"added.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.dotsData&&this._templates.splice(a.position,0,this._templates.pop())},this),"remove.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.dotsData&&this._templates.splice(a.position,1)},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&"position"==a.property.name&&this.draw()},this),"initialized.owl.carousel":a.proxy(function(a){a.namespace&&!this._initialized&&(this._core.trigger("initialize",null,"navigation"),this.initialize(),this.update(),this.draw(),this._initialized=!0,this._core.trigger("initialized",null,"navigation"))},this),"refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._initialized&&(this._core.trigger("refresh",null,"navigation"),this.update(),this.draw(),this._core.trigger("refreshed",null,"navigation"))},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this.$element.on(this._handlers)};e.Defaults={nav:!1,navText:['<span aria-label="Previous">&#x2039;</span>','<span aria-label="Next">&#x203a;</span>'],navSpeed:!1,navElement:'button type="button" role="presentation"',navContainer:!1,navContainerClass:"owl-nav",navClass:["owl-prev","owl-next"],slideBy:1,dotClass:"owl-dot",dotsClass:"owl-dots",dots:!0,dotsEach:!1,dotsData:!1,dotsSpeed:!1,dotsContainer:!1},e.prototype.initialize=function(){var b,c=this._core.settings;this._controls.$relative=(c.navContainer?a(c.navContainer):a("<div>").addClass(c.navContainerClass).appendTo(this.$element)).addClass("disabled"),this._controls.$previous=a("<"+c.navElement+">").addClass(c.navClass[0]).html(c.navText[0]).prependTo(this._controls.$relative).on("click",a.proxy(function(a){this.prev(c.navSpeed)},this)),this._controls.$next=a("<"+c.navElement+">").addClass(c.navClass[1]).html(c.navText[1]).appendTo(this._controls.$relative).on("click",a.proxy(function(a){this.next(c.navSpeed)},this)),c.dotsData||(this._templates=[a('<button role="button">').addClass(c.dotClass).append(a("<span>")).prop("outerHTML")]),this._controls.$absolute=(c.dotsContainer?a(c.dotsContainer):a("<div>").addClass(c.dotsClass).appendTo(this.$element)).addClass("disabled"),this._controls.$absolute.on("click","button",a.proxy(function(b){var d=a(b.target).parent().is(this._controls.$absolute)?a(b.target).index():a(b.target).parent().index();b.preventDefault(),this.to(d,c.dotsSpeed)},this));for(b in this._overrides)this._core[b]=a.proxy(this[b],this)},e.prototype.destroy=function(){var a,b,c,d,e;e=this._core.settings;for(a in this._handlers)this.$element.off(a,this._handlers[a]);for(b in this._controls)"$relative"===b&&e.navContainer?this._controls[b].html(""):this._controls[b].remove();for(d in this.overides)this._core[d]=this._overrides[d];for(c in Object.getOwnPropertyNames(this))"function"!=typeof this[c]&&(this[c]=null)},e.prototype.update=function(){var a,b,c,d=this._core.clones().length/2,e=d+this._core.items().length,f=this._core.maximum(!0),g=this._core.settings,h=g.center||g.autoWidth||g.dotsData?1:g.dotsEach||g.items;if("page"!==g.slideBy&&(g.slideBy=Math.min(g.slideBy,g.items)),g.dots||"page"==g.slideBy)for(this._pages=[],a=d,b=0,c=0;a<e;a++){if(b>=h||0===b){if(this._pages.push({start:Math.min(f,a-d),end:a-d+h-1}),Math.min(f,a-d)===f)break;b=0,++c}b+=this._core.mergers(this._core.relative(a))}},e.prototype.draw=function(){var b,c=this._core.settings,d=this._core.items().length<=c.items,e=this._core.relative(this._core.current()),f=c.loop||c.rewind;this._controls.$relative.toggleClass("disabled",!c.nav||d),c.nav&&(this._controls.$previous.toggleClass("disabled",!f&&e<=this._core.minimum(!0)),this._controls.$next.toggleClass("disabled",!f&&e>=this._core.maximum(!0))),this._controls.$absolute.toggleClass("disabled",!c.dots||d),c.dots&&(b=this._pages.length-this._controls.$absolute.children().length,c.dotsData&&0!==b?this._controls.$absolute.html(this._templates.join("")):b>0?this._controls.$absolute.append(new Array(b+1).join(this._templates[0])):b<0&&this._controls.$absolute.children().slice(b).remove(),this._controls.$absolute.find(".active").removeClass("active"),this._controls.$absolute.children().eq(a.inArray(this.current(),this._pages)).addClass("active"))},e.prototype.onTrigger=function(b){var c=this._core.settings;b.page={index:a.inArray(this.current(),this._pages),count:this._pages.length,size:c&&(c.center||c.autoWidth||c.dotsData?1:c.dotsEach||c.items)}},e.prototype.current=function(){var b=this._core.relative(this._core.current());return a.grep(this._pages,a.proxy(function(a,c){return a.start<=b&&a.end>=b},this)).pop()},e.prototype.getPosition=function(b){var c,d,e=this._core.settings;return"page"==e.slideBy?(c=a.inArray(this.current(),this._pages),d=this._pages.length,b?++c:--c,c=this._pages[(c%d+d)%d].start):(c=this._core.relative(this._core.current()),d=this._core.items().length,b?c+=e.slideBy:c-=e.slideBy),c},e.prototype.next=function(b){a.proxy(this._overrides.to,this._core)(this.getPosition(!0),b)},e.prototype.prev=function(b){a.proxy(this._overrides.to,this._core)(this.getPosition(!1),b)},e.prototype.to=function(b,c,d){var e;!d&&this._pages.length?(e=this._pages.length,a.proxy(this._overrides.to,this._core)(this._pages[(b%e+e)%e].start,c)):a.proxy(this._overrides.to,this._core)(b,c)},a.fn.owlCarousel.Constructor.Plugins.Navigation=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){"use strict";var e=function(c){this._core=c,this._hashes={},this.$element=this._core.$element,this._handlers={"initialized.owl.carousel":a.proxy(function(c){c.namespace&&"URLHash"===this._core.settings.startPosition&&a(b).trigger("hashchange.owl.navigation")},this),"prepared.owl.carousel":a.proxy(function(b){if(b.namespace){var c=a(b.content).find("[data-hash]").addBack("[data-hash]").attr("data-hash");if(!c)return;this._hashes[c]=b.content}},this),"changed.owl.carousel":a.proxy(function(c){if(c.namespace&&"position"===c.property.name){var d=this._core.items(this._core.relative(this._core.current())),e=a.map(this._hashes,function(a,b){return a===d?b:null}).join();if(!e||b.location.hash.slice(1)===e)return;b.location.hash=e}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this.$element.on(this._handlers),a(b).on("hashchange.owl.navigation",a.proxy(function(a){var c=b.location.hash.substring(1),e=this._core.$stage.children(),f=this._hashes[c]&&e.index(this._hashes[c]);f!==d&&f!==this._core.current()&&this._core.to(this._core.relative(f),!1,!0)},this))};e.Defaults={URLhashListener:!1},e.prototype.destroy=function(){var c,d;a(b).off("hashchange.owl.navigation");for(c in this._handlers)this._core.$element.off(c,this._handlers[c]);for(d in Object.getOwnPropertyNames(this))"function"!=typeof this[d]&&(this[d]=null)},a.fn.owlCarousel.Constructor.Plugins.Hash=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){function e(b,c){var e=!1,f=b.charAt(0).toUpperCase()+b.slice(1);return a.each((b+" "+h.join(f+" ")+f).split(" "),function(a,b){if(g[b]!==d)return e=!c||b,!1}),e}function f(a){return e(a,!0)}var g=a("<support>").get(0).style,h="Webkit Moz O ms".split(" "),i={transition:{end:{WebkitTransition:"webkitTransitionEnd",MozTransition:"transitionend",OTransition:"oTransitionEnd",transition:"transitionend"}},animation:{end:{WebkitAnimation:"webkitAnimationEnd",MozAnimation:"animationend",OAnimation:"oAnimationEnd",animation:"animationend"}}},j={csstransforms:function(){return!!e("transform")},csstransforms3d:function(){return!!e("perspective")},csstransitions:function(){return!!e("transition")},cssanimations:function(){return!!e("animation")}};j.csstransitions()&&(a.support.transition=new String(f("transition")),a.support.transition.end=i.transition.end[a.support.transition]),j.cssanimations()&&(a.support.animation=new String(f("animation")),a.support.animation.end=i.animation.end[a.support.animation]),j.csstransforms()&&(a.support.transform=new String(f("transform")),a.support.transform3d=j.csstransforms3d())}(window.Zepto||window.jQuery,window,document);(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    $(function() {
      var $this ,$scroll;
      var $articleContent = $('.js-article-content');
      var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
      var scroll = hasSidebar ? '.js-page-main' : 'html, body';
      $scroll = $(scroll);

      $articleContent.find('.highlight').each(function() {
        $this = $(this);
        $this.attr('data-lang', $this.find('code').attr('data-lang'));
      });
      $articleContent.find('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]').each(function() {
        $this = $(this);
        $this.append($('<a class="anchor d-print-none" aria-hidden="true"></a>').html('<i class="fas fa-anchor"></i>'));
      });
      $articleContent.on('click', '.anchor', function() {
        $scroll.scrollToAnchor('#' + $(this).parent().attr('id'), 400);
      });
    });
  });
})();

$(document).ready(function () {

  /* Versions Pagination*/
  $('.pagination_big').owlCarousel({
      margin:10,
      nav:true,
      dots:false,
      responsive:{
          0:{
              items:3
          },
          400:{
              items:4
          },
          500:{
              items:6
          },
          1600:{
              items:11
          }
      }
  });
});

</script></div><section class="page__comments d-print-none"></section></article><!-- start custom main bottom snippet -->

<!-- end custom main bottom snippet --></div>
            </div></div></div><div class="page__footer d-print-none">
<footer class="footer py-4 js-page-footer">
  <div class="main"><div itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content=""><meta itemprop="url" content="/"></div><div class="site-info mt-2">
      <div>© 2022 John Snow Labs Inc.
        <a href="http://www.johnsnowlabs.com/terms-of-service">Terms of Service</a> | <a href="http://www.johnsnowlabs.com/privacy-policy/">Privacy Policy</a>
      </div>
    </div>
  </div>
</footer>

<script>

/* Responsive menu
	 ========================================================*/
jQuery(document).ready(function($) {
	jQuery('#responsive_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.top_navigation').toggleClass('open');
  });
  jQuery('#aside_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.js-col-aside').toggleClass('open');
      if (jQuery(window).width() <= 1023)
      {
        jQuery('.page__sidebar').toggleClass('open'); 
      jQuery('.demomenu').toggleClass('open');
      }
  });
  jQuery('.toc--ellipsis a').click(function(e) {
    if (jQuery(window).width() <= 767)
      {
        jQuery('.js-col-aside').removeClass('open');
        jQuery('.page__sidebar').removeClass('open');    
        jQuery('#aside_menu').removeClass('close');  
      }       
  });
});

/*OPen by URL*/
jQuery(document).ready(function () {  
  const tabName = (window.location.hash || '').replace('#', '');
  const tab = document.getElementById(tabName || 'opensource');
  if (tab) {
    tab.click();
  }
});

//Accordion demos categories
if(document.querySelector(".acc-top")) {
  let acc = document.getElementsByClassName("acc-top"),
    isResizeble = false;

  if(!isResizeble && document.querySelector(".acc-top")) {
      let accBody = document.querySelector('.acc-body li.active');
      accBody.parentElement.style.maxHeight = accBody.parentElement.scrollHeight + 20 + "px";
      accBody.parentElement.classList.add('open');
      accBody.parentElement.previousElementSibling.classList.add('active');
      isResizeble = true;
  }

for (let i = 0; i < acc.length; i++) {
  acc[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var panel = this.nextElementSibling;
    if (panel.style.maxHeight) {
      panel.style.maxHeight = null;
      panel.classList.remove('open');
    } else {
      panel.style.maxHeight = panel.scrollHeight + 20 + "px";
      panel.classList.add('open');
    }
  });
}
}


//Show more in demos description
if(document.querySelector('.tab-description')) {
  let tabDescription = document.querySelectorAll('.tab-description');

  tabDescription.forEach(element => {
    let tabDescriptionInner = element.querySelector('.tab-description-inner');
    if(element.offsetHeight < tabDescriptionInner.offsetHeight) {
      element.classList.add('big-descr');
    }
  });

  let showMore = document.querySelectorAll('.show_more');

  showMore.forEach(element => {
    element.addEventListener("click", function(e) {
      e.preventDefault();
      this.parentElement.parentElement.classList.remove('big-descr');
      this.parentElement.parentElement.classList.add('big-descr-close');
    });
  });
}


//disable Colab link
if(document.querySelector('.btn.disable')) {
  let btnDisable = document.querySelectorAll('.btn.disable');

  btnDisable.forEach(element => {
    element.addEventListener("click", function(e) {
      e.preventDefault();
    });
  });
}


// Ancor click
const anchors = [].slice.call(document.querySelectorAll('.btn-box-install a')),
      animationTime = 300,
      framesCount = 20;

anchors.forEach(function(item) {
    item.addEventListener('click', function(e) {
        e.preventDefault();
        let coordY = document.querySelector(item.getAttribute('href')).getBoundingClientRect().top + window.pageYOffset -100;
    
        let scroller = setInterval(function() {
            let scrollBy = coordY / framesCount;
      
      if(scrollBy > window.pageYOffset - coordY && window.innerHeight + window.pageYOffset < document.body.offsetHeight) {
          window.scrollBy(0, scrollBy);
      } else {
                window.scrollTo(0, coordY);
        clearInterval(scroller);
      }
        }, animationTime / framesCount);
  });
}); 


//Pagination active
if(document.querySelector('.pagination_big')) {
  let paginationItems = document.querySelectorAll('.pagination_big li'),
      nextVersionContainer = document.querySelector('#nextver'),
      previosVersionContainer = document.querySelector('#previosver'),
      currentVersionContainer = document.querySelector('#currversion'),
      currentPageTitle = document.querySelector('#section').innerText;

  // Set active page and update version containers
  for (let i = 0; i < paginationItems.length; i++) {
    const item = paginationItems[i];
    const itemTitle = item.firstElementChild.innerHTML;
    if (itemTitle === currentPageTitle) {
      item.classList.add('active');
      currentVersionContainer.textContent = itemTitle;       
      if(item.previousElementSibling) {
        previosVersionContainer.textContent = item.previousElementSibling.innerText; 
        previosVersionContainer.parentElement.href += item.previousElementSibling.innerText.replaceAll('.', '_');
      } else {
        previosVersionContainer.parentElement.parentElement.classList.add('hide');
      }
      if(item.nextElementSibling) {
        nextVersionContainer.textContent = item.nextElementSibling.innerText;
        nextVersionContainer.parentElement.href += item.nextElementSibling.innerText.replaceAll('.', '_');
      } else {
        nextVersionContainer.parentElement.parentElement.classList.add('hide');
      }         
      break;
    }
  }
}
// copy to clipboard
if (document.querySelector('.button-copy-s3')) {
  let btnCopy = document.querySelectorAll('.button-copy-s3');

  btnCopy.forEach((element) => {
    //add span Copied!
    element.insertAdjacentHTML('beforeend', '<span>Copied!</span>');

    element.addEventListener('click', function (e) {
      e.preventDefault();
      element.classList.add('copied');
      setTimeout(function () {
        element.classList.remove('copied');
      }, 3000);
      navigator.clipboard.writeText(element.href);
    });
  });
}


</script></div></div>
    </div></div></div><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $body = $('body'), $window = $(window);
    var $pageRoot = $('.js-page-root'), $pageMain = $('.js-page-main');
    var activeCount = 0;
    function modal(options) {
      var $root = this, visible, onChange, hideWhenWindowScroll = false;
      var scrollTop;
      function setOptions(options) {
        var _options = options || {};
        visible = _options.initialVisible === undefined ? false : show;
        onChange = _options.onChange;
        hideWhenWindowScroll = _options.hideWhenWindowScroll;
      }
      function init() {
        setState(visible);
      }
      function setState(isShow) {
        if (isShow === visible) {
          return;
        }
        visible = isShow;
        if (visible) {
          activeCount++;
          scrollTop = $(window).scrollTop() || $pageMain.scrollTop();
          $root.addClass('modal--show');
          $pageMain.scrollTop(scrollTop);
          activeCount === 1 && ($pageRoot.addClass('show-modal'), $body.addClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.on('scroll', hide);
          $window.on('keyup', handleKeyup);
        } else {
          activeCount > 0 && activeCount--;
          $root.removeClass('modal--show');
          $window.scrollTop(scrollTop);
          activeCount === 0 && ($pageRoot.removeClass('show-modal'), $body.removeClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.off('scroll', hide);
          $window.off('keyup', handleKeyup);
        }
        onChange && onChange(visible);
      }
      function show() {
        setState(true);
      }
      function hide() {
        setState(false);
      }
      function handleKeyup(e) {
        // Char Code: 27  ESC
        if (e.which ===  27) {
          hide();
        }
      }
      setOptions(options);
      init();
      return {
        show: show,
        hide: hide,
        $el: $root
      };
    }
    $.fn.modal = modal;
  });
})();
</script><div class="modal modal--overflow page__search-modal d-print-none js-page-search-modal"></div></div>


<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function scrollToAnchor(anchor, duration, callback) {
      var $root = this;
      $root.animate({ scrollTop: $(anchor).position().top }, duration, function() {
        window.history.replaceState(null, '', window.location.href.split('#')[0] + anchor);
        callback && callback();
      });
    }
    $.fn.scrollToAnchor = scrollToAnchor;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function affix(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroll,
        offsetBottom = 0, scrollTarget = window, scroll = window.document, disabled = false, isOverallScroller = true,
        rootTop, rootLeft, rootHeight, scrollBottom, rootBottomTop,
        hasInit = false, curState;

      function setOptions(options) {
        var _options = options || {};
        _options.offsetBottom && (offsetBottom = _options.offsetBottom);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroll && (scroll = _options.scroll);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $scrollTarget = $(scrollTarget);
        isOverallScroller = window.isOverallScroller($scrollTarget[0]);
        $scroll = $(scroll);
      }
      function preCalc() {
        top();
        rootHeight = $root.outerHeight();
        rootTop = $root.offset().top + (isOverallScroller ? 0 :  $scrollTarget.scrollTop());
        rootLeft = $root.offset().left;
      }
      function calc(needPreCalc) {
        needPreCalc && preCalc();
        scrollBottom = $scroll.outerHeight() - offsetBottom - rootHeight;
        rootBottomTop = scrollBottom - rootTop;
      }
      function top() {
        if (curState !== 'top') {
          $root.removeClass('fixed').css({
            left: 0,
            top: 0
          });
          curState = 'top';
        }
      }
      function fixed() {
        if (curState !== 'fixed') {
          $root.addClass('fixed').css({
            left: rootLeft + 'px',
            top: 0
          });
          curState = 'fixed';
        }
      }
      function bottom() {
        if (curState !== 'bottom') {
          $root.removeClass('fixed').css({
            left: 0,
            top: rootBottomTop + 'px'
          });
          curState = 'bottom';
        }
      }
      function setState() {
        var scrollTop = $scrollTarget.scrollTop();
        if (scrollTop >= rootTop && scrollTop <= scrollBottom) {
          fixed();
        } else if (scrollTop < rootTop) {
          top();
        } else {
          bottom();
        }
      }
      function init() {
        if(!hasInit) {
          var interval, timeout;
          calc(true); setState();
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState();
          });
          $window.on('resize', function() {
            disabled || (calc(true), setState());
          });
          hasInit = true;
        }
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions,
        refresh: function() {
          calc(true, { animation: false }); setState();
        }
      };
    }
    $.fn.affix = affix;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function toc(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroller, $tocUl = $('<ul class="toc toc--ellipsis"></ul>'), $tocLi, $headings, $activeLast, $activeCur,
        selectors = 'h1,h2,h3',  container = 'body', scrollTarget = window, scroller = 'html, body', disabled = false,
        headingsPos, scrolling = false, hasRendered = false, hasInit = false;

        

      function setOptions(options) {
        var _options = options || {};
        _options.selectors && (selectors = _options.selectors);
        _options.container && (container = _options.container);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroller && (scroller = _options.scroller);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $headings = $(container).find(selectors).filter('[id]');
        $scrollTarget = $(scrollTarget);
        $scroller = $(scroller);
      }
      function calc() {
        headingsPos = [];
        $headings.each(function() {
          headingsPos.push(Math.floor($(this).position().top));
        });
      }
      function setState(element, disabled) {
        var scrollTop = $scrollTarget.scrollTop(), i;
        if (disabled || !headingsPos || headingsPos.length < 1) { return; }
        if (element) {
          $activeCur = element;
        } else {
          for (i = 0; i < headingsPos.length; i++) {
            if (scrollTop >= headingsPos[i]) {
              $activeCur = $tocLi.eq(i);
            } else {
              $activeCur || ($activeCur = $tocLi.eq(i));
              break;
            }
          }
        }
        $activeLast && $activeLast.removeClass('active');
        ($activeLast = $activeCur).addClass('active');
      }
      function render() {
        if(!hasRendered) {
          $root.append($tocUl);
          $headings.each(function() {
            var $this = $(this);
            $tocUl.append($('<li></li>').addClass('toc-' + $this.prop('tagName')
              .toLowerCase() + ' ' + $this.prop('className'))
              .append($('<a></a>').text($this.text()).attr('href', '#' + $this.prop('id'))));
          });
          $tocLi = $tocUl.children('li');
          $tocUl.on('click', 'a', function(e) {
            e.preventDefault();
            var $this = $(this);
            scrolling = true;
            setState($this.parent());
            $scroller.scrollToAnchor($this.attr('href'), 400, function() {
              scrolling = false;
            });
          });
        }
        hasRendered = true;
      }
      function init() {
        var interval, timeout;
        if(!hasInit) {
          render(); calc(); setState(null, scrolling);
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState(null, scrolling);
          });
          $window.on('resize', window.throttle(function() {
            if (!disabled) {
              render(); calc(); setState(null, scrolling);
            }
          }, 100));
        }
        hasInit = true;
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions
      };
    }
    $.fn.toc = toc;
  });
})();
/*(function () {

})();*/
</script><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;

  window.Lazyload.js(SOURCES.jquery, function() {
    var $pageMask = $('.js-page-mask');
    var $pageRoot = $('.js-page-root');
    var $sidebarShow = $('.js-sidebar-show');
    var $sidebarHide = $('.js-sidebar-hide');

    function freeze(e) {
      if (e.target === $pageMask[0]) {
        e.preventDefault();
      }
    }
    function stopBodyScrolling(bool) {
      if (bool === true) {
        window.addEventListener('touchmove', freeze, { passive: false });
      } else {
        window.removeEventListener('touchmove', freeze, { passive: false });
      }
    }

    $sidebarShow.on('click', function() {
      stopBodyScrolling(true); $pageRoot.addClass('show-sidebar');
    });
    $sidebarHide.on('click', function() {
      stopBodyScrolling(false); $pageRoot.removeClass('show-sidebar');
    });
  });
})();
</script><script>
  /* toc must before affix, since affix need to konw toc' height. */(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  var TOC_SELECTOR = window.TEXT_VARIABLES.site.toc.selectors;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window);
    var $articleContent = $('.js-article-content');
    var $tocRoot = $('.js-toc-root'), $col2 = $('.js-col-aside');
    var toc;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
    var hasToc = $articleContent.find(TOC_SELECTOR).length > 0;

    function disabled() {
      return $col2.css('display') === 'none' || !hasToc;
    }

    tocDisabled = disabled();

    toc = $tocRoot.toc({
      selectors: TOC_SELECTOR,
      container: $articleContent,
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      tocDisabled = disabled();
      toc && toc.setOptions({
        disabled: tocDisabled
      });
    }, 100));

  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window), $pageFooter = $('.js-page-footer');
    var $pageAside = $('.js-page-aside');
    var affix;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');

    affix = $pageAside.affix({
      offsetBottom: $pageFooter.outerHeight(),
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      scroll: hasSidebar ? $('.js-page-main').children() : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      affix && affix.setOptions({
        disabled: tocDisabled
      });
    }, 100));

    window.pageAsideAffix = affix;
  });
})();
</script>
    </div>
    <script>(function () {
  var $root = document.getElementsByClassName('root')[0];
  if (window.hasEvent('touchstart')) {
    $root.dataset.isTouch = true;
    document.addEventListener('touchstart', function(){}, false);
  }
})();
</script>
  </body>
</html>