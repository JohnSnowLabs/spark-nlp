<!DOCTYPE html><html lang="en">
  <head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-59JLR64');</script>
<!-- End Google Tag Manager --><title>Spark NLP for Healthcare Annotators - Spark NLP</title><meta name="description" content="High Performance NLP with Apache Spark
">
<link rel="canonical" href="/docs/en/licensed_annotators"><link rel="alternate" type="application/rss+xml" title="Spark NLP" href="/feed.xml"><!-- start favicons snippet, use https://realfavicongenerator.net/ -->
<!---->
<!-- <link rel="apple-touch-icon" sizes="180x180" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="32x32" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="16x16" href="/fav.ico"> -->

<!---->
<!-- <link rel="manifest" href="/fav.ico"> --><link rel="mask-icon" href="/fav.ico" color="#fc4d50"><link rel="shortcut icon" href="/fav.ico">

<meta name="msapplication-TileColor" content="#ffc40d"><meta name="msapplication-config" content="/assets/browserconfig.xml">

<meta name="theme-color" content="#ffffff">
<!-- end favicons snippet --><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" ><!-- start custom head snippets -->
 <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800&display=swap" rel="stylesheet"> 
 <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
<!-- end custom head snippets -->
<script>(function() {
  window.isArray = function(val) {
    return Object.prototype.toString.call(val) === '[object Array]';
  };
  window.isString = function(val) {
    return typeof val === 'string';
  };

  window.decodeUrl = function(str) {
    return str ? decodeURIComponent(str.replace(/\+/g, '%20')) : '';
  };

  window.hasEvent = function(event) {
    return 'on'.concat(event) in window.document;
  };

  window.isOverallScroller = function(node) {
    return node === document.documentElement || node === document.body || node === window;
  };

  window.isFormElement = function(node) {
    var tagName = node.tagName;
    return tagName === 'INPUT' || tagName === 'SELECT' || tagName === 'TEXTAREA';
  };

  window.pageLoad = (function () {
    var loaded = false, cbs = [];
    window.addEventListener('load', function () {
      var i;
      loaded = true;
      if (cbs.length > 0) {
        for (i = 0; i < cbs.length; i++) {
          cbs[i]();
        }
      }
    });
    return {
      then: function(cb) {
        cb && (loaded ? cb() : (cbs.push(cb)));
      }
    };
  })();
})();
(function() {
  window.throttle = function(func, wait) {
    var args, result, thisArg, timeoutId, lastCalled = 0;

    function trailingCall() {
      lastCalled = new Date;
      timeoutId = null;
      result = func.apply(thisArg, args);
    }
    return function() {
      var now = new Date,
        remaining = wait - (now - lastCalled);

      args = arguments;
      thisArg = this;

      if (remaining <= 0) {
        clearTimeout(timeoutId);
        timeoutId = null;
        lastCalled = now;
        result = func.apply(thisArg, args);
      } else if (!timeoutId) {
        timeoutId = setTimeout(trailingCall, remaining);
      }
      return result;
    };
  };
})();
(function() {
  var Set = (function() {
    var add = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (data[i] === item) {
          return;
        }
      }
      this.size ++;
      data.push(item);
      return data;
    };

    var Set = function(data) {
      this.size = 0;
      this._data = [];
      var i;
      if (data.length > 0) {
        for (i = 0; i < data.length; i++) {
          add.call(this, data[i]);
        }
      }
    };
    Set.prototype.add = add;
    Set.prototype.get = function(index) { return this._data[index]; };
    Set.prototype.has = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (this.get(i) === item) {
          return true;
        }
      }
      return false;
    };
    Set.prototype.is = function(map) {
      if (map._data.length !== this._data.length) { return false; }
      var i, j, flag, tData = this._data, mData = map._data;
      for (i = 0; i < tData.length; i++) {
        for (flag = false, j = 0; j < mData.length; j++) {
          if (tData[i] === mData[j]) {
            flag = true;
            break;
          }
        }
        if (!flag) { return false; }
      }
      return true;
    };
    Set.prototype.values = function() {
      return this._data;
    };
    return Set;
  })();

  window.Lazyload = (function(doc) {
    var queue = {js: [], css: []}, sources = {js: {}, css: {}}, context = this;
    var createNode = function(name, attrs) {
      var node = doc.createElement(name), attr;
      for (attr in attrs) {
        if (attrs.hasOwnProperty(attr)) {
          node.setAttribute(attr, attrs[attr]);
        }
      }
      return node;
    };
    var end = function(type, url) {
      var s, q, qi, cbs, i, j, cur, val, flag;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        s[url] = true;
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (cur.urls.has(url)) {
            qi = cur, val = qi.urls.values();
            qi && (cbs = qi.callbacks);
            for (flag = true, j = 0; j < val.length; j++) {
              cur = val[j];
              if (!s[cur]) {
                flag = false;
              }
            }
            if (flag && cbs && cbs.length > 0) {
              for (j = 0; j < cbs.length; j++) {
                cbs[j].call(context);
              }
              qi.load = true;
            }
          }
        }
      }
    };
    var load = function(type, urls, callback) {
      var s, q, qi, node, i, cur,
        _urls = typeof urls === 'string' ? new Set([urls]) : new Set(urls), val, url;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (_urls.is(cur.urls)) {
            qi = cur;
            break;
          }
        }
        val = _urls.values();
        if (qi) {
          callback && (qi.load || qi.callbacks.push(callback));
          callback && (qi.load && callback());
        } else {
          q.push({
            urls: _urls,
            callbacks: callback ? [callback] : [],
            load: false
          });
          for (i = 0; i < val.length; i++) {
            node = null, url = val[i];
            if (s[url] === undefined) {
              (type === 'js' ) && (node = createNode('script', { src: url }));
              (type === 'css') && (node = createNode('link', { rel: 'stylesheet', href: url }));
              if (node) {
                node.onload = (function(type, url) {
                  return function() {
                    end(type, url);
                  };
                })(type, url);
                (doc.head || doc.body).appendChild(node);
                s[url] = false;
              }
            }
          }
        }
      }
    };
    return {
      js: function(url, callback) {
        load('js', url, callback);
      },
      css: function(url, callback) {
        load('css', url, callback);
      }
    };
  })(this.document);
})();
</script><script>
  (function() {
    var TEXT_VARIABLES = {
      version: '2.2.4',
      sources: {
        font_awesome: 'https://use.fontawesome.com/releases/v5.0.13/css/all.css',
        jquery: 'https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js',
        leancloud_js_sdk: '//cdn1.lncld.net/static/js/3.4.1/av-min.js',
        chart: 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js',
        gitalk: {
          js: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.js',
          css: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.css'
        },
        valine: 'https://unpkg.com/valine/dist/Valine.min.js',
        mathjax: 'https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML',
        mermaid: 'https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js'
      },
      site: {
        toc: {
          selectors: 'h1,h2,h3'
        }
      },
      paths: {
        search_js: '/assets/search.js'
      }
    };
    window.TEXT_VARIABLES = TEXT_VARIABLES;
  })();
</script></head>
  <body>
    <div class="root" data-is-touch="false">
      <div class="layout--page layout--page--sidebar clearfix js-page-root&nbsp; layout--page--aside">
  <div class="page__mask d-print-none js-page-mask js-sidebar-hide"></div>
  <div class="page__viewport">
    <div class="page__actions d-print-none">
      <div class="js-sidebar-show">
        <i class="fas fa-bars icon--show"></i>
      </div>
    </div>

    <div class="grid page__grid">

      <div class="page__sidebar d-print-none"><a title="High Performance NLP with Apache Spark
" href="/">
    <!--<svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
-->
</a><div class="sidebar-toc"><ul class="toc toc--navigator"><li class="toc-h1">Spark NLP</li><li class="toc-h2"><a href="/docs/en/quickstart">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/install">Install Spark NLP</a></li><li class="toc-h2"><a href="/docs/en/concepts">General Concepts</a></li><li class="toc-h2"><a href="/docs/en/annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/transformers">Transformers</a></li><li class="toc-h2"><a href="/docs/en/auxiliary">Helpers</a></li><li class="toc-h2"><a href="/docs/en/pipelines">Pipelines</a></li><li class="toc-h2"><a href="/models">Models</a></li><li class="toc-h2"><a href="/docs/en/training">Training</a></li><li class="toc-h2"><a href="/api/">Scaladoc</a></li><li class="toc-h2"><a href="/docs/en/display">Spark NLP Display</a></li><li class="toc-h2"><a href="/docs/en/developers">Developers</a></li><li class="toc-h2"><a href="/docs/en/release_notes">Release Notes</a></li><li class="toc-h1">Annotation Lab</li><li class="toc-h2"><a href="/docs/en/alab">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/byol">License Setup</a></li><li class="toc-h2"><a href="/docs/en/start_page">Start Page</a></li><li class="toc-h2"><a href="/docs/en/user_management">User Management</a></li><li class="toc-h2"><a href="/docs/en/project_setup">Project Setup</a></li><li class="toc-h2"><a href="/docs/en/models_hub">NLP Models Hub</a></li><li class="toc-h2"><a href="/docs/en/preannotations">Preannotations with Spark NLP</a></li><li class="toc-h2"><a href="/docs/en/active_learning">Active Learning</a></li><li class="toc-h2"><a href="/docs/en/import">Import Documents</a></li><li class="toc-h2"><a href="/docs/en/tasks">Tasks</a></li><li class="toc-h2"><a href="/docs/en/annotation">Annotate</a></li><li class="toc-h2"><a href="/docs/en/export">Export Data</a></li><li class="toc-h2"><a href="/docs/en/workflow">Workflow Setup</a></li><li class="toc-h2"><a href="/docs/en/tutorials">Video Tutorials</a></li><li class="toc-h1">Spark NLP for Healthcare</li><li class="toc-h2"><a href="/docs/en/licensed_install">Getting Started</a></li><li class="toc-h2 active"><a href="/docs/en/licensed_annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/licensed_models">Models</a></li><li class="toc-h2"><a href="/docs/en/evaluation">Evaluation</a></li><li class="toc-h2"><a href="/licensed/api/">Scaladoc</a></li><li class="toc-h2"><a href="/docs/en/licensed_release_notes">Release Notes</a></li><li class="toc-h1">Spark OCR</li><li class="toc-h2"><a href="/docs/en/ocr">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/ocr_install">Installation</a></li><li class="toc-h2"><a href="/docs/en/ocr_pipeline_components">Pipeline components</a></li><li class="toc-h2"><a href="/docs/en/ocr_table_recognition">Table recognition</a></li><li class="toc-h2"><a href="/docs/en/ocr_visual_document_understanding">Visual document understanding</a></li><li class="toc-h2"><a href="/docs/en/ocr_object_detection">Object detection</a></li><li class="toc-h2"><a href="/docs/en/ocr_structures">Structures and helpers</a></li><li class="toc-h2"><a href="/docs/en/ocr_release_notes">Release notes</a></li></ul></div></div><div class="page__main js-page-main has-aside cell cell--auto">

      <div class="page__main-inner"><div class="page__header d-print-none"><!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-59JLR64"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) --><header class="header"><div class="main">
      <div class="header__title">
        <a class="responsive_btn" href="#" id="responsive_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
        <div class="header__brand">
          <a title="High Performance NLP with Apache Spark
" href="https://www.johnsnowlabs.com" target="_blank"><svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
</a><!---->
            <!-- <a title="High Performance NLP with Apache Spark
" href="/">Spark NLP</a> -->
          <!---->
        </div></div><nav class="navigation top_navigation">
        <ul class="top-menu"><li class="navigation__item "><a href="/">Home</a></li><li class="navigation__item navigation__item--active"><a href="/docs/en/quickstart">Docs</a></li><li class="navigation__item "><a href="/learn">Learn</a></li><li class="navigation__item "><a href="/models">Models</a></li><li class="navigation__item "><a href="/demos">Demo</a></li><li class="navigation__item "><a href="https://github.com/JohnSnowLabs/spark-nlp"><span style="color: #FF8A00;"><i class="fab fa-github fa-2x"></i></span></a></li><li class="navigation__item "><a href="https://www.johnsnowlabs.com/slack-redirect/"><span style="color: #FF8A00;"><i class="fab fa-slack-hash fa-2x"></i></span></a></li></ul>
      </nav><a class="responsive_btn" href="#" id="aside_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
    </div>
  </header>
</div><div class="page__content "><div class ="main"><div class="grid grid--reverse">

              <div class="col-aside d-print-none js-col-aside"><aside class="page__aside js-page-aside"><div class="toc-aside js-toc-root"></div></aside></div>

              <div class="col-main cell cell--auto"><!-- start custom main top snippet -->

<!-- end custom main top snippet --><article itemscope itemtype="http://schema.org/Article"><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script><div class="article__header"><header><h1>Spark NLP for Healthcare Annotators</h1></header><span class="split-space">&nbsp;</span>
          <a class="edit-on-github"
            title="Edit on Github"
            href="https://github.com/johnsnowlabs/spark-nlp/tree/master/docs/en/licensed_annotators.md">
            <i class="far fa-edit"></i></a></div><meta itemprop="headline" content="Spark NLP for Healthcare Annotators"><meta itemprop="author" content=""/><div class="js-article-content"><div class="docs-wrapper">
<div class="layout--article"><!-- start custom article top snippet -->

<!-- end custom article top snippet --><div class="article__content" itemprop="articleBody"><div class="h3-box">

  <p>A Spark NLP for Healthcare subscription includes access to several pretrained annotators.
At the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/e06141715bc14e5ed43388585ce002b8b37e3f18/tutorials/Certification_Trainings/Healthcare">Spark NLP Healthcare Workshop</a> you can see different types of annotators in action.</p>

  <p>Check out the <a href="https://nlp.johnsnowlabs.com/docs/en/annotators">Spark NLP Annotators page</a> for more information on how to read this page.</p>

</div>

<h2 id="available-annotators">Available Annotators</h2>

<table class="table-model-big">
  <thead>
    <tr>
      <th>Annotator</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="#assertiondl">AssertionDL</a></td>
      <td>AssertionDL is a deep Learning based approach used to extract Assertion Status from extracted entities and text.</td>
    </tr>
    <tr>
      <td><a href="#assertionfilterer">AssertionFilterer</a></td>
      <td>Filters entities coming from ASSERTION type annotations and returns the CHUNKS.</td>
    </tr>
    <tr>
      <td><a href="#assertionlogreg">AssertionLogReg</a></td>
      <td>Logarithmic Regression is used to extract Assertion Status from extracted entities and text.</td>
    </tr>
    <tr>
      <td><a href="#chunk2token">Chunk2Token</a></td>
      <td>A feature transformer that converts the input array of strings (annotatorType CHUNK) into an array of chunk-based tokens (annotatorType TOKEN).</td>
    </tr>
    <tr>
      <td><a href="#chunkentityresolver">ChunkEntityResolver</a></td>
      <td>Returns a normalized entity for a particular trained ontology / curated dataset (e.g. ICD-10, RxNorm, SNOMED etc).</td>
    </tr>
    <tr>
      <td><a href="#chunkfilterer">ChunkFilterer</a></td>
      <td>Filters entities coming from CHUNK annotations.</td>
    </tr>
    <tr>
      <td><a href="#chunkmerge">ChunkMerge</a></td>
      <td>Merges entities coming from different CHUNK annotations.</td>
    </tr>
    <tr>
      <td><a href="#contextualparser">ContextualParser</a></td>
      <td>Extracts entity from a document based on user defined rules.</td>
    </tr>
    <tr>
      <td><a href="#deidentification">DeIdentification</a></td>
      <td>Deidentifies Input Annotations of types DOCUMENT, TOKEN and CHUNK, by either masking or obfuscating the given CHUNKS.</td>
    </tr>
    <tr>
      <td><a href="#documentlogregclassifier">DocumentLogRegClassifier</a></td>
      <td>Classifies documents with a Logarithmic Regression algorithm.</td>
    </tr>
    <tr>
      <td><a href="#drugnormalizer">DrugNormalizer</a></td>
      <td>Annotator which normalizes raw text from clinical documents, e.g. scraped web pages or xml documents</td>
    </tr>
    <tr>
      <td><a href="#featuresassembler">FeaturesAssembler</a></td>
      <td>Collects features from different columns.</td>
    </tr>
    <tr>
      <td><a href="#genericclassifier">GenericClassifier</a></td>
      <td>Creates a generic single-label classifier which uses pre-generated Tensorflow graphs.</td>
    </tr>
    <tr>
      <td><a href="#iobtagger">IOBTagger</a></td>
      <td>Merges token tags and NER labels from chunks in the specified format.</td>
    </tr>
    <tr>
      <td><a href="#nerchunker">NerChunker</a></td>
      <td>Extracts phrases that fits into a known pattern using the NER tags.</td>
    </tr>
    <tr>
      <td><a href="#nerconverterinternal">NerConverterInternal</a></td>
      <td>Converts a IOB or IOB2 representation of NER to a user-friendly one, by associating the tokens of recognized entities and their label.</td>
    </tr>
    <tr>
      <td><a href="#nerdisambiguator">NerDisambiguator</a></td>
      <td>Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB).</td>
    </tr>
    <tr>
      <td><a href="#renerchunksfilter">RENerChunksFilter</a></td>
      <td>Filters and outputs combinations of relations between extracted entities, for further processing.</td>
    </tr>
    <tr>
      <td><a href="#reidentification">ReIdentification</a></td>
      <td>Reidentifies obfuscated entities by DeIdentification.</td>
    </tr>
    <tr>
      <td><a href="#relationextraction">RelationExtraction</a></td>
      <td>Extracts and classifies instances of relations between named entities.</td>
    </tr>
    <tr>
      <td><a href="#relationextractiondl">RelationExtractionDL</a></td>
      <td>Extracts and classifies instances of relations between named entities.</td>
    </tr>
    <tr>
      <td><a href="#sentenceentityresolver">SentenceEntityResolver</a></td>
      <td>Returns the normalized entity for a particular trained ontology / curated dataset (e.g. ICD-10, RxNorm, SNOMED etc.) based on sentence embeddings.</td>
    </tr>
  </tbody>
</table>

<script> jQuery(document).ready(function () {
    $(".model-button").click(function () {
        $(this).closest(".tabs-box").find(".model-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        //remove  active class from all other buttons
        $(this).closest(".tabs-box").find(".approach-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".h3-box.approach-content").hide()
        $(this.parentNode).siblings(".h3-box.model-content").show()
    });

    $(".approach-button").click(function () {
        //set current button to active class and remove unactive class
        $(this).closest(".tabs-box").find(".approach-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        //remove  active class from all other buttons
        $(this).closest(".tabs-box").find(".model-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".h3-box.model-content").hide()
        $(this.parentNode).siblings(".h3-box.approach-content").show()
    });
});
 </script>

<div class="tabs-box">

  <h2 id="assertiondl">AssertionDL</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains AssertionDL, a deep Learning based approach used to extract Assertion Status
from extracted entities and text.
Contains all the methods for training an AssertionDLModel.
For pretrained models please use AssertionDLModel and see the
<a href="https://nlp.johnsnowlabs.com/models?task=Assertion+Status">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/dl/AssertionDLApproach">AssertionDLApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined.
</span><span class="n">document</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">chunk</span> <span class="o">=</span> <span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>
<span class="n">token</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Define AssertionDLApproach with parameters and start training
</span><span class="n">assertionStatus</span> <span class="o">=</span> <span class="n">AssertionDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.012</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.015</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxSentLen</span><span class="p">(</span><span class="mi">250</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document</span><span class="p">,</span>
    <span class="n">chunk</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">assertionStatus</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">assertionResults</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined.</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Define AssertionDLApproach with parameters and start training</span>
<span class="k">val</span> <span class="nv">assertionStatus</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">128</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.012f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLearningRate</span><span class="o">(</span><span class="mf">0.015f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSentLen</span><span class="o">(</span><span class="mi">250</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">chunk</span><span class="o">,</span>
  <span class="n">token</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">assertionStatus</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">assertionResults</span> <span class="k">=</span> <span class="nv">assertionModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>AssertionDL is a deep Learning based approach used to extract Assertion Status
from extracted entities and text. AssertionDLModel requires DOCUMENT, CHUNK and WORD_EMBEDDINGS type
annotator inputs, which can be obtained by e.g a
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/DocumentAssembler">DocumentAssembler</a>,
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter">NerConverter</a>
and <a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel">WordEmbeddingsModel</a>.
The result is an assertion status annotation for each recognized entity.
Possible values include <code class="language-plaintext highlighter-rouge">“present”, “absent”, “hypothetical”, “conditional”, “associated_with_other_person”</code> etc.</p>

    <p>For pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Assertion+Status">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/dl/AssertionDLModel">AssertionDLModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Define pipeline stages to extract NER chunks first
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
  <span class="p">[</span><span class="s">"Patient with severe fever and sore throat"</span><span class="p">],</span>
  <span class="p">[</span><span class="s">"Patient shows no stomach pain"</span><span class="p">],</span>
  <span class="p">[</span><span class="s">"She was maintained on an epidural and PCA for pain control."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="n">nerModel</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1"># Then a pretrained AssertionDLModel is used to extract the assertion status
</span><span class="n">clinicalAssertion</span> <span class="o">=</span> <span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"assertion_dl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">nerModel</span><span class="p">,</span>
  <span class="n">nerConverter</span><span class="p">,</span>
  <span class="n">clinicalAssertion</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"ner_chunk.result"</span><span class="p">,</span> <span class="s">"assertion.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                          <span class="o">|</span><span class="n">result</span>                          <span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">severe</span> <span class="n">fever</span><span class="p">,</span> <span class="n">sore</span> <span class="n">throat</span><span class="p">]</span>     <span class="o">|</span><span class="p">[</span><span class="n">present</span><span class="p">,</span> <span class="n">present</span><span class="p">]</span>              <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">stomach</span> <span class="n">pain</span><span class="p">]</span>                  <span class="o">|</span><span class="p">[</span><span class="n">absent</span><span class="p">]</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">an</span> <span class="n">epidural</span><span class="p">,</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">pain</span> <span class="n">control</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">present</span><span class="p">,</span> <span class="n">present</span><span class="p">,</span> <span class="n">hypothetical</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Define pipeline stages to extract NER chunks first</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Patient with severe fever and sore throat"</span><span class="o">,</span>
  <span class="s">"Patient shows no stomach pain"</span><span class="o">,</span>
  <span class="s">"She was maintained on an epidural and PCA for pain control."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="c1">// Then a pretrained AssertionDLModel is used to extract the assertion status</span>
<span class="k">val</span> <span class="nv">clinicalAssertion</span> <span class="k">=</span> <span class="nv">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"assertion_dl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">clinicalAssertion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">assertionModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"ner_chunk.result"</span><span class="o">,</span> <span class="s">"assertion.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">3</span><span class="o">,</span> <span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                          <span class="o">|</span><span class="n">result</span>                          <span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|[</span><span class="kt">severe</span> <span class="kt">fever</span>, <span class="kt">sore</span> <span class="kt">throat</span><span class="o">]</span>     <span class="o">|[</span><span class="kt">present</span>, <span class="kt">present</span><span class="o">]</span>              <span class="o">|</span>
<span class="o">|[</span><span class="kt">stomach</span> <span class="kt">pain</span><span class="o">]</span>                  <span class="o">|[</span><span class="kt">absent</span><span class="o">]</span>                        <span class="o">|</span>
<span class="o">|[</span><span class="kt">an</span> <span class="kt">epidural</span>, <span class="kt">PCA</span>, <span class="kt">pain</span> <span class="kt">control</span><span class="o">]|[</span><span class="kt">present</span>, <span class="kt">present</span>, <span class="kt">hypothetical</span><span class="o">]|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="assertionfilterer">AssertionFilterer</h2>

  <p>Filters entities coming from ASSERTION type annotations and returns the CHUNKS.
Filters can be set via a white list on the extracted chunk, the assertion or a regular expression.
White list for assertion is enabled by default. To use chunk white list, <code class="language-plaintext highlighter-rouge">criteria</code> has to be set to <code class="language-plaintext highlighter-rouge">"isin"</code>.
For regex, <code class="language-plaintext highlighter-rouge">criteria</code> has to be set to <code class="language-plaintext highlighter-rouge">"regex"</code>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, ASSERTION</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/AssertionFilterer">AssertionFilterer</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># To see how the assertions are extracted, see the example for AssertionDLModel.
# Define an extra step where the assertions are filtered
</span><span class="n">assertionFilterer</span> <span class="o">=</span> <span class="n">AssertionFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">,</span><span class="s">"assertion"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"present"</span><span class="p">])</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">nerModel</span><span class="p">,</span>
  <span class="n">nerConverter</span><span class="p">,</span>
  <span class="n">clinicalAssertion</span><span class="p">,</span>
  <span class="n">assertionFilterer</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">assertionModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="c1"># Show results:
</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"ner_chunk.result"</span><span class="p">,</span> <span class="s">"assertion.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                          <span class="o">|</span><span class="n">result</span>                          <span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">severe</span> <span class="n">fever</span><span class="p">,</span> <span class="n">sore</span> <span class="n">throat</span><span class="p">]</span>     <span class="o">|</span><span class="p">[</span><span class="n">present</span><span class="p">,</span> <span class="n">present</span><span class="p">]</span>              <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">stomach</span> <span class="n">pain</span><span class="p">]</span>                  <span class="o">|</span><span class="p">[</span><span class="n">absent</span><span class="p">]</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">an</span> <span class="n">epidural</span><span class="p">,</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">pain</span> <span class="n">control</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">present</span><span class="p">,</span> <span class="n">present</span><span class="p">,</span> <span class="n">hypothetical</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"filtered.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="n">result</span>                     <span class="o">|</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">severe</span> <span class="n">fever</span><span class="p">,</span> <span class="n">sore</span> <span class="n">throat</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[]</span>                         <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">an</span> <span class="n">epidural</span><span class="p">,</span> <span class="n">PCA</span><span class="p">]</span>         <span class="o">|</span>
<span class="o">+---------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// To see how the assertions are extracted, see the example for</span>
<span class="c1">// [[com.johnsnowlabs.nlp.annotators.assertion.dl.AssertionDLModel AssertionDLModel]].</span>
<span class="c1">// Define an extra step where the assertions are filtered</span>
<span class="k">val</span> <span class="nv">assertionFilterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionFilterer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"present"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">clinicalAssertion</span><span class="o">,</span>
  <span class="n">assertionFilterer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">assertionModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results:</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("ner_chunk.result", "assertion.result").show(3, truncate=false)</span>
<span class="c1">// +--------------------------------+--------------------------------+</span>
<span class="c1">// |result                          |result                          |</span>
<span class="c1">// +--------------------------------+--------------------------------+</span>
<span class="c1">// |[severe fever, sore throat]     |[present, present]              |</span>
<span class="c1">// |[stomach pain]                  |[absent]                        |</span>
<span class="c1">// |[an epidural, PCA, pain control]|[present, present, hypothetical]|</span>
<span class="c1">// +--------------------------------+--------------------------------+</span>
<span class="c1">// result.select("filtered.result").show(3, truncate=false)</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">// |result                     |</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">// |[severe fever, sore throat]|</span>
<span class="c1">// |[]                         |</span>
<span class="c1">// |[an epidural, PCA]         |</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">//</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box">

  <h2 id="assertionlogreg">AssertionLogReg</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a classification method, which uses the Logarithmic Regression Algorithm. It is used to extract Assertion Status
from extracted entities and text.
Contains all the methods for training a AssertionLogRegModel, together with trainWithChunk, trainWithStartEnd.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/logreg/AssertionLogRegApproach">AssertionLogRegApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Training with Glove Embeddings
# First define pipeline stages to extract embeddings and text chunks
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">glove</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="c1"># Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.
</span><span class="n">assertion</span> <span class="o">=</span> <span class="n">AssertionLogRegApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setReg</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBefore</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAfter</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerModel</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">assertion</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Training with Glove Embeddings</span>
<span class="c1">// First define pipeline stages to extract embeddings and text chunks</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">glove</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="c1">// Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.</span>
<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionLogRegApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReg</span><span class="o">(</span><span class="mf">0.01</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBefore</span><span class="o">(</span><span class="mi">11</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAfter</span><span class="o">(</span><span class="mi">13</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">assertion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>This is a main class in AssertionLogReg family. Logarithmic Regression is used to extract Assertion Status
from extracted entities and text. AssertionLogRegModel requires DOCUMENT, CHUNK and WORD_EMBEDDINGS type
annotator inputs, which can be obtained by e.g a
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/DocumentAssembler">DocumentAssembler</a>,
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter">NerConverter</a>
and <a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/embeddings/WordEmbeddingsModel">WordEmbeddingsModel</a>.
The result is an assertion status annotation for each recognized entity.
Possible values are <code class="language-plaintext highlighter-rouge">"Negated", "Affirmed" and "Historical"</code>.</p>

    <p>Unlike the DL Model, this class does not extend AnnotatorModel.
Instead it extends the RawAnnotator, that’s why the main point of interest is method transform().</p>

    <p>At the moment there are no pretrained models available for this class. Please refer to AssertionLogRegApproach to
train your own model.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/logreg/AssertionLogRegModel">AssertionLogRegModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="chunk2token">Chunk2Token</h2>

  <p>A feature transformer that converts the input array of strings (annotatorType CHUNK) into an
array of chunk-based tokens (annotatorType TOKEN).</p>

  <p>When the input is empty, an empty array is returned.</p>

  <p>This Annotator is specially convenient when using NGramGenerator annotations as inputs to WordEmbeddingsModels</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/Chunk2Token">Chunk2Token</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Define a pipeline for generating n-grams
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">token</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">ngrammer</span> <span class="o">=</span> <span class="n">NGramGenerator</span><span class="p">()</span> \
 <span class="p">.</span><span class="n">setN</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setEnableCumulative</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
 <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngrams"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setDelimiter</span><span class="p">(</span><span class="s">"_"</span><span class="p">)</span>

<span class="c1"># Stage to convert n-gram CHUNKS to TOKEN type
</span><span class="n">chunk2Token</span> <span class="o">=</span> <span class="n">Chunk2Token</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ngrams"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngram_tokens"</span><span class="p">)</span>
<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="n">sentenceDetector</span><span class="p">,</span> <span class="n">token</span><span class="p">,</span> <span class="n">ngrammer</span><span class="p">,</span> <span class="n">chunk2Token</span><span class="p">]).</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ngram_tokens)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
    <span class="o">+----------------------------------------------------------------+</span>
    <span class="o">|</span><span class="n">col</span>                                                             <span class="o">|</span>
    <span class="o">+----------------------------------------------------------------+</span>
    <span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">A_63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>  <span class="o">|</span>
    <span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old_man</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
    <span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">man_presents</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>  <span class="o">|</span>
    <span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="n">presents_to</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
    <span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="n">to_the</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="p">},</span> <span class="p">[]}</span>        <span class="o">|</span>
    <span class="o">+----------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Define a pipeline for generating n-grams</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ngrammer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NGramGenerator</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setEnableCumulative</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setDelimiter</span><span class="o">(</span><span class="s">"_"</span><span class="o">)</span>

<span class="c1">// Stage to convert n-gram CHUNKS to TOKEN type</span>
<span class="k">val</span> <span class="nv">chunk2Token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunk2Token</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngram_tokens"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document</span><span class="o">,</span> <span class="n">sentenceDetector</span><span class="o">,</span> <span class="n">token</span><span class="o">,</span> <span class="n">ngrammer</span><span class="o">,</span> <span class="n">chunk2Token</span><span class="o">)).</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(ngram_tokens)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                             <span class="o">|</span>
<span class="o">+----------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">15</span><span class="o">,</span> <span class="nc">A_63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">},</span> <span class="o">[]}</span>  <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">19</span><span class="o">,</span> <span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old_man</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">17</span><span class="o">,</span> <span class="mi">28</span><span class="o">,</span> <span class="n">man_presents</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="o">},</span> <span class="o">[]}</span>  <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">21</span><span class="o">,</span> <span class="mi">31</span><span class="o">,</span> <span class="n">presents_to</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="o">},</span> <span class="o">[]}</span>   <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">30</span><span class="o">,</span> <span class="mi">35</span><span class="o">,</span> <span class="n">to_the</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">},</span> <span class="o">[]}</span>        <span class="o">|</span>
<span class="o">+----------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box">

  <h2 id="chunkentityresolver">ChunkEntityResolver</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Contains all the parameters and methods to train a ChunkEntityResolverModel.
It transform a dataset with two Input Annotations of types TOKEN and WORD_EMBEDDINGS, coming from e.g. ChunkTokenizer
and ChunkEmbeddings Annotators and returns the normalized entity for a particular trained ontology / curated dataset.
(e.g. ICD-10, RxNorm, SNOMED etc.)</p>

    <p>To use pretrained models please use ChunkEntityResolverModel
and see the <a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/ChunkEntityResolverApproach">ChunkEntityResolverApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Training a SNOMED model
# Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data
# and their labels.
</span><span class="n">document</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">chunk</span> <span class="o">=</span> <span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_healthcare_100d"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">chunkEmb</span> <span class="o">=</span> <span class="n">ChunkEmbeddings</span><span class="p">()</span> \
        <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
        <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk_embeddings"</span><span class="p">)</span>

<span class="n">snomedTrainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document</span><span class="p">,</span>
    <span class="n">chunk</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">chunkEmb</span>
<span class="p">])</span>

<span class="n">snomedTrainingModel</span> <span class="o">=</span> <span class="n">snomedTrainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">snomedData</span> <span class="o">=</span> <span class="n">snomedTrainingModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Then the Resolver can be trained with
</span><span class="n">snomedExtractor</span> <span class="o">=</span> <span class="n">ChunkEntityResolverApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"chunk_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"recognized"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setNeighbours</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAlternatives</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setNormalizedCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEnableWmd</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableTfidf</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableJaccard</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEnableSorensenDice</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableJaroWinkler</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableLevenshtein</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDistanceWeights</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setAllDistancesMetadata</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"MAX"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mf">1e32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">snomedExtractor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snomedData</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Training a SNOMED model</span>
<span class="c1">// Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data</span>
<span class="c1">// and their labels.</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_healthcare_100d"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkEmb</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkEmbeddings</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedTrainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">chunk</span><span class="o">,</span>
  <span class="n">token</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">chunkEmb</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">snomedTrainingModel</span> <span class="k">=</span> <span class="nv">snomedTrainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedData</span> <span class="k">=</span> <span class="nv">snomedTrainingModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Then the Resolver can be trained with</span>
<span class="k">val</span> <span class="nv">snomedExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkEntityResolverApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"chunk_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"recognized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNeighbours</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAlternatives</span><span class="o">(</span><span class="mi">25</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNormalizedCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEnableWmd</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableTfidf</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableJaccard</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEnableSorensenDice</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableJaroWinkler</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableLevenshtein</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceWeights</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setAllDistancesMetadata</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"MAX"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mi">1</span><span class="n">e32</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">snomedExtractor</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">snomedData</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Returns a normalized entity for a particular trained ontology / curated dataset
(e.g. ICD-10, RxNorm, SNOMED etc).</p>

    <p>For available pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/ChunkEntityResolverModel">ChunkEntityResolverModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Using pretrained models for SNOMED
# First the prior steps of the pipeline are defined.
# Output of types TOKEN and WORD_EMBEDDINGS are needed.
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>
<span class="n">icdo_ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_bionlp"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icdo_ner"</span><span class="p">)</span>
<span class="n">icdo_chunk</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"icdo_ner"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icdo_chunk"</span><span class="p">).</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Cancer"</span><span class="p">])</span>
<span class="n">icdo_chunk_embeddings</span> <span class="o">=</span> <span class="n">ChunkEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"icdo_chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icdo_chunk_embeddings"</span><span class="p">)</span>
<span class="n">icdo_chunk_resolver</span> <span class="o">=</span> <span class="n">ChunkEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"chunkresolve_icdo_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span><span class="s">"icdo_chunk_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tm_icdo_code"</span><span class="p">)</span>
<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
<span class="n">ner_chunk_tokenizer</span> <span class="o">=</span> <span class="n">ChunkTokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_token"</span><span class="p">)</span>
<span class="n">ner_chunk_embeddings</span> <span class="o">=</span> <span class="n">ChunkEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_embeddings"</span><span class="p">)</span>

<span class="c1"># Definition of the SNOMED Resolution
</span><span class="n">ner_snomed_resolver</span> <span class="o">=</span> <span class="n">ChunkEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"chunkresolve_snomed_findings_clinical"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_token"</span><span class="p">,</span><span class="s">"ner_chunk_embeddings"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_result"</span><span class="p">)</span>
<span class="n">pipelineFull</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">docAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>

      <span class="n">clinical_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_chunk_embeddings</span><span class="p">,</span>
      <span class="n">ner_chunk_tokenizer</span><span class="p">,</span>
      <span class="n">ner_snomed_resolver</span><span class="p">,</span>

      <span class="n">icdo_ner</span><span class="p">,</span>
      <span class="n">icdo_chunk</span><span class="p">,</span>
      <span class="n">icdo_chunk_embeddings</span><span class="p">,</span>
      <span class="n">icdo_chunk_resolver</span>
<span class="p">])</span>
<span class="n">pipelineModelFull</span> <span class="o">=</span> <span class="n">pipelineFull</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipelineModelFull</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(snomed_result)"</span><span class="p">)</span>
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"col.metadata.target_text"</span><span class="p">,</span>
    <span class="s">"col.metadata.resolved_text"</span><span class="p">,</span>
    <span class="s">"col.metadata.confidence"</span><span class="p">,</span>
    <span class="s">"col.metadata.all_k_results"</span><span class="p">,</span>
    <span class="s">"col.metadata.all_k_resolutions"</span><span class="p">)</span>
  <span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="err">$</span><span class="s">"confidence"</span> <span class="o">&gt;</span> <span class="mf">0.2</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="o">+--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="o">|</span>         <span class="n">target_text</span><span class="o">|</span>       <span class="n">resolved_text</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>       <span class="n">all_k_results</span><span class="o">|</span>   <span class="n">all_k_resolutions</span><span class="o">|</span>
<span class="o">+--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="o">|</span><span class="n">hypercholesterolemia</span><span class="o">|</span><span class="n">Hypercholesterolemia</span><span class="o">|</span>    <span class="mf">0.2524</span><span class="o">|</span><span class="mi">13644009</span><span class="p">:::</span><span class="mf">267432.</span><span class="p">..</span><span class="o">|</span><span class="n">Hypercholesterole</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>                 <span class="n">CBC</span><span class="o">|</span>             <span class="n">Neocyte</span><span class="o">|</span>    <span class="mf">0.4980</span><span class="o">|</span><span class="mi">259680000</span><span class="p">:::</span><span class="mf">11573.</span><span class="p">..</span><span class="o">|</span><span class="n">Neocyte</span><span class="p">:::</span><span class="n">Blood</span> <span class="n">g</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>                <span class="n">CD38</span><span class="o">|</span>       <span class="n">Hypoviscosity</span><span class="o">|</span>    <span class="mf">0.2560</span><span class="o">|</span><span class="mi">47872005</span><span class="p">:::</span><span class="mf">370970.</span><span class="p">..</span><span class="o">|</span><span class="n">Hypoviscosity</span><span class="p">:::</span><span class="n">E</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>           <span class="n">platelets</span><span class="o">|</span> <span class="n">Increased</span> <span class="n">platelets</span><span class="o">|</span>    <span class="mf">0.5267</span><span class="o">|</span><span class="mi">6631009</span><span class="p">:::</span><span class="mf">2596800.</span><span class="p">..</span><span class="o">|</span><span class="n">Increased</span> <span class="n">platele</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>                <span class="n">CD38</span><span class="o">|</span>       <span class="n">Hypoviscosity</span><span class="o">|</span>    <span class="mf">0.2560</span><span class="o">|</span><span class="mi">47872005</span><span class="p">:::</span><span class="mf">370970.</span><span class="p">..</span><span class="o">|</span><span class="n">Hypoviscosity</span><span class="p">:::</span><span class="n">E</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------+--------------------+----------+--------------------+--------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Using pretrained models for SNOMED</span>
<span class="c1">// First the prior steps of the pipeline are defined.</span>
<span class="c1">// Output of types TOKEN and WORD_EMBEDDINGS are needed.</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">icdo_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_bionlp"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"icdo_ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">icdo_chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"icdo_ner"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"icdo_chunk"</span><span class="o">).</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"Cancer"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">icdo_chunk_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"icdo_chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"icdo_chunk_embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">icdo_chunk_resolver</span> <span class="k">=</span> <span class="nv">ChunkEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"chunkresolve_icdo_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span><span class="s">"icdo_chunk_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tm_icdo_code"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_chunk_tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkTokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_chunk_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_embeddings"</span><span class="o">)</span>

<span class="c1">// Definition of the SNOMED Resolution</span>
<span class="k">val</span> <span class="nv">ner_snomed_resolver</span> <span class="k">=</span> <span class="nv">ChunkEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"chunkresolve_snomed_findings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_token"</span><span class="o">,</span><span class="s">"ner_chunk_embeddings"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"snomed_result"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineFull</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">docAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">word_embeddings</span><span class="o">,</span>

    <span class="n">clinical_ner</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">ner_chunk_embeddings</span><span class="o">,</span>
    <span class="n">ner_chunk_tokenizer</span><span class="o">,</span>
    <span class="n">ner_snomed_resolver</span><span class="o">,</span>

    <span class="n">icdo_ner</span><span class="o">,</span>
    <span class="n">icdo_chunk</span><span class="o">,</span>
    <span class="n">icdo_chunk_embeddings</span><span class="o">,</span>
    <span class="n">icdo_chunk_resolver</span>
<span class="o">))</span>
<span class="k">val</span> <span class="nv">pipelineModelFull</span> <span class="k">=</span> <span class="nv">pipelineFull</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipelineModelFull</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(snomed_result)")</span>
<span class="c1">//   .selectExpr(</span>
<span class="c1">//     "col.metadata.target_text",</span>
<span class="c1">//     "col.metadata.resolved_text",</span>
<span class="c1">//     "col.metadata.confidence",</span>
<span class="c1">//     "col.metadata.all_k_results",</span>
<span class="c1">//     "col.metadata.all_k_resolutions")</span>
<span class="c1">//   .filter($"confidence" &gt; 0.2).show(5)</span>
<span class="c1">// +--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="c1">// |         target_text|       resolved_text|confidence|       all_k_results|   all_k_resolutions|</span>
<span class="c1">// +--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="c1">// |hypercholesterolemia|Hypercholesterolemia|    0.2524|13644009:::267432...|Hypercholesterole...|</span>
<span class="c1">// |                 CBC|             Neocyte|    0.4980|259680000:::11573...|Neocyte:::Blood g...|</span>
<span class="c1">// |                CD38|       Hypoviscosity|    0.2560|47872005:::370970...|Hypoviscosity:::E...|</span>
<span class="c1">// |           platelets| Increased platelets|    0.5267|6631009:::2596800...|Increased platele...|</span>
<span class="c1">// |                CD38|       Hypoviscosity|    0.2560|47872005:::370970...|Hypoviscosity:::E...|</span>
<span class="c1">// +--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="c1">//</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="chunkfilterer">ChunkFilterer</h2>

  <p>Filters entities coming from CHUNK annotations. Filters can be set via a white list of terms or a regular expression.
White list criteria is enabled by default. To use regex, <code class="language-plaintext highlighter-rouge">criteria</code> has to be set to <code class="language-plaintext highlighter-rouge">regex</code>.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT,CHUNK</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkFilterer">ChunkFilterer</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Filtering POS tags
# First pipeline stages to extract the POS tags are defined
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Has a past history of gastroenteritis and stomach pain, however patient ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">chunker</span> <span class="o">=</span> <span class="n">Chunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"pos"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"(&lt;NN&gt;)+"</span><span class="p">])</span>

<span class="c1"># Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.
</span><span class="n">chunkerFilter</span> <span class="o">=</span> <span class="n">ChunkFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"chunk"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"isin"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"gastroenteritis"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">docAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">posTagger</span><span class="p">,</span>
  <span class="n">chunker</span><span class="p">,</span>
  <span class="n">chunkerFilter</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(chunk)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                              <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="n">gastroenteritis</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span>                <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">42</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span> <span class="n">stomach</span> <span class="n">pain</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>                   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="n">patient</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">81</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="n">stomach</span> <span class="n">pain</span> <span class="n">now</span><span class="p">.</span><span class="n">We</span> <span class="n">don</span><span class="s">'t care, {sentence -&gt; 0, chunk -&gt; 4}, []}|
|{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []}              |
+---------------------------------------------------------------------------------+

result.selectExpr("explode(filtered)").show(truncate=False)
+-------------------------------------------------------------------+
|col                                                                |
+-------------------------------------------------------------------+
|{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []}  |
|{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []}|
+-------------------------------------------------------------------+
</span></code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Filtering POS tags</span>
<span class="c1">// First pipeline stages to extract the POS tags are defined</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Has a past history of gastroenteritis and stomach pain, however patient ..."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"pos"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"(&lt;NN&gt;)+"</span><span class="o">))</span>

<span class="c1">// Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.</span>
<span class="k">val</span> <span class="nv">chunkerFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkFilterer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"isin"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"gastroenteritis"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">docAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">posTagger</span><span class="o">,</span>
  <span class="n">chunker</span><span class="o">,</span>
  <span class="n">chunkerFilter</span><span class="o">))</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(chunk)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                              <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">11</span><span class="o">,</span> <span class="mi">17</span><span class="o">,</span> <span class="n">history</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">},</span> <span class="o">[]}</span>                        <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">22</span><span class="o">,</span> <span class="mi">36</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span>                <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">42</span><span class="o">,</span> <span class="mi">53</span><span class="o">,</span> <span class="n">stomach</span> <span class="n">pain</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="o">},</span> <span class="o">[]}</span>                   <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">64</span><span class="o">,</span> <span class="mi">70</span><span class="o">,</span> <span class="n">patient</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="o">},</span> <span class="o">[]}</span>                        <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">81</span><span class="o">,</span> <span class="mi">110</span><span class="o">,</span> <span class="n">stomach</span> <span class="n">pain</span> <span class="nv">now</span><span class="o">.</span><span class="py">We</span> <span class="n">don</span><span class="ss">'t</span> <span class="n">care</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">118</span><span class="o">,</span> <span class="mi">132</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="o">},</span> <span class="o">[]}</span>              <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------+</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(filtered)"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span><span class="k">=</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+-------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">22</span><span class="o">,</span> <span class="mi">36</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span>  <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">118</span><span class="o">,</span> <span class="mi">132</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">+-------------------------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box">

  <h2 id="chunkmerge">ChunkMerge</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Merges two chunk columns coming from two annotators(NER, ContextualParser or any other annotator producing
chunks). The merger of the two chunk columns is made by selecting one chunk from one of the columns according
to certain criteria.
The decision on which chunk to select is made according to the chunk indices in the source document.
(chunks with longer lengths and highest information will be kept from each source)
Labels can be changed by setReplaceDictResource.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/merge/ChunkMergeApproach">ChunkMergeApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Define a pipeline with 2 different NER models with a ChunkMergeApproach at the end
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
 <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">),</span>
 <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
 <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">),</span>
  <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embs"</span><span class="p">),</span>
  <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"jsl_ner"</span><span class="p">),</span>
 <span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"jsl_ner"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"jsl_ner_chunk"</span><span class="p">),</span>
  <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_bionlp"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bionlp_ner"</span><span class="p">),</span>
 <span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"bionlp_ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bionlp_ner_chunk"</span><span class="p">),</span>
 <span class="n">ChunkMergeApproach</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"jsl_ner_chunk"</span><span class="p">,</span> <span class="s">"bionlp_ner_chunk"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"merged_chunk"</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(merged_chunk) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span><span class="s">"a.end"</span><span class="p">,</span><span class="s">"a.result as chunk"</span><span class="p">,</span><span class="s">"a.metadata.entity as entity"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+-----+---+-----------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">chunk</span>      <span class="o">|</span><span class="n">entity</span>   <span class="o">|</span>
<span class="o">+-----+---+-----------+---------+</span>
<span class="o">|</span><span class="mi">5</span>    <span class="o">|</span><span class="mi">15</span> <span class="o">|</span><span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">|</span><span class="n">Age</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">17</span>   <span class="o">|</span><span class="mi">19</span> <span class="o">|</span><span class="n">man</span>        <span class="o">|</span><span class="n">Gender</span>   <span class="o">|</span>
<span class="o">|</span><span class="mi">64</span>   <span class="o">|</span><span class="mi">72</span> <span class="o">|</span><span class="n">recurrent</span>  <span class="o">|</span><span class="n">Modifier</span> <span class="o">|</span>
<span class="o">|</span><span class="mi">98</span>   <span class="o">|</span><span class="mi">107</span><span class="o">|</span><span class="n">cellulitis</span> <span class="o">|</span><span class="n">Diagnosis</span><span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">pneumonias</span> <span class="o">|</span><span class="n">Diagnosis</span><span class="o">|</span>
<span class="o">+-----+---+-----------+---------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Define a pipeline with 2 different NER models with a ChunkMergeApproach at the end</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">),</span>
  <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">),</span>
  <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">),</span>
  <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embs"</span><span class="o">),</span>
  <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embs"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"jsl_ner"</span><span class="o">),</span>
  <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"jsl_ner"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"jsl_ner_chunk"</span><span class="o">),</span>
  <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_bionlp"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embs"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bionlp_ner"</span><span class="o">),</span>
  <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"bionlp_ner"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bionlp_ner_chunk"</span><span class="o">),</span>
  <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"jsl_ner_chunk"</span><span class="o">,</span> <span class="s">"bionlp_ner_chunk"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"merged_chunk"</span><span class="o">)</span>
<span class="o">))</span>

<span class="c1">// Show results</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(merged_chunk) as a"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"a.begin"</span><span class="o">,</span><span class="s">"a.end"</span><span class="o">,</span><span class="s">"a.result as chunk"</span><span class="o">,</span><span class="s">"a.metadata.entity as entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>
<span class="o">+-----+---+-----------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">chunk</span>      <span class="o">|</span><span class="n">entity</span>   <span class="o">|</span>
<span class="o">+-----+---+-----------+---------+</span>
<span class="o">|</span><span class="mi">5</span>    <span class="o">|</span><span class="mi">15</span> <span class="o">|</span><span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">|</span><span class="nc">Age</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">17</span>   <span class="o">|</span><span class="mi">19</span> <span class="o">|</span><span class="n">man</span>        <span class="o">|</span><span class="nc">Gender</span>   <span class="o">|</span>
<span class="o">|</span><span class="mi">64</span>   <span class="o">|</span><span class="mi">72</span> <span class="o">|</span><span class="n">recurrent</span>  <span class="o">|</span><span class="nc">Modifier</span> <span class="o">|</span>
<span class="o">|</span><span class="mi">98</span>   <span class="o">|</span><span class="mi">107</span><span class="o">|</span><span class="n">cellulitis</span> <span class="o">|</span><span class="nc">Diagnosis</span><span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">pneumonias</span> <span class="o">|</span><span class="nc">Diagnosis</span><span class="o">|</span>
<span class="o">+-----+---+-----------+---------+</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Merges entities coming from different CHUNK annotations</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/merge/ChunkMergeModel">ChunkMergeModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box">

  <h2 id="contextualparser">ContextualParser</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Creates a model, that extracts entity from a document based on user defined rules.
Rule matching is based on a RegexMatcher defined in a JSON file. It is set through the parameter setJsonPath()
In this JSON file, regex is defined that you want to match along with the information that will output on metadata
field. Additionally, a dictionary can be provided with <code class="language-plaintext highlighter-rouge">setDictionary</code> to map extracted entities
to a unified representation. The first column of the dictionary file should be the representation with following
columns the possible matches.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/context/ContextualParserApproach">ContextualParserApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># An example JSON file `regex_token.json` can look like this:
#
# {
#    "entity": "Stage",
#    "ruleScope": "sentence",
#    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",
#    "matchScope": "token"
#  }
#
# Which means to extract the stage code on a sentence level.
# An example pipeline could then be defined like this
# Pipeline could then be defined like this
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Define the parser (json file needs to be provided)
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... "</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">contextualParser</span> <span class="o">=</span> <span class="n">ContextualParserApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setJsonPath</span><span class="p">(</span><span class="s">"/path/to/regex_token.json"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setContextMatch</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">contextualParser</span>
  <span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show Results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(entity)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                                                                      <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="n">pT1bN0M0</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">T5</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>         <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">148</span><span class="p">,</span> <span class="mi">156</span><span class="p">,</span> <span class="n">cT4bcN2M1</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">189</span><span class="p">,</span> <span class="mi">194</span><span class="p">,</span> <span class="n">T</span><span class="err">?</span><span class="n">N3M1</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">316</span><span class="p">,</span> <span class="mi">323</span><span class="p">,</span> <span class="n">pT1bN0M0</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// An example JSON file `regex_token.json` can look like this:</span>
<span class="c1">//</span>
<span class="c1">// {</span>
<span class="c1">//    "entity": "Stage",</span>
<span class="c1">//    "ruleScope": "sentence",</span>
<span class="c1">//    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",</span>
<span class="c1">//    "matchScope": "token"</span>
<span class="c1">//  }</span>
<span class="c1">//</span>
<span class="c1">// Which means to extract the stage code on a sentence level.</span>
<span class="c1">// An example pipeline could then be defined like this</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Define the parser (json file needs to be provided)</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... "</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">contextualParser</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ContextualParserApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setJsonPath</span><span class="o">(</span><span class="s">"/path/to/regex_token.json"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setContextMatch</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">contextualParser</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show Results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(entity)").show(5, truncate=false)</span>
<span class="c1">// +-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |col                                                                                                                      |</span>
<span class="c1">// +-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |{chunk, 32, 39, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []}   |</span>
<span class="c1">// |{chunk, 49, 50, T5, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []}         |</span>
<span class="c1">// |{chunk, 148, 156, cT4bcN2M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 1}, []}|</span>
<span class="c1">// |{chunk, 189, 194, T?N3M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 2}, []}   |</span>
<span class="c1">// |{chunk, 316, 323, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 3}, []} |</span>
<span class="c1">// +-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">//</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Extracts entity from a document based on user defined rules. Rule matching is based on a RegexMatcher defined in a
JSON file. In this file, regex is defined that you want to match along with the information that will output on
metadata field. To instantiate a model, see ContextualParserApproach and its accompanied example.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/context/ContextualParserModel">ContextualParserModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box">

  <h2 id="deidentification">DeIdentification</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Contains all the methods for training a DeIdentificationModel model.
This module can obfuscate or mask the entities that contains personal information. These can be set with a file of
regex patterns with setRegexPatternsDictionary, where each line is a mapping of
entity to regex.</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DATE \d{4}
AID \d{6,7}
</code></pre></div>    </div>

    <p>Additionally, obfuscation strings can be defined with setObfuscateRefFile, where each line
is a mapping of string to entity. The format and seperator can be speficied with
setRefFileFormat and setRefSep.</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Dr. Gregory House#DOCTOR
01010101#MEDICALRECORD
</code></pre></div>    </div>

    <p>Ideally this annotator works in conjunction with Demographic Named EntityRecognizers that can be trained either using
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/TextMatcher">TextMatchers</a>,
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/RegexMatcher">RegexMatchers</a>,
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/DateMatcher">DateMatchers</a>,
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/ner/crf/NerCrfApproach">NerCRFs</a> or
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/ner/dl/NerDLApproach">NerDLs</a></p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/DeIdentification">DeIdentification</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

 <span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Ner entities
</span><span class="n">clinical_sensitive_entities</span> <span class="o">=</span> <span class="n">MedicalNerModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_enriched"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_con"</span><span class="p">)</span>

<span class="c1"># Deidentification
</span><span class="n">deIdentification</span> <span class="o">=</span> <span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
    <span class="c1"># file with custom regex pattern for custom entities
</span>    <span class="p">.</span><span class="n">setRegexPatternsDictionary</span><span class="p">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="p">)</span> \
    <span class="c1"># file with custom obfuscator names for the entities
</span>    <span class="p">.</span><span class="n">setObfuscateRefFile</span><span class="p">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefFileFormat</span><span class="p">(</span><span class="s">"csv"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefSep</span><span class="p">(</span><span class="s">"#"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormats</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s">"MM/dd/yy"</span><span class="p">,</span><span class="s">"yyyy-MM-dd"</span><span class="p">))</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDays</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"file"</span><span class="p">)</span>

<span class="c1"># Pipeline
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09."</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">clinical_sensitive_entities</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">deIdentification</span>
<span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show Results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"dei.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                            <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="c1"># 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]|
</span><span class="o">+--------------------------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
     <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Ner entities</span>
<span class="k">val</span> <span class="nv">clinical_sensitive_entities</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_enriched"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
        <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_con"</span><span class="o">)</span>

<span class="c1">// Deidentification</span>
<span class="k">val</span> <span class="nv">deIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
     <span class="c1">// file with custom regex patterns for custom entities</span>
     <span class="o">.</span><span class="py">setRegexPatternsDictionary</span><span class="o">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="o">)</span>
     <span class="c1">// file with custom obfuscator names for the entities</span>
     <span class="o">.</span><span class="py">setObfuscateRefFile</span><span class="o">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefFileFormat</span><span class="o">(</span><span class="s">"csv"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefSep</span><span class="o">(</span><span class="s">"#"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateFormats</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"MM/dd/yy"</span><span class="o">,</span><span class="s">"yyyy-MM-dd"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateTag</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDays</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"file"</span><span class="o">)</span>

<span class="c1">// Pipeline</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">clinical_sensitive_entities</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">deIdentification</span>
<span class="o">))</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"dei.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>

<span class="c1">// Show Results</span>
<span class="c1">//</span>
<span class="c1">// result.select("dei.result").show(truncate = false)</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |result                                                                                            |</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]|</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">//</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Deidentifies Input Annotations of types DOCUMENT, TOKEN and CHUNK, by either masking or obfuscating the given CHUNKS.</p>

    <p>To create a configured DeIdentificationModel, please see the example of DeIdentification.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/DeIdentificationModel">DeIdentificationModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="tabs-box">

  <h2 id="documentlogregclassifier">DocumentLogRegClassifier</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a model to classify documents with a Logarithmic Regression algorithm. Training data requires columns for
text and their label. The result is a trained DocumentLogRegClassifierModel.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/DocumentLogRegClassifierApproach">DocumentLogRegClassifierApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Define pipeline stages to prepare the data
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">Normalizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span>

<span class="n">stopwords_cleaner</span> <span class="o">=</span> <span class="n">StopWordsCleaner</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"normalized"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">Stemmer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"cleanTokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"stem"</span><span class="p">)</span>

<span class="c1"># Define the document classifier and fit training data to it
</span><span class="n">logreg</span> <span class="o">=</span> <span class="n">DocumentLogRegClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"stem"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">normalizer</span><span class="p">,</span>
  <span class="n">stopwords_cleaner</span><span class="p">,</span>
  <span class="n">stemmer</span><span class="p">,</span>
  <span class="n">logreg</span>
<span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Define pipeline stages to prepare the data</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopwords_cleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsCleaner</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stemmer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Stemmer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>

<span class="c1">// Define the document classifier and fit training data to it</span>
<span class="k">val</span> <span class="nv">logreg</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentLogRegClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">normalizer</span><span class="o">,</span>
  <span class="n">stopwords_cleaner</span><span class="o">,</span>
  <span class="n">stemmer</span><span class="o">,</span>
  <span class="n">logreg</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Classifies documents with a Logarithmic Regression algorithm.
Currently there are no pretrained models available.
Please see DocumentLogRegClassifierApproach to train your own model.</p>

    <p>Please check out the
<a href="https://nlp.johnsnowlabs.com/models">Models Hub</a> for available models in the future.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/DocumentLogRegClassifierModel">DocumentLogRegClassifierModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="drugnormalizer">DrugNormalizer</h2>

  <p>Annotator which normalizes raw text from clinical documents, e.g. scraped web pages or xml documents, from document type columns into Sentence.
Removes all dirty characters from text following one or more input regex patterns.
Can apply non wanted character removal which a specific policy.
Can apply lower case normalization.</p>

  <p>See <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/23.Drug_Normalizer.ipynb">Spark NLP Workshop</a> for more examples of usage.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/DrugNormalizer">DrugNormalizer</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
  <span class="p">[</span><span class="s">"Sodium Chloride/Potassium Chloride 13bag"</span><span class="p">],</span>
  <span class="p">[</span><span class="s">"interferon alfa-2b 10 million unit ( 1 ml ) injec"</span><span class="p">],</span>
  <span class="p">[</span><span class="s">"aspirin 10 meq/ 5 ml oral sol"</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">document</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">drugNormalizer</span> <span class="o">=</span> <span class="n">DrugNormalizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document_normalized"</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document</span><span class="p">,</span> <span class="n">drugNormalizer</span><span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(document_normalized.result) as normalized_text"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------------------------------------+</span>
<span class="o">|</span><span class="n">normalized_text</span>                                     <span class="o">|</span>
<span class="o">+----------------------------------------------------+</span>
<span class="o">|</span><span class="n">Sodium</span> <span class="n">Chloride</span> <span class="o">/</span> <span class="n">Potassium</span> <span class="n">Chloride</span> <span class="mi">13</span> <span class="n">bag</span>         <span class="o">|</span>
<span class="o">|</span><span class="n">interferon</span> <span class="n">alfa</span> <span class="o">-</span> <span class="mi">2</span><span class="n">b</span> <span class="mi">10000000</span> <span class="n">unt</span> <span class="p">(</span> <span class="mi">1</span> <span class="n">ml</span> <span class="p">)</span> <span class="n">injection</span><span class="o">|</span>
<span class="o">|</span><span class="n">aspirin</span> <span class="mi">2</span> <span class="n">meq</span><span class="o">/</span><span class="n">ml</span> <span class="n">oral</span> <span class="n">solution</span>                      <span class="o">|</span>
<span class="o">+----------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">"Sodium Chloride/Potassium Chloride 13bag"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"interferon alfa-2b 10 million unit ( 1 ml ) injec"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"aspirin 10 meq/ 5 ml oral sol"</span><span class="o">)</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">drugNormalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DrugNormalizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document_normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document</span><span class="o">,</span> <span class="n">drugNormalizer</span><span class="o">))</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(document_normalized.result) as normalized_text"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">+----------------------------------------------------+</span>
<span class="o">|</span><span class="n">normalized_text</span>                                     <span class="o">|</span>
<span class="o">+----------------------------------------------------+</span>
<span class="o">|</span><span class="nc">Sodium</span> <span class="nc">Chloride</span> <span class="o">/</span> <span class="nc">Potassium</span> <span class="nc">Chloride</span> <span class="mi">13</span> <span class="n">bag</span>         <span class="o">|</span>
<span class="o">|</span><span class="n">interferon</span> <span class="n">alfa</span> <span class="o">-</span> <span class="mi">2</span><span class="n">b</span> <span class="mi">10000000</span> <span class="nf">unt</span> <span class="o">(</span> <span class="mi">1</span> <span class="n">ml</span> <span class="o">)</span> <span class="n">injection</span><span class="o">|</span>
<span class="o">|</span><span class="n">aspirin</span> <span class="mi">2</span> <span class="n">meq</span><span class="o">/</span><span class="n">ml</span> <span class="n">oral</span> <span class="n">solution</span>                      <span class="o">|</span>
<span class="o">+----------------------------------------------------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="featuresassembler">FeaturesAssembler</h2>

  <p>The FeaturesAssembler is used to collect features from different columns. It can collect features from single value
columns (anything which can be cast to a float, if casts fails then the value is set to 0), array columns or
SparkNLP annotations (if the annotation is an embedding, it takes the embedding, otherwise tries to cast the
<code class="language-plaintext highlighter-rouge">result</code> field). The output of the transformer is a <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code> annotation (the numeric vector is in the
<code class="language-plaintext highlighter-rouge">embeddings</code> field).</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">"feature_vector"</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/FeaturesAssembler">FeaturesAssembler</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">features_asm</span> <span class="o">=</span> <span class="n">FeaturesAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">GenericClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">features_asm</span><span class="p">,</span>
  <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box">

  <h2 id="genericclassifier">GenericClassifier</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a TensorFlow model for generic classification of feature vectors. It takes FEATURE_VECTOR annotations from
<code class="language-plaintext highlighter-rouge">FeaturesAssembler</code> as input, classifies them and outputs CATEGORY annotations.
Please see the Parameters section for required training parameters.</p>

    <p>For a more extensive example please see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/8.Generic_Classifier.ipynb">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/generic_classifier/GenericClassifierApproach">GenericClassifierApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">features_asm</span> <span class="o">=</span> <span class="n">FeaturesAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">GenericClassifierApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setlearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">features_asm</span><span class="p">,</span>
    <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Creates a generic single-label classifier which uses pre-generated Tensorflow graphs.
The model operates on FEATURE_VECTOR annotations which can be produced using FeatureAssembler.
Requires the FeaturesAssembler to create the input.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/generic_classifier/GenericClassifierModel">GenericClassifierModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="iobtagger">IOBTagger</h2>

  <p>Merges token tags and NER labels from chunks in the specified format.
For example output columns as inputs from
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter.html">NerConverter</a>
and <a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/Tokenizer">Tokenizer</a> can be used to merge.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, CHUNK</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/IOBTagger">IOBTagger</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Pipeline stages are defined where NER is done. NER is converted to chunks.
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">().</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embs"</span><span class="p">)</span>
<span class="n">nerModel</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">).</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1"># Define the IOB tagger, which needs tokens and chunks as input. Show results.
</span><span class="n">iobTagger</span> <span class="o">=</span> <span class="n">IOBTagger</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">]).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">docAssembler</span><span class="p">,</span> <span class="n">sentenceDetector</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">nerModel</span><span class="p">,</span> <span class="n">nerConverter</span><span class="p">,</span> <span class="n">iobTagger</span><span class="p">])</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_label) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span><span class="s">"a.end"</span><span class="p">,</span><span class="s">"a.result as chunk"</span><span class="p">,</span><span class="s">"a.metadata.word as word"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="s">"chunk!='O'"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----+---+-----------+-----------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">chunk</span>      <span class="o">|</span><span class="n">word</span>       <span class="o">|</span>
<span class="o">+-----+---+-----------+-----------+</span>
<span class="o">|</span><span class="mi">5</span>    <span class="o">|</span><span class="mi">15</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">Age</span>      <span class="o">|</span><span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">|</span>
<span class="o">|</span><span class="mi">17</span>   <span class="o">|</span><span class="mi">19</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">Gender</span>   <span class="o">|</span><span class="n">man</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">64</span>   <span class="o">|</span><span class="mi">72</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">Modifier</span> <span class="o">|</span><span class="n">recurrent</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">98</span>   <span class="o">|</span><span class="mi">107</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">Diagnosis</span><span class="o">|</span><span class="n">cellulitis</span> <span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">Diagnosis</span><span class="o">|</span><span class="n">pneumonias</span> <span class="o">|</span>
<span class="o">+-----+---+-----------+-----------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Pipeline stages are defined where NER is done. NER is converted to chunks.</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">().</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embs"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">).</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embs"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="c1">// Define the IOB tagger, which needs tokens and chunks as input. Show results.</span>
<span class="k">val</span> <span class="nv">iobTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IOBTagger</span><span class="o">().</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_label"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">docAssembler</span><span class="o">,</span> <span class="n">sentenceDetector</span><span class="o">,</span> <span class="n">tokenizer</span><span class="o">,</span> <span class="n">embeddings</span><span class="o">,</span> <span class="n">nerModel</span><span class="o">,</span> <span class="n">nerConverter</span><span class="o">,</span> <span class="n">iobTagger</span><span class="o">))</span>

<span class="nv">result</span><span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"explode(ner_label) as a"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">selectExpr</span><span class="o">(</span><span class="s">"a.begin"</span><span class="o">,</span><span class="s">"a.end"</span><span class="o">,</span><span class="s">"a.result as chunk"</span><span class="o">,</span><span class="s">"a.metadata.word as word"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">where</span><span class="o">(</span><span class="s">"chunk!='O'"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="mi">5</span><span class="o">,</span> <span class="kc">false</span><span class="o">)</span>

<span class="o">+-----+---+-----------+-----------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">chunk</span>      <span class="o">|</span><span class="n">word</span>       <span class="o">|</span>
<span class="o">+-----+---+-----------+-----------+</span>
<span class="o">|</span><span class="mi">5</span>    <span class="o">|</span><span class="mi">15</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">Age</span>      <span class="o">|</span><span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">|</span>
<span class="o">|</span><span class="mi">17</span>   <span class="o">|</span><span class="mi">19</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">Gender</span>   <span class="o">|</span><span class="n">man</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">64</span>   <span class="o">|</span><span class="mi">72</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">Modifier</span> <span class="o">|</span><span class="n">recurrent</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">98</span>   <span class="o">|</span><span class="mi">107</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">Diagnosis</span><span class="o">|</span><span class="n">cellulitis</span> <span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">Diagnosis</span><span class="o">|</span><span class="n">pneumonias</span> <span class="o">|</span>
<span class="o">+-----+---+-----------+-----------+</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="nerchunker">NerChunker</h2>

  <p>Extracts phrases that fits into a known pattern using the NER tags. Useful for entity groups with neighboring tokens
when there is no pretrained NER model to address certain issues. A Regex needs to be provided to extract the tokens
between entities.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, NAMED_ENTITY</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/NerChunker">NerChunker</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Defining pipeline stages for NER
</span><span class="n">data</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"She has cystic cyst on her kidney."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">documentAssembler</span><span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span><span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_radiology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setIncludeConfidence</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Define the NerChunker to combine to chunks
</span><span class="n">chunker</span> <span class="o">=</span> <span class="n">NerChunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;"</span><span class="p">])</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">ner</span><span class="p">,</span>
  <span class="n">chunker</span>
<span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results:
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(arrays_zip(ner.metadata , ner.result))"</span><span class="p">)</span>
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"col['0'].word as word"</span> <span class="p">,</span> <span class="s">"col['1'] as ner"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+-----------------+</span>
<span class="o">|</span><span class="n">word</span>  <span class="o">|</span><span class="n">ner</span>              <span class="o">|</span>
<span class="o">+------+-----------------+</span>
<span class="o">|</span><span class="n">She</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">has</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">cystic</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ImagingFindings</span><span class="o">|</span>
<span class="o">|</span><span class="n">cyst</span>  <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ImagingFindings</span><span class="o">|</span>
<span class="o">|</span><span class="n">on</span>    <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">her</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">kidney</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">BodyPart</span>       <span class="o">|</span>
<span class="o">|</span><span class="p">.</span>     <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">+------+-----------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner_chunk.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="n">result</span>                     <span class="o">|</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">cystic</span> <span class="n">cyst</span> <span class="n">on</span> <span class="n">her</span> <span class="n">kidney</span><span class="p">]</span><span class="o">|</span>
<span class="o">+---------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Defining pipeline stages for NER</span>
<span class="k">val</span> <span class="nv">data</span><span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"She has cystic cyst on her kidney."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span><span class="k">=new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span><span class="k">=new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span><span class="k">=new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_radiology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setIncludeConfidence</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="c1">// Define the NerChunker to combine to chunks</span>
<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerChunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"&lt;ImagingFindings&gt;.&lt;BodyPart&gt;"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span><span class="k">=new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner</span><span class="o">,</span>
  <span class="n">chunker</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results:</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(arrays_zip(ner.metadata , ner.result))")</span>
<span class="c1">//   .selectExpr("col['0'].word as word" , "col['1'] as ner").show(truncate=false)</span>
<span class="c1">// +------+-----------------+</span>
<span class="c1">// |word  |ner              |</span>
<span class="c1">// +------+-----------------+</span>
<span class="c1">// |She   |O                |</span>
<span class="c1">// |has   |O                |</span>
<span class="c1">// |cystic|B-ImagingFindings|</span>
<span class="c1">// |cyst  |I-ImagingFindings|</span>
<span class="c1">// |on    |O                |</span>
<span class="c1">// |her   |O                |</span>
<span class="c1">// |kidney|B-BodyPart       |</span>
<span class="c1">// |.     |O                |</span>
<span class="c1">// +------+-----------------+</span>
<span class="c1">// result.select("ner_chunk.result").show(truncate=false)</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">// |result                     |</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">// |[cystic cyst on her kidney]|</span>
<span class="c1">// +---------------------------+</span>
<span class="c1">//</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="nerconverterinternal">NerConverterInternal</h2>

  <p>Converts a IOB or IOB2 representation of NER to a user-friendly one,
by associating the tokens of recognized entities and their label.
Chunks with no associated entity (tagged “O”) are filtered.
See also <a href="https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)">Inside–outside–beginning (tagging)</a> for more information.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, NAMED_ENTITY</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/NerConverterInternal">NerConverterInternal</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># The output of a MedicalNerModel follows the Annotator schema and looks like this after the transformation.
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_result)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                       <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="p">{</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">A</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.994</span><span class="p">},</span> <span class="p">[]}</span>             <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">Age</span><span class="p">,</span> <span class="p">{</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">1.0</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">Gender</span><span class="p">,</span> <span class="p">{</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">man</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.9858</span><span class="p">},</span> <span class="p">[]}</span> <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="p">{</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">presents</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.9952</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">named_entity</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="p">{</span><span class="n">word</span> <span class="o">-&gt;</span> <span class="n">to</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">-&gt;</span> <span class="mf">0.7063</span><span class="p">},</span> <span class="p">[]}</span>         <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------+</span>

<span class="c1"># After the converter is used:
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_converter_result)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                                <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="p">,</span> <span class="p">{</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">Age</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>        <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="n">man</span><span class="p">,</span> <span class="p">{</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">Gender</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span>            <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">72</span><span class="p">,</span> <span class="n">recurrent</span><span class="p">,</span> <span class="p">{</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">Modifier</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>    <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">98</span><span class="p">,</span> <span class="mi">107</span><span class="p">,</span> <span class="n">cellulitis</span><span class="p">,</span> <span class="p">{</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">Diagnosis</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span> <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="n">pneumonias</span><span class="p">,</span> <span class="p">{</span><span class="n">entity</span> <span class="o">-&gt;</span> <span class="n">Diagnosis</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// The output of a [[MedicalNerModel]] follows the Annotator schema and looks like this after the transformation.</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(ner_result)").show(5, false)</span>
<span class="c1">// +--------------------------------------------------------------------------+</span>
<span class="c1">// |col                                                                       |</span>
<span class="c1">// +--------------------------------------------------------------------------+</span>
<span class="c1">// |{named_entity, 3, 3, O, {word -&gt; A, confidence -&gt; 0.994}, []}             |</span>
<span class="c1">// |{named_entity, 5, 15, B-Age, {word -&gt; 63-year-old, confidence -&gt; 1.0}, []}|</span>
<span class="c1">// |{named_entity, 17, 19, B-Gender, {word -&gt; man, confidence -&gt; 0.9858}, []} |</span>
<span class="c1">// |{named_entity, 21, 28, O, {word -&gt; presents, confidence -&gt; 0.9952}, []}   |</span>
<span class="c1">// |{named_entity, 30, 31, O, {word -&gt; to, confidence -&gt; 0.7063}, []}         |</span>
<span class="c1">// +--------------------------------------------------------------------------+</span>
<span class="c1">//</span>
<span class="c1">// After the converter is used:</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(ner_converter_result)").show(5, false)</span>
<span class="c1">// +-----------------------------------------------------------------------------------+</span>
<span class="c1">// |col                                                                                |</span>
<span class="c1">// +-----------------------------------------------------------------------------------+</span>
<span class="c1">// |{chunk, 5, 15, 63-year-old, {entity -&gt; Age, sentence -&gt; 0, chunk -&gt; 0}, []}        |</span>
<span class="c1">// |{chunk, 17, 19, man, {entity -&gt; Gender, sentence -&gt; 0, chunk -&gt; 1}, []}            |</span>
<span class="c1">// |{chunk, 64, 72, recurrent, {entity -&gt; Modifier, sentence -&gt; 0, chunk -&gt; 2}, []}    |</span>
<span class="c1">// |{chunk, 98, 107, cellulitis, {entity -&gt; Diagnosis, sentence -&gt; 0, chunk -&gt; 3}, []} |</span>
<span class="c1">// |{chunk, 110, 119, pneumonias, {entity -&gt; Diagnosis, sentence -&gt; 0, chunk -&gt; 4}, []}|</span>
<span class="c1">// +-----------------------------------------------------------------------------------+</span>
<span class="c1">//</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box">

  <h2 id="nerdisambiguator">NerDisambiguator</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Links words of interest, such as names of persons, locations and companies, from an input text document to
a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs),
mentions, or surface forms.
The model needs extracted CHUNKS and SENTENCE_EMBEDDINGS type input from e.g.
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings.html">SentenceEmbeddings</a> and
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/ner/NerConverter.html">NerConverter</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DISAMBIGUATION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/disambiguation/NerDisambiguator">NerDisambiguator</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Extracting Person identities
# First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.
# Extracting Person identities
# First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"The show also had a contestant named Donald Trump who later defeated Christina Aguilera ..."</span><span class="p">]])</span> \
  <span class="p">.</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">SentenceEmbeddings</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>
<span class="n">ner_model</span> <span class="o">=</span> <span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"PER"</span><span class="p">])</span>

<span class="c1"># Then the extracted entities can be disambiguated.
</span><span class="n">disambiguator</span> <span class="o">=</span> <span class="n">NerDisambiguator</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setS3KnowledgeBaseName</span><span class="p">(</span><span class="s">"i-per"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"disambiguation"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setNumFirstChars</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">word_embeddings</span><span class="p">,</span>
  <span class="n">sentence_embeddings</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span>
  <span class="n">ner_converter</span><span class="p">,</span>
  <span class="n">disambiguator</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(disambiguation)"</span><span class="p">)</span>
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"col.metadata.chunk as chunk"</span><span class="p">,</span> <span class="s">"col.result as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>             <span class="o">|</span><span class="n">result</span>                                                                                                                  <span class="o">|</span>
<span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">Donald</span> <span class="n">Trump</span>      <span class="o">|</span><span class="n">http</span><span class="p">:</span><span class="c1">#en.wikipedia.org/?curid=4848272, http:#en.wikipedia.org/?curid=31698421, http:#en.wikipedia.org/?curid=55907961   |
</span><span class="o">|</span><span class="n">Christina</span> <span class="n">Aguilera</span><span class="o">|</span><span class="n">http</span><span class="p">:</span><span class="c1">#en.wikipedia.org/?curid=144171, http:#en.wikipedia.org/?curid=6636454                                             |
</span><span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Extracting Person identities</span>
<span class="c1">// First define pipeline stages that extract entities and embeddings. Entities are filtered for PER type entities.</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The show also had a contestant named Donald Trump who later defeated Christina Aguilera ..."</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"PER"</span><span class="o">)</span>

<span class="c1">// Then the extracted entities can be disambiguated.</span>
<span class="k">val</span> <span class="nv">disambiguator</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDisambiguator</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setS3KnowledgeBaseName</span><span class="o">(</span><span class="s">"i-per"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"disambiguation"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNumFirstChars</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">word_embeddings</span><span class="o">,</span>
  <span class="n">sentence_embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">ner_converter</span><span class="o">,</span>
  <span class="n">disambiguator</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(disambiguation)")</span>
<span class="c1">//   .selectExpr("col.metadata.chunk as chunk", "col.result as result").show(5, false)</span>
<span class="c1">// +------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |chunk             |result                                                                                                                  |</span>
<span class="c1">// +------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |Donald Trump      |http://en.wikipedia.org/?curid=4848272, http://en.wikipedia.org/?curid=31698421, http://en.wikipedia.org/?curid=55907961|</span>
<span class="c1">// |Christina Aguilera|http://en.wikipedia.org/?curid=144171, http://en.wikipedia.org/?curid=6636454                                           |</span>
<span class="c1">// +------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">//</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Links words of interest, such as names of persons, locations and companies, from an input text document to
a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs),
mentions, or surface forms.
Instantiated / pretrained model of the NerDisambiguator.
Links words of interest, such as names of persons, locations and companies, from an input text document to
a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs),
mentions, or surface forms.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DISAMBIGUATION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/disambiguation/NerDisambiguatorModel">NerDisambiguatorModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="renerchunksfilter">RENerChunksFilter</h2>

  <p>Filters and outputs combinations of relations between extracted entities, for further processing.
This annotator is especially useful to create inputs for the RelationExtractionDLModel.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, DEPENDENCY</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RENerChunksFilter">RENerChunksFilter</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Define pipeline stages to extract entities
</span><span class="n">documenter</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">DependencyParserModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">clinical_ner_tagger</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"jsl_ner_wip_greedy_clinical"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="c1"># Define the relation pairs and the filter
</span><span class="n">relationPairs</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s">"direction-external_body_part_or_region"</span><span class="p">,</span>
  <span class="s">"external_body_part_or_region-direction"</span><span class="p">,</span>
  <span class="s">"direction-internal_organ_or_component"</span><span class="p">,</span>
  <span class="s">"internal_organ_or_component-direction"</span>
<span class="p">]</span>

<span class="n">re_ner_chunk_filter</span> <span class="o">=</span> <span class="n">RENerChunksFilter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"internal_organ_or_component-direction"</span><span class="p">])</span>

<span class="n">trained_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documenter</span><span class="p">,</span>
  <span class="n">sentencer</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">words_embedder</span><span class="p">,</span>
  <span class="n">pos_tagger</span><span class="p">,</span>
  <span class="n">clinical_ner_tagger</span><span class="p">,</span>
  <span class="n">ner_chunker</span><span class="p">,</span>
  <span class="n">dependency_parser</span><span class="p">,</span>
  <span class="n">re_ner_chunk_filter</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trained_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(re_ner_chunks) as re_chunks"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"re_chunks.begin"</span><span class="p">,</span> <span class="s">"re_chunks.result"</span><span class="p">,</span> <span class="s">"re_chunks.metadata.entity"</span><span class="p">,</span> <span class="s">"re_chunks.metadata.paired_to"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----+-------------+---------------------------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">result</span>       <span class="o">|</span><span class="n">entity</span>                     <span class="o">|</span><span class="n">paired_to</span><span class="o">|</span>
<span class="o">+-----+-------------+---------------------------+---------+</span>
<span class="o">|</span><span class="mi">35</span>   <span class="o">|</span><span class="n">upper</span>        <span class="o">|</span><span class="n">Direction</span>                  <span class="o">|</span><span class="mi">41</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">41</span>   <span class="o">|</span><span class="n">brain</span> <span class="n">stem</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">35</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">35</span>   <span class="o">|</span><span class="n">upper</span>        <span class="o">|</span><span class="n">Direction</span>                  <span class="o">|</span><span class="mi">59</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">59</span>   <span class="o">|</span><span class="n">cerebellum</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">35</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">35</span>   <span class="o">|</span><span class="n">upper</span>        <span class="o">|</span><span class="n">Direction</span>                  <span class="o">|</span><span class="mi">81</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">81</span>   <span class="o">|</span><span class="n">basil</span> <span class="n">ganglia</span><span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">35</span>       <span class="o">|</span>
<span class="o">+-----+-------------+---------------------------+---------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Define pipeline stages to extract entities</span>
<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner_tagger</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"jsl_ner_wip_greedy_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_tags"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span>

<span class="c1">// Define the relation pairs and the filter</span>
<span class="k">val</span> <span class="nv">relationPairs</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"direction-external_body_part_or_region"</span><span class="o">,</span>
                      <span class="s">"external_body_part_or_region-direction"</span><span class="o">,</span>
                      <span class="s">"direction-internal_organ_or_component"</span><span class="o">,</span>
                      <span class="s">"internal_organ_or_component-direction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_ner_chunk_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RENerChunksFilter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"internal_organ_or_component-direction"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">trained_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documenter</span><span class="o">,</span>
  <span class="n">sentencer</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">words_embedder</span><span class="o">,</span>
  <span class="n">pos_tagger</span><span class="o">,</span>
  <span class="n">clinical_ner_tagger</span><span class="o">,</span>
  <span class="n">ner_chunker</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">re_ner_chunk_filter</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trained_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(re_ner_chunks) as re_chunks")</span>
<span class="c1">//   .selectExpr("re_chunks.begin", "re_chunks.result", "re_chunks.metadata.entity", "re_chunks.metadata.paired_to")</span>
<span class="c1">//   .show(6, truncate=false)</span>
<span class="c1">// +-----+-------------+---------------------------+---------+</span>
<span class="c1">// |begin|result       |entity                     |paired_to|</span>
<span class="c1">// +-----+-------------+---------------------------+---------+</span>
<span class="c1">// |35   |upper        |Direction                  |41       |</span>
<span class="c1">// |41   |brain stem   |Internal_organ_or_component|35       |</span>
<span class="c1">// |35   |upper        |Direction                  |59       |</span>
<span class="c1">// |59   |cerebellum   |Internal_organ_or_component|35       |</span>
<span class="c1">// |35   |upper        |Direction                  |81       |</span>
<span class="c1">// |81   |basil ganglia|Internal_organ_or_component|35       |</span>
<span class="c1">// +-----+-------------+---------------------------+---------+</span>
<span class="c1">//</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="h3-box model-content">

  <h2 id="reidentification">ReIdentification</h2>

  <p>Reidentifies obfuscated entities by DeIdentification. This annotator requires the outputs
from the deidentification as input. Input columns need to be the deidentified document and the deidentification
mappings set with DeIdentification.setMappingsColumn.
To see how the entities are deidentified, please refer to the example of that class.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT,CHUNK</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/ReIdentification">ReIdentification</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Define the reidentification stage and transform the deidentified documents
</span><span class="n">reideintification</span> <span class="o">=</span> <span class="n">ReIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"dei"</span><span class="p">,</span> <span class="s">"protectedEntities"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"reid"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"dei.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                            <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="c1"># 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]|
</span><span class="o">+--------------------------------------------------------------------------------------------------+</span>

<span class="n">reideintification</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(reid.result)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                                <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="c1"># 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.|
</span><span class="o">+-----------------------------------------------------------------------------------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Define the reidentification stage and transform the deidentified documents</span>
<span class="k">val</span> <span class="nv">reideintification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ReIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"dei"</span><span class="o">,</span> <span class="s">"protectedEntities"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"reid"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">result</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.select("dei.result").show(truncate = false)</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |result                                                                                            |</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |[# 01010101 Date : 01/18/93 PCP : Dr. Gregory House , &lt;AGE&gt; years-old , Record date : 2079-11-14.]|</span>
<span class="c1">// +--------------------------------------------------------------------------------------------------+</span>
<span class="c1">// reideintification.selectExpr("explode(reid.result)").show(false)</span>
<span class="c1">// +-----------------------------------------------------------------------------------+</span>
<span class="c1">// |col                                                                                |</span>
<span class="c1">// +-----------------------------------------------------------------------------------+</span>
<span class="c1">// |# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.|</span>
<span class="c1">// +-----------------------------------------------------------------------------------+</span>
<span class="c1">//</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box">

  <h2 id="relationextraction">RelationExtraction</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Trains a TensorFlow model for relation extraction. The Tensorflow graph in <code class="language-plaintext highlighter-rouge">.pb</code> format needs to be specified with
<code class="language-plaintext highlighter-rouge">setModelFile</code>. The result is a RelationExtractionModel.
To start training, see the parameters that need to be set in the Parameters section.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionApproach">RelationExtractionApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Defining pipeline stages to extract entities first
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">embedder</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">PerceptronModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"posTags"</span><span class="p">)</span>

<span class="n">nerTagger</span> <span class="o">=</span> <span class="n">MedicalNerModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_events_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"nerChunks"</span><span class="p">)</span>

<span class="n">depencyParser</span> <span class="o">=</span> <span class="n">DependencyParserModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"posTags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="c1"># Then define `RelationExtractionApproach` and training parameters
</span><span class="n">re</span> <span class="o">=</span> <span class="n">RelationExtractionApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"posTags"</span><span class="p">,</span> <span class="s">"train_ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations_t"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target_rel"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"path/to/graph_file.pb"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFromEntity</span><span class="p">(</span><span class="s">"from_begin"</span><span class="p">,</span> <span class="s">"from_end"</span><span class="p">,</span> <span class="s">"from_label"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setToEntity</span><span class="p">(</span><span class="s">"to_begin"</span><span class="p">,</span> <span class="s">"to_end"</span><span class="p">,</span> <span class="s">"to_label"</span><span class="p">)</span>

<span class="n">finisher</span> <span class="o">=</span> <span class="n">Finisher</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"relations_t"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"relations"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setValueSplitSymbol</span><span class="p">(</span><span class="s">","</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setAnnotationSplitSymbol</span><span class="p">(</span><span class="s">","</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputAsArray</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Define complete pipeline and start training
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embedder</span><span class="p">,</span>
    <span class="n">posTagger</span><span class="p">,</span>
    <span class="n">nerTagger</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">depencyParser</span><span class="p">,</span>
    <span class="n">re</span><span class="p">,</span>
    <span class="n">finisher</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainData</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Defining pipeline stages to extract entities first</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embedder</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nc">PerceptronModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"posTags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="nc">MedicalNerModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_events_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_tags"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"nerChunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">depencyParser</span> <span class="k">=</span> <span class="nc">DependencyParserModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"posTags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="c1">// Then define `RelationExtractionApproach` and training parameters</span>
<span class="k">val</span> <span class="nv">re</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RelationExtractionApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span> <span class="s">"posTags"</span><span class="o">,</span> <span class="s">"train_ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations_t"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target_rel"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">300</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">200</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.05f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFromEntity</span><span class="o">(</span><span class="s">"from_begin"</span><span class="o">,</span> <span class="s">"from_end"</span><span class="o">,</span> <span class="s">"from_label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setToEntity</span><span class="o">(</span><span class="s">"to_begin"</span><span class="o">,</span> <span class="s">"to_end"</span><span class="o">,</span> <span class="s">"to_label"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">finisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Finisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"relations_t"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"relations"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValueSplitSymbol</span><span class="o">(</span><span class="s">","</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAnnotationSplitSymbol</span><span class="o">(</span><span class="s">","</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsArray</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// Define complete pipeline and start training</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embedder</span><span class="o">,</span>
    <span class="n">posTagger</span><span class="o">,</span>
    <span class="n">nerTagger</span><span class="o">,</span>
    <span class="n">nerConverter</span><span class="o">,</span>
    <span class="n">depencyParser</span><span class="o">,</span>
    <span class="n">re</span><span class="o">,</span>
    <span class="n">finisher</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainData</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>Extracts and classifies instances of relations between named entities. For this, relation pairs
need to be defined with <code class="language-plaintext highlighter-rouge">setRelationPairs</code>, to specify between which entities the extraction should be done.</p>

    <p>For pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Relation+Extraction">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionModel">RelationExtractionModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Relation Extraction between body parts
# Define pipeline stages to extract entities
</span><span class="n">documenter</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">DependencyParserModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">clinical_ner_tagger</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"jsl_ner_wip_greedy_clinical"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="c1"># Define the relations that are to be extracted
</span><span class="n">relationPairs</span> <span class="o">=</span> <span class="p">[</span>
  <span class="s">"direction-external_body_part_or_region"</span><span class="p">,</span>
  <span class="s">"external_body_part_or_region-direction"</span><span class="p">,</span>
  <span class="s">"direction-internal_organ_or_component"</span><span class="p">,</span>
  <span class="s">"internal_organ_or_component-direction"</span>
<span class="p">]</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">RelationExtractionModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"re_bodypart_directions"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">(</span><span class="n">relationPairs</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documenter</span><span class="p">,</span>
    <span class="n">sentencer</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">words_embedder</span><span class="p">,</span>
    <span class="n">pos_tagger</span><span class="p">,</span>
    <span class="n">clinical_ner_tagger</span><span class="p">,</span>
    <span class="n">ner_chunker</span><span class="p">,</span>
    <span class="n">dependency_parser</span><span class="p">,</span>
    <span class="n">re_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
#
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(relations) as relations"</span><span class="p">)</span>
 <span class="p">.</span><span class="n">select</span><span class="p">(</span>
   <span class="s">"relations.metadata.chunk1"</span><span class="p">,</span>
   <span class="s">"relations.metadata.entity1"</span><span class="p">,</span>
   <span class="s">"relations.metadata.chunk2"</span><span class="p">,</span>
   <span class="s">"relations.metadata.entity2"</span><span class="p">,</span>
   <span class="s">"relations.result"</span>
 <span class="p">)</span>
 <span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="s">"result != 0"</span><span class="p">)</span>
 <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(relations) as relations"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">select</span><span class="p">(</span>
     <span class="s">"relations.metadata.chunk1"</span><span class="p">,</span>
     <span class="s">"relations.metadata.entity1"</span><span class="p">,</span>
     <span class="s">"relations.metadata.chunk2"</span><span class="p">,</span>
     <span class="s">"relations.metadata.entity2"</span><span class="p">,</span>
     <span class="s">"relations.result"</span>
  <span class="p">).</span><span class="n">where</span><span class="p">(</span><span class="s">"result != 0"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
<span class="o">|</span><span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span>  <span class="o">|</span><span class="n">chunk2</span>       <span class="o">|</span><span class="n">entity2</span>                    <span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
<span class="o">|</span><span class="n">upper</span> <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">brain</span> <span class="n">stem</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">left</span>  <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">cerebellum</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">right</span> <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">basil</span> <span class="n">ganglia</span><span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Relation Extraction between body parts</span>
<span class="c1">// Define pipeline stages to extract entities</span>
<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner_tagger</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"jsl_ner_wip_greedy_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_tags"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span>

<span class="c1">// Define the relations that are to be extracted</span>
<span class="k">val</span> <span class="nv">relationPairs</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"direction-external_body_part_or_region"</span><span class="o">,</span>
                      <span class="s">"external_body_part_or_region-direction"</span><span class="o">,</span>
                      <span class="s">"direction-internal_organ_or_component"</span><span class="o">,</span>
                      <span class="s">"internal_organ_or_component-direction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_model</span> <span class="k">=</span> <span class="nv">RelationExtractionModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"re_bodypart_directions"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="n">relationPairs</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.9f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documenter</span><span class="o">,</span>
  <span class="n">sentencer</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">words_embedder</span><span class="o">,</span>
  <span class="n">pos_tagger</span><span class="o">,</span>
  <span class="n">clinical_ner_tagger</span><span class="o">,</span>
  <span class="n">ner_chunker</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">re_model</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(relations) as relations")</span>
<span class="c1">//  .select(</span>
<span class="c1">//    "relations.metadata.chunk1",</span>
<span class="c1">//    "relations.metadata.entity1",</span>
<span class="c1">//    "relations.metadata.chunk2",</span>
<span class="c1">//    "relations.metadata.entity2",</span>
<span class="c1">//    "relations.result"</span>
<span class="c1">//  )</span>
<span class="c1">//  .where("result != 0")</span>
<span class="c1">//  .show(truncate=false)</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">// |chunk1|entity1  |chunk2       |entity2                    |result|</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">// |upper |Direction|brain stem   |Internal_organ_or_component|1     |</span>
<span class="c1">// |left  |Direction|cerebellum   |Internal_organ_or_component|1     |</span>
<span class="c1">// |right |Direction|basil ganglia|Internal_organ_or_component|1     |</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">//</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

</div>

<div class="h3-box model-content">

  <h2 id="relationextractiondl">RelationExtractionDL</h2>

  <p>Extracts and classifies instances of relations between named entities.
In contrast with RelationExtractionModel, RelationExtractionDLModel is based on BERT.
For pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Relation+Extraction">Models Hub</a> for available models.</p>

  <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, DOCUMENT</code></p>

  <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

  <table>
    <tbody>
      <tr>
        <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionDLModel">RelationExtractionDLModel</a></td>
      </tr>
    </tbody>
  </table>

  <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

      <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Relation Extraction between body parts
# This is a continuation of the RENerChunksFilter example. See that class on how to extract the relation chunks.
# Define the extraction model
</span><span class="n">re_ner_chunk_filter</span> <span class="o">=</span> <span class="n">RENerChunksFilter</span><span class="p">()</span> \
 <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
 <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"internal_organ_or_component-direction"</span><span class="p">])</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">RelationExtractionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"redl_bodypart_direction_biobert"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunks"</span><span class="p">,</span> <span class="s">"sentences"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>

<span class="n">trained_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documenter</span><span class="p">,</span>
  <span class="n">sentencer</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">words_embedder</span><span class="p">,</span>
  <span class="n">pos_tagger</span><span class="p">,</span>
  <span class="n">clinical_ner_tagger</span><span class="p">,</span>
  <span class="n">ner_chunker</span><span class="p">,</span>
  <span class="n">dependency_parser</span><span class="p">,</span>
  <span class="n">re_ner_chunk_filter</span><span class="p">,</span>
  <span class="n">re_model</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trained_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(relations) as relations"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">select</span><span class="p">(</span>
   <span class="s">"relations.metadata.chunk1"</span><span class="p">,</span>
   <span class="s">"relations.metadata.entity1"</span><span class="p">,</span>
   <span class="s">"relations.metadata.chunk2"</span><span class="p">,</span>
   <span class="s">"relations.metadata.entity2"</span><span class="p">,</span>
   <span class="s">"relations.result"</span>
 <span class="p">)</span> \
 <span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="s">"result != 0"</span><span class="p">)</span> \
 <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
<span class="o">|</span><span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span>  <span class="o">|</span><span class="n">chunk2</span>       <span class="o">|</span><span class="n">entity2</span>                    <span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
<span class="o">|</span><span class="n">upper</span> <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">brain</span> <span class="n">stem</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">left</span>  <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">cerebellum</span>   <span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">right</span> <span class="o">|</span><span class="n">Direction</span><span class="o">|</span><span class="n">basil</span> <span class="n">ganglia</span><span class="o">|</span><span class="n">Internal_organ_or_component</span><span class="o">|</span><span class="mi">1</span>     <span class="o">|</span>
<span class="o">+------+---------+-------------+---------------------------+------+</span>
</code></pre></div>      </div>

      <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Relation Extraction between body parts</span>
<span class="c1">// This is a continuation of the [[RENerChunksFilter]] example. See that class on how to extract the relation chunks.</span>
<span class="c1">// Define the extraction model</span>
<span class="k">val</span> <span class="nv">re_ner_chunk_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RENerChunksFilter</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"internal_organ_or_component-direction"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">re_model</span> <span class="k">=</span> <span class="nv">RelationExtractionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"redl_bodypart_direction_biobert"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.5f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">,</span> <span class="s">"sentences"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trained_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documenter</span><span class="o">,</span>
  <span class="n">sentencer</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">words_embedder</span><span class="o">,</span>
  <span class="n">pos_tagger</span><span class="o">,</span>
  <span class="n">clinical_ner_tagger</span><span class="o">,</span>
  <span class="n">ner_chunker</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">re_ner_chunk_filter</span><span class="o">,</span>
  <span class="n">re_model</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trained_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(relations) as relations")</span>
<span class="c1">//  .select(</span>
<span class="c1">//    "relations.metadata.chunk1",</span>
<span class="c1">//    "relations.metadata.entity1",</span>
<span class="c1">//    "relations.metadata.chunk2",</span>
<span class="c1">//    "relations.metadata.entity2",</span>
<span class="c1">//    "relations.result"</span>
<span class="c1">//  )</span>
<span class="c1">//  .where("result != 0")</span>
<span class="c1">//  .show(truncate=false)</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">// |chunk1|entity1  |chunk2       |entity2                    |result|</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">// |upper |Direction|brain stem   |Internal_organ_or_component|1     |</span>
<span class="c1">// |left  |Direction|cerebellum   |Internal_organ_or_component|1     |</span>
<span class="c1">// |right |Direction|basil ganglia|Internal_organ_or_component|1     |</span>
<span class="c1">// +------+---------+-------------+---------------------------+------+</span>
<span class="c1">//</span>
</code></pre></div>      </div>

    </div>

</details>

</div>

<div class="tabs-box">

  <h2 id="sentenceentityresolver">SentenceEntityResolver</h2>

  <div class="top_tab_li" style="text-align: center;">
    <button class="tab-li code-selector-active approach-button">Approach</button>
    <button class="tab-li code-selector-un-active model-button">Model</button>
</div>

  <div class="h3-box approach-content">

    <p>Contains all the parameters and methods to train a SentenceEntityResolverModel.
The model transforms a dataset with Input Annotation type SENTENCE_EMBEDDINGS, coming from e.g.
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.html">BertSentenceEmbeddings</a>
and returns the normalized entity for a particular trained ontology / curated dataset.
(e.g. ICD-10, RxNorm, SNOMED etc.)</p>

    <p>To use pretrained models please use SentenceEntityResolverModel
and see the <a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/SentenceEntityResolverApproach">SentenceEntityResolverApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Training a SNOMED resolution model using BERT sentence embeddings
# Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">bertEmbeddings</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">snomedTrainingPipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">bertEmbeddings</span>
<span class="p">])</span>
<span class="n">snomedTrainingModel</span> <span class="o">=</span> <span class="n">snomedTrainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">snomedData</span> <span class="o">=</span> <span class="n">snomedTrainingModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Then the Resolver can be trained with
</span><span class="n">bertExtractor</span> <span class="o">=</span> <span class="n">SentenceEntityResolverApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setNeighbours</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"bert_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setNormalizedCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_code"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDIAN"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">snomedModel</span> <span class="o">=</span> <span class="n">bertExtractor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snomedData</span><span class="p">)</span>
</code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Training a SNOMED resolution model using BERT sentence embeddings</span>
<span class="c1">// Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">bertEmbeddings</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedTrainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
   <span class="n">documentAssembler</span><span class="o">,</span>
   <span class="n">sentenceDetector</span><span class="o">,</span>
   <span class="n">bertEmbeddings</span>
 <span class="o">))</span>
 <span class="k">val</span> <span class="nv">snomedTrainingModel</span> <span class="k">=</span> <span class="nv">snomedTrainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedData</span> <span class="k">=</span> <span class="nv">snomedTrainingModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Then the Resolver can be trained with</span>
<span class="k">val</span> <span class="nv">bertExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEntityResolverApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setNeighbours</span><span class="o">(</span><span class="mi">25</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNormalizedCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"snomed_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDIAN"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedModel</span> <span class="k">=</span> <span class="nv">bertExtractor</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">snomedData</span><span class="o">)</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

  <div class="h3-box model-content" style="display: none;">

    <p>The model transforms a dataset with Input Annotation type SENTENCE_EMBEDDINGS, coming from e.g.
<a href="https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/embeddings/BertSentenceEmbeddings.html">BertSentenceEmbeddings</a>
and returns the normalized entity for a particular trained ontology / curated dataset.
(e.g. ICD-10, RxNorm, SNOMED etc.)</p>

    <p>To use pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/SentenceEntityResolverModel">SentenceEntityResolverModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-box">

        <div class="top_tab_li">   
    <button class="tab-li code-selector-active python-button">Python</button><button class="tab-li code-selector-un-active scala-button">Scala</button>
</div>

        <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">sparknlp</span>
<span class="kn">from</span> <span class="nn">sparknlp.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.common</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp.training</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">sparknlp_jsl</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.base</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="c1"># Resolving CPT
# First define pipeline stages to extract entities
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>
<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>
<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">MedicalNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"jsl_ner_wip_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Test"</span><span class="p">,</span><span class="s">"Procedure"</span><span class="p">])</span>
<span class="n">c2doc</span> <span class="o">=</span> <span class="n">Chunk2Doc</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span>
<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">BertSentenceEmbeddings</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>

<span class="c1"># Then the resolver is defined on the extracted entities and sentence embeddings
</span><span class="n">cpt_resolver</span> <span class="o">=</span> <span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_cpt_procedures_augmented"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sbert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cpt_code"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>
<span class="n">sbert_pipeline_cpt</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">c2doc</span><span class="p">,</span>
    <span class="n">sbert_embedder</span><span class="p">,</span>
    <span class="n">cpt_resolver</span><span class="p">])</span>

<span class="n">sbert_outputs</span> <span class="o">=</span> <span class="n">sbert_pipeline_cpt</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_ner</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c1"># Show results
#
# sbert_outputs
#   .select("explode(arrays_zip(ner_chunk.result ,ner_chunk.metadata, cpt_code.result, cpt_code.metadata, ner_chunk.begin, ner_chunk.end)) as cpt_code")
#   .selectExpr(
#     "cpt_code['0'] as chunk",
#     "cpt_code['1'].entity as entity",
#     "cpt_code['2'] as code",
#     "cpt_code['3'].confidence as confidence",
#     "cpt_code['3'].all_k_resolutions as all_k_resolutions",
#     "cpt_code['3'].all_k_results as all_k_results"
#   ).show(5)
# +--------------------+---------+-----+----------+--------------------+--------------------+
# |               chunk|   entity| code|confidence|   all_k_resolutions|         all_k_codes|
# +--------------------+---------+-----+----------+--------------------+--------------------+
# |          heart cath|Procedure|93566|    0.1180|CCA - Cardiac cat...|93566:::62319:::9...|
# |selective coronar...|     Test|93460|    0.1000|Coronary angiogra...|93460:::93458:::9...|
# |common femoral an...|     Test|35884|    0.1808|Femoral artery by...|35884:::35883:::3...|
# |   StarClose closure|Procedure|33305|    0.1197|Heart closure:::H...|33305:::33300:::3...|
# |         stress test|     Test|93351|    0.2795|Cardiovascular st...|93351:::94621:::9...|
# +--------------------+---------+-----+----------+--------------------+--------------------+
#
</span></code></pre></div>        </div>

        <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Resolving CPT</span>
<span class="c1">// First define pipeline stages to extract entities</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"jsl_ner_wip_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"Test"</span><span class="o">,</span><span class="s">"Procedure"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">c2doc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunk2Doc</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_doc"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sbert_embedder</span> <span class="k">=</span> <span class="nc">BertSentenceEmbeddings</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk_doc"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sbert_embeddings"</span><span class="o">)</span>

<span class="c1">// Then the resolver is defined on the extracted entities and sentence embeddings</span>
<span class="k">val</span> <span class="nv">cpt_resolver</span> <span class="k">=</span> <span class="nv">SentenceEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobertresolve_cpt_procedures_augmented"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"sbert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cpt_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">sbert_pipeline_cpt</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">word_embeddings</span><span class="o">,</span>
  <span class="n">clinical_ner</span><span class="o">,</span>
  <span class="n">ner_converter</span><span class="o">,</span>
  <span class="n">c2doc</span><span class="o">,</span>
  <span class="n">sbert_embedder</span><span class="o">,</span>
  <span class="n">cpt_resolver</span><span class="o">))</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// sbert_outputs</span>
<span class="c1">//   .select("explode(arrays_zip(ner_chunk.result ,ner_chunk.metadata, cpt_code.result, cpt_code.metadata, ner_chunk.begin, ner_chunk.end)) as cpt_code")</span>
<span class="c1">//   .selectExpr(</span>
<span class="c1">//     "cpt_code['0'] as chunk",</span>
<span class="c1">//     "cpt_code['1'].entity as entity",</span>
<span class="c1">//     "cpt_code['2'] as code",</span>
<span class="c1">//     "cpt_code['3'].confidence as confidence",</span>
<span class="c1">//     "cpt_code['3'].all_k_resolutions as all_k_resolutions",</span>
<span class="c1">//     "cpt_code['3'].all_k_results as all_k_results"</span>
<span class="c1">//   ).show(5)</span>
<span class="c1">// +--------------------+---------+-----+----------+--------------------+--------------------+</span>
<span class="c1">// |               chunk|   entity| code|confidence|   all_k_resolutions|         all_k_codes|</span>
<span class="c1">// +--------------------+---------+-----+----------+--------------------+--------------------+</span>
<span class="c1">// |          heart cath|Procedure|93566|    0.1180|CCA - Cardiac cat...|93566:::62319:::9...|</span>
<span class="c1">// |selective coronar...|     Test|93460|    0.1000|Coronary angiogra...|93460:::93458:::9...|</span>
<span class="c1">// |common femoral an...|     Test|35884|    0.1808|Femoral artery by...|35884:::35883:::3...|</span>
<span class="c1">// |   StarClose closure|Procedure|33305|    0.1197|Heart closure:::H...|33305:::33300:::3...|</span>
<span class="c1">// |         stress test|     Test|93351|    0.2795|Cardiovascular st...|93351:::94621:::9...|</span>
<span class="c1">// +--------------------+---------+-----+----------+--------------------+--------------------+</span>
<span class="c1">//</span>
</code></pre></div>        </div>

      </div>

</details>

  </div>

</div>

</div><div class="d-print-none"><footer class="article__footer"><span class="footer_date">Last updated
      <time itemprop="dateModified" datetime="2020-08-10T00:00:00+00:00">Aug 10, 2020</time>
    </span><!-- start custom article footer snippet -->

<!-- end custom article footer snippet --></footer>

<script>


jQuery(document).ready(function(){  
    $( ".scala-button" ).click(function() {
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-scala" ).show();
        $(this).closest( ".tabs-box" ).find( ".language-python, .nlu-block" ).hide();
    });

    $( ".python-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-un-active').addClass( "code-selector-active" ); 

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');


        //toggle language snippets
        $(this).closest( ".tabs-box" ).find( ".language-python" ).show();
        $(this).closest( ".tabs-box" ).find( ".nlu-block, .language-scala" ).hide();
    });

    $( ".nlu-button" ).click(function() {
        //set current button to active class and remove unactive class
        $(this).closest( ".tabs-box" ).find(".nlu-button").removeClass('code-selector-un-active').addClass( "code-selector-active" );        

        //remove  active class from all other buttons
        $(this).closest( ".tabs-box" ).find(".scala-button").removeClass('code-selector-active').addClass('code-selector-un-active');
        $(this).closest( ".tabs-box" ).find(".python-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle language snippets        
        $(this).closest( ".tabs-box" ).find( ".language-python, .language-scala" ).hide();
        $(this).closest( ".tabs-box" ).find( ".nlu-block" ).show();
    });
});

function togglePython1() {

    //set current button to active class and remove unactive class
    $( ".python-button" ).addClass( "code-selector-active" );


    //toggle language snippets
    $( ".tabs-box .language-python" ).show() 
    $( ".tabs-box .nlu-block" ).hide()
    $( ".tabs-box .language-scala" ).hide()
}

function defer(method) { //wait until jquery ready
    if (window.jQuery) {
        method();
    } else {
        setTimeout(function() { defer(method) }, 15);
    }
}

defer(function () { // load inital language
    togglePython1()
});




</script>


<style>
  /* Remove Scrollbar from Code Segments */
.article__content .highlighter-rouge > .highlight > pre > code, .article__content figure.highlight > pre > code  {
    overflow: auto;
}



button.code-selector-active {
 background-color: white;
 color: #08c;
 font-weight: bold;
 border-width: 1px;
 padding-left: 12px;
 padding-right: 12px;
 width: 90px;
 padding-top: 6px;
 margin-right: 2px;

 border-bottom: none;

 position: relative;
 z-index: 2;
}

button.code-selector-un-active {
    background-color: white;
    padding-left: 12px;
    padding-right: 12px;
    width: 90px;
    margin-right: 2px;
    padding-top: 8px;
    position: relative;
    border-bottom: none;

   }

hr.code-selector-underlie {
    border-top: 1px solid;
    background-color: black;
    width: fill;
    height: 1px;
    margin-top: -3px;
    position: relative;

}

</style><div class="article__section-navigator clearfix"><div class="previous nav_link"><span>PREVIOUS</span><a href="/docs/en/licensed_install">Getting Started</a></div><div class="next nav_link"><span>NEXT</span><a href="/docs/en/licensed_models">Models</a></div></div></div>

</div>
</div>

<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    $(function() {
      var $this ,$scroll;
      var $articleContent = $('.js-article-content');
      var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
      var scroll = hasSidebar ? '.js-page-main' : 'html, body';
      $scroll = $(scroll);

      $articleContent.find('.highlight').each(function() {
        $this = $(this);
        $this.attr('data-lang', $this.find('code').attr('data-lang'));
      });
      $articleContent.find('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]').each(function() {
        $this = $(this);
        $this.append($('<a class="anchor d-print-none" aria-hidden="true"></a>').html('<i class="fas fa-anchor"></i>'));
      });
      $articleContent.on('click', '.anchor', function() {
        $scroll.scrollToAnchor('#' + $(this).parent().attr('id'), 400);
      });
    });
  });
})();
</script></div><section class="page__comments d-print-none"></section></article><!-- start custom main bottom snippet -->

<!-- end custom main bottom snippet --></div>
            </div></div></div><div class="page__footer d-print-none">
<footer class="footer py-4 js-page-footer">
  <div class="main"><div itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content=""><meta itemprop="url" content="/"></div><div class="site-info mt-2">
      <div>© 2021 John Snow Labs Inc.
        <a href="http://www.johnsnowlabs.com/terms-of-service">Terms of Service</a> | <a href="http://www.johnsnowlabs.com/privacy-policy/">Privacy Policy</a>
      </div>
    </div>
  </div>
</footer>

<script>

/* Responsive menu
	 ========================================================*/
jQuery(document).ready(function($) {
	jQuery('#responsive_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.top_navigation').toggleClass('open');
  });
  jQuery('#aside_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.js-col-aside').toggleClass('open');
      if (jQuery(window).width() <= 1023)
      {
        jQuery('.page__sidebar').toggleClass('open'); 
      jQuery('.demopage-sidemenu').toggleClass('open');
      }
  });
  jQuery('.toc--ellipsis a').click(function(e) {
    if (jQuery(window).width() <= 767)
      {
        jQuery('.js-col-aside').removeClass('open');
        jQuery('.page__sidebar').removeClass('open');    
        jQuery('#aside_menu').removeClass('close');  
      }       
  });
});

/*TABS*/
function openTabCall(cityName){
  // Declare all variables
  var i, tabcontent, tablinks;

  // Get all elements with class="tabcontent" and hide them
  tabcontent = document.getElementsByClassName("tabcontent");
  for (i = 0; i < tabcontent.length; i++) {
    tabcontent[i].style.display = "none";
  }

  // Get all elements with class="tablinks" and remove the class "active"
  tablinks = document.getElementsByClassName("tablinks");
  for (i = 0; i < tablinks.length; i++) {
    tablinks[i].className = tablinks[i].className.replace(" active", "");
  }

  // Show the current tab, and add an "active" class to the button that opened the tab
  document.getElementById(cityName).style.display = "block";
}

function openTab(evt, cityName) {
  openTabCall(cityName);
  evt.currentTarget.className += " active";
}

/*OPen by URL*/
$(document).ready(function () {  
  const tabName = (window.location.hash || '').replace('#', '');
  const tab = document.getElementById(tabName || 'opensource');
  if (tab) {
    tab.click();
  }
});

jQuery(document).ready(function(){
	jQuery('.tab-item').click(function(event) {		
		if (($(window).width() > 400) && ($(window).width() < 1199))
	    {
	    	jQuery('.tab-item').removeClass('open');
	        jQuery(this).toggleClass('open');
	    }
  });
  

});


 

</script></div></div>
    </div></div></div><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $body = $('body'), $window = $(window);
    var $pageRoot = $('.js-page-root'), $pageMain = $('.js-page-main');
    var activeCount = 0;
    function modal(options) {
      var $root = this, visible, onChange, hideWhenWindowScroll = false;
      var scrollTop;
      function setOptions(options) {
        var _options = options || {};
        visible = _options.initialVisible === undefined ? false : show;
        onChange = _options.onChange;
        hideWhenWindowScroll = _options.hideWhenWindowScroll;
      }
      function init() {
        setState(visible);
      }
      function setState(isShow) {
        if (isShow === visible) {
          return;
        }
        visible = isShow;
        if (visible) {
          activeCount++;
          scrollTop = $(window).scrollTop() || $pageMain.scrollTop();
          $root.addClass('modal--show');
          $pageMain.scrollTop(scrollTop);
          activeCount === 1 && ($pageRoot.addClass('show-modal'), $body.addClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.on('scroll', hide);
          $window.on('keyup', handleKeyup);
        } else {
          activeCount > 0 && activeCount--;
          $root.removeClass('modal--show');
          $window.scrollTop(scrollTop);
          activeCount === 0 && ($pageRoot.removeClass('show-modal'), $body.removeClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.off('scroll', hide);
          $window.off('keyup', handleKeyup);
        }
        onChange && onChange(visible);
      }
      function show() {
        setState(true);
      }
      function hide() {
        setState(false);
      }
      function handleKeyup(e) {
        // Char Code: 27  ESC
        if (e.which ===  27) {
          hide();
        }
      }
      setOptions(options);
      init();
      return {
        show: show,
        hide: hide,
        $el: $root
      };
    }
    $.fn.modal = modal;
  });
})();
</script><div class="modal modal--overflow page__search-modal d-print-none js-page-search-modal"></div></div>


<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function scrollToAnchor(anchor, duration, callback) {
      var $root = this;
      $root.animate({ scrollTop: $(anchor).position().top }, duration, function() {
        window.history.replaceState(null, '', window.location.href.split('#')[0] + anchor);
        callback && callback();
      });
    }
    $.fn.scrollToAnchor = scrollToAnchor;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function affix(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroll,
        offsetBottom = 0, scrollTarget = window, scroll = window.document, disabled = false, isOverallScroller = true,
        rootTop, rootLeft, rootHeight, scrollBottom, rootBottomTop,
        hasInit = false, curState;

      function setOptions(options) {
        var _options = options || {};
        _options.offsetBottom && (offsetBottom = _options.offsetBottom);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroll && (scroll = _options.scroll);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $scrollTarget = $(scrollTarget);
        isOverallScroller = window.isOverallScroller($scrollTarget[0]);
        $scroll = $(scroll);
      }
      function preCalc() {
        top();
        rootHeight = $root.outerHeight();
        rootTop = $root.offset().top + (isOverallScroller ? 0 :  $scrollTarget.scrollTop());
        rootLeft = $root.offset().left;
      }
      function calc(needPreCalc) {
        needPreCalc && preCalc();
        scrollBottom = $scroll.outerHeight() - offsetBottom - rootHeight;
        rootBottomTop = scrollBottom - rootTop;
      }
      function top() {
        if (curState !== 'top') {
          $root.removeClass('fixed').css({
            left: 0,
            top: 0
          });
          curState = 'top';
        }
      }
      function fixed() {
        if (curState !== 'fixed') {
          $root.addClass('fixed').css({
            left: rootLeft + 'px',
            top: 0
          });
          curState = 'fixed';
        }
      }
      function bottom() {
        if (curState !== 'bottom') {
          $root.removeClass('fixed').css({
            left: 0,
            top: rootBottomTop + 'px'
          });
          curState = 'bottom';
        }
      }
      function setState() {
        var scrollTop = $scrollTarget.scrollTop();
        if (scrollTop >= rootTop && scrollTop <= scrollBottom) {
          fixed();
        } else if (scrollTop < rootTop) {
          top();
        } else {
          bottom();
        }
      }
      function init() {
        if(!hasInit) {
          var interval, timeout;
          calc(true); setState();
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState();
          });
          $window.on('resize', function() {
            disabled || (calc(true), setState());
          });
          hasInit = true;
        }
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions,
        refresh: function() {
          calc(true, { animation: false }); setState();
        }
      };
    }
    $.fn.affix = affix;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function toc(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroller, $tocUl = $('<ul class="toc toc--ellipsis"></ul>'), $tocLi, $headings, $activeLast, $activeCur,
        selectors = 'h1,h2,h3', container = 'body', scrollTarget = window, scroller = 'html, body', disabled = false,
        headingsPos, scrolling = false, hasRendered = false, hasInit = false;

      function setOptions(options) {
        var _options = options || {};
        _options.selectors && (selectors = _options.selectors);
        _options.container && (container = _options.container);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroller && (scroller = _options.scroller);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $headings = $(container).find(selectors).filter('[id]');
        $scrollTarget = $(scrollTarget);
        $scroller = $(scroller);
      }
      function calc() {
        headingsPos = [];
        $headings.each(function() {
          headingsPos.push(Math.floor($(this).position().top));
        });
      }
      function setState(element, disabled) {
        var scrollTop = $scrollTarget.scrollTop(), i;
        if (disabled || !headingsPos || headingsPos.length < 1) { return; }
        if (element) {
          $activeCur = element;
        } else {
          for (i = 0; i < headingsPos.length; i++) {
            if (scrollTop >= headingsPos[i]) {
              $activeCur = $tocLi.eq(i);
            } else {
              $activeCur || ($activeCur = $tocLi.eq(i));
              break;
            }
          }
        }
        $activeLast && $activeLast.removeClass('active');
        ($activeLast = $activeCur).addClass('active');
      }
      function render() {
        if(!hasRendered) {
          $root.append($tocUl);
          $headings.each(function() {
            var $this = $(this);
            $tocUl.append($('<li></li>').addClass('toc-' + $this.prop('tagName').toLowerCase())
              .append($('<a></a>').text($this.text()).attr('href', '#' + $this.prop('id'))));
          });
          $tocLi = $tocUl.children('li');
          $tocUl.on('click', 'a', function(e) {
            e.preventDefault();
            var $this = $(this);
            scrolling = true;
            setState($this.parent());
            $scroller.scrollToAnchor($this.attr('href'), 400, function() {
              scrolling = false;
            });
          });
        }
        hasRendered = true;
      }
      function init() {
        var interval, timeout;
        if(!hasInit) {
          render(); calc(); setState(null, scrolling);
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState(null, scrolling);
          });
          $window.on('resize', window.throttle(function() {
            if (!disabled) {
              render(); calc(); setState(null, scrolling);
            }
          }, 100));
        }
        hasInit = true;
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions
      };
    }
    $.fn.toc = toc;
  });
})();
/*(function () {

})();*/
</script><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;

  window.Lazyload.js(SOURCES.jquery, function() {
    var $pageMask = $('.js-page-mask');
    var $pageRoot = $('.js-page-root');
    var $sidebarShow = $('.js-sidebar-show');
    var $sidebarHide = $('.js-sidebar-hide');

    function freeze(e) {
      if (e.target === $pageMask[0]) {
        e.preventDefault();
      }
    }
    function stopBodyScrolling(bool) {
      if (bool === true) {
        window.addEventListener('touchmove', freeze, { passive: false });
      } else {
        window.removeEventListener('touchmove', freeze, { passive: false });
      }
    }

    $sidebarShow.on('click', function() {
      stopBodyScrolling(true); $pageRoot.addClass('show-sidebar');
    });
    $sidebarHide.on('click', function() {
      stopBodyScrolling(false); $pageRoot.removeClass('show-sidebar');
    });
  });
})();
</script><script>
  /* toc must before affix, since affix need to konw toc' height. */(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  var TOC_SELECTOR = window.TEXT_VARIABLES.site.toc.selectors;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window);
    var $articleContent = $('.js-article-content');
    var $tocRoot = $('.js-toc-root'), $col2 = $('.js-col-aside');
    var toc;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
    var hasToc = $articleContent.find(TOC_SELECTOR).length > 0;

    function disabled() {
      return $col2.css('display') === 'none' || !hasToc;
    }

    tocDisabled = disabled();

    toc = $tocRoot.toc({
      selectors: TOC_SELECTOR,
      container: $articleContent,
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      tocDisabled = disabled();
      toc && toc.setOptions({
        disabled: tocDisabled
      });
    }, 100));

  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window), $pageFooter = $('.js-page-footer');
    var $pageAside = $('.js-page-aside');
    var affix;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');

    affix = $pageAside.affix({
      offsetBottom: $pageFooter.outerHeight(),
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      scroll: hasSidebar ? $('.js-page-main').children() : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      affix && affix.setOptions({
        disabled: tocDisabled
      });
    }, 100));

    window.pageAsideAffix = affix;
  });
})();
</script><script>
  window.Lazyload.js(['https://cdn.bootcss.com/jquery/3.1.1/jquery.min.js', 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js'], function() {
    var $canvas = null, $this = null, _ctx = null, _text = '';
    $('.language-chart').each(function(){
      $this = $(this);
      $canvas = $('<canvas></canvas>');
      _text = $this.text();
      $this.text('').append($canvas);
      _ctx = $canvas.get(0).getContext('2d');
      (_ctx && _text) && (new Chart(_ctx, JSON.parse(_text)) && $this.attr('data-processed', true));
    });
  });
</script><script type="text/x-mathjax-config">
	var _config = { tex2jax: {
		inlineMath: [['$','$'], ['\\(','\\)']]
	}};_config.TeX = { equationNumbers: { autoNumber: "all" } };MathJax.Hub.Config(_config);
</script>
<script type="text/javascript" src="https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script>
  window.Lazyload.js('https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js', function() {
    mermaid.initialize({
      startOnLoad: true
    });
    mermaid.init(undefined, '.language-mermaid');
  });
</script>
    </div>
    <script>(function () {
  var $root = document.getElementsByClassName('root')[0];
  if (window.hasEvent('touchstart')) {
    $root.dataset.isTouch = true;
    document.addEventListener('touchstart', function(){}, false);
  }
})();
</script>
  </body>
</html>