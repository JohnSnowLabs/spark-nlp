<!DOCTYPE html>
<!--[if IE 8]>
<html lang="en" class="ie8"> <![endif]-->
<!--[if IE 9]>
<html lang="en" class="ie9"> <![endif]-->
<!--[if !IE]><!-->
<html lang="en"> <!--<![endif]-->
<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-70312582-2"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-70312582-2');
    </script>
    <title>Spark NLP</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="shortcut icon" href="fav.ico">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800'
          rel='stylesheet' type='text/css'>
    <!-- Global CSS -->
    <link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">
    <!-- Plugins CSS -->
    <link rel="stylesheet" href="assets/plugins/font-awesome/css/font-awesome.css">
    <link rel="stylesheet" href="assets/plugins/prism/prism.css">
    <link rel="stylesheet" href="assets/plugins/lightbox/dist/ekko-lightbox.min.css">
    <link rel="stylesheet" href="assets/plugins/elegant_font/css/style.css">

    <!-- Theme CSS -->
    <link id="theme-style" rel="stylesheet" href="assets/css/styles.css">
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!--   <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet"/>
       <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
       <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
   -->
    <script type="text/javascript" src="assets/plugins/jquery-1.12.3.min.js"></script>
    <script>
        function getTasks() {
            $.get("https://api.github.com/repos/JohnSnowLabs/spark-nlp/commits?path=docs/components.html",
                    function (data) {
                        var dateObject = new Date(data[0].commit.author.date);
                        $(".wrapper").html(dateObject.toDateString());
                    });
        }
        getTasks();
    </script>
</head>

<body class="body-pink">
<script>
    $(function () {
        $("#includedHeader").load("header.html");
        $("#includedFooter").load("footer.html");
    });
</script>
<div class="page-wrapper">
    <!-- ******Header****** -->
    <header id="header" class="header">
        <div class="container">
            <div id="includedHeader"></div>
            <ol class="breadcrumb">
                <li><a href="index.html">Home</a></li>
                <li class="active">Annotators</li>
            </ol>
        </div>
    </header>
    <div style="border:1px solid #e7e7e7;"></div>
    <div class="doc-wrapper">
        <div class="container">
            <div id="doc-header" class="doc-header text-center">
                <h1 class="doc-title"><span aria-hidden="true" class="icon icon_puzzle_alt"></span> SparkNLP- Annotators
                </h1>
                <div class="meta"><i class="fa fa-clock-o"></i> Last updated: <span class="wrapper"></span></div>
            </div><!--//doc-header-->
            <div class="doc-body">
                <div class="doc-content">
                    <div class="content-inner">
                        <section id="code-section" class="doc-section">
                            <h2 class="section-title">Annotators</h2>
                            <div>
                                <h4 id="DocumentAssembler" class="section-block"> 1. DocumentAssembler: Getting data
                                    in</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>

                                                In order to get through the NLP process, we need to get raw data
                                                annotated. There is a special transformer that does this for us: the
                                                DocumentAssembler, it creates the first annotation of type Document
                                                which may be used by annotators down the road
                                                <br><b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">from sparknlp.annotator import *
from sparknlp.common import *
from sparknlp.base import *
from pyspark.ml import Pipeline
documentAssembler = new DocumentAssembler() \
.setInputCol("text") \
.setOutputCol("document")</code></pre>

                                            <b>Settable parameters are:</b>
                                            <ul>
                                                <li>
                                                    setInputCol()
                                                </li>
                                                <li>
                                                    setOutputCol()
                                                </li>
                                                <li>
                                                    setIdCol() -> OPTIONAL: Sring type column with id information
                                                </li>
                                                <li>
                                                    setMetadataCol() -> OPTIONAL: Map type column with metadata
                                                    information
                                                </li>
                                            </ul>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>

                                                In order to get through the NLP process, we need to get raw data
                                                annotated. There is a special transformer that does this for us: the
                                                DocumentAssembler, it creates the first annotation of type Document
                                                which may be used by annotators down the road
                                                <br><b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">import com.johnsnowlabs.nlp._
import com.johnsnowlabs.nlp.annotators._
import org.apache.spark.ml.Pipeline
documentAssembler = new DocumentAssembler()
.setInputCol("text")
.setOutputCol("document")</code></pre>

                                            <b>Settable parameters are:</b>
                                            <ul>
                                                <li>
                                                    setInputCol()
                                                </li>
                                                <li>
                                                    setOutputCol()
                                                </li>
                                                <li>
                                                    setIdCol() -> OPTIONAL: Sring type column with id information
                                                </li>
                                                <li>
                                                    setMetadataCol() -> OPTIONAL: Map type column with metadata
                                                    information
                                                </li>
                                            </ul>
                                        </div><!--//code-block--></div>
                                </div>

                                <h4 id="Tokenizer" class="section-block">2. Tokenizer: Word tokens</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs.<br>
                                                <b>Type:</b> Token<br>
                                                <b>Requires:</b> Document<br>
                                                <b>Functions:</b>
                                            <ul>
                                          <li>
                                            setTargetPattern: Basic regex rule to identify a candidate for tokenization. Defaults to \S+ which means anything not a space
                                          </li>
                                          <li>
                                            setSuffixPattern: Regex to identify token characters that are in the end of the token. Regex has to end with \z and must contain groups (). Each group will become a separate token within the prefix. Defaults to non-letter characters. e.g. quotes or parenthesis
                                          </li>
                                          <li>
                                            setPrefixPattern: Regex to identify token characters that come in the beggining of the token. Regex has to start with \A and must contain groups (). Each group will become a separate token within the prefix. Defaults to non-letter characters. e.g. quotes or parenthesis
                                          </li>
                                          <li>
                                            setExtensionPatterns: Array of Regex with groups () to match tokens within the target pattern. Every group () will become its own separate token. Order matters (later rules will apply first). Its default rules should cover most cases, e.g. part-of-speech as single token
                                          </li>
                                          <li>
                                            addInfixPattern: Add an extension pattern regex with groups to the top of the rules (will target first, then the others).
                                          </li>
                                          <li>
                                            setCompositeTokens: Adds a list of compound words to mark for ignore. E.G. New York so it doesnt get split in New and York
                                          </li>
                                            </ul>
                                            <br>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">tokenizer = Tokenizer() \
  .setInputCols(["sentences"]) \
  .setOutputCol("token") \
  .addInfixPattern("(\p{L}+)(n't\b)")</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                          <p>
                                            Identifies tokens with tokenization open standards. A few rules will help customizing it if defaults do not fit user needs.<br>
                                            <b>Type:</b> Token<br>
                                            <b>Requires:</b> Document<br>
                                            <b>Functions:</b>
                                          <ul>
                                            <li>
                                              setTargetPattern: Basic regex rule to identify a candidate for tokenization. Defaults to \S+ which means anything not a space
                                            </li>
                                            <li>
                                              setSuffixPattern: Regex to identify token characters that are in the end of the token. Regex has to end with \z and must contain groups (). Each group will become a separate token within the prefix. Defaults to non-letter characters. e.g. quotes or parenthesis
                                            </li>
                                            <li>
                                              setPrefixPattern: Regex to identify token characters that come in the beggining of the token. Regex has to start with \A and must contain groups (). Each group will become a separate token within the prefix. Defaults to non-letter characters. e.g. quotes or parenthesis
                                            </li>
                                            <li>
                                              setExtensionPatterns: Array of Regex with groups () to match tokens within the target pattern. Every group () will become its own separate token. Order matters (later rules will apply first). Its default rules should cover most cases, e.g. part-of-speech as single token
                                            </li>
                                            <li>
                                              addInfixPattern: Add an extension pattern regex with groups to the top of the rules (will target first, then the others).
                                            </li>
                                            <li>
                                              setCompositeTokens: Adds a list of compound words to mark for ignore. E.G. New York so it doesnt get split in New and York
                                            </li>
                                          </ul>
                                            <br>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val tokenizer = new Tokenizer()
  .setInputCols("sentence")
  .setOutputCol("token")
  .addInfixPattern("(\p{L}+)(n't\b)")</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                </div>
                                <h4 id="Normalizer" class="section-block">3. Normalizer: Text cleaning</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Removes all dirty characters from text<br>
                                                <b>Type:</b> Token<br>
                                                <b>Requires:</b> Token<br>
                                                <b>Functions:</b>
                                            <ul>
                                              <li>
                                                setPattern(pattern): Regular expression for normalization, defaults [^A-Za-z]
                                                setLowercase(value): lowercase tokens, default true
                                              </li>
                                            </ul>
                                                <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">normalizer = Normalizer() \
  .setInputCols(["token"]) \
  .setOutputCol("normalized")</code></pre>
                                        </div><!--//code-block-->

                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>
                                                Removes all dirty characters from text<br>
                                                <b>Type:</b> Token<br>
                                                <b>Requires:</b> Token<br>
                                                <b>Functions:</b>
                                            <ul>
                                              <li>
                                                setPattern(pattern): Regular expression for normalization, defaults [^A-Za-z]
                                              </li>
                                            </ul>
                                                <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val normalizer = new Normalizer()
  .setInputCols(Array("token"))
  .setOutputCol("normalized")</code></pre>
                                        </div><!--//code-block--></div>
                                </div>
                                <h4 id="Stemmer" class="section-block"> 4. Stemmer: Hard stems</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Returns hard-stems out of words with the objective of retrieving the
                                                meaningful
                                                part of the word<br>
                                                <b>Type:</b> Token<br>
                                                <b>Requires:</b> Token<br>
                                                <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">stemmer = Stemmer() \
  .setInputCols(["token"]) \
  .setOutputCol("stem")</code></pre>
                                        </div>
                                    </div>
                                    <div role="tabpanel" class="tab-pane active" id="scala">
                                        <div class="code-block">
                                            <p>
                                                Returns hard-stems out of words with the objective of retrieving the
                                                meaningful
                                                part of the word<br>
                                                <b>Type:</b> Token<br>
                                                <b>Requires:</b> Token<br>
                                                <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val stemmer = new Stemmer()
  .setInputCols(Array("token"))
  .setOutputCol("stem")</code></pre>
                                        </div>
                                    </div>
                                </div>
                                <h4 id="Lemmatizer" class="section-block"> 5. Lemmatizer: Lemmas</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Retrieves lemmas out of words with the objective of returning a base
                                                dictionary
                                                word<br>
                                                <b>Type:</b> Token<br>
                                                <b>Requires:</b> Token<br>
                                                <b>Input:</b> abduct -> abducted abducting abduct abducts<br>
                                                <b>Functions:</b> --<br>
                                            <ul>
                                                <li>
                                                    setDictionary(path): Path to file containing multiple key to value
                                                    dictionary, or key,value lemma dictionary. Default: Not provided
                                                </li>
                                                <li>
                                                    setLemmaFormat(format): TXT for txt files or TXTDS for text files read as dataset (allows hdfs)
                                                    Default:
                                                    Looks up path in configuration
                                                </li>
                                                <li>
                                                    setLemmaKeySep(format): Separator for keys and multiple values
                                                    Default:
                                                    "->" or Looks up path in configuration
                                                </li>
                                                <li>
                                                    setLemmaValSep(format): Separator among values
                                                    Default:
                                                    "\t" or Looks up path in configuration
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">lemmatizer = Lemmatizer() \
  .setDocumentCol("document") \
  .setInputCols(["token"]) \
  .setOutputCol("lemma") \
  .setDictionary("./lemmas001.txt")</code></pre>
                                        </div>
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>
                                                Retrieves lemmas out of words with the objective of returning a base
                                                dictionary
                                                word<br>
                                                <b>Type:</b> Token<br>
                                                <b>Requires:</b> None<br>
                                                <b>Input:</b> abduct -> abducted abducting abduct abducts<br>
                                                <b>Functions:</b> --<br>
                                            <ul>
                                                <li>
                                                    setDictionary(path): Path to file containing multiple key to value
                                                    dictionary, or key,value lemma dictionary. Default: Not provided
                                                </li>
                                                <li>
                                                    setLemmaFormat(format): TXT for txt files or TXTDS for text files read as dataset (allows hdfs)
                                                    Default:
                                                    Looks up path in configuration
                                                </li>
                                                <li>
                                                    setLemmaKeySep(format): Separator for keys and multiple values
                                                    Default:
                                                    "->" or Looks up path in configuration
                                                </li>
                                                <li>
                                                    setLemmaValSep(format): Separator among values
                                                    Default:
                                                    "\t" or Looks up path in configuration
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val lemmatizer = new Lemmatizer()
  .setInputCols(Array("token"))
  .setOutputCol("lemma")
  .setLemmaDict("./lemmas001.txt")</code></pre>
                                        </div>
                                    </div>
                                </div>
                                <h4 id="RegexMatcher" class="section-block"> 6. RegexMatcher: Rule matching</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Uses a reference file to match a set of regular expressions and put them
                                                inside
                                                a provided key. File must be comma separated.<br>
                                                <b>Type:</b> Regex<br>
                                                <b>Requires:</b> Document<br>
                                                <b>Input:</b> "the\s\w+", "followed by 'the'"<br>
                                                <b>Functions:</b> <br>
                                            <ul>
                                                <li>
                                                    setStrategy(strategy): Can be any of
                                                    MATCH_FIRST|MATCH_ALL|MATCH_COMPLETE
                                                </li>
                                                <li>
                                                    setRulesPath(path): Path to file containing a set of regex,key pair.
                                                    Default:
                                                    Looks up path in configuration
                                                </li>
                                                <li>
                                                    setRulesFormat(format): TXT for txt files or TXTDS for text files read as dataset (allows hdfs)
                                                    Default:
                                                    TXT or looks up path in configuration
                                                </li>
                                                <li>
                                                    setRulesSeparator(sep): Separator for rules file
                                                    Default:
                                                    "," or looks up path in configuration
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">regex_matcher = RegexMatcher() \
  .setStrategy("MATCH_ALL") \
  .setOutputCol("regex")</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>
                                                Uses a reference file to match a set of regular expressions and put them
                                                inside
                                                a provided key. File must be comma separated.<br>
                                                <b>Type:</b> Regex<br>
                                                <b>Requires:</b> Document<br>
                                                <b>Input:</b> "the\s\w+", "followed by 'the'"<br>
                                                <b>Functions:</b> <br>
                                            <ul>
                                                <li>
                                                    setStrategy(strategy): Can be any of
                                                    MATCH_FIRST|MATCH_ALL|MATCH_COMPLETE
                                                </li>
                                                <li>
                                                    setRulesPath(path): Path to file containing a set of regex,key pair.
                                                    Default:
                                                    Looks up path in configuration
                                                </li>
                                                <li>
                                                    setRulesFormat(format): TXT for txt files or TXTDS for text files read as dataset (allows hdfs)
                                                    Default:
                                                    TXT or looks up path in configuration
                                                </li>
                                                <li>
                                                    setRulesSeparator(sep): Separator for rules file
                                                    Default:
                                                    "," or looks up path in configuration
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val regexMatcher = new RegexMatcher()
  .setStrategy(strategy)
  .setInputCols(Array("document"))
  .setOutputCol("regex")</code></pre>
                                        </div>
                                    </div>
                                </div>

                                <h4 id="EntityExtractor" class="section-block"> 7. EntityExtractor: Phrase matching</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Annotator to match entire phrases provided in a file against a
                                                Document<br>
                                                <b>Type:</b> Entity<br>
                                                <b>Requires:</b> Document<br>
                                                <b>Input:</b> hello world, I am looking for you<br>
                                                <b>Functions:</b> <br>
                                            <ul>
                                                <li>
                                                    setRequireSentences(false): Enable require SBD and utilizes sentence
                                                    boundaries for better precision
                                                </li>
                                                <li>
                                                    setEntities(path, format, options): Provides a file with phrases to match. Default: Looks up path in configuration.</br>
                                                    path: a path to a file that contains the entities in the specified format.</br>
                                                    format: the format of the file, can be one of {ReadAs.LINE_BY_LINE, ReadAs.SPARK_DATASET}. Defaults to LINE_BY_LINE.</br>
                                                    options: a map of additional parameters. Defaults to {"format": "text"}.
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">entity_extractor = EntityExtractor() \
 .setInputCols(["inputCol"])\
 .setOutputCol("entity")\
 .setEntities("/path/to/file/myentities.txt")
</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>
                                                Annotator to match entire phrases provided in a file against a
                                                Document<br>
                                                <b>Type:</b> Entity<br>
                                                <b>Requires:</b> Document<br>
                                                <b>Input:</b> hello world, I am looking for you<br>
                                                <b>Functions:</b> <br>
                                            <ul>
                                                <li>
                                                    setRequireSentences(false): Enable require SBD and utilizes sentence
                                                    boundaries for better precision
                                                </li>
                                                <li>
                                                    setEntities(path, format, options): Provides a file with phrases to match. Default: Looks up path in configuration.</br>
                                                    path: a path to a file that contains the entities in the specified format.</br>
                                                    format: the format of the file, can be one of {ReadAs.LINE_BY_LINE, ReadAs.SPARK_DATASET}. Defaults to LINE_BY_LINE.</br>
                                                    options: a map of additional parameters. Defaults to Map("format" -> "text").
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val entityExtractor = new EntityExtractor()
 .setInputCols("inputCol")
 .setOutputCol("entity")
 .setEntities("/path/to/file/myentities.txt")
</code></pre>
                                        </div>
                                    </div>
                                </div>

                                <h4 id="DateMatcher" class="section-block"> 8. DateMatcher: Date-time parsing</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Reads from different forms of date and time expressions and converts
                                                them to a
                                                provided date format<br>
                                                <b>Type:</b> Date<br>
                                                <b>Requires:</b> Document<br>
                                                <b>Functions:</b> <br>
                                            <ul>
                                                <li>
                                                    setDateFormat(format): SimpleDateFormat standard date formatting.
                                                    Defaults
                                                    to yyyy/MM/dd
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">date_matcher = DateMatcher() \
  .setOutputCol("date") \
  .setDateFormat("yyyyMM")</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>
                                                Reads from different forms of date and time expressions and converts
                                                them to a
                                                provided date format<br>
                                                <b>Type:</b> Date<br>
                                                <b>Requires:</b> Document<br>
                                                <b>Functions:</b> <br>
                                            <ul>
                                                <li>
                                                    setDateFormat(format): SimpleDateFormat standard date formatting.
                                                    Defaults
                                                    to yyyy/MM/dd
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val dateMatcher = new DateMatcher()
  .setFormat("yyyyMM")
  .setOutputCol("date")</code></pre>
                                        </div><!--//code-block--></div>
                                </div>

                                <h4 id="SentenceDetector" class="section-block"> 9. SentenceDetector: Sentence Boundary
                                    Detector</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Finds sentence bounds in raw text.<br>
                                                <b>Type:</b> Document<br>
                                                <b>Requires:</b> Document<br>
                                                <b>Functions:</b> <br>
                                            <ul>
                                              <li>
                                                setCustomBounds(characters): Custom sentence separator text
                                              </li>
                                            </ul>
                                                <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">sentence_detector = SentenceDetector() \
  .setInputCols(["document"]) \
  .setOutputCol("sentence") \
  .setUseAbbreviations(True)</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>
                                                Finds sentence bounds in raw text.<br>
                                                <b>Type:</b> Document<br>
                                                <b>Requires:</b> Document<br>
                                              <b>Functions:</b> <br>
                                          <ul>
                                            <li>
                                              setCustomBounds(characters): Custom sentence separator text
                                            </li>
                                          </ul>
                                                <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val sentenceDetector = new SentenceDetector()
  .setInputCols("document")
  .setOutputCol("sentence")</code></pre>
                                        </div>
                                    </div>
                                </div>

                                <h4 id="POSTagger" class="section-block"> 10. POSTagger: Part of speech tagger</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Sets a POS tag to each word within a sentence<br>
                                                <b>Type:</b> POS<br>
                                                <b>Input:</b> A|DT few|JJ months|NNS ago|RB you|PRP received|VBD a|DT
                                                letter|NN<br>
                                                <b>Requires:</b> Document, Token<br>
                                                <b>Functions:</b> <br>
                                            <ul>
                                                <li>
                                                    setCorpusPath: Path to a pipe separated file or directory with
                                                    correct
                                                    word|tag in sentence per line
                                                </li>
                                                <li>
                                                    setNIterations: Number of iterations for training. May improve
                                                    accuracy but
                                                    takes longer. Default 5.
                                                </li>
                                                <li>
                                                  setCorpusFormat: TXT or TXTDS, the latter will read corpusPath as a Spark dataset, which should work better for bigger corpora.
                                                </li>
                                                <li>
                                                  setCorpusLimit: When path is a folder, sets a limit for the amount of files being read.
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">pos_tagger = PerceptronApproach() \
  .setInputCols(["token", "sentence"]) \
  .setOutputCol("pos") \
  .setCorpusPath("./src/main/resources/anc-pos-corpus") \
  .setIterations(2) \
  .fit(data)</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>
                                                Sets a POS tag to each word within a sentence<br>
                                                <b>Type:</b> POS<br>
                                                <b>Input:</b> A|DT few|JJ months|NNS ago|RB you|PRP received|VBD a|DT
                                                letter|NN<br>
                                                <b>Requires:</b> Document, Token<br>
                                                <b>Functions:</b> <br>
                                            <ul>
                                                <li>
                                                    setCorpusPath: Path to a pipe separated file or directory with
                                                    correct
                                                    word|tag in sentence per line
                                                </li>
                                                <li>
                                                    setIterations: Number of iterations for training. May improve
                                                    accuracy but
                                                    takes longer. Default 5.
                                                </li>
                                                <li>
                                                  setCorpusFormat: TXT or TXTDS, the latter will read corpusPath as a Spark dataset, which should work better for bigger corpora.
                                                </li>
                                                <li>
                                                  setCorpusLimit: When path is a folder, sets a limit for the amount of files being read.
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val posTagger = new PerceptronApproach()
  .setInputCols(Array("sentence", "token"))
  .setOutputCol("pos")
  .fit(data)</code></pre>
                                        </div><!--//code-block--></div>
                                </div>

                              <h4 id="ViveknSentimentDetector" class="section-block"> 11. ViveknSentimentDetector:
                                Sentiment
                                analysis</h4>
                              <ul class="nav nav-tabs" role="tablist">
                                <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                          role="tab" data-toggle="tab">Python</a>
                                </li>
                                <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                           data-toggle="tab">Scala</a></li>
                              </ul>
                              <div class="tab-content">
                                <div role="tabpanel" class="tab-pane active" id="python">
                                  <div class="code-block">
                                    <p>
                                      Scores a sentence for a sentiment<br>
                                      <b>Type:</b> sentiment<br>
                                      <b>Requires:</b> Document, Token<br>
                                      <b>Functions:</b>
                                    <ul>
                                      <li>
                                        setPositiveSource(path)
                                      </li>
                                      <li>
                                        setNegativeSource(path)
                                      </li>
                                      <li>
                                        setPruneCorpus(true): when training on small data you may want
                                        to disable this to not cut off unfrequent words
                                      </li>
                                    </ul>
                                    <br>
                                    <b>Input:</b> File or folder of text files of positive and negative data<br>
                                    <b>Example:</b><br>
                                    </p>
                                    <pre><code class="language-python">sentiment_detector = SentimentDetector() \
    .setInputCols(["lemma", "sentence"]) \
    .setOutputCol("sentiment")</code></pre>
                                  </div><!--//code-block-->
                                </div>
                                <div role="tabpanel" class="tab-pane" id="scala">
                                  <div class="code-block">
                                    <p>
                                      Scores a sentence for a sentiment<br>
                                      <b>Type:</b> sentiment<br>
                                      <b>Requires:</b> Document, Token<br>
                                      <b>Functions:</b>
                                    <ul>
                                      <li>
                                        setPositiveSourcePath(path)
                                      </li>
                                      <li>
                                        setNegativeSourcePath(path)
                                      </li>
                                      <li>
                                        setCorpusPrune(true): when training on small data you may want
                                        to disable this to not cut off unfrequent words
                                      </li>
                                    </ul>
                                    <br>
                                    <b>Input:</b> File or folder of text files of positive and negative data<br>
                                    <b>Example:</b><br>
                                    </p>
                                    <pre><code class="language-python">new ViveknSentimentApproach()
      .setInputCols(Array("token", "sentence"))
      .setOutputCol("vivekn")
      .setPositiveSourcePath("./positive/1.txt")
      .setNegativeSourcePath("./negative/1.txt")
      .setCorpusPrune(false)</code></pre>
                                  </div>
                                </div>
                              </div>

                                <h4 id="SentimentDetector" class="section-block"> 12. SentimentDetector: Sentiment
                                    analysis</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Scores a sentence for a sentiment<br>
                                                <b>Type:</b> sentiment<br>
                                                <b>Requires:</b> Document, Token<br>
                                                <b>Functions:</b>
                                            <ul>
                                                <li>
                                                    setDictPath(path)
                                                </li>
                                                <li>
                                                    setDictFormat(path)
                                                </li>
                                                <li>
                                                    setDictSeparator(path)
                                                </li>
                                            </ul>
                                            <br>
                                            <b>Input:</b>
                                            <ul>
                                                <li>superb,positive</li>
                                                <li>bad,negative</li>
                                                <li>lack of,revert</li>
                                                <li>very,increment</li>
                                                <li>barely,decrement</li>
                                            </ul>
                                            <br>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">sentiment_detector = SentimentDetector() \
  .setInputCols(["lemma", "sentence"]) \
  .setOutputCol("sentiment")</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>
                                                Scores a sentence for a sentiment<br>
                                                <b>Type:</b> sentiment<br>
                                                <b>Requires:</b> Document, Token<br>
                                                <b>Functions:</b>
                                            <ul>
                                                <li>
                                                    setDictPath(path)
                                                </li>
                                                <li>
                                                    setDictFormat(path)
                                                </li>
                                                <li>
                                                    setDictSeparator(path)
                                                </li>
                                            </ul>
                                            <br>
                                            <b>Input:</b>
                                            <ul>
                                                <li>superb,positive</li>
                                                <li>bad,negative</li>
                                                <li>lack of,revert</li>
                                                <li>very,increment</li>
                                                <li>barely,decrement</li>
                                            </ul>
                                            <br>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val sentimentDetector = new SentimentDetector
  .setInputCols(Array("token", "sentence"))
  .setOutputCol("sentiment")</code></pre>
                                        </div><!--//code-block--></div>
                                </div>

                                <h4 id="NERCRF" class="section-block"> 13. Named Entity Recognition CRF
                                    annotator</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                              This Named Entity recognition annotator allows for a generic model
                                              to be trained by utilizing a CRF machine learning algorithm. Its inputs are either a labeled dataset with an Annotations column or an external CoNLL 2003 IOB based dataset, and optionally
                                              the user can provide both an entities dictionary and a word embeddings file for better accuracy<br>
                                                <b>Type:</b> named_entity<br>
                                                <b>Requires:</b> Document, token, pos<br>
                                                <b>Functions:</b> <br>
                                          <ul>
                                            <li>
                                              setDatasetPath: Path to a CoNLL 2003 IOB NER and POS annotated file (https://www.clips.uantwerpen.be/conll2003/ner). If this is provided. label column is not needed.
                                            </li>
                                            <li>
                                              setLabelColumn: If DatasetPath is not provided, this Seq[Annotation] type of column should have labeled data per token
                                            </li>
                                            <li>
                                              setMinEpochs: Minimum number of epochs to train
                                            </li>
                                            <li>
                                              setMaxEpochs: Maximum number of epochs to train
                                            </li>
                                            <li>
                                              setL2: L2 regularization coefficient for CRF
                                            </li>
                                            <li>
                                              setC0: c0 defines decay speed for gradient
                                            </li>
                                            <li>
                                              setLossEps: If epoch relative improvement lass than this vallue, training is stopped
                                            </li>
                                            <li>
                                              setMinW: Features with less weights than this value will be filtered out
                                            </li>
                                            <li>
                                              setEmbeddingsSource:(path, nDims, format) - sets word embeddings options https://en.wikipedia.org/wiki/Word_embedding.
                                              path - word embeddings file
                                              nDims - number of word embeddings dimentions
                                              format - format of word embeddings files:
                                              1 - spark-nlp format.
                                              2 - text. This format is usually used by Glove https://nlp.stanford.edu/projects/glove/
                                              3 - binary. This format is usually used by Word2Vec https://code.google.com/archive/p/word2vec/
                                            </li>
                                            <li>
                                              setDicts: Array of additional dictionary paths to use as features. A dict .txt files is a line separated file that has something like this: Volvo:ORG
                                            </li>
                                            <li>
                                              setEntities: Array of entities to recognize
                                            </li>
                                            <li>
                                              setVerbose: Verbosity level
                                            </li>
                                            <li>
                                              setRandomSeed: Random seed
                                            </li>
                                          </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">nerTagger = NerCrfApproach()\
  .setInputCols(["sentence", "token", "pos"])\
  .setLabelColumn("label")\
  .setOutputCol("ner")\
  .setMinEpochs(1)\
  .setMaxEpochs(20)\
  .setLossEps(1e-3)\
  .setDicts(["ner-corpus/dict.txt"])\
  .setDatasetPath("eng.train")\
  .setEmbeddingsSource("glove.6B.100d.txt", 100, 2)\
  .setL2(1)\
  .setC0(1250000)\
  .setRandomSeed(0)\
  .setVerbose(2)</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>
                                              This Named Entity recognition annotator allows for a generic model
                                              to be trained by utilizing a CRF machine learning algorithm. Its inputs are either a labeled dataset with an Annotations column or an external CoNLL 2003 IOB based dataset, and optionally
                                              the user can provide both an entities dictionary and a word embeddings file for better accuracy<br>
                                              <b>Type:</b> named_entity<br>
                                              <b>Requires:</b> Document, token, pos<br>
                                                <b>Functions:</b> <br>
                                            <ul>
                                                <li>
                                                  setDatasetPath: Path to a CoNLL 2003 IOB NER and POS annotated file (https://www.clips.uantwerpen.be/conll2003/ner). If this is provided. label column is not needed.
                                                </li>
                                                <li>
                                                  setLabelColumn: If DatasetPath is not provided, this Seq[Annotation] type of column should have labeled data per token
                                                </li>
                                                <li>
                                                  setMinEpochs: Minimum number of epochs to train
                                                </li>
                                                <li>
                                                  setMaxEpochs: Maximum number of epochs to train
                                                </li>
                                                <li>
                                                  setL2: L2 regularization coefficient for CRF
                                                </li>
                                                <li>
                                                  setC0: c0 defines decay speed for gradient
                                                </li>
                                                <li>
                                                  setLossEps: If epoch relative improvement lass than this vallue, training is stopped
                                                </li>
                                                <li>
                                                  setMinW: Features with less weights than this value will be filtered out
                                                </li>
                                                <li>
                                                  setEmbeddingsSource:(path, nDims, format) - sets word embeddings options https://en.wikipedia.org/wiki/Word_embedding.
                                                  path - word embeddings file
                                                  nDims - number of word embeddings dimentions
                                                  format - format of word embeddings files from com.johnsnowlabs.nlp.embeddings.WordEmbeddingsFormat:
                                                  SparkNlp -> For Spark-NLP own embeddings format file
                                                  Text -> This format is usually used by Glove https://nlp.stanford.edu/projects/glove/
                                                  Binary -> This format is usually used by Word2Vec https://code.google.com/archive/p/word2vec/
                                                </li>
                                                <li>
                                                  setDicts: Array of additional dictionary paths to use as features. A dict .txt files is a line separated file that has something like this: Volvo:ORG
                                                </li>
                                                <li>
                                                  setEntities: Array of entities to recognize
                                                </li>
                                                <li>
                                                  setVerbose: Verbosity level
                                                </li>
                                                <li>
                                                  setRandomSeed: Random seed
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">new NerCrfApproach()
  .setInputCols("sentence", "token", "pos")
  .setLabelColumn("label")
  .setMinEpochs(1)
  .setMaxEpochs(3)
  .setDatasetPath("src/test/resources/ner-corpus/test_ner_dataset.txt")
  .setEmbeddingsSource("src/test/resources/ner-corpus/test_embeddings.txt", 3, WordEmbeddingsFormat.Text)
  .setC0(34)
  .setL2(3.0)
  .setOutputCol("ner")
  .fit(df)</code></pre>
                                        </div><!--//code-block--></div>
                                </div>
                                <h4 id="SpellChecker" class="section-block"> 14. SpellChecker: Token spell
                                    corrector</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                This annotator retrieves tokens and makes corrections automatically if
                                                not found
                                                on an english dictionary<br>
                                                <b>Type:</b> Token<br>
                                                <b>Inputs:</b> Any text for corpus. A list of words for dictionary. A
                                                comma
                                                separated custom dictionary.<br>
                                                <b>Requires:</b> Tokenizer<br>
                                                <b>Functions:</b><br>
                                            <ul>
                                                <li>
                                                    setDictPath: path to english words dictionary
                                                </li>
                                                <li>
                                                    setCorpusPath: path to training corpus. Can be any good text.
                                                </li>
                                                <li>
                                                    setCorpusFormat(format): Allowed txt or txtds. The latter uses spark dataframes from text
                                                </li>
                                                <li>
                                                    setSlangPath: path to custom dictionares, separated by comma
                                                </li>
                                                <li>
                                                    setCaseSensitive: defaults to false. Might affect accuracy
                                                </li>
                                                <li>
                                                    setDoubleVariants: enables extra check for word combinations, more
                                                    accuracy
                                                    at performance
                                                </li>
                                                <li>
                                                    setShortCircuit: faster but less accurate mode
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">spell_checker = NorvigSweetingApproach() \
  .setInputCols(["token"]) \
  .setOutputCol("spell") \
  .setCorpusPath("./sherlockholmes.txt")</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>
                                                This annotator retrieves tokens and makes corrections automatically if
                                                not found
                                                on an english dictionary<br>
                                                <b>Type:</b> Token<br>
                                                <b>Inputs:</b> Any text for corpus. A list of words for dictionary. A
                                                comma
                                                separated custom dictionary.<br>
                                                <b>Requires:</b> Tokenizer<br>
                                                <b>Functions:</b><br>
                                            <ul>
                                                <li>
                                                    setDictPath: path to english words dictionary
                                                </li>
                                                <li>
                                                    setCorpusPath: path to training corpus. Can be any good text.
                                                </li>
                                                <li>
                                                    setCorpusFormat(format): Allowed txt or txtds. The latter uses spark dataframes from text
                                                </li>
                                                <li>
                                                    setSlangPath: path to custom dictionares, separated by comma
                                                </li>
                                                <li>
                                                    setCaseSensitive: defaults to false. Might affect accuracy
                                                </li>
                                                <li>
                                                    setDoubleVariants: enables extra check for word combinations, more
                                                    accuracy
                                                    at performance
                                                </li>
                                                <li>
                                                    setShortCircuit: faster but less accurate mode
                                                </li>
                                            </ul>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val spellChecker = new NorvigSweetingApproach()
  .setInputCols(Array("normalized"))
  .setOutputCol("spell")
  .setCorpusPath("./sherlockholmes.txt")</code></pre>
                                        </div><!--//code-block--></div>
                                </div>


                                <h4 id="AssertionStatus" class="section-block"> 15. AssertionStatus: Assertion Status Classifier</h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane" id="python">
                                        <div class="code-block">
                                            <p>
                                                Assigns an assertion status to a target within a sentence. For example, in the sentence "there's no intention to evacuate the area", considering "intention to evacuate the area" as a target, a possible status could be "Negated". This annotator allows you to specify a text, a target, and a set of possible labels describing the assertion status.<br>
                                                <b>Type:</b> assertion<br>
                                                <b>Requires:</b> Document<br>
                                                <b>Functions:</b>
                                            <ul>
                                                <li>
                                                    setLabelCol(name): sets the name of the column that contains the label for the assertion. The set of labels is inferred from the values present in this column.
                                                    You don't need to specify them explicitly.
                                                </li>
                                                <li>
                                                    setInputCol(document): sets the name of the column that contains the text to be analyzed.
                                                </li>
                                                <li>
                                                    setOutputCol(name): this is where the annotations with the label will be after the algorithm runs.
                                                </li>
                                                <li>
                                                    setBefore(n): specifies the number of context tokens before the target term(s) that will be used in the algorithm.
                                                </li>
                                                <li>
                                                    setAfter(m): specifies the number of context tokens after the first token of the target term(s) that will be used in the algorithm.
                                                </li>
                                                <li>
                                                    setEmbeddingsSource(path, size, format): specifies the path to the embeddings file(string), the size of the vectors(integer), and the format of the file(one of the constants Text, Binary, SparkNlp). An example embeddings file is provided in the appropriate python notebook.
                                                </li>
                                            </ul>
                                            <br>
                                            <b>Input:</b> a document as output by the Document Assembler.<br>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">
assertion_status = AssertionStatusApproach() \
.setLabelCol("label") \
      .setInputCols("document") \
      .setOutputCol("assertion") \
      .setBefore(11) \
      .setAfter(13) \
      .setEmbeddingsSource(embeddingsFile, 200, 3)</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane active" id="scala">
                                        <div class="code-block">
                                            <p>
                                                Assigns an assertion status to a target within a sentence. For example, in the sentence "there's no intention to evacuate the area", considering "intention to evacuate the area" as a target, a possible status could be "Negated". This annotator allows you to specify a text, a target, and a set of possible labels describing the assertion status.<br>
                                                <b>Type:</b> assertion<br>
                                                <b>Requires:</b> Document<br>
                                                <b>Functions:</b>
                                            <ul>
                                                <li>
                                                    setLabelCol(name): sets the name of the column that contains the label for the assertion. The set of labels is inferred from the values present in this column.
                                                    You don't need to specify them explicitly.
                                                </li>
                                                <li>
                                                    setInputCol(document): sets the name of the column that contains the text to be analyzed.
                                                </li>
                                                <li>
                                                    setOutputCol(name): this is where the annotations with the label will be after the algorithm runs.
                                                </li>
                                                <li>
                                                    setBefore(n): specifies the number of context tokens before the target term(s) that will be used in the algorithm.
                                                </li>
                                                <li>
                                                    setAfter(m): specifies the number of context tokens after the first token of the target term(s) that will be used in the algorithm.
                                                </li>
                                                <li>
                                                    setEmbeddingsSource(path, size, format): specifies the path to the embeddings file(string), the size of the vectors(integer), and the format of the file(one of the constants Text, Binary, SparkNlp). An example embeddings file is provided in the appropriate python notebook.
                                                </li>
                                            </ul>
                                            <br>
                                            <b>Input:</b> a document as output by the Document Assembler.<br>
                                            <b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">
val assertionStatus = new AssertionStatusApproach() 
.setLabelCol("label") 
      .setInputCols("document") 
      .setOutputCol("assertion") 
      .setBefore(11) 
      .setAfter(13)
      .setEmbeddingsSource(embeddingsFile, 200, WordEmbeddingsFormat.Binary)</code></pre>
                                        </div><!--//code-block-->
                                    </div>
                                </div>

                                <h4 id="Finisher" class="section-block"> 16. Finisher: Getting data out </h4>
                                <ul class="nav nav-tabs" role="tablist">
                                    <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                              role="tab" data-toggle="tab">Python</a>
                                    </li>
                                    <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                               data-toggle="tab">Scala</a></li>
                                </ul>
                                <div class="tab-content">
                                    <div role="tabpanel" class="tab-pane active" id="python">
                                        <div class="code-block">
                                            <p>
                                                Once we have our NLP pipeline ready to go, we might want to use our
                                                annotation results somewhere else where it is easy to use. The Finisher
                                                outputs annotation(s) values into string.
                                                <br><b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">finisher = Finisher() \
  .setInputCols(["sentiment"]) \
  .setIncludeKeys(True)
</code></pre>

                                            <b>Settable parameters are:</b>
                                            <ul>
                                                <li>
                                                    setInputCols()
                                                </li>
                                                <li>
                                                    setOutputCols()
                                                </li>
                                                <li>
                                                    setCleanAnnotations(True) -> Whether to remove intermediate
                                                    annotations
                                                </li>
                                                <li>
                                                    setValueSplitSymbol("#") -> split values within an annotation
                                                    character
                                                </li>
                                                <li>
                                                    setAnnotationSplitSymbol("@") -> split values between annotations
                                                    character
                                                </li>
                                                <li>
                                                    setIncludeKeys(False) -> Whether to include metadata keys. Sometimes
                                                    useful in some annotations
                                                </li>
                                                <li>
                                                  setOutputAsArray(False) -> Whether to output as Array. Useful as input for other Spark transformers.
                                                </li>
                                            </ul>
                                        </div><!--//code-block-->
                                    </div>
                                    <div role="tabpanel" class="tab-pane" id="scala">
                                        <div class="code-block">
                                            <p>


                                                Once we have our NLP pipeline ready to go, we might want to use our
                                                annotation results somewhere else where it is easy to use. The Finisher
                                                outputs annotation(s) values into string.
                                                <br><b>Example:</b><br>
                                            </p>
                                            <pre><code class="language-python">val finisher = new Finisher()
  .setInputCols("token")
</code></pre>

                                            <b>Settable parameters are:</b>
                                            <ul>
                                                <li>
                                                    setInputCols()
                                                </li>
                                                <li>
                                                    setOutputCols()
                                                </li>
                                                <li>
                                                    setCleanAnnotations(true) -> Whether to remove intermediate
                                                    annotations
                                                </li>
                                                <li>
                                                    setValueSplitSymbol("#") -> split values within an annotation
                                                    character
                                                </li>
                                                <li>
                                                    setAnnotationSplitSymbol("@") -> split values between annotations
                                                    character
                                                </li>
                                                <li>
                                                    setIncludeKeys(false) -> Whether to include metadata keys. Sometimes
                                                    useful in some annotations
                                                </li>
                                                <li>
                                                  setOutputAsArray(false) -> Whether to output as Array. Useful as input for other Spark transformers.
                                                </li>
                                            </ul>
                                        </div><!--//code-block--></div>
                                </div>
                              <h4 id="TokenAssembler" class="section-block"> 17. TokenAssembler: Getting data reshaped </h4>
                              <ul class="nav nav-tabs" role="tablist">
                                <li role="presentation" class="active"><a href="#python" aria-controls="home"
                                                                          role="tab" data-toggle="tab">Python</a>
                                </li>
                                <li role="presentation"><a href="#scala" aria-controls="profile" role="tab"
                                                           data-toggle="tab">Scala</a></li>
                              </ul>
                              <div class="tab-content">
                                <div role="tabpanel" class="tab-pane active" id="python">
                                  <div class="code-block">
                                    <p>


                                      This transformer reconstructs a Document type annotation from tokens, usually after these
                                      have been normalized, lemmatized, normalized, spell checked, etc, in order to use this
                                      document annotation in further annotators.
                                      <br><b>Example:</b><br>
                                    </p>
                                    <pre><code class="language-python">token_assembler = TokenAssembler() \
.setInputCols(["normalized"]) \
.setOutputCol("assembled")
</code></pre>

                                    <b>Settable parameters are:</b>
                                    <ul>
                                      <li>
                                        setInputCol()
                                      </li>
                                      <li>
                                        setOutputCol()
                                      </li>
                                    </ul>
                                  </div><!--//code-block-->
                                </div>
                                <div role="tabpanel" class="tab-pane" id="scala">
                                  <div class="code-block">
                                    <p>


                                      This transformer reconstructs a Document type annotation from tokens, usually after these
                                      have been normalized, lemmatized, spell checked, etc, in order to use this
                                      document annotation in further annotators.
                                      <br><b>Example:</b><br>
                                    </p>
                                    <pre><code class="language-python">token_assembler = TokenAssembler()
.setInputCols("normalized")
.setOutputCol("assembled")
</code></pre>

                                    <b>Settable parameters are:</b>
                                    <ul>
                                      <li>
                                        setInputCol()
                                      </li>
                                      <li>
                                        setOutputCol()
                                      </li>
                                    </ul>
                                  </div><!--//code-block--></div>
                              </div>
                            </div>
                        </section>
                    </div>
                </div>
                <div class="doc-sidebar hidden-xs">
                    <nav id="doc-nav">
                        <ul id="doc-menu" class="nav doc-menu" data-spy="affix">
                            <li>
                                <a class="scrollto" href="#code-section">Annotators</a>
                                <ul class="nav doc-sub-menu">
                                    <li><a class="scrollto" href="#DocumentAssembler">Document Assembler</a></li>
                                    <li><a class="scrollto" href="#Tokenizer">Tokenizer</a></li>
                                    <li><a class="scrollto" href="#Normalizer">Normalizer</a></li>
                                    <li><a class="scrollto" href="#Stemmer">Stemmer</a></li>
                                    <li><a class="scrollto" href="#Lemmatizer">Lemmatizer</a></li>
                                    <li><a class="scrollto" href="#RegexMatcher">Regex Matcher</a></li>
                                    <li><a class="scrollto" href="#EntityExtractor">Entity Extractor</a></li>
                                    <li><a class="scrollto" href="#DateMatcher">Date Matcher</a></li>
                                    <li><a class="scrollto" href="#SentenceDetector">Sentence Detector</a></li>
                                    <li><a class="scrollto" href="#POSTagger">Part of Speech Tagger</a></li>
                                    <li><a class="scrollto" href="#ViveknSentimentDetector">Vivekn Sentiment Detector</a></li>
                                    <li><a class="scrollto" href="#SentimentDetector">Rule based Sentiment Detector</a></li>
                                    <li><a class="scrollto" href="#NERCRF">Named Entity Recognition CRF</a></li>
                                    <li><a class="scrollto" href="#SpellChecker">Spell Checker</a></li>
                                    <li><a class="scrollto" href="#AssertionStatus">Assertion Status</a></li>
                                    <li><a class="scrollto" href="#Finisher">Finisher</a></li>

                                </ul><!--//nav-->
                            </li>
                        </ul>
                    </nav>
                </div>
            </div>
        </div>
    </div>
</div>
<footer id="footer" class="footer text-center">
    <div id="includedFooter"></div>
</footer>
<!-- Main Javascript -->
<script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="assets/plugins/prism/prism.js"></script>
<script type="text/javascript" src="assets/plugins/jquery-scrollTo/jquery.scrollTo.min.js"></script>
<script type="text/javascript" src="assets/plugins/lightbox/dist/ekko-lightbox.min.js"></script>
<script type="text/javascript" src="assets/plugins/jquery-match-height/jquery.matchHeight-min.js"></script>
<script type="text/javascript" src="assets/js/main.js"></script>
<script>

    $('.nav-tabs li a').click(function (e) {
        //get selected href
        var href = $(this).attr('href');

        //set all nav tabs to inactive
        $('.nav-tabs li').removeClass('active');

        //get all nav tabs matching the href and set to active
        $('.nav-tabs li a[href="' + href + '"]').closest('li').addClass('active');

        //active tab
        $('.tab-pane').removeClass('active');
        $('.tab-pane' + href).addClass('active');
    })

</script>
</body>
</html>
