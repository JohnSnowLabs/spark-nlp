---
layout: model
title: Glove Embeddings 6B 100
author: John Snow Labs
name: glove_100d
date: 2020-01-22
task: Embeddings
language: en
nav_key: models
edition: Spark NLP 2.4.0
spark_version: 2.4
tags: [open_source, embeddings, en]
supported: true
annotator: WordEmbeddingsModel
article_header:
type: cover
use_language_switcher: "Python-Scala-Java"
---

## Description
GloVe (Global Vectors) is a model for distributed word representation. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity. It outperformed many common Word2vec models on the word analogy task. One benefit of GloVe is that it is the result of directly modeling relationships, instead of getting them as a side effect of training a language model.

{:.btn-box}
[Live Demo](https://demo.johnsnowlabs.com/public/NER_EN/){:.button.button-orange}{:target="_blank"}
[Open in Colab](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_dl.ipynb){:.button.button-orange.button-orange-trans.co.button-icon}{:target="_blank"}
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/glove_100d_en_2.4.0_2.4_1579690104032.zip){:.button.button-orange.button-orange-trans.arr.button-icon}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/public/models/glove_100d_en_2.4.0_2.4_1579690104032.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use 

<div class="tabs-box" markdown="1">

{% include programmingLanguageSelectScalaPythonNLU.html %}

```python
...
embeddings = WordEmbeddingsModel.pretrained("glove_100d", "en") \
.setInputCols("sentence", "token") \
.setOutputCol("embeddings")
nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, embeddings])
pipeline_model = nlp_pipeline.fit(spark.createDataFrame([[""]]).toDF("text"))
result = pipeline_model.transform(spark.createDataFrame([['I love Spark NLP']], ["text"]))
```

```scala
...
val embeddings = WordEmbeddingsModel.pretrained("glove_100d", "en")
.setInputCols("sentence", "token")
.setOutputCol("embeddings")
val pipeline = new Pipeline().setStages(Array(document_assembler, sentence_detector, tokenizer, embeddings))
val data = Seq("I love Spark NLP").toDF("text")
val result = pipeline.fit(data).transform(data)
```

{:.nlu-block}
```python
import nlu

text = ["""I love Spark NLP"""]
glove_df = nlu.load('en.embed.glove.100d').predict(text)
glove_df
```

</div>

{:.h2_title}
## Results
```bash

token  |  glove_embeddings                                  |
-------|----------------------------------------------------|
I	| [0.1941000074148178, 0.22603000700473785, -0.4...] |
love	| [0.13948999345302582, 0.534529983997345, -0.25...] |
Spark	| [0.20353999733924866, 0.6292600035667419, 0.27...] |
NLP	| [0.059436000883579254, 0.18411000072956085, -0...] |
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|glove_100d|
|Type:|word_embeddings|
|Compatibility:|Spark NLP 2.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[sentence, token]|
|Output Labels:|[embeddings]|
|Language:|[en]|
|Dimension:|100|
|Case sensitive:|false|


{:.h2_title}
## Data Source
The model is imported from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)
