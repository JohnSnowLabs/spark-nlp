---
layout: model
title: Word Embeddings for French (word2vec_wiki_1000)
author: John Snow Labs
name: word2vec_wiki_1000
date: 2022-01-26
tags: [fr, open_source]
task: Embeddings
language: fr
edition: Spark NLP 3.4.0
spark_version: 3.0
supported: true
annotator: WordEmbeddingsModel
article_header:
type: cover
use_language_switcher: "Python-Scala-Java"
---

## Description

This French Word2Vec model was trained by [Jean-Philippe Fauconnier](https://fauconnier.github.io/) on a  [French Wikipedia Dump of 2015](https://dumps.wikimedia.org/frwiki/) over a window size of 100 and dimensions of 1000.

## Predicted Entities



{:.btn-box}
<button class="button button-orange" disabled>Live Demo</button>
<button class="button button-orange" disabled>Open in Colab</button>
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/models/word2vec_wiki_1000_fr_3.4.0_3.0_1643203216331.zip){:.button.button-orange.button-orange-trans.arr.button-icon}

## How to use



<div class="tabs-box" markdown="1">
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler()\
.setInputCol("text")\
.setOutputCol("document")

tokenizer = Tokenizer()\
.setInputCols("document")\
.setOutputCol("token")

embeddings = WordEmbeddingsModel.pretrained("word2vec_wiki_1000", "fr")\
.setInputCols(["document", "token"])\
.setOutputCol("embeddings")
```
```scala
val documentAssembler = new DocumentAssembler()
.setInputCol("text")
.setOutputCol("document")

val tokenizer = new Tokenizer()
.setInputCols("document")
.setOutputCol("token")

val embeddings = WordEmbeddingsModel.pretrained("word2vec_wiki_1000", "fr")
.setInputCols(Array("document", "token"))
.setOutputCol("embeddings")
```


{:.nlu-block}
```python
import nlu
nlu.load("fr.embed.word2vec_wiki_1000").predict("""Put your text here.""")
```

</div>

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|word2vec_wiki_1000|
|Type:|embeddings|
|Compatibility:|Spark NLP 3.4.0+|
|License:|Open Source|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[embeddings]|
|Language:|fr|
|Size:|248.8 MB|
|Case sensitive:|false|
|Dimension:|1000|

## References

This model was trained by [Jean-Philippe Fauconnier](https://fauconnier.github.io/) on a [French Wikipedia Dump of 2015](https://dumps.wikimedia.org/frwiki/). [[1]](#1)

<a id="1">[1]</a>
Fauconnier, Jean-Philippe (2015), French Word Embeddings, http://fauconnier.github.io
