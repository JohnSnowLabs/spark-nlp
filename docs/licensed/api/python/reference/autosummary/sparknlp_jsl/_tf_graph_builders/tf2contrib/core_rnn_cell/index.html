
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell &#8212; Spark NLP 4.0.0 documentation</title>
    
  <link href="../../../../../../static/css/theme.css" rel="stylesheet" />
  <link href="../../../../../../static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../../../../static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../../../static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../../../static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../../../../static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../static/basic.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../../static/css/custom.css" />
    
  <link rel="preload" as="script" href="../../../../../../static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../../../../../" id="documentation_options" src="../../../../../../static/documentation_options.js"></script>
    <script src="../../../../../../static/jquery.js"></script>
    <script src="../../../../../../static/underscore.js"></script>
    <script src="../../../../../../static/doctools.js"></script>
    <script src="../../../../../../static/toggleprompt.js"></script>
    <link rel="shortcut icon" href="../../../../../../static/fav.ico"/>
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../../../../index.html">
  <img src="../../../../../../static/logo.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../../../getting_started/index.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../../index.html">
  API Reference
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   <code class="xref py py-mod docutils literal notranslate">
    <span class="pre">
     sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fused_rnn_cell/index.html">
   <code class="xref py py-mod docutils literal notranslate">
    <span class="pre">
     sparknlp_jsl._tf_graph_builders.tf2contrib.fused_rnn_cell
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../gru_ops/index.html">
   <code class="xref py py-mod docutils literal notranslate">
    <span class="pre">
     sparknlp_jsl._tf_graph_builders.tf2contrib.gru_ops
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../lstm_ops/index.html">
   <code class="xref py py-mod docutils literal notranslate">
    <span class="pre">
     sparknlp_jsl._tf_graph_builders.tf2contrib.lstm_ops
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../rnn/index.html">
   <code class="xref py py-mod docutils literal notranslate">
    <span class="pre">
     sparknlp_jsl._tf_graph_builders.tf2contrib.rnn
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../rnn_cell/index.html">
   <code class="xref py py-mod docutils literal notranslate">
    <span class="pre">
     sparknlp_jsl._tf_graph_builders.tf2contrib.rnn_cell
    </span>
   </code>
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-contents">
   Module Contents
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classes">
     Classes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#attributes">
     Attributes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.RNNCell">
       RNNCell
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper">
       EmbeddingWrapper
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.state_size">
         state_size
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.output_size">
         output_size
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.zero_state">
         zero_state
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.call">
         call
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper">
       InputProjectionWrapper
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.state_size">
         state_size
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.output_size">
         output_size
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.zero_state">
         zero_state
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.call">
         call
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper">
       OutputProjectionWrapper
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.state_size">
         state_size
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.output_size">
         output_size
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.zero_state">
         zero_state
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.call">
         call
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="module-sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell">
<span id="sparknlp-jsl-tf-graph-builders-tf2contrib-core-rnn-cell"></span><h1><a class="reference internal" href="#module-sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell" title="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell</span></code></a><a class="headerlink" href="#module-sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell" title="Permalink to this headline">¶</a></h1>
<p>Module implementing RNN Cells that used to be in core.</p>
<p>&#64;&#64;EmbeddingWrapper
&#64;&#64;InputProjectionWrapper
&#64;&#64;OutputProjectionWrapper</p>
<div class="section" id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h3>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper" title="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">EmbeddingWrapper</span></code></a></p></td>
<td><p>Operator adding input embedding to the given cell.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper" title="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">InputProjectionWrapper</span></code></a></p></td>
<td><p>Operator adding an input projection to the given cell.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper" title="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OutputProjectionWrapper</span></code></a></p></td>
<td><p>Operator adding an output projection to the given cell.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="attributes">
<h3>Attributes<a class="headerlink" href="#attributes" title="Permalink to this headline">¶</a></h3>
<table class="longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.RNNCell" title="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.RNNCell"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RNNCell</span></code></a></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<dl class="py data">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.RNNCell">
<span class="sig-name descname"><span class="pre">RNNCell</span></span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#RNNCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.RNNCell" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">EmbeddingWrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cell</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reuse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#EmbeddingWrapper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Operator adding input embedding to the given cell.</p>
<p>Note: in many cases it may be more efficient to not use this wrapper,
but instead concatenate the whole sequence of your inputs in time,
do the embedding on this batch-concatenated sequence, then split it and
feed into your RNN.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.state_size">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">state_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#EmbeddingWrapper.state_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.state_size" title="Permalink to this definition">¶</a></dt>
<dd><p>size(s) of state(s) used by this cell.</p>
<p>It can be represented by an Integer, a TensorShape or a tuple of Integers
or TensorShapes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.output_size">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#EmbeddingWrapper.output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.output_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Integer or TensorShape: size of outputs produced by this cell.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.zero_state">
<span class="sig-name descname"><span class="pre">zero_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#EmbeddingWrapper.zero_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.zero_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Return zero-filled state tensor(s).</p>
<dl>
<dt>Args:</dt><dd><p>batch_size: int, float, or unit Tensor representing the batch size.
dtype: the data type to use for the state.</p>
</dd>
<dt>Returns:</dt><dd><p>If <cite>state_size</cite> is an int or TensorShape, then the return value is a
<cite>N-D</cite> tensor of shape <cite>[batch_size, state_size]</cite> filled with zeros.</p>
<p>If <cite>state_size</cite> is a nested list or tuple, then the return value is
a nested list or tuple (of the same structure) of <cite>2-D</cite> tensors with
the shapes <cite>[batch_size, s]</cite> for each s in <cite>state_size</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#EmbeddingWrapper.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.EmbeddingWrapper.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the cell on embedded inputs.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">InputProjectionWrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cell</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_proj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reuse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#InputProjectionWrapper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Operator adding an input projection to the given cell.</p>
<p>Note: in many cases it may be more efficient to not use this wrapper,
but instead concatenate the whole sequence of your inputs in time,
do the projection on this batch-concatenated sequence, then split it.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.state_size">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">state_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#InputProjectionWrapper.state_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.state_size" title="Permalink to this definition">¶</a></dt>
<dd><p>size(s) of state(s) used by this cell.</p>
<p>It can be represented by an Integer, a TensorShape or a tuple of Integers
or TensorShapes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.output_size">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#InputProjectionWrapper.output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.output_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Integer or TensorShape: size of outputs produced by this cell.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.zero_state">
<span class="sig-name descname"><span class="pre">zero_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#InputProjectionWrapper.zero_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.zero_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Return zero-filled state tensor(s).</p>
<dl>
<dt>Args:</dt><dd><p>batch_size: int, float, or unit Tensor representing the batch size.
dtype: the data type to use for the state.</p>
</dd>
<dt>Returns:</dt><dd><p>If <cite>state_size</cite> is an int or TensorShape, then the return value is a
<cite>N-D</cite> tensor of shape <cite>[batch_size, state_size]</cite> filled with zeros.</p>
<p>If <cite>state_size</cite> is a nested list or tuple, then the return value is
a nested list or tuple (of the same structure) of <cite>2-D</cite> tensors with
the shapes <cite>[batch_size, s]</cite> for each s in <cite>state_size</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#InputProjectionWrapper.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.InputProjectionWrapper.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the input projection and then the cell.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">OutputProjectionWrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cell</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reuse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#OutputProjectionWrapper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Operator adding an output projection to the given cell.</p>
<p>Note: in many cases it may be more efficient to not use this wrapper,
but instead concatenate the whole sequence of your outputs in time,
do the projection on this batch-concatenated sequence, then split it
if needed or directly feed into a softmax.</p>
<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.state_size">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">state_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#OutputProjectionWrapper.state_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.state_size" title="Permalink to this definition">¶</a></dt>
<dd><p>size(s) of state(s) used by this cell.</p>
<p>It can be represented by an Integer, a TensorShape or a tuple of Integers
or TensorShapes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.output_size">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#OutputProjectionWrapper.output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.output_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Integer or TensorShape: size of outputs produced by this cell.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.zero_state">
<span class="sig-name descname"><span class="pre">zero_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#OutputProjectionWrapper.zero_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.zero_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Return zero-filled state tensor(s).</p>
<dl>
<dt>Args:</dt><dd><p>batch_size: int, float, or unit Tensor representing the batch size.
dtype: the data type to use for the state.</p>
</dd>
<dt>Returns:</dt><dd><p>If <cite>state_size</cite> is an int or TensorShape, then the return value is a
<cite>N-D</cite> tensor of shape <cite>[batch_size, state_size]</cite> filled with zeros.</p>
<p>If <cite>state_size</cite> is a nested list or tuple, then the return value is
a nested list or tuple (of the same structure) of <cite>2-D</cite> tensors with
the shapes <cite>[batch_size, s]</cite> for each s in <cite>state_size</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../../../modules/sparknlp_jsl/_tf_graph_builders/tf2contrib/core_rnn_cell.html#OutputProjectionWrapper.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#sparknlp_jsl._tf_graph_builders.tf2contrib.core_rnn_cell.OutputProjectionWrapper.call" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the cell and output projection on inputs, starting from state.</p>
</dd></dl>

</dd></dl>

</div>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../../../../static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, John Snow Labs.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>